,summary,config,name,group,tag
0,"{'test/runtime': 0.9576, 'eval/precision_micro': 1, '_wandb': {'runtime': 8240}, 'train/epoch': 100, 'eval/runtime': 0.4755, 'test/f1_macro': 0.819228896103896, 'eval/precision_macro': 1, 'eval/steps_per_second': 4.206, 'eval/precision_weighted': 1, 'test/precision_weighted': 0.8286450900050643, 'train/loss': 0.0005, 'eval/f1_micro': 1, 'test/accuracy': 0.822429906542056, 'test/recall_weighted': 0.822429906542056, 'eval/samples_per_second': 88.328, 'train/train_steps_per_second': 1.457, 'eval/accuracy': 1, 'train/global_step': 1200, 'train/learning_rate': 5.65282548498716e-07, 'test/f1_weighted': 0.818109904114577, 'eval/loss': 3.290424865554087e-05, 'test/loss': 1.7870416641235352, '_timestamp': 1706783775.9181657, 'test/precision_macro': 0.8205665024630542, 'test/steps_per_second': 4.177, 'train/train_samples_per_second': 46.504, 'test/f1_micro': 0.822429906542056, 'eval/recall_macro': 1, 'eval/recall_weighted': 1, 'eval/recall_micro': 1, 'test/recall_micro': 0.822429906542056, 'test/precision_micro': 0.822429906542056, '_step': 1030, '_runtime': 8241.9244556427, 'train/train_loss': 0.000853156919280688, 'train/total_flos': 1.0306671052844496e+16, 'test/recall_macro': 0.8331501831501831, 'train/train_runtime': 823.5856, 'eval/f1_macro': 1, 'eval/f1_weighted': 1, 'test/samples_per_second': 111.741}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 100, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 8, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 32, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Feb01_08-18-56_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'value'], 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 9, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaModel'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 3.3916952909922963e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",whole-sea-1440,LORA:microsoft/codebert-base,"['no custom weights', 'preprocessed', 'rerun']"
1,"{'test/recall_micro': 0.8504672897196262, '_runtime': 863.0395264625549, 'eval/f1_macro': 1, 'test/f1_macro': 0.8446833523412836, 'eval/precision_micro': 1, 'test/precision_macro': 0.8443235492577598, 'train/train_steps_per_second': 2.796, 'test/samples_per_second': 119.05, 'train/train_samples_per_second': 44.614, '_step': 110, 'train/total_flos': 1011248134414848.0, 'test/recall_weighted': 0.8504672897196262, 'train/train_loss': 0.001616678759455681, 'eval/recall_macro': 1, 'train/global_step': 240, 'eval/precision_macro': 1, 'test/precision_micro': 0.8504672897196262, 'eval/samples_per_second': 106.244, '_timestamp': 1706775530.0466464, 'test/runtime': 0.8988, 'test/accuracy': 0.8504672897196262, 'eval/f1_micro': 1, 'eval/f1_weighted': 1, 'test/f1_weighted': 0.8439947775637291, 'eval/recall_micro': 1, 'eval/recall_weighted': 1, 'eval/loss': 0.00017348516848869622, 'eval/runtime': 0.3953, 'eval/accuracy': 1, 'eval/steps_per_second': 7.589, 'test/steps_per_second': 7.788, 'eval/precision_weighted': 1, 'train/train_runtime': 85.8475, '_wandb': {'runtime': 861}, 'test/loss': 1.5922285318374634, 'test/f1_micro': 0.850467289719626, 'train/epoch': 10, 'test/recall_macro': 0.85625, 'test/precision_weighted': 0.8478606202782296}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 10, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 16, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 16, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Feb01_08-04-31_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['key'], 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 8, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaModel'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 2.508714802981713e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",lemon-elevator-1439,LORA:microsoft/codebert-base,"['no custom weights', 'preprocessed', 'rerun']"
2,"{'eval/accuracy': 1, 'train/train_loss': 0.0008018502604681999, 'test/recall_macro': 0.8523809523809524, '_timestamp': 1706774657.828882, 'eval/runtime': 0.3816, 'test/f1_macro': 0.8365336490115961, 'train/total_flos': 1.0289350131150288e+16, 'eval/precision_macro': 1, 'test/precision_macro': 0.8422227443609023, 'test/precision_weighted': 0.8516003794533061, 'test/samples_per_second': 118.694, 'test/loss': 1.9644170999526975, 'eval/f1_weighted': 1, 'train/train_steps_per_second': 1.458, 'eval/steps_per_second': 5.241, 'test/steps_per_second': 4.437, 'train/global_step': 1200, 'eval/precision_micro': 1, 'test/precision_micro': 0.8411214953271028, 'test/accuracy': 0.8411214953271028, 'test/recall_micro': 0.8411214953271028, 'eval/f1_macro': 1, 'eval/recall_macro': 1, 'eval/recall_micro': 1, 'eval/samples_per_second': 110.061, '_wandb': {'runtime': 8240}, 'train/epoch': 100, 'test/f1_micro': 0.8411214953271028, 'test/f1_weighted': 0.835698119932282, 'train/train_runtime': 823.1575, 'train/loss': 0.0001, 'test/runtime': 0.9015, 'eval/loss': 2.3633536329725757e-05, 'eval/f1_micro': 1, 'train/learning_rate': 2.487328297642208e-06, 'eval/recall_weighted': 1, 'test/recall_weighted': 0.8411214953271028, 'eval/precision_weighted': 1, '_step': 1030, '_runtime': 8241.35057091713, 'train/train_samples_per_second': 46.528}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 100, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 8, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 32, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Feb01_05-47-01_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['dense'], 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 7, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaModel'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.4923969785853248e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",colorful-bush-1438,LORA:microsoft/codebert-base,"['no custom weights', 'preprocessed', 'rerun']"
3,"{'_timestamp': 1706766412.9002829, 'train/epoch': 10, 'eval/f1_micro': 1, 'eval/recall_weighted': 1, 'test/steps_per_second': 4.426, 'train/train_steps_per_second': 1.454, '_runtime': 830.1540188789368, 'eval/runtime': 0.392, 'test/accuracy': 0.822429906542056, 'test/f1_macro': 0.8222977390049819, 'eval/recall_macro': 1, 'eval/steps_per_second': 5.102, 'eval/loss': 0.001824687817133963, 'train/train_loss': 0.02614784240722656, 'test/recall_micro': 0.822429906542056, 'test/recall_weighted': 0.822429906542056, 'eval/samples_per_second': 107.144, 'test/precision_weighted': 0.843476487168076, '_wandb': {'runtime': 828}, 'eval/f1_macro': 1, 'test/f1_weighted': 0.8216614029288588, '_step': 110, 'eval/precision_macro': 1, 'test/loss': 1.2066644430160522, 'train/total_flos': 1030487389507584.0, 'test/recall_macro': 0.8372252747252747, 'eval/precision_micro': 1, 'test/samples_per_second': 118.396, 'eval/precision_weighted': 1, 'test/runtime': 0.9037, 'eval/accuracy': 1, 'eval/f1_weighted': 1, 'eval/recall_micro': 1, 'train/train_runtime': 82.5026, 'test/precision_macro': 0.8306051587301588, 'test/f1_micro': 0.822429906542056, 'train/global_step': 120, 'test/precision_micro': 0.822429906542056, 'train/train_samples_per_second': 46.423}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 10, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 8, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 32, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Feb01_05-33-06_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'value', 'dense'], 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 6, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaModel'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 5.548991474425276e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",eager-firebrand-1437,LORA:microsoft/codebert-base,"['no custom weights', 'preprocessed', 'rerun']"
4,"{'test/runtime': 0.9003, 'eval/f1_macro': 0.9525560224089636, 'test/f1_micro': 0.7102803738317757, 'train/train_runtime': 82.4813, 'eval/precision_micro': 0.9523809523809524, 'test/recall_weighted': 0.7102803738317757, 'eval/precision_weighted': 0.9597069597069596, 'train/epoch': 10, 'eval/runtime': 0.3821, 'eval/accuracy': 0.9523809523809524, 'eval/recall_macro': 0.9494949494949496, 'eval/precision_macro': 0.9615384615384616, 'test/samples_per_second': 118.843, '_wandb': {'runtime': 830}, 'eval/f1_weighted': 0.9530979058289982, 'train/train_samples_per_second': 46.435, 'test/f1_macro': 0.7099689975529841, 'test/f1_weighted': 0.7019557521540756, 'eval/recall_micro': 0.9523809523809524, 'test/precision_macro': 0.733466819221968, 'test/precision_micro': 0.7102803738317757, 'test/accuracy': 0.7102803738317757, 'test/recall_macro': 0.7390713453213453, 'train/global_step': 120, 'eval/loss': 0.21836331486701965, 'train/total_flos': 1032222094921728.0, 'eval/recall_weighted': 0.9523809523809524, 'test/steps_per_second': 4.443, 'eval/samples_per_second': 109.928, '_step': 110, 'train/train_loss': 0.2801885922749837, 'eval/steps_per_second': 5.235, 'train/train_steps_per_second': 1.455, 'test/precision_weighted': 0.7519151393314656, '_runtime': 831.4636082649231, 'test/loss': 0.9637264609336852, '_timestamp': 1706765578.1234522, 'eval/f1_micro': 0.9523809523809524, 'test/recall_micro': 0.7102803738317757}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 10, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 8, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 32, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Feb01_05-19-11_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'dense'], 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 5, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaModel'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.4310656359177292e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",youthful-cosmos-1436,LORA:microsoft/codebert-base,"['no custom weights', 'preprocessed', 'rerun']"
5,"{'train/train_steps_per_second': 2.787, 'train/train_samples_per_second': 44.474, '_timestamp': 1706764742.060254, 'test/f1_macro': 0.8516677539140907, 'eval/recall_micro': 1, 'eval/precision_weighted': 1, 'test/f1_weighted': 0.8481207956118663, 'test/recall_micro': 0.8504672897196262, 'train/learning_rate': 1.2756361192139125e-05, 'train/train_runtime': 861.1748, 'eval/precision_micro': 1, 'eval/samples_per_second': 105.141, 'test/runtime': 0.9015, 'eval/accuracy': 1, 'test/accuracy': 0.8504672897196262, 'train/train_loss': 0.0018468598446149068, 'eval/recall_macro': 1, 'test/precision_micro': 0.8504672897196262, '_wandb': {'runtime': 8646}, 'train/loss': 0, 'eval/f1_micro': 1, 'test/f1_micro': 0.850467289719626, 'test/recall_weighted': 0.8504672897196262, 'train/epoch': 100, 'eval/f1_macro': 1, 'eval/recall_weighted': 1, 'test/precision_macro': 0.8493104638157112, 'train/total_flos': 1.0177264519199232e+16, 'eval/precision_macro': 1, 'test/samples_per_second': 118.696, '_runtime': 8647.775392055511, 'eval/loss': 1.8921253285952844e-05, 'test/loss': 2.4634294509887695, 'eval/f1_weighted': 1, 'eval/runtime': 0.3995, 'train/global_step': 2400, 'eval/steps_per_second': 7.51, 'test/steps_per_second': 7.765, '_step': 1050, 'test/recall_macro': 0.8644001831501831, 'test/precision_weighted': 0.8560955392352778}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 100, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 16, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 16, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Feb01_02-54-56_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['value', 'dense'], 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 4, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaModel'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 7.653816715283475e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",robust-violet-1435,LORA:microsoft/codebert-base,"['no custom weights', 'preprocessed', 'rerun']"
6,"{'test/steps_per_second': 4.446, '_step': 110, 'eval/accuracy': 0.5714285714285714, 'eval/recall_macro': 0.5555555555555556, 'eval/recall_micro': 0.5714285714285714, 'eval/f1_weighted': 0.5543947410614077, 'eval/recall_weighted': 0.5714285714285714, 'test/precision_weighted': 0.5544429609850171, 'train/epoch': 10, 'test/runtime': 0.8998, 'test/accuracy': 0.4299065420560747, 'test/f1_micro': 0.4299065420560747, 'test/precision_micro': 0.4299065420560747, 'test/samples_per_second': 118.918, 'train/train_samples_per_second': 46.237, '_wandb': {'runtime': 829}, '_runtime': 831.1330642700195, 'eval/f1_macro': 0.5457239057239057, 'train/train_runtime': 82.834, 'eval/loss': 1.0025006532669067, 'test/loss': 1.2523387670516968, 'eval/precision_micro': 0.5714285714285714, 'eval/steps_per_second': 5.182, 'test/recall_micro': 0.4299065420560747, 'train/train_steps_per_second': 1.449, 'eval/runtime': 0.386, 'train/train_loss': 1.1215237935384117, 'train/global_step': 120, 'eval/precision_weighted': 0.6595238095238095, 'test/recall_macro': 0.4555257242757243, 'eval/precision_macro': 0.675, '_timestamp': 1706756088.5737422, 'eval/f1_micro': 0.5714285714285714, 'test/f1_weighted': 0.4185883759715535, 'train/total_flos': 1032222094921728.0, 'test/f1_macro': 0.4263973063973064, 'test/precision_macro': 0.5168650793650794, 'test/recall_weighted': 0.4299065420560747, 'eval/samples_per_second': 108.814}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 10, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 8, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 32, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Feb01_02-41-01_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'key', 'dense'], 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 3, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaModel'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.1431175355475987e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",distinctive-donkey-1434,LORA:microsoft/codebert-base,"['no custom weights', 'preprocessed', 'rerun']"
7,"{'train/epoch': 10, 'eval/f1_weighted': 1, 'eval/steps_per_second': 5.231, 'test/precision_weighted': 0.8311582109479305, '_timestamp': 1706755252.9520328, 'test/f1_weighted': 0.8011608398483866, 'train/total_flos': 1067783555911680.0, '_wandb': {'runtime': 837}, 'test/f1_macro': 0.8047295778447152, 'eval/precision_macro': 1, 'eval/recall_weighted': 1, 'test/precision_macro': 0.8168898809523809, 'test/recall_weighted': 0.8037383177570093, 'eval/runtime': 0.3824, 'test/runtime': 0.9047, 'eval/f1_macro': 1, 'train/train_runtime': 83.3613, 'eval/loss': 0.016795024275779724, 'test/f1_micro': 0.8037383177570093, 'train/train_loss': 0.01625876029332479, 'test/samples_per_second': 118.268, 'test/loss': 1.4989826679229736, 'eval/f1_micro': 1, 'eval/recall_micro': 1, 'test/recall_micro': 0.8037383177570093, 'eval/precision_micro': 1, 'test/precision_micro': 0.8037383177570093, 'test/steps_per_second': 4.421, 'train/train_samples_per_second': 45.945, '_step': 110, 'test/accuracy': 0.8037383177570093, 'eval/recall_macro': 1, 'test/recall_macro': 0.8229395604395604, 'train/global_step': 120, 'eval/precision_weighted': 1, '_runtime': 839.3029267787933, 'eval/samples_per_second': 109.844, 'train/train_steps_per_second': 1.44, 'eval/accuracy': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 10, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 16, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 32, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Feb01_02-26-56_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'key'], 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 2, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaModel'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.5288916758011677e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",sunny-thunder-1433,LORA:microsoft/codebert-base,"['no custom weights', 'preprocessed', 'rerun']"
8,"{'eval/f1_weighted': 0.9513888888888888, 'eval/recall_micro': 0.9523809523809524, 'test/recall_micro': 0.7570093457943925, 'train/global_step': 1200, 'eval/precision_weighted': 0.9597069597069596, '_runtime': 4232.56569814682, 'eval/f1_micro': 0.9523809523809524, 'test/steps_per_second': 7.826, 'eval/loss': 0.13080117106437683, 'test/f1_micro': 0.7570093457943925, 'train/total_flos': 5194131213655104.0, 'eval/recall_macro': 0.9444444444444444, 'test/precision_micro': 0.7570093457943925, 'test/loss': 1.2761614322662354, 'eval/runtime': 0.3968, 'test/runtime': 0.8944, 'test/recall_macro': 0.7872252747252747, 'train/epoch': 50, 'train/learning_rate': 1.9501966564919184e-07, 'test/precision_macro': 0.7956709956709958, 'test/precision_weighted': 0.8179552534692722, 'train/train_loss': 0.04153525114059448, 'eval/precision_micro': 0.9523809523809524, 'test/recall_weighted': 0.7570093457943925, 'eval/samples_per_second': 105.844, 'test/samples_per_second': 119.63, '_step': 530, 'train/loss': 0.0397, 'eval/accuracy': 0.9523809523809524, 'test/accuracy': 0.7570093457943925, 'test/f1_macro': 0.757709031132356, 'eval/recall_weighted': 0.9523809523809524, 'eval/steps_per_second': 7.56, 'train/train_steps_per_second': 2.849, '_wandb': {'runtime': 4231}, '_timestamp': 1706754405.421406, 'eval/f1_macro': 0.9479166666666666, 'test/f1_weighted': 0.7497871727727964, 'train/train_runtime': 421.2451, 'eval/precision_macro': 0.9615384615384616, 'train/train_samples_per_second': 45.46}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 50, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 16, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 16, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Feb01_01-16-16_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'value'], 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 1, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaModel'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.1701179938951512e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",deep-water-1432,LORA:microsoft/codebert-base,"['no custom weights', 'preprocessed', 'rerun']"
9,"{'eval/samples_per_second': 106.365, 'eval/f1_macro': 0.9479166666666666, 'test/accuracy': 0.8317757009345794, 'test/f1_weighted': 0.831360765611234, 'test/precision_macro': 0.841048134290626, 'test/runtime': 0.8787, 'test/f1_macro': 0.8322957329384844, 'train/train_runtime': 81.9685, 'train/total_flos': 1042688098755072.0, 'eval/precision_macro': 0.9615384615384616, 'test/recall_weighted': 0.8317757009345794, 'test/recall_micro': 0.8317757009345794, 'test/precision_weighted': 0.8570771072928195, '_runtime': 822.8827517032623, 'eval/loss': 0.09607766568660736, 'train/train_loss': 0.059064205487569174, '_step': 110, 'eval/recall_micro': 0.9523809523809524, 'train/global_step': 240, 'train/epoch': 10, 'eval/precision_micro': 0.9523809523809524, 'eval/steps_per_second': 7.598, 'eval/f1_weighted': 0.9513888888888888, 'eval/recall_macro': 0.9444444444444444, 'test/precision_micro': 0.8317757009345794, '_wandb': {'runtime': 822}, 'test/loss': 1.358364462852478, '_timestamp': 1706750166.5173538, 'test/f1_micro': 0.8317757009345794, 'test/recall_macro': 0.8476419413919414, 'eval/recall_weighted': 0.9523809523809524, 'test/steps_per_second': 7.967, 'eval/precision_weighted': 0.9597069597069596, 'eval/runtime': 0.3949, 'eval/accuracy': 0.9523809523809524, 'eval/f1_micro': 0.9523809523809524, 'test/samples_per_second': 121.778, 'train/train_steps_per_second': 2.928, 'train/train_samples_per_second': 46.725}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 10, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 32, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 16, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Feb01_01-02-26_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'dense'], 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 0, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaModel'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 5.5857287896214495e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",sandy-wood-1431,LORA:microsoft/codebert-base,"['no custom weights', 'preprocessed', 'rerun']"
10,"{'test/precision_micro': 0.8317757009345794, 'train/epoch': 100, 'test/accuracy': 0.8317757009345794, 'test/recall_micro': 0.8317757009345794, 'eval/f1_macro': 1, 'test/f1_micro': 0.8317757009345794, 'eval/recall_micro': 1, 'test/recall_macro': 0.8337454212454214, 'train/global_step': 2400, '_step': 1050, '_wandb': {'runtime': 7818}, 'train/loss': 0.0092, 'eval/precision_macro': 1, 'eval/steps_per_second': 7.766, 'test/samples_per_second': 131.066, '_timestamp': 1706748837.6896627, 'test/f1_macro': 0.8226609890745608, 'test/f1_weighted': 0.8259700503907637, 'eval/recall_macro': 1, 'eval/samples_per_second': 108.719, 'eval/loss': 7.13660047040321e-05, 'eval/accuracy': 1, 'eval/f1_weighted': 1, 'eval/recall_weighted': 1, 'test/recall_weighted': 0.8317757009345794, 'train/total_flos': 9339620557567968.0, 'train/train_loss': 0.012541937430699666, 'eval/precision_micro': 1, 'test/steps_per_second': 8.574, 'eval/precision_weighted': 1, 'eval/f1_micro': 1, 'train/train_runtime': 770.8855, 'test/precision_macro': 0.822311487854251, 'eval/runtime': 0.3863, 'train/train_samples_per_second': 49.683, 'train/learning_rate': 1.1897016421003455e-06, 'test/precision_weighted': 0.8300779919785085, 'train/train_steps_per_second': 3.113, '_runtime': 7820.044015645981, 'test/loss': 1.278769850730896, 'test/runtime': 0.8164}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 100, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 32, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 16, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan31_22-43-41_erc-hpc-comp054', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['value', 'dense'], 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 9, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForMaskedLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 7.138209852602074e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",deft-sunset-1430,LORA:bert-base-uncased,"['no custom weights', 'preprocessed', 'rerun']"
11,"{'eval/precision_micro': 0.2619047619047619, 'test/steps_per_second': 4.724, 'eval/precision_weighted': 0.1960591133004926, 'eval/loss': 1.361600399017334, 'eval/f1_macro': 0.19791666666666669, 'eval/f1_weighted': 0.19464285714285717, 'train/global_step': 120, 'train/total_flos': 1035214813885776.0, 'train/train_runtime': 80.1418, 'test/precision_macro': 0.24998543123543124, '_runtime': 809.1136946678162, 'test/runtime': 0.8468, 'test/f1_macro': 0.22350612815976595, 'test/f1_weighted': 0.24928800836616, 'test/accuracy': 0.2803738317757009, 'eval/steps_per_second': 5.384, 'eval/samples_per_second': 113.059, 'train/train_steps_per_second': 1.497, 'test/loss': 1.3729901313781738, 'test/f1_micro': 0.2803738317757009, 'eval/recall_micro': 0.2619047619047619, 'train/train_samples_per_second': 47.79, '_timestamp': 1706741011.9011776, 'eval/runtime': 0.3715, 'test/recall_micro': 0.2803738317757009, 'test/samples_per_second': 126.354, '_step': 110, 'train/train_loss': 1.37698237101237, 'eval/recall_weighted': 0.2619047619047619, 'test/recall_macro': 0.2613407425907426, 'eval/precision_macro': 0.20229885057471264, '_wandb': {'runtime': 807}, 'train/epoch': 10, 'eval/accuracy': 0.2619047619047619, 'eval/recall_macro': 0.2601010101010101, 'eval/f1_micro': 0.2619047619047619, 'test/precision_micro': 0.2803738317757009, 'test/recall_weighted': 0.2803738317757009, 'test/precision_weighted': 0.2834041348060039}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 10, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 32, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 32, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan31_22-30-06_erc-hpc-comp054', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'key', 'dense'], 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 8, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForMaskedLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.4545619887363105e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",peachy-galaxy-1429,LORA:bert-base-uncased,"['no custom weights', 'preprocessed', 'rerun']"
12,"{'_timestamp': 1706740198.2068653, 'test/runtime': 0.8454, 'eval/recall_macro': 0.5025252525252525, 'test/steps_per_second': 4.731, 'eval/accuracy': 0.5, 'test/f1_macro': 0.39027972027972024, 'eval/f1_weighted': 0.49800497121925696, 'eval/samples_per_second': 113.11, 'eval/loss': 1.2626549005508425, 'eval/recall_weighted': 0.5, 'eval/steps_per_second': 5.386, 'train/epoch': 10, 'eval/recall_micro': 0.5, 'eval/precision_macro': 0.6315126050420168, 'eval/precision_weighted': 0.6275710284113646, 'test/samples_per_second': 126.562, '_step': 110, 'eval/f1_macro': 0.5037774725274726, 'train/global_step': 120, 'train/train_runtime': 80.208, 'test/precision_micro': 0.40186915887850466, 'train/train_steps_per_second': 1.496, '_wandb': {'runtime': 803}, 'eval/f1_micro': 0.5, 'test/precision_macro': 0.4286713286713287, 'test/accuracy': 0.40186915887850466, 'test/f1_micro': 0.40186915887850466, 'train/total_flos': 1035214813885776.0, 'train/train_loss': 1.3171853383382162, 'test/recall_macro': 0.3850545288045288, 'test/recall_micro': 0.40186915887850466, 'eval/precision_micro': 0.5, 'train/train_samples_per_second': 47.751, '_runtime': 804.5375382900238, 'test/loss': 1.314896583557129, 'eval/runtime': 0.3713, 'test/f1_weighted': 0.4070949611136527, 'test/recall_weighted': 0.40186915887850466, 'test/precision_weighted': 0.44169662113587344}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 10, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 32, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 32, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan31_22-16-36_erc-hpc-comp054', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'value', 'key', 'dense'], 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 7, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForMaskedLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 8.443787418667664e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",wild-surf-1428,LORA:bert-base-uncased,"['no custom weights', 'preprocessed', 'rerun']"
13,"{'_step': 110, 'test/steps_per_second': 8.516, 'eval/recall_macro': 1, 'eval/steps_per_second': 7.752, 'eval/runtime': 0.387, 'test/f1_macro': 0.8111772486772486, 'test/f1_micro': 0.822429906542056, 'eval/f1_macro': 1, 'eval/precision_macro': 1, 'test/precision_macro': 0.8117368742368742, 'train/train_runtime': 77.4262, 'eval/precision_micro': 1, 'test/precision_micro': 0.822429906542056, 'eval/samples_per_second': 108.53, 'test/precision_weighted': 0.8159426243538392, 'eval/loss': 0.26915454864501953, 'eval/accuracy': 1, 'test/f1_weighted': 0.8146911931958661, 'train/train_samples_per_second': 49.466, 'train/train_loss': 0.4382607777913411, 'test/recall_macro': 0.8208562271062271, 'train/global_step': 240, 'eval/f1_micro': 1, 'eval/f1_weighted': 1, 'train/total_flos': 925477734827520.0, 'eval/recall_weighted': 1, 'train/train_steps_per_second': 3.1, '_wandb': {'runtime': 781}, 'test/runtime': 0.822, 'test/accuracy': 0.822429906542056, 'test/samples_per_second': 130.17, 'train/epoch': 10, 'test/recall_weighted': 0.822429906542056, 'eval/precision_weighted': 1, 'eval/recall_micro': 1, 'test/recall_micro': 0.822429906542056, '_runtime': 782.5347290039062, 'test/loss': 0.7060085535049438, '_timestamp': 1706739385.241507}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 10, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 8, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 16, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan31_22-03-26_erc-hpc-comp054', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['dense'], 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 6, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForMaskedLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 3.6555167565975553e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",zany-blaze-1427,LORA:bert-base-uncased,"['no custom weights', 'preprocessed', 'rerun']"
14,"{'test/f1_macro': 0.8425143524522406, 'test/recall_weighted': 0.8411214953271028, 'test/recall_macro': 0.8507097069597069, 'eval/recall_weighted': 1, 'test/steps_per_second': 4.572, 'eval/precision_weighted': 1, 'eval/samples_per_second': 105.637, 'test/loss': 1.2313711643218994, 'test/f1_weighted': 0.8400427446111547, 'train/global_step': 600, 'train/train_steps_per_second': 1.452, '_runtime': 4188.327159166336, 'eval/loss': 4.920443825540133e-05, 'test/runtime': 0.8749, 'eval/f1_micro': 1, 'eval/runtime': 0.3976, 'eval/accuracy': 1, 'test/accuracy': 0.8411214953271028, 'train/total_flos': 5412473455307520.0, 'eval/recall_macro': 1, 'test/precision_micro': 0.8411214953271028, '_timestamp': 1706738595.442969, 'train/loss': 0.0023, 'eval/steps_per_second': 5.03, 'test/samples_per_second': 122.294, 'eval/f1_weighted': 1, 'train/train_loss': 0.0020349264641602834, 'train/train_runtime': 413.3598, 'test/precision_macro': 0.838452380952381, 'train/train_samples_per_second': 46.328, 'eval/f1_macro': 1, 'test/f1_micro': 0.8411214953271028, 'test/recall_micro': 0.8411214953271028, 'train/learning_rate': 2.525644952391811e-06, 'eval/precision_micro': 1, 'test/precision_weighted': 0.8436671117044949, 'train/epoch': 50, 'eval/recall_micro': 1, 'eval/precision_macro': 1, '_step': 520, '_wandb': {'runtime': 4186}}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 50, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 64, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 32, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan31_20-53-31_erc-hpc-comp054', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'dense'], 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 5, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForMaskedLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.5153869714350868e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",sleek-elevator-1426,LORA:bert-base-uncased,"['no custom weights', 'preprocessed', 'rerun']"
15,"{'train/train_steps_per_second': 2.982, 'eval/f1_macro': 1, 'eval/f1_micro': 1, 'test/f1_macro': 0.8640962537599124, 'eval/recall_macro': 1, 'eval/recall_weighted': 1, 'eval/samples_per_second': 105.858, 'test/precision_weighted': 0.8658325975533232, 'eval/runtime': 0.3968, 'test/accuracy': 0.8691588785046729, 'train/train_loss': 9.515828181368608e-06, '_timestamp': 1706734402.1759882, 'eval/accuracy': 1, 'test/recall_micro': 0.8691588785046729, 'test/runtime': 0.8476, 'test/precision_micro': 0.8691588785046729, 'test/f1_weighted': 0.8666876225086187, 'train/train_runtime': 80.4801, 'test/precision_macro': 0.8611482471776589, 'eval/recall_micro': 1, 'train/global_step': 240, 'eval/precision_micro': 1, 'test/recall_weighted': 0.8691588785046729, 'eval/steps_per_second': 7.561, '_runtime': 815.9790832996368, 'test/loss': 1.2751563787460327, 'train/total_flos': 989983376524800.0, 'test/samples_per_second': 126.24, 'train/train_samples_per_second': 47.589, 'eval/f1_weighted': 1, 'test/recall_macro': 0.8688644688644689, 'eval/precision_macro': 1, 'eval/precision_weighted': 1, '_step': 110, 'eval/loss': 2.670850108188461e-06, 'train/epoch': 10, '_wandb': {'runtime': 814}, 'test/f1_micro': 0.8691588785046729, 'test/steps_per_second': 8.259}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 10, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 64, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 16, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan31_20-39-51_erc-hpc-comp054', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'value'], 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 4, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForMaskedLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.3143334730793138e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",sunny-frost-1425,LORA:bert-base-uncased,"['no custom weights', 'preprocessed', 'rerun']"
16,"{'eval/f1_macro': 1, 'train/global_step': 1200, 'eval/recall_weighted': 1, 'train/train_steps_per_second': 2.995, 'train/train_samples_per_second': 47.797, '_wandb': {'runtime': 4073}, 'test/loss': 2.247866153717041, 'train/loss': 0.0005, 'train/epoch': 50, 'eval/runtime': 0.3983, 'eval/f1_weighted': 1, 'test/f1_weighted': 0.7940862623087618, 'train/total_flos': 4925239574120880.0, 'test/recall_weighted': 0.8037383177570093, 'test/precision_weighted': 0.795241836029933, 'test/samples_per_second': 126.483, '_runtime': 4075.0584015846257, 'eval/loss': 8.231116055412714e-08, 'test/runtime': 0.846, 'eval/recall_macro': 1, 'eval/precision_macro': 1, '_timestamp': 1706733580.4053416, 'test/f1_macro': 0.7960615461417772, 'test/accuracy': 0.8037383177570093, 'train/train_loss': 0.0018518415197710664, 'train/train_runtime': 400.6495, 'test/precision_macro': 0.8012590389250731, 'eval/steps_per_second': 7.532, 'eval/accuracy': 1, 'eval/f1_micro': 1, 'train/learning_rate': 1.4567146288246792e-05, 'test/precision_micro': 0.8037383177570093, 'test/steps_per_second': 8.275, 'eval/samples_per_second': 105.453, '_step': 530, 'test/f1_micro': 0.8037383177570093, 'test/recall_micro': 0.8037383177570093, 'eval/precision_weighted': 1, 'eval/recall_micro': 1, 'test/recall_macro': 0.8024954212454214, 'eval/precision_micro': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 50, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 64, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 16, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan31_19-31-46_erc-hpc-comp054', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'value', 'dense'], 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 3, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForMaskedLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 8.740287772948076e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",vibrant-firefly-1424,LORA:bert-base-uncased,"['no custom weights', 'preprocessed', 'rerun']"
17,"{'_timestamp': 1706729495.402937, 'eval/accuracy': 1, 'test/f1_weighted': 0.8149585566034556, 'train/train_loss': 0.002965394159158071, 'test/precision_macro': 0.8138009123492995, 'test/recall_weighted': 0.822429906542056, 'test/samples_per_second': 122.184, '_runtime': 8363.002213001251, '_wandb': {'runtime': 8361}, 'eval/loss': 6.745784776285291e-05, 'test/f1_macro': 0.8125660678605149, 'train/learning_rate': 1.936859972065229e-06, 'eval/precision_micro': 1, 'eval/recall_weighted': 1, 'eval/precision_weighted': 1, '_step': 1030, 'eval/f1_weighted': 1, 'eval/recall_micro': 1, 'test/recall_macro': 0.8233287545787547, 'eval/precision_macro': 1, 'test/precision_weighted': 0.8185041247567627, 'eval/f1_micro': 1, 'train/train_steps_per_second': 1.446, 'train/train_samples_per_second': 46.147, 'test/accuracy': 0.822429906542056, 'train/global_step': 1200, 'eval/f1_macro': 1, 'train/loss': 0.0013, 'train/epoch': 100, 'train/total_flos': 1.086709243925424e+16, 'test/recall_micro': 0.822429906542056, 'test/loss': 1.2957093715667725, 'test/f1_micro': 0.822429906542056, 'train/train_runtime': 829.9642, 'eval/steps_per_second': 5.21, 'test/steps_per_second': 4.568, 'test/runtime': 0.8757, 'eval/recall_macro': 1, 'test/precision_micro': 0.822429906542056, 'eval/samples_per_second': 109.409, 'eval/runtime': 0.3839}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 100, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 64, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 32, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan31_17-12-16_erc-hpc-comp054', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['key', 'dense'], 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 2, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForMaskedLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.1621159832391374e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",soft-leaf-1423,LORA:bert-base-uncased,"['no custom weights', 'preprocessed', 'rerun']"
18,"{'_timestamp': 1706721127.4525435, 'test/runtime': 0.8773, 'test/f1_macro': 0.3888199939135727, 'eval/recall_micro': 0.5238095238095238, 'eval/precision_macro': 0.5950892857142858, 'eval/runtime': 0.3858, 'test/f1_micro': 0.3925233644859813, 'train/total_flos': 1096155531900240.0, 'test/recall_micro': 0.3925233644859813, 'eval/recall_weighted': 0.5238095238095238, 'test/samples_per_second': 121.959, 'eval/f1_macro': 0.5308796296296296, 'test/accuracy': 0.3925233644859813, 'train/train_loss': 1.3060929616292318, 'train/train_runtime': 83.6607, 'test/recall_weighted': 0.3925233644859813, '_wandb': {'runtime': 838}, 'eval/loss': 1.2435247898101809, 'eval/recall_macro': 0.5252525252525252, 'test/precision_macro': 0.42205572877079234, 'test/precision_weighted': 0.4354254612239245, 'train/global_step': 120, 'test/steps_per_second': 4.559, 'train/train_steps_per_second': 1.434, '_step': 110, '_runtime': 839.9002206325531, 'test/f1_weighted': 0.40144054925739897, 'test/precision_micro': 0.3925233644859813, 'eval/steps_per_second': 5.184, 'eval/samples_per_second': 108.861, 'train/train_samples_per_second': 45.78, 'test/loss': 1.3065446615219116, 'train/epoch': 10, 'eval/accuracy': 0.5238095238095238, 'eval/f1_weighted': 0.5263977072310405, 'eval/precision_micro': 0.5238095238095238, 'eval/f1_micro': 0.5238095238095238, 'test/recall_macro': 0.3821324508824509, 'eval/precision_weighted': 0.5894132653061225}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 10, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 64, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 32, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan31_16-58-11_erc-hpc-comp054', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['query', 'value', 'key', 'dense'], 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 1, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForMaskedLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 9.01714744413695e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",gentle-lake-1422,LORA:bert-base-uncased,"['no custom weights', 'preprocessed', 'rerun']"
19,"{'eval/accuracy': 1, 'train/train_loss': 0.003697244677847872, 'test/recall_micro': 0.7757009345794392, 'eval/samples_per_second': 118.769, '_wandb': {'runtime': 6289}, 'eval/recall_micro': 1, 'test/steps_per_second': 9.584, 'train/epoch': 100, 'train/total_flos': 8850347211536352.0, 'train/global_step': 2400, 'eval/precision_micro': 1, 'test/precision_micro': 0.7757009345794392, 'eval/precision_weighted': 1, 'train/train_samples_per_second': 61.908, '_step': 1050, 'eval/loss': 4.598069267558458e-07, 'eval/f1_macro': 1, 'eval/f1_micro': 1, 'test/accuracy': 0.7757009345794392, 'test/f1_weighted': 0.7612219696331847, 'train/learning_rate': 1.503544519063469e-05, '_runtime': 6292.15058016777, '_timestamp': 1706720283.504322, 'eval/recall_macro': 1, 'test/recall_macro': 0.7777930402930404, 'train/train_runtime': 618.6558, 'train/loss': 0.0002, 'test/f1_macro': 0.766524024024024, 'eval/precision_macro': 1, 'eval/recall_weighted': 1, 'test/precision_macro': 0.7868818681318682, 'test/precision_weighted': 0.7755853959124988, 'test/loss': 3.766829252243042, 'eval/runtime': 0.3536, 'eval/f1_weighted': 1, 'test/runtime': 0.7304, 'test/f1_micro': 0.7757009345794392, 'test/recall_weighted': 0.7757009345794392, 'eval/steps_per_second': 8.483, 'test/samples_per_second': 146.491, 'train/train_steps_per_second': 3.879}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'epochs': 100, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'lora_rank': 16, 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'batch_size': 16, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan31_15-13-16_erc-hpc-comp054', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': None, 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'lora_modules': ['value', 'key'], 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'trial.number': 0, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForMaskedLM'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 9.021267114380814e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",fanciful-plant-1421,LORA:bert-base-uncased,"['no custom weights', 'preprocessed', 'rerun']"
20,"{'train/learning_rate': 9.080285557866052e-06, 'train/loss': 0, 'test/f1_micro': 0.8411214953271028, 'test/accuracy': 0.8411214953271028, 'eval/precision_macro': 1, 'test/precision_weighted': 0.8413854147951224, '_step': 530, 'eval/loss': 0, 'test/recall_weighted': 0.8411214953271028, 'eval/precision_weighted': 1, 'test/f1_weighted': 0.8379498890051106, 'eval/recall_micro': 1, 'eval/f1_micro': 1, 'train/total_flos': 4917360536253984.0, 'train/train_runtime': 503.9819, 'eval/precision_micro': 1, 'eval/recall_weighted': 1, 'train/train_samples_per_second': 37.997, 'test/loss': 2.718516111373902, 'eval/f1_macro': 1, 'eval/recall_macro': 1, 'test/precision_macro': 0.8401487998262192, 'train/train_steps_per_second': 2.381, 'test/runtime': 0.7875, 'test/f1_macro': 0.8435267611407304, 'test/recall_macro': 0.8539835164835166, 'test/recall_micro': 0.8411214953271028, 'test/samples_per_second': 135.877, '_wandb': {'runtime': 5053}, 'eval/runtime': 0.3814, 'test/precision_micro': 0.8411214953271028, 'test/steps_per_second': 8.889, 'eval/samples_per_second': 110.107, '_runtime': 5053.442204713821, 'train/epoch': 50, 'eval/f1_weighted': 1, 'train/train_loss': 2.228490126299221e-07, 'train/global_step': 1200, 'eval/steps_per_second': 7.865, '_timestamp': 1706024346.9184368, 'eval/accuracy': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models/best', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models/best', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/best/runs/Jan23_14-14-53_erc-hpc-comp035', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 5.448171334719632e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",fresh-deluge-1384,Fine-Tuned LLM:microsoft/codebert-base,"['new_eval', 'no custom weights', 'preprocessed']"
21,"{'eval/recall_macro': 1, 'test/precision_weighted': 0.8960114720862383, 'train/train_samples_per_second': 37.132, 'test/f1_micro': 0.8878504672897196, 'eval/f1_weighted': 1, 'train/global_step': 1200, '_runtime': 5151.667406320572, 'eval/runtime': 0.3562, 'test/runtime': 0.8195, 'train/total_flos': 4917360536253984.0, 'train/train_loss': 3.7666823734146716e-11, 'eval/recall_micro': 1, 'eval/precision_macro': 1, 'train/train_steps_per_second': 2.327, '_step': 530, 'train/epoch': 50, 'eval/f1_micro': 1, 'train/train_runtime': 515.7327, 'test/precision_macro': 0.8873280423280423, 'test/recall_weighted': 0.8878504672897196, 'train/loss': 0, '_timestamp': 1705626598.6838672, 'train/learning_rate': 9.080285557866052e-06, 'eval/precision_micro': 1, 'test/steps_per_second': 8.542, 'eval/samples_per_second': 117.912, 'eval/loss': 0, 'eval/accuracy': 1, 'test/accuracy': 0.8878504672897196, 'test/recall_micro': 0.8878504672897196, 'test/precision_micro': 0.8878504672897196, 'eval/precision_weighted': 1, 'test/loss': 1.846317768096924, 'test/recall_macro': 0.9044642857142856, 'eval/recall_weighted': 1, 'eval/steps_per_second': 8.422, 'test/samples_per_second': 130.568, 'test/f1_weighted': 0.88553575990578, 'eval/f1_macro': 1, 'test/f1_macro': 0.8903430662282452, '_wandb': {'runtime': 5150}}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan18_23-44-08_erc-hpc-comp032', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 5.448171334719632e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",golden-terrain-1356,Fine-Tuned LLM:microsoft/codebert-base,"['new_eval', 'no custom weights', 'preprocessed']"
22,"{'_wandb': {'runtime': 10119}, '_timestamp': 1705621440.1191628, 'eval/precision_micro': 1, 'eval/recall_micro': 1, 'train/loss': 0, 'train/epoch': 100, 'eval/accuracy': 1, 'eval/f1_macro': 1, 'eval/f1_micro': 1, 'test/f1_macro': 0.8903430662282452, 'test/f1_micro': 0.8878504672897196, 'test/recall_weighted': 0.8878504672897196, 'test/precision_weighted': 0.8960114720862383, 'train/train_samples_per_second': 38.355, '_runtime': 10120.989416837692, 'test/loss': 1.8263919353485107, 'eval/runtime': 0.3387, 'eval/recall_macro': 1, 'eval/precision_macro': 1, 'eval/precision_weighted': 1, 'test/samples_per_second': 130.385, 'test/runtime': 0.8206, 'eval/f1_weighted': 1, 'test/recall_macro': 0.9044642857142856, 'train/global_step': 1200, 'train/learning_rate': 8.374323350441229e-07, '_step': 1030, 'train/train_loss': 4.88693954932747e-10, 'test/precision_micro': 0.8878504672897196, 'test/recall_micro': 0.8878504672897196, 'train/train_runtime': 998.5609, 'eval/steps_per_second': 5.905, 'test/steps_per_second': 4.874, 'train/train_steps_per_second': 1.202, 'eval/loss': 0, 'test/accuracy': 0.8878504672897196, 'test/f1_weighted': 0.88553575990578, 'train/total_flos': 1.0060839793314024e+16, 'eval/recall_weighted': 1, 'test/precision_macro': 0.8873280423280423, 'eval/samples_per_second': 123.996}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan18_20-55-23_erc-hpc-comp032', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 5.024594010264738e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",laced-paper-1355,Fine-Tuned LLM:microsoft/codebert-base,"['new_eval', 'no custom weights', 'preprocessed']"
23,"{'eval/steps_per_second': 8.291, 'train/train_samples_per_second': 37.335, '_runtime': 1030.8426089286804, 'test/loss': 1.825527548789978, 'eval/precision_micro': 1, 'test/precision_micro': 0.8878504672897196, 'test/f1_macro': 0.8903430662282452, 'test/f1_micro': 0.8878504672897196, 'eval/f1_weighted': 1, 'eval/recall_micro': 1, 'test/precision_weighted': 0.8960114720862383, 'test/runtime': 0.8137, 'eval/f1_micro': 1, 'eval/recall_macro': 1, 'test/f1_weighted': 0.88553575990578, 'test/recall_micro': 0.8878504672897196, 'eval/precision_weighted': 1, 'eval/loss': 0, 'eval/accuracy': 1, 'test/accuracy': 0.8878504672897196, 'train/train_loss': 7.181531813671427e-10, 'test/recall_macro': 0.9044642857142856, 'test/steps_per_second': 8.603, 'eval/f1_macro': 1, 'train/train_runtime': 102.5856, 'train/train_steps_per_second': 2.34, 'eval/recall_weighted': 1, 'test/samples_per_second': 131.5, 'train/epoch': 10, 'train/global_step': 240, 'eval/precision_macro': 1, 'eval/runtime': 0.3618, 'train/total_flos': 987128183238912.0, 'test/precision_macro': 0.8873280423280423, 'test/recall_weighted': 0.8878504672897196, 'eval/samples_per_second': 116.073, '_step': 110, '_wandb': {'runtime': 1029}, '_timestamp': 1705611313.595113}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan18_20-38-08_erc-hpc-comp032', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 4.2923441855476145e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",fresh-violet-1354,Fine-Tuned LLM:microsoft/codebert-base,"['new_eval', 'no custom weights', 'preprocessed']"
24,"{'eval/f1_micro': 1, 'test/accuracy': 0.8878504672897196, 'eval/recall_weighted': 1, 'eval/precision_weighted': 1, 'test/samples_per_second': 128.283, '_timestamp': 1705610277.0853176, 'eval/precision_macro': 1, 'eval/precision_micro': 1, '_wandb': {'runtime': 5049}, 'eval/runtime': 0.3401, 'test/f1_weighted': 0.88553575990578, 'train/learning_rate': 1.1624773158228228e-05, 'test/precision_macro': 0.8873280423280423, 'test/precision_micro': 0.8878504672897196, '_step': 520, 'train/epoch': 50, 'train/train_loss': 2.2431853115752648e-10, 'eval/recall_macro': 1, 'train/global_step': 600, 'test/steps_per_second': 4.796, '_runtime': 5050.748565673828, 'test/runtime': 0.8341, 'test/recall_micro': 0.8878504672897196, 'train/train_runtime': 499.2963, 'train/loss': 0, 'test/f1_macro': 0.8903430662282452, 'eval/f1_weighted': 1, 'train/train_steps_per_second': 1.202, 'eval/f1_macro': 1, 'train/total_flos': 5029123075033824.0, 'eval/recall_micro': 1, 'eval/steps_per_second': 5.88, 'eval/samples_per_second': 123.478, 'eval/loss': 0, 'eval/accuracy': 1, 'test/f1_micro': 0.8878504672897196, 'test/recall_macro': 0.9044642857142856, 'test/recall_weighted': 0.8878504672897196, 'test/precision_weighted': 0.8960114720862383, 'train/train_samples_per_second': 38.354, 'test/loss': 1.8238590955734253}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan18_19-13-48_erc-hpc-comp032', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 6.974863894936938e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",earnest-sun-1353,Fine-Tuned LLM:microsoft/codebert-base,"['new_eval', 'no custom weights', 'preprocessed']"
25,"{'eval/loss': 0, 'eval/recall_micro': 1, 'train/global_step': 120, 'eval/recall_weighted': 1, 'test/precision_macro': 0.8873280423280423, 'eval/f1_micro': 1, 'test/accuracy': 0.8878504672897196, 'test/f1_macro': 0.8903430662282452, 'test/f1_weighted': 0.88553575990578, 'train/total_flos': 1007601879877632.0, 'train/train_loss': 2.958200677009396e-09, 'test/samples_per_second': 121.021, '_timestamp': 1705605220.9420302, 'eval/runtime': 0.3833, 'test/f1_micro': 0.8878504672897196, 'test/precision_micro': 0.8878504672897196, 'eval/precision_weighted': 1, '_step': 110, '_wandb': {'runtime': 1023}, '_runtime': 1024.845653295517, 'eval/samples_per_second': 109.587, 'test/loss': 1.8102091550827024, 'eval/precision_micro': 1, 'train/epoch': 10, 'eval/recall_macro': 1, 'test/recall_weighted': 0.8878504672897196, 'train/train_samples_per_second': 37.678, 'eval/precision_macro': 1, 'test/runtime': 0.8841, 'eval/accuracy': 1, 'eval/f1_macro': 1, 'eval/f1_weighted': 1, 'test/recall_macro': 0.9044642857142856, 'test/recall_micro': 0.8878504672897196, 'train/train_runtime': 101.6507, 'eval/steps_per_second': 5.218, 'test/steps_per_second': 4.524, 'test/precision_weighted': 0.8960114720862383, 'train/train_steps_per_second': 1.181}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan18_18-56-38_erc-hpc-comp032', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 2.8748857838210947e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",azure-pine-1352,Fine-Tuned LLM:microsoft/codebert-base,"['new_eval', 'no custom weights', 'preprocessed']"
26,"{'eval/samples_per_second': 108.709, 'test/samples_per_second': 124.806, '_wandb': {'runtime': 10083}, '_timestamp': 1705604191.9446888, 'eval/runtime': 0.3864, 'eval/accuracy': 1, 'test/recall_macro': 0.9044642857142856, 'test/precision_macro': 0.8873280423280423, 'eval/steps_per_second': 5.177, 'test/steps_per_second': 4.666, 'train/loss': 0, 'test/accuracy': 0.8878504672897196, 'test/f1_micro': 0.8878504672897196, 'eval/recall_macro': 1, 'eval/recall_micro': 1, 'train/global_step': 1200, 'test/precision_micro': 0.8878504672897196, 'train/train_samples_per_second': 37.462, '_runtime': 10084.904525756836, 'test/runtime': 0.8573, 'eval/f1_macro': 1, 'eval/f1_micro': 1, 'train/train_loss': 2.1810971325327463e-10, 'eval/precision_weighted': 1, 'test/precision_weighted': 0.8960114720862383, '_step': 1030, 'test/f1_macro': 0.8903430662282452, 'test/f1_weighted': 0.88553575990578, 'eval/precision_macro': 1, 'test/recall_weighted': 0.8878504672897196, 'test/recall_micro': 0.8878504672897196, 'train/learning_rate': 1.3342331850073122e-05, 'train/train_runtime': 1022.365, 'eval/precision_micro': 1, 'eval/loss': 0, 'test/loss': 1.8096009492874143, 'train/epoch': 100, 'eval/f1_weighted': 1, 'train/total_flos': 1.0060839793314024e+16, 'eval/recall_weighted': 1, 'train/train_steps_per_second': 1.174}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan18_16-08-28_erc-hpc-comp032', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 8.005399110043874e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",quiet-donkey-1351,Fine-Tuned LLM:microsoft/codebert-base,"['new_eval', 'no custom weights', 'preprocessed']"
27,"{'eval/precision_weighted': 1, 'eval/samples_per_second': 115.106, 'eval/f1_macro': 1, 'test/f1_micro': 0.8878504672897196, 'train/total_flos': 987128183238912.0, 'train/global_step': 240, 'train/train_steps_per_second': 2.342, 'test/f1_macro': 0.8903430662282452, 'eval/f1_weighted': 1, 'test/recall_macro': 0.9044642857142856, 'eval/precision_micro': 1, 'test/recall_weighted': 0.8878504672897196, 'train/train_samples_per_second': 37.368, 'eval/f1_micro': 1, 'eval/recall_micro': 1, 'test/recall_micro': 0.8878504672897196, 'test/precision_micro': 0.8878504672897196, 'test/runtime': 0.8262, 'test/f1_weighted': 0.88553575990578, '_step': 110, '_wandb': {'runtime': 1025}, 'eval/runtime': 0.3649, '_timestamp': 1705594101.9468744, 'eval/accuracy': 1, 'train/train_runtime': 102.4932, 'test/precision_macro': 0.8873280423280423, 'eval/recall_weighted': 1, '_runtime': 1026.8347504138949, 'eval/loss': 0, 'eval/recall_macro': 1, 'eval/precision_macro': 1, 'eval/steps_per_second': 8.222, 'test/steps_per_second': 8.472, 'test/precision_weighted': 0.8960114720862383, 'test/samples_per_second': 129.504, 'test/loss': 1.787523627281189, 'train/epoch': 10, 'test/accuracy': 0.8878504672897196, 'train/train_loss': 8.4274338026565e-09}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan18_15-51-18_erc-hpc-comp032', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 3.166330039387619e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",glorious-terrain-1350,Fine-Tuned LLM:microsoft/codebert-base,"['new_eval', 'no custom weights', 'preprocessed']"
28,"{'test/loss': 1.7851102352142334, 'test/runtime': 0.8323, 'eval/recall_macro': 1, 'test/recall_macro': 0.9044642857142856, 'test/steps_per_second': 8.41, 'train/train_samples_per_second': 37.642, 'eval/accuracy': 1, 'eval/f1_macro': 1, 'test/accuracy': 0.8878504672897196, 'train/total_flos': 4917360536253984.0, 'train/train_runtime': 508.7381, 'test/samples_per_second': 128.552, 'eval/samples_per_second': 120.317, '_runtime': 5106.847406387329, 'train/epoch': 50, 'eval/runtime': 0.3491, 'eval/f1_weighted': 1, 'train/train_loss': 6.771749951894889e-09, 'test/recall_micro': 0.8878504672897196, 'train/learning_rate': 3.015996637573098e-07, 'eval/f1_micro': 1, 'test/f1_micro': 0.8878504672897196, 'test/f1_weighted': 0.88553575990578, 'eval/precision_macro': 1, 'eval/loss': 0, 'test/precision_micro': 0.8878504672897196, 'eval/precision_weighted': 1, 'train/train_steps_per_second': 2.359, '_step': 530, '_wandb': {'runtime': 5105}, 'eval/precision_micro': 1, 'eval/recall_weighted': 1, 'eval/steps_per_second': 8.594, 'test/precision_weighted': 0.8960114720862383, 'test/f1_macro': 0.8903430662282452, 'eval/recall_micro': 1, 'train/global_step': 1200, 'test/precision_macro': 0.8873280423280423, '_timestamp': 1705593069.7231815, 'train/loss': 0, 'test/recall_weighted': 0.8878504672897196}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan18_14-26-08_erc-hpc-comp032', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.809597982543859e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",worthy-snow-1349,Fine-Tuned LLM:microsoft/codebert-base,"['new_eval', 'no custom weights', 'preprocessed']"
29,"{'test/recall_macro': 0.9044642857142856, 'test/f1_macro': 0.8903430662282452, 'train/train_loss': 7.121513097748296e-09, 'eval/recall_micro': 1, 'eval/recall_weighted': 1, 'test/loss': 1.7835510969161987, '_timestamp': 1705587957.65134, 'train/epoch': 10, 'eval/f1_weighted': 1, 'train/global_step': 240, 'train/train_samples_per_second': 37.364, '_runtime': 1025.6742660999298, 'eval/loss': 0, 'eval/recall_macro': 1, 'eval/precision_macro': 1, 'eval/precision_micro': 1, 'test/precision_macro': 0.8873280423280423, 'test/precision_micro': 0.8878504672897196, 'test/steps_per_second': 8.501, '_step': 110, 'eval/f1_micro': 1, 'eval/precision_weighted': 1, 'test/recall_micro': 0.8878504672897196, '_wandb': {'runtime': 1024}, 'test/accuracy': 0.8878504672897196, 'test/runtime': 0.8234, 'eval/samples_per_second': 120.177, 'train/total_flos': 987128183238912.0, 'eval/steps_per_second': 8.584, 'train/train_steps_per_second': 2.341, 'eval/f1_macro': 1, 'test/f1_weighted': 0.88553575990578, 'test/f1_micro': 0.8878504672897196, 'train/train_runtime': 102.5052, 'test/recall_weighted': 0.8878504672897196, 'test/precision_weighted': 0.8960114720862383, 'test/samples_per_second': 129.942, 'eval/runtime': 0.3495, 'eval/accuracy': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan18_14-08-53_erc-hpc-comp032', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.9677940177918867e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",fragrant-bee-1348,Fine-Tuned LLM:microsoft/codebert-base,"['new_eval', 'no custom weights', 'preprocessed']"
30,"{'eval/accuracy': 1, 'eval/f1_macro': 1, 'train/learning_rate': 6.525578658461116e-06, 'train/train_runtime': 1017.275, 'eval/samples_per_second': 119.888, 'eval/runtime': 0.3503, '_runtime': 10213.08109664917, 'test/f1_macro': 0.8903430662282452, 'test/recall_macro': 0.9044642857142856, 'test/recall_weighted': 0.8878504672897196, 'train/train_samples_per_second': 37.65, '_step': 1050, '_timestamp': 1705586924.7922475, 'test/f1_micro': 0.8878504672897196, 'test/f1_weighted': 0.88553575990578, 'eval/precision_macro': 1, 'test/precision_micro': 0.8878504672897196, 'test/loss': 1.762040138244629, 'test/accuracy': 0.8878504672897196, 'train/global_step': 2400, 'test/samples_per_second': 129.431, 'eval/loss': 0, 'eval/recall_micro': 1, 'eval/precision_micro': 1, 'test/precision_macro': 0.8873280423280423, 'test/steps_per_second': 8.467, 'eval/f1_micro': 1, 'train/epoch': 100, 'test/runtime': 0.8267, 'eval/f1_weighted': 1, 'train/train_loss': 1.0975118887775654e-09, 'eval/recall_macro': 1, 'eval/steps_per_second': 8.563, 'test/precision_weighted': 0.8960114720862383, 'train/loss': 0, 'train/train_steps_per_second': 2.359, 'eval/recall_weighted': 1, 'test/recall_micro': 0.8878504672897196, 'train/total_flos': 9832620257451264.0, 'eval/precision_weighted': 1, '_wandb': {'runtime': 10212}}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan18_11-18-33_erc-hpc-comp032', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 3.91534719507667e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",honest-bird-1347,Fine-Tuned LLM:microsoft/codebert-base,"['new_eval', 'no custom weights', 'preprocessed']"
31,"{'test/precision_macro': 0.7843137254901961, 'train/train_loss': 6.208816794028849e-12, 'test/recall_macro': 0.7914835164835166, 'train/learning_rate': 1.151142125308178e-05, 'eval/recall_weighted': 1, 'test/loss': 3.655574321746826, 'test/f1_macro': 0.78077424702283, 'test/recall_micro': 0.7850467289719626, 'test/recall_weighted': 0.7850467289719626, 'train/global_step': 2400, 'eval/precision_macro': 1, 'eval/samples_per_second': 118.567, '_timestamp': 1705543174.671533, 'train/loss': 0, 'test/accuracy': 0.7850467289719626, 'test/f1_micro': 0.7850467289719625, 'test/precision_weighted': 0.7791827011178303, 'test/samples_per_second': 147.983, 'eval/f1_macro': 1, 'train/total_flos': 8789502886240752.0, 'eval/recall_macro': 1, 'test/steps_per_second': 9.681, 'test/precision_micro': 0.7850467289719626, 'train/train_samples_per_second': 42.383, '_wandb': {'runtime': 9149}, '_runtime': 9150.875199317932, 'eval/loss': 0, 'test/f1_weighted': 0.7755730067494176, 'train/epoch': 100, 'test/runtime': 0.7231, 'train/train_steps_per_second': 2.656, 'eval/precision_weighted': 1, 'eval/runtime': 0.3542, 'eval/accuracy': 1, 'eval/f1_micro': 1, 'eval/precision_micro': 1, 'eval/steps_per_second': 8.469, '_step': 1050, 'eval/f1_weighted': 1, 'eval/recall_micro': 1, 'train/train_runtime': 903.666}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan17_23-27-09_erc-hpc-comp039', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 6.906852751849069e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",feasible-frost-1346,Fine-Tuned LLM:bert-base-uncased,"['new_eval', 'no custom weights', 'preprocessed']"
32,"{'eval/recall_micro': 1, 'test/precision_macro': 0.7843137254901961, 'eval/steps_per_second': 5.785, 'test/steps_per_second': 5.348, 'test/accuracy': 0.7850467289719626, 'eval/precision_micro': 1, 'train/train_samples_per_second': 40.292, '_timestamp': 1705534019.2854097, 'train/epoch': 10, 'test/runtime': 0.7479, 'eval/f1_micro': 1, 'eval/f1_weighted': 1, 'train/train_runtime': 95.0554, 'eval/precision_macro': 1, 'eval/samples_per_second': 121.493, 'test/recall_macro': 0.7914835164835166, 'eval/recall_weighted': 1, 'eval/precision_weighted': 1, '_step': 110, 'eval/loss': 0, 'test/f1_micro': 0.7850467289719625, 'train/total_flos': 974239107300264.0, 'eval/runtime': 0.3457, 'train/train_loss': 1.8626450012012203e-10, 'test/samples_per_second': 143.066, 'train/train_steps_per_second': 1.262, '_wandb': {'runtime': 951}, '_runtime': 952.347978591919, 'eval/recall_macro': 1, 'train/global_step': 120, 'test/precision_weighted': 0.7791827011178303, 'eval/accuracy': 1, 'test/f1_macro': 0.78077424702283, 'test/f1_weighted': 0.7755730067494176, 'test/recall_weighted': 0.7850467289719626, 'test/loss': 3.58465838432312, 'eval/f1_macro': 1, 'test/recall_micro': 0.7850467289719626, 'test/precision_micro': 0.7850467289719626}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan17_23-11-09_erc-hpc-comp039', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.1681784023950268e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",rosy-firefly-1345,Fine-Tuned LLM:bert-base-uncased,"['new_eval', 'no custom weights', 'preprocessed']"
33,"{'train/total_flos': 879875613377280.0, 'train/train_loss': 2.7939674277869623e-10, 'eval/precision_macro': 1, '_step': 110, 'eval/loss': 0, 'eval/precision_weighted': 1, 'eval/accuracy': 1, 'eval/recall_weighted': 1, 'test/f1_weighted': 0.7755730067494176, 'train/train_samples_per_second': 42.182, 'test/f1_macro': 0.78077424702283, 'eval/f1_weighted': 1, 'eval/runtime': 0.3545, 'eval/recall_micro': 1, 'test/recall_micro': 0.7850467289719626, 'train/train_runtime': 90.7964, 'eval/precision_micro': 1, 'eval/samples_per_second': 118.473, '_timestamp': 1705533061.5815792, 'train/epoch': 10, 'test/precision_weighted': 0.7791827011178303, 'test/loss': 3.585188150405884, 'test/runtime': 0.7317, 'test/precision_micro': 0.7850467289719626, 'eval/steps_per_second': 8.462, 'train/train_steps_per_second': 2.643, '_wandb': {'runtime': 916}, '_runtime': 917.5963892936708, 'test/samples_per_second': 146.239, 'test/accuracy': 0.7850467289719626, 'test/recall_weighted': 0.7850467289719626, 'test/f1_micro': 0.7850467289719625, 'eval/recall_macro': 1, 'train/global_step': 240, 'test/steps_per_second': 9.567, 'eval/f1_macro': 1, 'eval/f1_micro': 1, 'test/recall_macro': 0.7914835164835166, 'test/precision_macro': 0.7843137254901961}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan17_22-55-49_erc-hpc-comp039', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 7.0000797644425705e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",smooth-plasma-1344,Fine-Tuned LLM:bert-base-uncased,"['new_eval', 'no custom weights', 'preprocessed']"
34,"{'_runtime': 917.4493937492372, 'eval/f1_micro': 1, 'test/recall_macro': 0.7914835164835166, 'test/steps_per_second': 9.594, 'train/train_steps_per_second': 2.643, 'eval/runtime': 0.3464, 'train/global_step': 240, 'train/train_runtime': 90.8039, 'eval/steps_per_second': 8.66, 'eval/loss': 0, 'test/f1_macro': 0.78077424702283, 'test/precision_macro': 0.7843137254901961, '_timestamp': 1705532137.6235878, 'test/f1_micro': 0.7850467289719625, 'eval/precision_micro': 1, 'test/recall_weighted': 0.7850467289719626, 'eval/samples_per_second': 121.235, 'train/epoch': 10, 'test/runtime': 0.7296, 'eval/accuracy': 1, 'eval/f1_macro': 1, 'eval/recall_micro': 1, 'eval/precision_weighted': 1, 'test/precision_weighted': 0.7791827011178303, 'test/samples_per_second': 146.657, 'train/train_samples_per_second': 42.179, '_step': 110, 'test/loss': 3.576197624206543, 'test/f1_weighted': 0.7755730067494176, 'train/total_flos': 879875613377280.0, 'train/train_loss': 3.7252900024024406e-10, 'eval/recall_macro': 1, 'test/recall_micro': 0.7850467289719626, 'eval/precision_macro': 1, 'eval/recall_weighted': 1, '_wandb': {'runtime': 916}, 'test/accuracy': 0.7850467289719626, 'eval/f1_weighted': 1, 'test/precision_micro': 0.7850467289719626}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan17_22-40-24_erc-hpc-comp039', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 5.346440506814257e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",dulcet-sun-1343,Fine-Tuned LLM:bert-base-uncased,"['new_eval', 'no custom weights', 'preprocessed']"
35,"{'_step': 1050, '_runtime': 9146.179871559145, 'eval/f1_macro': 1, 'eval/runtime': 0.3469, 'train/total_flos': 8789502886240752.0, 'test/recall_macro': 0.7914835164835166, 'test/recall_weighted': 0.7850467289719626, 'eval/steps_per_second': 8.648, 'test/steps_per_second': 9.7, 'eval/loss': 0, 'test/loss': 3.5691394805908203, 'eval/accuracy': 1, 'test/f1_weighted': 0.7755730067494176, 'test/precision_micro': 0.7850467289719626, 'eval/precision_weighted': 1, 'train/train_steps_per_second': 2.65, 'train/epoch': 100, 'eval/f1_micro': 1, 'test/f1_macro': 0.78077424702283, 'eval/recall_macro': 1, 'eval/precision_micro': 1, 'test/samples_per_second': 148.267, 'eval/samples_per_second': 121.065, '_wandb': {'runtime': 9144}, 'test/runtime': 0.7217, 'test/f1_micro': 0.7850467289719625, 'train/train_loss': 7.761020492935699e-11, 'eval/recall_micro': 1, 'test/recall_micro': 0.7850467289719626, 'test/accuracy': 0.7850467289719626, 'eval/recall_weighted': 1, 'train/train_samples_per_second': 42.288, '_timestamp': 1705531214.7060285, 'train/loss': 0, 'eval/f1_weighted': 1, 'train/learning_rate': 1.895398581754545e-06, 'train/train_runtime': 905.701, 'eval/precision_macro': 1, 'train/global_step': 2400, 'test/precision_macro': 0.7843137254901961, 'test/precision_weighted': 0.7791827011178303}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan17_20-07-49_erc-hpc-comp039', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.137239149052727e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",lyric-violet-1342,Fine-Tuned LLM:bert-base-uncased,"['new_eval', 'no custom weights', 'preprocessed']"
36,"{'eval/accuracy': 1, 'eval/f1_weighted': 1, 'test/f1_weighted': 0.7755730067494176, 'test/recall_weighted': 0.7850467289719626, 'train/train_steps_per_second': 2.665, 'train/train_samples_per_second': 42.537, 'test/loss': 3.5515270233154297, 'train/loss': 0, 'eval/f1_macro': 1, 'test/f1_macro': 0.78077424702283, 'train/total_flos': 4377445413802968.0, 'train/train_runtime': 450.2004, 'test/samples_per_second': 148.346, '_runtime': 4566.486047029495, 'train/epoch': 50, 'train/global_step': 1200, '_timestamp': 1705522063.92145, 'test/f1_micro': 0.7850467289719625, 'test/recall_micro': 0.7850467289719626, 'eval/samples_per_second': 121.721, 'test/precision_weighted': 0.7791827011178303, 'eval/runtime': 0.3451, 'train/train_loss': 5.608631129897881e-10, 'train/learning_rate': 1.89170152346808e-07, 'test/precision_macro': 0.7843137254901961, '_step': 530, 'eval/recall_micro': 1, 'test/recall_macro': 0.7914835164835166, 'test/precision_micro': 0.7850467289719626, 'test/steps_per_second': 9.705, 'eval/precision_weighted': 1, 'test/runtime': 0.7213, 'eval/f1_micro': 1, 'eval/steps_per_second': 8.694, 'test/accuracy': 0.7850467289719626, 'eval/precision_macro': 1, 'eval/recall_macro': 1, 'eval/precision_micro': 1, 'eval/recall_weighted': 1, '_wandb': {'runtime': 4565}, 'eval/loss': 0}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan17_18-51-39_erc-hpc-comp039', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.135020914080848e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",jolly-sponge-1341,Fine-Tuned LLM:bert-base-uncased,"['new_eval', 'no custom weights', 'preprocessed']"
37,"{'_wandb': {'runtime': 9104}, '_timestamp': 1705517492.1932166, 'eval/accuracy': 1, 'eval/recall_macro': 1, 'train/loss': 0, 'test/runtime': 0.7203, 'test/accuracy': 0.7850467289719626, 'test/f1_macro': 0.78077424702283, 'test/recall_macro': 0.7914835164835166, 'eval/precision_micro': 1, 'test/recall_weighted': 0.7850467289719626, 'test/f1_micro': 0.7850467289719625, 'train/learning_rate': 5.684088707661881e-06, 'test/precision_macro': 0.7843137254901961, 'eval/loss': 0, 'test/steps_per_second': 9.719, 'eval/precision_weighted': 1, 'train/train_steps_per_second': 2.667, 'eval/f1_macro': 1, 'train/train_loss': 5.298190478934354e-11, 'eval/runtime': 0.3449, 'test/f1_weighted': 0.7755730067494176, 'eval/recall_weighted': 1, 'test/precision_micro': 0.7850467289719626, 'test/precision_weighted': 0.7791827011178303, 'train/train_samples_per_second': 42.56, '_step': 1050, 'test/loss': 3.5497384071350098, 'train/epoch': 100, 'eval/precision_macro': 1, 'train/train_runtime': 899.896, '_runtime': 9105.358508586884, 'eval/f1_micro': 1, 'eval/f1_weighted': 1, 'train/total_flos': 8789502886240752.0, 'eval/recall_micro': 1, 'test/recall_micro': 0.7850467289719626, 'train/global_step': 2400, 'eval/steps_per_second': 8.699, 'eval/samples_per_second': 121.791, 'test/samples_per_second': 148.557}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan17_16-19-49_erc-hpc-comp039', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 3.4104532245971286e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",dry-waterfall-1340,Fine-Tuned LLM:bert-base-uncased,"['new_eval', 'no custom weights', 'preprocessed']"
38,"{'eval/f1_weighted': 1, '_wandb': {'runtime': 910}, '_runtime': 911.5817940235138, 'eval/loss': 0, 'train/epoch': 10, 'eval/runtime': 0.3618, 'eval/f1_micro': 1, 'test/accuracy': 0.7850467289719626, 'test/precision_macro': 0.7843137254901961, 'test/precision_micro': 0.7850467289719626, 'test/precision_weighted': 0.7791827011178303, 'train/train_samples_per_second': 42.395, 'test/loss': 3.429201602935791, 'train/total_flos': 879875613377280.0, 'eval/recall_weighted': 1, 'eval/steps_per_second': 8.291, 'test/steps_per_second': 9.675, 'eval/f1_macro': 1, 'test/f1_micro': 0.7850467289719625, 'test/f1_weighted': 0.7755730067494176, 'eval/recall_micro': 1, 'eval/precision_macro': 1, 'eval/precision_micro': 1, 'test/samples_per_second': 147.89, '_step': 110, 'test/runtime': 0.7235, 'train/train_loss': 3.49142463088962e-09, 'train/train_steps_per_second': 2.657, '_timestamp': 1705508381.484926, 'eval/recall_macro': 1, 'test/recall_micro': 0.7850467289719626, 'train/train_runtime': 90.3417, 'eval/precision_weighted': 1, 'eval/samples_per_second': 116.078, 'eval/accuracy': 1, 'test/f1_macro': 0.78077424702283, 'test/recall_macro': 0.7914835164835166, 'train/global_step': 240, 'test/recall_weighted': 0.7850467289719626}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan17_16-04-34_erc-hpc-comp039', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 7.934538604279951e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",iconic-grass-1339,Fine-Tuned LLM:bert-base-uncased,"['new_eval', 'no custom weights', 'preprocessed']"
39,"{'train/loss': 0, 'test/accuracy': 0.7850467289719626, 'test/f1_weighted': 0.7755730067494176, 'train/train_loss': 2.5565116569244614e-06, 'train/train_runtime': 466.3277, 'eval/loss': 0, 'test/recall_micro': 0.7850467289719626, 'test/precision_macro': 0.7843137254901961, 'eval/steps_per_second': 5.974, 'eval/precision_weighted': 1, 'train/total_flos': 4810488250918272.0, '_timestamp': 1705507461.8687203, 'test/runtime': 0.7613, 'eval/f1_weighted': 1, 'train/global_step': 600, '_runtime': 4710.509891271591, 'test/f1_macro': 0.78077424702283, 'test/precision_micro': 0.7850467289719626, 'test/recall_weighted': 0.7850467289719626, 'eval/samples_per_second': 125.46, 'train/train_steps_per_second': 1.287, '_wandb': {'runtime': 4709}, 'test/f1_micro': 0.7850467289719625, 'eval/recall_micro': 1, 'eval/f1_micro': 1, 'test/recall_macro': 0.7914835164835166, 'train/learning_rate': 4.3968364473469775e-06, 'eval/precision_macro': 1, 'eval/recall_weighted': 1, 'test/steps_per_second': 5.254, 'test/samples_per_second': 140.554, '_step': 520, 'train/epoch': 50, 'eval/f1_macro': 1, 'eval/recall_macro': 1, 'train/train_samples_per_second': 41.066, 'test/loss': 3.3851027488708496, 'eval/accuracy': 1, 'eval/precision_micro': 1, 'test/precision_weighted': 0.7791827011178303, 'eval/runtime': 0.3348}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan17_14-45-54_erc-hpc-comp039', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 2.6381018684081867e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",celestial-oath-1338,Fine-Tuned LLM:bert-base-uncased,"['new_eval', 'no custom weights', 'preprocessed']"
40,"{'eval/f1_micro': 0.9761904761904762, 'test/f1_macro': 0.78077424702283, 'test/f1_weighted': 0.7755730067494176, 'train/global_step': 1200, '_timestamp': 1705502745.8817086, 'eval/steps_per_second': 5.68, 'eval/precision_weighted': 0.9785714285714286, 'test/recall_macro': 0.7914835164835166, 'train/train_runtime': 934.9404, 'test/recall_weighted': 0.7850467289719626, 'test/precision_weighted': 0.7791827011178303, 'test/recall_micro': 0.7850467289719626, 'train/learning_rate': 1.6534234948919296e-05, 'eval/precision_micro': 0.9761904761904762, 'test/precision_micro': 0.7850467289719626, '_runtime': 9424.407322645187, 'test/accuracy': 0.7850467289719626, 'eval/f1_weighted': 0.97625014918248, 'train/train_loss': 0.01832714309178603, 'eval/samples_per_second': 119.272, 'eval/recall_macro': 0.9772727272727272, 'train/train_steps_per_second': 1.284, 'train/train_samples_per_second': 40.965, '_wandb': {'runtime': 9423}, 'test/loss': 3.3248467445373535, 'eval/runtime': 0.3521, 'eval/accuracy': 0.9761904761904762, 'eval/f1_macro': 0.974937343358396, 'train/total_flos': 9658434527639664.0, 'eval/recall_micro': 0.9761904761904762, 'test/samples_per_second': 142.544, 'eval/loss': 0.04816126078367233, 'test/runtime': 0.7506, 'eval/precision_macro': 0.975, 'eval/recall_weighted': 0.9761904761904762, 'test/precision_macro': 0.7843137254901961, 'test/steps_per_second': 5.329, '_step': 1030, 'train/loss': 0.0161, 'train/epoch': 100, 'test/f1_micro': 0.7850467289719625}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan17_12-08-44_erc-hpc-comp039', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 9.920540969351578e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",exalted-sponge-1337,Fine-Tuned LLM:bert-base-uncased,"['new_eval', 'no custom weights', 'preprocessed']"
41,"{'_runtime': 297.5437548160553, '_timestamp': 1705493139.6635375, 'eval/recall_micro': 1, 'eval/precision_micro': 1, 'eval/steps_per_second': 8.696, 'eval/samples_per_second': 124.636, '_step': 34, 'train/epoch': 2, 'eval/f1_micro': 1, 'train/train_loss': 0.0007905860741933187, 'train/train_runtime': 90.6324, 'eval/recall_weighted': 1, 'train/train_samples_per_second': 42.148, 'eval/loss': 5.034102650824934e-05, 'train/total_flos': 882619828740000.0, 'eval/recall_macro': 1, 'train/global_step': 48, 'eval/precision_macro': 1, 'train/train_steps_per_second': 2.648, 'eval/runtime': 0.345, 'eval/accuracy': 1, 'eval/f1_macro': 1, 'eval/f1_weighted': 1, 'eval/precision_weighted': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan17_12-00-48_erc-hpc-comp035', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.422891216319351e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",sage-brook-1336,Fine-Tuned LLM:bert-base-uncased,"['new_eval', 'no custom weights', 'preprocessed']"
42,"{'train/loss': 0.0035, 'eval/f1_macro': 1, 'eval/f1_weighted': 1, 'eval/precision_weighted': 1, 'eval/accuracy': 1, 'train/train_samples_per_second': 40.77, 'train/epoch': 50, 'train/train_loss': 0.002972800244266788, 'train/learning_rate': 3.566209438101244e-07, 'test/recall_weighted': 0.8317757009345794, 'eval/recall_weighted': 1, 'test/steps_per_second': 5.331, '_step': 520, '_wandb': {'runtime': 4722}, 'eval/runtime': 0.3451, 'eval/recall_macro': 1, 'test/precision_micro': 0.8317757009345794, 'eval/steps_per_second': 5.795, 'test/precision_weighted': 0.8349503124315357, 'test/samples_per_second': 142.617, 'eval/f1_micro': 1, 'train/total_flos': 4810488250918272.0, 'train/global_step': 600, 'eval/precision_micro': 1, 'eval/precision_macro': 1, 'test/precision_macro': 0.8308885994790622, '_runtime': 4722.411797761917, 'test/runtime': 0.7503, 'test/accuracy': 0.8317757009345794, 'eval/recall_micro': 1, 'eval/samples_per_second': 121.687, 'train/train_steps_per_second': 1.277, 'eval/loss': 0.00011689741222653538, 'test/loss': 1.3383641242980957, 'test/f1_macro': 0.833114878446543, 'test/f1_micro': 0.8317757009345794, 'train/train_runtime': 469.7132, '_timestamp': 1705492838.2436478, 'test/f1_weighted': 0.8296079246608531, 'test/recall_macro': 0.8435668498168498, 'test/recall_micro': 0.8317757009345794}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan17_10-41-58_erc-hpc-comp035', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 2.1397256628607466e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",whole-rain-1334,Fine-Tuned LLM:bert-base-uncased,"['new_eval', 'no custom weights', 'preprocessed']"
43,"{'eval/precision_macro': 1, 'test/latency_in_seconds': 0.007931577981363713, 'eval/f1_micro': 1, 'train/learning_rate': 4.517375809647309e-06, '_wandb': {'runtime': 5107}, 'train/loss': 0, 'eval/recall_micro': 1, 'eval/precision_micro': 1, '_runtime': 5107.704284191132, 'eval/f1_macro': 1, 'eval/f1_weighted': 1, 'train/train_loss': 4.149559342062995e-09, 'test/samples_per_second': 126.07831661614269, '_step': 530, 'train/train_runtime': 509.7653, 'eval/steps_per_second': 8.539, 'eval/loss': 0, 'eval/accuracy': 1, 'eval/precision_weighted': 1, 'eval/samples_per_second': 119.548, 'eval/runtime': 0.3513, 'test/accuracy': 0.6542056074766355, 'train/global_step': 1200, 'train/train_steps_per_second': 2.354, 'train/train_samples_per_second': 37.566, 'train/epoch': 50, 'train/total_flos': 4917360536253984.0, 'eval/recall_macro': 1, 'eval/recall_weighted': 1, 'test/total_time_in_seconds': 0.8486788440059172, '_timestamp': 1705410116.7333453}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan16_11-36-49_erc-hpc-comp039', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 2.7104254857883858e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",helpful-pine-1314,Fine-Tuned LLM:microsoft/codebert-base,"['no custom weights', 'preprocessed']"
44,"{'_timestamp': 1705395932.7258868, 'eval/recall_macro': 1, 'train/learning_rate': 1.5357024965625198e-05, 'eval/precision_macro': 1, 'test/accuracy': 0.6074766355140186, 'train/train_loss': 8.071461684207767e-11, 'train/loss': 0, '_step': 520, '_wandb': {'runtime': 4670}, 'train/epoch': 50, 'eval/runtime': 0.3297, 'train/train_runtime': 461.2968, 'eval/precision_micro': 1, 'eval/steps_per_second': 6.066, 'train/train_samples_per_second': 41.513, 'train/train_steps_per_second': 1.301, 'eval/loss': 0, 'train/global_step': 600, 'eval/recall_weighted': 1, 'eval/precision_weighted': 1, 'eval/samples_per_second': 127.388, 'test/samples_per_second': 140.77986008550334, 'test/total_time_in_seconds': 0.7600518990075216, '_runtime': 4671.929133892059, 'eval/f1_micro': 1, 'eval/f1_weighted': 1, 'train/total_flos': 4810488250918272.0, 'eval/recall_micro': 1, 'test/latency_in_seconds': 0.0071032887757712295, 'eval/accuracy': 1, 'eval/f1_macro': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan16_07-47-43_erc-hpc-comp051', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 9.21421497937512e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",elated-bush-1295,Fine-Tuned LLM:bert-base-uncased,"['no custom weights', 'preprocessed']"
45,"{'train/epoch': 50, 'eval/runtime': 0.3293, 'eval/accuracy': 1, 'test/accuracy': 0.6074766355140186, 'eval/precision_weighted': 1, 'test/samples_per_second': 141.50717835701627, '_wandb': {'runtime': 4671}, 'eval/f1_weighted': 1, 'train/train_runtime': 461.8682, 'eval/precision_macro': 1, 'test/total_time_in_seconds': 0.7561453859962057, 'eval/f1_micro': 1, 'eval/recall_weighted': 1, 'eval/steps_per_second': 6.074, 'test/latency_in_seconds': 0.007066779308375754, 'train/train_samples_per_second': 41.462, '_step': 520, 'eval/recall_macro': 1, 'eval/recall_micro': 1, 'eval/samples_per_second': 127.559, 'train/train_loss': 0.04390045314988432, 'eval/precision_micro': 1, 'eval/f1_macro': 1, 'train/loss': 0.0527, 'eval/loss': 6.062589818611741e-06, 'train/learning_rate': 5.835656435734492e-06, 'train/train_steps_per_second': 1.299, '_runtime': 4673.288024663925, 'train/total_flos': 4810488250918272.0, 'train/global_step': 600, '_timestamp': 1705391255.3841546}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan16_06-29-43_erc-hpc-comp051', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 3.5013938614406954e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",vivid-dew-1294,Fine-Tuned LLM:bert-base-uncased,"['no custom weights', 'preprocessed']"
46,"{'train/learning_rate': 3.0887177484485782e-06, 'eval/precision_weighted': 1, 'train/train_samples_per_second': 43.183, 'train/loss': 0, 'test/latency_in_seconds': 0.007087185971817506, 'test/samples_per_second': 141.09972617856258, 'eval/precision_macro': 1, '_wandb': {'runtime': 4506}, 'train/epoch': 50, 'eval/recall_micro': 1, 'eval/recall_weighted': 1, 'train/train_steps_per_second': 2.706, '_step': 530, 'eval/f1_micro': 1, 'eval/f1_weighted': 1, 'train/global_step': 1200, '_runtime': 4507.647782564163, 'eval/accuracy': 1, 'train/train_loss': 1.6805197677882687e-10, 'eval/runtime': 0.3509, 'eval/samples_per_second': 119.688, 'eval/f1_macro': 1, '_timestamp': 1705386578.0951746, 'train/total_flos': 4377445413802968.0, 'eval/loss': 0, 'eval/recall_macro': 1, 'train/train_runtime': 443.4581, 'eval/precision_micro': 1, 'eval/steps_per_second': 8.549, 'test/total_time_in_seconds': 0.7583288989844732, 'test/accuracy': 0.6074766355140186}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan16_05-14-33_erc-hpc-comp051', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.853230649069147e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",charmed-sea-1293,Fine-Tuned LLM:bert-base-uncased,"['no custom weights', 'preprocessed']"
47,"{'eval/accuracy': 1, 'eval/f1_macro': 1, 'test/latency_in_seconds': 0.007096860532770717, '_wandb': {'runtime': 9008}, 'eval/recall_micro': 1, '_runtime': 9010.122846841812, 'test/total_time_in_seconds': 0.7593640770064667, 'train/total_flos': 8789502886240752.0, 'eval/recall_weighted': 1, 'eval/precision_weighted': 1, 'eval/runtime': 0.3654, 'eval/recall_macro': 1, 'eval/precision_micro': 1, 'eval/steps_per_second': 8.21, 'train/learning_rate': 4.778720901733864e-06, 'eval/precision_macro': 1, 'train/train_steps_per_second': 2.699, '_step': 1050, 'eval/loss': 5.875307351743686e-07, '_timestamp': 1705382065.352044, 'train/train_loss': 0.013345122467933427, 'train/train_runtime': 889.209, 'eval/samples_per_second': 114.941, 'test/samples_per_second': 140.90737663257778, 'train/train_samples_per_second': 43.072, 'train/loss': 0.0636, 'train/epoch': 100, 'eval/f1_micro': 1, 'test/accuracy': 0.6074766355140186, 'eval/f1_weighted': 1, 'train/global_step': 2400}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan16_02-44-18_erc-hpc-comp051', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 2.8672325410403186e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",quiet-bush-1292,Fine-Tuned LLM:bert-base-uncased,"['no custom weights', 'preprocessed']"
48,"{'train/epoch': 10, 'train/train_steps_per_second': 2.67, '_timestamp': 1705373048.2946715, 'eval/f1_micro': 1, 'train/train_loss': 6.539953763725256e-10, 'eval/recall_macro': 1, 'eval/precision_micro': 1, 'test/samples_per_second': 141.4194639032594, 'eval/recall_weighted': 1, 'eval/precision_weighted': 1, 'eval/samples_per_second': 122.585, 'train/train_samples_per_second': 42.607, 'eval/recall_micro': 1, 'train/global_step': 240, '_step': 110, '_wandb': {'runtime': 904}, 'eval/loss': 0, 'train/train_runtime': 89.8907, 'test/latency_in_seconds': 0.007071162429834046, 'test/total_time_in_seconds': 0.7566143799922429, 'test/accuracy': 0.6074766355140186, 'eval/precision_macro': 1, 'eval/runtime': 0.3426, 'eval/accuracy': 1, 'eval/f1_weighted': 1, 'train/total_flos': 879875613377280.0, '_runtime': 906.0143206119536, 'eval/f1_macro': 1, 'eval/steps_per_second': 8.756}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan16_02-29-03_erc-hpc-comp051', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 2.49357002559908e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",hearty-river-1291,Fine-Tuned LLM:bert-base-uncased,"['no custom weights', 'preprocessed']"
49,"{'train/train_loss': 3.0464594254671807e-10, 'eval/f1_macro': 1, 'train/learning_rate': 2.538242004253466e-06, '_runtime': 4538.299600124359, 'eval/f1_micro': 1, 'eval/recall_weighted': 1, 'test/samples_per_second': 139.96323736518667, 'train/train_steps_per_second': 2.689, 'train/train_samples_per_second': 42.908, 'eval/accuracy': 1, 'eval/steps_per_second': 8.772, 'eval/recall_macro': 1, 'train/loss': 0, 'train/epoch': 50, 'test/accuracy': 0.6074766355140186, 'train/global_step': 1200, '_wandb': {'runtime': 4536}, 'train/total_flos': 4377445413802968.0, 'train/train_runtime': 446.3035, 'eval/precision_macro': 1, 'test/total_time_in_seconds': 0.7644864609756041, '_step': 530, 'eval/f1_weighted': 1, 'eval/precision_weighted': 1, 'test/latency_in_seconds': 0.007144733280145833, 'eval/runtime': 0.342, '_timestamp': 1705372137.7616842, 'eval/recall_micro': 1, 'eval/precision_micro': 1, 'eval/samples_per_second': 122.803, 'eval/loss': 0}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan16_01-13-23_erc-hpc-comp051', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.5229452025520795e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",volcanic-firebrand-1290,Fine-Tuned LLM:bert-base-uncased,"['no custom weights', 'preprocessed']"
50,"{'train/train_steps_per_second': 2.677, 'eval/loss': 1.384596824645996, 'eval/accuracy': 0.2619047619047619, 'eval/f1_macro': 0.10377358490566038, 'train/loss': 1.4217, 'eval/f1_micro': 0.2619047619047619, 'eval/recall_micro': 0.2619047619047619, 'train/learning_rate': 1.666554035250256e-05, 'eval/samples_per_second': 113.682, 'test/latency_in_seconds': 0.007235295392483665, 'test/total_time_in_seconds': 0.7741766069957521, '_runtime': 9149.604887008669, 'eval/recall_macro': 0.25, '_wandb': {'runtime': 9148}, 'eval/precision_macro': 0.06547619047619048, 'eval/precision_micro': 0.2619047619047619, 'eval/recall_weighted': 0.2619047619047619, 'eval/steps_per_second': 8.12, '_step': 1050, 'test/accuracy': 0.6074766355140186, 'eval/f1_weighted': 0.10871518418688232, 'train/total_flos': 8789502886240752.0, 'train/train_loss': 0.6735713704803752, 'train/global_step': 2400, 'train/train_runtime': 896.6365, 'eval/precision_weighted': 0.06859410430839002, 'train/train_samples_per_second': 42.715, 'train/epoch': 100, '_timestamp': 1705367594.367672, 'eval/runtime': 0.3695, 'test/samples_per_second': 138.21135776140432}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan15_22-40-48_erc-hpc-comp051', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 9.999324211501538e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",hearty-field-1289,Fine-Tuned LLM:bert-base-uncased,"['no custom weights', 'preprocessed']"
51,"{'train/train_runtime': 935.1497, 'train/train_samples_per_second': 40.956, 'train/total_flos': 9658434527639664.0, '_runtime': 9434.088194847109, 'eval/runtime': 0.3461, 'eval/accuracy': 1, 'eval/precision_macro': 1, 'eval/samples_per_second': 121.335, '_step': 1030, 'eval/loss': 0, 'train/epoch': 100, 'eval/f1_micro': 1, 'test/accuracy': 0.6074766355140186, 'eval/f1_weighted': 1, 'train/train_loss': 1.9910578619904606e-08, '_wandb': {'runtime': 9432}, 'train/loss': 0, 'eval/recall_weighted': 1, '_timestamp': 1705358436.5288718, 'test/total_time_in_seconds': 0.7639333530096337, 'test/latency_in_seconds': 0.007139564046819006, 'eval/precision_micro': 1, 'test/samples_per_second': 140.06457445333018, 'train/global_step': 1200, 'eval/recall_macro': 1, 'eval/recall_micro': 1, 'eval/precision_weighted': 1, 'eval/f1_macro': 1, 'eval/steps_per_second': 5.778, 'train/train_steps_per_second': 1.283, 'train/learning_rate': 3.5884364371143746e-07}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan15_20-03-23_erc-hpc-comp051', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 2.1530618622686248e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",vivid-shape-1288,Fine-Tuned LLM:bert-base-uncased,"['no custom weights', 'preprocessed']"
52,"{'test/samples_per_second': 139.00476065174684, 'eval/accuracy': 1, 'eval/f1_micro': 1, 'test/accuracy': 0.616822429906542, 'eval/steps_per_second': 8.542, 'test/total_time_in_seconds': 0.7697578090010211, 'eval/runtime': 0.3512, 'eval/precision_macro': 1, 'train/train_samples_per_second': 42.716, 'train/epoch': 50, 'eval/f1_weighted': 1, 'eval/recall_weighted': 1, '_step': 530, 'eval/f1_macro': 1, 'eval/recall_macro': 1, 'eval/recall_micro': 1, 'train/learning_rate': 5.370360459413592e-07, 'test/latency_in_seconds': 0.007193998214962814, 'train/train_steps_per_second': 2.677, '_timestamp': 1705348996.5779183, 'train/train_loss': 4.7240821080170774e-08, 'train/global_step': 1200, 'eval/precision_weighted': 1, 'train/total_flos': 4377445413802968.0, '_runtime': 4584.09325838089, 'train/loss': 0, 'eval/samples_per_second': 119.588, '_wandb': {'runtime': 4582}, 'train/train_runtime': 448.3063, 'eval/precision_micro': 1, 'eval/loss': 0}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan15_18-46-53_erc-hpc-comp051', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 3.2222162756481552e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",pretty-smoke-1287,Fine-Tuned LLM:bert-base-uncased,"['no custom weights', 'preprocessed']"
53,"{'train/total_flos': 9658434527639664.0, 'eval/precision_micro': 1, 'test/latency_in_seconds': 0.007193236000059069, 'test/total_time_in_seconds': 0.7696762520063203, 'train/train_steps_per_second': 1.283, 'train/train_samples_per_second': 40.938, '_wandb': {'runtime': 9687}, 'eval/f1_weighted': 1, 'eval/recall_macro': 1, 'train/global_step': 1200, 'test/samples_per_second': 139.01948997527515, 'eval/loss': 2.4068895072559826e-06, '_timestamp': 1705344408.520514, 'eval/f1_micro': 1, 'eval/recall_micro': 1, 'eval/runtime': 0.3409, 'train/learning_rate': 6.878988075782553e-07, 'train/train_runtime': 935.5725, 'eval/f1_macro': 1, 'eval/precision_macro': 1, 'eval/samples_per_second': 123.192, 'eval/precision_weighted': 1, '_step': 1030, '_runtime': 9687.40994501114, 'train/epoch': 100, 'eval/accuracy': 1, 'test/accuracy': 0.6355140186915887, 'eval/recall_weighted': 1, 'train/loss': 0.0013, 'train/train_loss': 0.0018796347081661223, 'eval/steps_per_second': 5.866}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan15_16-05-23_erc-hpc-comp051', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 4.127392845469532e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",blooming-forest-1286,Fine-Tuned LLM:bert-base-uncased,"['no custom weights', 'preprocessed']"
54,"{'eval/loss': 0, 'test/accuracy': 0.5607476635514018, 'eval/steps_per_second': 6.019, 'test/total_time_in_seconds': 0.7939535169862211, 'eval/recall_macro': 1, 'eval/precision_macro': 1, 'test/samples_per_second': 134.7685950257677, '_step': 110, '_wandb': {'runtime': 949}, 'eval/runtime': 0.3323, 'eval/f1_weighted': 1, 'eval/recall_micro': 1, 'train/train_runtime': 94.8593, 'train/train_steps_per_second': 1.265, 'eval/f1_macro': 1, 'eval/f1_micro': 1, 'eval/precision_weighted': 1, 'test/latency_in_seconds': 0.0074201263269740286, 'eval/samples_per_second': 126.394, '_runtime': 951.3786668777466, '_timestamp': 1704685843.328158, 'eval/accuracy': 1, 'train/total_flos': 974239107300264.0, 'train/train_loss': 1.5522041429960606e-10, 'eval/precision_micro': 1, 'train/epoch': 10, 'train/global_step': 120, 'eval/recall_weighted': 1, 'train/train_samples_per_second': 40.376}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan08_03-34-54_erc-hpc-comp036', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.202847813107891e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",major-vortex-1284,Fine-Tuned LLM:bert-base-uncased,['preprocessed']
55,"{'_wandb': {'runtime': 4582}, '_runtime': 4583.71542930603, '_timestamp': 1704684888.3625274, 'eval/samples_per_second': 121.226, 'test/latency_in_seconds': 0.007309077878778573, 'train/epoch': 50, 'eval/runtime': 0.3465, '_step': 530, 'eval/f1_weighted': 1, 'train/global_step': 1200, 'eval/steps_per_second': 8.659, 'eval/accuracy': 1, 'train/total_flos': 4377445413802968.0, 'eval/recall_weighted': 1, 'eval/precision_weighted': 1, 'train/loss': 0, 'eval/f1_macro': 1, 'train/train_runtime': 451.4382, 'eval/precision_macro': 1, 'train/train_samples_per_second': 42.42, 'test/accuracy': 0.5607476635514018, 'eval/recall_micro': 1, 'eval/precision_micro': 1, 'test/samples_per_second': 136.81616430759811, 'test/total_time_in_seconds': 0.7820713330293074, 'train/train_steps_per_second': 2.658, 'eval/loss': 0, 'eval/f1_micro': 1, 'train/train_loss': 1.3659396872848598e-10, 'eval/recall_macro': 1, 'train/learning_rate': 1.993336505790721e-07}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan08_02-18-27_erc-hpc-comp036', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.1960019034744326e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",silver-monkey-1283,Fine-Tuned LLM:bert-base-uncased,['preprocessed']
56,"{'_timestamp': 1704680299.8865988, 'eval/f1_macro': 1, 'eval/recall_macro': 1, 'train/epoch': 50, 'eval/runtime': 0.3453, 'eval/accuracy': 1, 'eval/f1_micro': 1, 'eval/steps_per_second': 8.688, 'eval/samples_per_second': 121.637, '_wandb': {'runtime': 4587}, 'eval/loss': 0, 'train/total_flos': 4377445413802968.0, 'train/train_runtime': 451.312, 'train/global_step': 1200, 'eval/recall_weighted': 1, 'train/loss': 0, 'eval/f1_weighted': 1, 'train/train_samples_per_second': 42.432, 'train/train_steps_per_second': 2.659, '_runtime': 4589.46507191658, 'test/accuracy': 0.5607476635514018, 'train/train_loss': 1.8626450012012204e-11, 'test/total_time_in_seconds': 0.7802982809953392, 'train/learning_rate': 9.984111892928648e-06, 'eval/precision_macro': 1, 'test/samples_per_second': 137.12704821483405, 'test/latency_in_seconds': 0.007292507299021861, '_step': 530, 'eval/recall_micro': 1, 'eval/precision_micro': 1, 'eval/precision_weighted': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan08_01-01-52_erc-hpc-comp036', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 5.990467135757189e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",lucky-aardvark-1282,Fine-Tuned LLM:bert-base-uncased,['preprocessed']
57,"{'eval/precision_micro': 0.2619047619047619, 'test/latency_in_seconds': 0.007312570887870182, 'eval/loss': 1.383790373802185, '_timestamp': 1704675703.9446418, 'eval/recall_macro': 0.25, 'test/samples_per_second': 136.75081108051376, 'train/train_steps_per_second': 1.277, 'eval/runtime': 0.3385, 'train/total_flos': 9658434527639664.0, 'train/learning_rate': 1.2238208299528026e-05, 'test/accuracy': 0.5794392523364486, 'train/train_samples_per_second': 40.764, 'train/loss': 1.4106, 'train/train_runtime': 939.5553, 'eval/precision_weighted': 0.06859410430839002, 'eval/precision_macro': 0.06547619047619048, 'eval/recall_weighted': 0.2619047619047619, 'eval/steps_per_second': 5.908, 'train/train_loss': 1.1076919809977213, 'train/global_step': 1200, '_step': 1030, '_runtime': 9462.378722906113, 'eval/f1_micro': 0.2619047619047619, 'eval/f1_weighted': 0.10871518418688232, 'eval/recall_micro': 0.2619047619047619, 'eval/f1_macro': 0.10377358490566038, 'eval/samples_per_second': 124.064, 'test/total_time_in_seconds': 0.7824450850021094, '_wandb': {'runtime': 9461}, 'train/epoch': 100, 'eval/accuracy': 0.2619047619047619}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_22-24-03_erc-hpc-comp036', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 7.342924979716816e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",curious-shadow-1281,Fine-Tuned LLM:bert-base-uncased,['preprocessed']
58,"{'eval/runtime': 0.3359, 'eval/f1_macro': 1, 'eval/precision_macro': 1, 'eval/recall_weighted': 1, '_timestamp': 1704666236.2954226, 'train/train_steps_per_second': 1.264, 'train/total_flos': 974239107300264.0, '_step': 110, '_wandb': {'runtime': 950}, 'train/epoch': 10, 'eval/f1_micro': 1, 'train/train_loss': 2.0208697530203307e-09, 'eval/recall_macro': 1, 'train/global_step': 120, 'eval/samples_per_second': 125.048, 'test/latency_in_seconds': 0.007212447542174954, 'test/samples_per_second': 138.64918866341517, 'train/train_samples_per_second': 40.341, 'eval/accuracy': 1, 'train/train_runtime': 94.9399, 'eval/precision_micro': 1, 'test/accuracy': 0.5607476635514018, 'eval/f1_weighted': 1, 'eval/steps_per_second': 5.955, 'eval/precision_weighted': 1, '_runtime': 951.8057215213776, 'eval/loss': 0, 'eval/recall_micro': 1, 'test/total_time_in_seconds': 0.7717318870127201}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_22-08-06_erc-hpc-comp036', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 6.785238563403128e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",clean-salad-1280,Fine-Tuned LLM:bert-base-uncased,['preprocessed']
59,"{'test/latency_in_seconds': 0.007221766009330576, '_step': 520, 'train/train_loss': 7.71896110733176e-10, 'eval/precision_micro': 1, 'eval/steps_per_second': 5.905, 'eval/runtime': 0.3387, 'train/train_steps_per_second': 1.282, 'eval/loss': 0, 'eval/recall_micro': 1, 'train/learning_rate': 3.0447395618024054e-06, 'eval/accuracy': 1, 'eval/f1_macro': 1, 'train/loss': 0, 'test/accuracy': 0.5607476635514018, 'eval/precision_macro': 1, 'train/global_step': 600, 'eval/precision_weighted': 1, 'test/samples_per_second': 138.4702853440547, '_wandb': {'runtime': 4733}, 'eval/f1_micro': 1, 'eval/f1_weighted': 1, 'eval/recall_macro': 1, 'eval/recall_weighted': 1, 'eval/samples_per_second': 124.012, 'train/train_samples_per_second': 40.911, '_runtime': 4734.541317939758, '_timestamp': 1704665278.654387, 'train/epoch': 50, 'train/train_runtime': 468.0927, 'train/total_flos': 4810488250918272.0, 'test/total_time_in_seconds': 0.7727289629983716}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_20-49-06_erc-hpc-comp036', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.8268437370814433e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",curious-donkey-1279,Fine-Tuned LLM:bert-base-uncased,['preprocessed']
60,"{'eval/recall_macro': 0.5068181818181818, 'eval/recall_micro': 0.5116279069767442, 'eval/precision_macro': 0.4946428571428571, 'eval/precision_micro': 0.5116279069767442, 'eval/f1_weighted': 0.48962185642416334, 'eval/recall_weighted': 0.5116279069767442, '_runtime': 421.1522047519684, 'eval/loss': 1.057578458477436, '_timestamp': 1704656931.9734528, 'eval/accuracy': 0.5116279069767442, 'eval/f1_macro': 0.48651547733430944, 'eval/f1_micro': 0.5116279069767442, 'eval/precision_weighted': 0.4961794019933555, '_step': 4, 'split': 3}","{'dt_criterion': 'gini', 'dt_max_depth': 17, 'trial.number': 39, 'dt_min_samples_leaf': 14}",vital-yogurt-1278,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
61,"{'eval/accuracy': 0.5581395348837209, 'eval/f1_weighted': 0.5529847935129564, 'eval/f1_macro': 0.5511121444625281, 'eval/recall_micro': 0.5581395348837209, 'eval/recall_weighted': 0.5581395348837209, 'split': 6, '_timestamp': 1704656826.2668867, 'eval/recall_macro': 0.5545454545454546, '_step': 10, '_runtime': 805.6036357879639, 'eval/loss': 8.001655701040388, 'eval/f1_micro': 0.5581395348837209, 'eval/precision_macro': 0.558066933066933, 'eval/precision_micro': 0.5581395348837209, 'eval/precision_weighted': 0.557756197291081}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 51, 'dt_min_samples_leaf': 5}",honest-waterfall-1277,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
62,"{'eval/recall_macro': 0.33409090909090905, 'split': 9, 'eval/accuracy': 0.3333333333333333, 'eval/f1_macro': 0.31136363636363634, 'eval/precision_micro': 0.3333333333333333, '_step': 16, '_runtime': 1411.9557800292969, 'eval/loss': 7.603061116996217, 'eval/recall_micro': 0.3333333333333333, '_timestamp': 1704657013.595477, 'eval/f1_micro': 0.3333333333333333, 'eval/f1_weighted': 0.3129251700680272, 'eval/precision_macro': 0.33914141414141413, 'eval/recall_weighted': 0.3333333333333333, 'eval/precision_weighted': 0.3439153439153439}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 46, 'dt_min_samples_leaf': 9}",rare-sunset-1276,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
63,"{'split': 10, '_step': 20, 'eval/loss': 5.431818849377296, 'eval/accuracy': 0.7142857142857143, 'eval/precision_macro': 0.6875, 'test/precision_macro': 0.5882183908045977, 'test/recall_weighted': 0.616822429906542, 'eval/f1_weighted': 0.688145613976816, 'eval/precision_weighted': 0.6865079365079365, 'test/recall_macro': 0.6080901856763926, 'test/precision_weighted': 0.5937694704049844, 'eval/recall_micro': 0.7142857142857143, 'test/recall_micro': 0.616822429906542, 'test/loss': 8.373564879264766, 'test/accuracy': 0.616822429906542, 'test/f1_macro': 0.5909499617857303, 'test/f1_micro': 0.616822429906542, 'test/f1_weighted': 0.5986010089911727, 'eval/recall_macro': 0.7204545454545455, '_timestamp': 1704656015.2674084, 'eval/f1_macro': 0.6919902348291095, 'eval/f1_micro': 0.7142857142857143, 'eval/precision_micro': 0.7142857142857143, 'test/precision_micro': 0.616822429906542, '_wandb': {'runtime': 1643}, '_runtime': 1644.7432823181152, 'eval/recall_weighted': 0.7142857142857143}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 50, 'dt_min_samples_leaf': 5}",volcanic-fire-1275,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
64,"{'test/accuracy': 0.5420560747663551, 'eval/recall_macro': 0.8318181818181818, 'eval/precision_macro': 0.8416666666666667, '_wandb': {'runtime': 2137}, 'eval/f1_micro': 0.8333333333333334, 'test/f1_macro': 0.5428317098164129, 'eval/recall_micro': 0.8333333333333334, 'test/precision_micro': 0.5420560747663551, 'eval/precision_weighted': 0.8412698412698413, '_runtime': 2139.230990886688, 'eval/accuracy': 0.8333333333333334, 'test/precision_macro': 0.5598316912972086, 'eval/f1_weighted': 0.8363299553230903, 'test/recall_macro': 0.5426724137931035, 'eval/precision_micro': 0.8333333333333334, 'eval/recall_weighted': 0.8333333333333334, 'eval/loss': 2.8066054380524, 'test/recall_micro': 0.5420560747663551, 'test/f1_micro': 0.5420560747663551, 'split': 10, 'eval/f1_macro': 0.8357551487414188, 'test/recall_weighted': 0.5420560747663551, 'test/loss': 7.826974624162988, '_timestamp': 1704656505.867385, 'test/precision_weighted': 0.5750157297853077, '_step': 20, 'test/f1_weighted': 0.5507258131978813}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 38, 'dt_min_samples_leaf': 5}",absurd-rain-1274,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
65,"{'_wandb': {'runtime': 1810}, 'test/accuracy': 0.4953271028037383, 'test/recall_micro': 0.4953271028037383, 'test/precision_macro': 0.5530283605283606, 'test/f1_weighted': 0.4963336308362955, 'eval/recall_macro': 0.4727272727272727, 'test/loss': 9.563455682299823, 'eval/f1_weighted': 0.45938843764930715, 'test/precision_micro': 0.4953271028037383, 'split': 10, 'eval/f1_macro': 0.45735785953177255, 'test/recall_macro': 0.5060880016722408, 'eval/precision_micro': 0.47619047619047616, 'test/recall_weighted': 0.4953271028037383, '_runtime': 1812.325659990311, '_timestamp': 1704655595.69095, 'test/f1_micro': 0.4953271028037383, 'test/precision_weighted': 0.5703913324474071, '_step': 20, 'test/f1_macro': 0.49807081890529126, 'eval/recall_micro': 0.47619047619047616, 'eval/precision_macro': 0.5128205128205129, 'eval/loss': 9.086919300640394, 'eval/accuracy': 0.47619047619047616, 'eval/f1_micro': 0.47619047619047616, 'eval/recall_weighted': 0.47619047619047616, 'eval/precision_weighted': 0.5103785103785103}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 45, 'dt_min_samples_leaf': 5}",fallen-waterfall-1273,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
66,"{'test/precision_weighted': 0.5744233844769854, '_runtime': 1642.6335382461548, 'test/f1_weighted': 0.5789065151374498, 'test/recall_macro': 0.5958775419982316, 'test/recall_micro': 0.6074766355140186, 'test/precision_macro': 0.5682987967914439, 'eval/precision_weighted': 0.6882783882783883, '_wandb': {'runtime': 1641}, '_timestamp': 1704654366.130443, 'eval/f1_weighted': 0.6675724637681159, 'test/recall_weighted': 0.6074766355140186, 'test/loss': 5.834841271530875, 'eval/accuracy': 0.6904761904761905, 'test/f1_micro': 0.6074766355140186, 'test/precision_micro': 0.6074766355140186, 'split': 10, 'test/accuracy': 0.6074766355140186, 'eval/recall_macro': 0.6954545454545454, 'eval/precision_micro': 0.6904761904761905, '_step': 20, 'eval/f1_micro': 0.6904761904761905, 'test/f1_macro': 0.5690516568413686, 'eval/f1_macro': 0.668848814229249, 'eval/recall_micro': 0.6904761904761905, 'eval/precision_macro': 0.684965034965035, 'eval/loss': 5.5663545004466455, 'eval/recall_weighted': 0.6904761904761905}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 49, 'dt_min_samples_leaf': 6}",devoted-night-1272,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
67,"{'eval/f1_weighted': 0.8363299553230903, 'eval/precision_weighted': 0.8412698412698413, '_wandb': {'runtime': 2139}, 'eval/f1_micro': 0.8333333333333334, 'test/precision_macro': 0.597421798631476, 'test/f1_weighted': 0.5896893461155358, 'eval/precision_macro': 0.8416666666666667, 'test/precision_weighted': 0.6178259836836866, 'eval/accuracy': 0.8333333333333334, 'eval/recall_weighted': 0.8333333333333334, 'test/loss': 9.381980707524844, 'test/f1_macro': 0.5774061463408517, '_step': 20, 'split': 10, 'test/recall_micro': 0.5794392523364486, 'test/f1_micro': 0.5794392523364486, 'eval/recall_micro': 0.8333333333333334, 'eval/precision_micro': 0.8333333333333334, 'test/precision_micro': 0.5794392523364486, 'eval/loss': 2.81876795290397, 'eval/f1_macro': 0.8357551487414188, 'eval/recall_macro': 0.8318181818181818, 'test/recall_weighted': 0.5794392523364486, '_runtime': 2140.465326309204, 'test/accuracy': 0.5794392523364486, '_timestamp': 1704654361.8737133, 'test/recall_macro': 0.5771551724137931}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 37, 'dt_min_samples_leaf': 5}",light-sun-1271,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
68,"{'_runtime': 1812.1565980911255, 'eval/f1_macro': 0.4582867132867132, 'test/f1_macro': 0.5099521946979574, 'test/precision_weighted': 0.5851142626843562, 'eval/f1_micro': 0.47619047619047616, 'test/precision_macro': 0.5702214452214452, 'test/precision_micro': 0.5046728971962616, 'eval/f1_weighted': 0.4613553113553114, 'eval/precision_macro': 0.5184149184149184, 'eval/precision_micro': 0.47619047619047616, 'test/loss': 10.185722362191315, 'test/f1_weighted': 0.506869422883996, 'test/recall_micro': 0.5046728971962616, 'eval/recall_weighted': 0.47619047619047616, 'eval/precision_weighted': 0.5177045177045176, 'split': 10, 'test/recall_weighted': 0.5046728971962616, '_step': 20, 'eval/loss': 9.89345738846772, 'test/accuracy': 0.5046728971962616, 'test/f1_micro': 0.5046728971962616, 'eval/recall_macro': 0.4727272727272727, 'eval/recall_micro': 0.47619047619047616, '_wandb': {'runtime': 1809}, 'test/recall_macro': 0.5157033862876255, '_timestamp': 1704653778.199295, 'eval/accuracy': 0.47619047619047616}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 44, 'dt_min_samples_leaf': 5}",eager-pyramid-1270,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
69,"{'_runtime': 9170.192525625229, 'eval/recall_micro': 1, 'eval/precision_micro': 1, 'eval/samples_per_second': 121.596, 'test/samples_per_second': 129.4111797719831, '_wandb': {'runtime': 9168}, 'train/loss': 0, 'train/total_flos': 8789502886240752.0, 'train/train_runtime': 905.4976, '_timestamp': 1704660537.3681986, 'train/global_step': 2400, 'eval/runtime': 0.3454, 'eval/f1_weighted': 1, 'eval/recall_weighted': 1, '_step': 1050, 'eval/accuracy': 1, 'train/train_loss': 2.297262193436585e-10, 'eval/recall_macro': 1, 'train/learning_rate': 1.963986140301922e-06, 'test/latency_in_seconds': 0.0077273076542687955, 'train/train_steps_per_second': 2.65, 'eval/loss': 0, 'test/accuracy': 0.5607476635514018, 'test/total_time_in_seconds': 0.8268219190067612, 'eval/f1_macro': 1, 'eval/precision_macro': 1, 'eval/steps_per_second': 8.685, 'eval/precision_weighted': 1, 'train/train_samples_per_second': 42.297, 'eval/f1_micro': 1, 'train/epoch': 100}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_18-16-09_erc-hpc-comp036', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.1783916841811532e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",royal-fire-1269,Fine-Tuned LLM:bert-base-uncased,['preprocessed']
70,"{'eval/f1_weighted': 0.20641359992272773, 'eval/precision_micro': 0.30952380952380953, 'eval/recall_weighted': 0.30952380952380953, '_wandb': {'runtime': 1641}, 'test/f1_weighted': 0.1803779436902671, 'test/recall_macro': 0.26795977011494254, '_runtime': 1642.666186094284, 'test/f1_micro': 0.27102803738317754, 'eval/precision_macro': 0.15625, 'eval/recall_macro': 0.31136363636363634, 'test/recall_weighted': 0.27102803738317754, 'eval/f1_micro': 0.30952380952380953, 'test/precision_macro': 0.13333333333333333, 'eval/precision_weighted': 0.15674603174603177, 'test/precision_weighted': 0.135202492211838, '_timestamp': 1704652718.792716, 'test/f1_macro': 0.17803268384663734, 'eval/recall_micro': 0.30952380952380953, '_step': 20, 'split': 10, 'eval/loss': 1.3490770364695868, 'test/loss': 1.3978350666711672, 'test/accuracy': 0.27102803738317754, 'test/recall_micro': 0.27102803738317754, 'test/precision_micro': 0.27102803738317754, 'eval/accuracy': 0.30952380952380953, 'eval/f1_macro': 0.2063894523326572}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 48, 'dt_min_samples_leaf': 5}",fiery-lion-1268,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
71,"{'test/f1_macro': 0.5006822903872922, 'test/precision_weighted': 0.5754927151877471, 'test/precision_micro': 0.4953271028037383, '_step': 20, 'eval/f1_macro': 0.4582867132867132, 'eval/f1_micro': 0.47619047619047616, 'test/f1_weighted': 0.49821158280092226, 'eval/recall_micro': 0.47619047619047616, 'eval/accuracy': 0.47619047619047616, 'test/loss': 9.866288836685689, 'eval/f1_weighted': 0.4613553113553114, 'eval/precision_macro': 0.5184149184149184, 'eval/recall_weighted': 0.47619047619047616, 'test/recall_weighted': 0.4953271028037383, 'split': 10, 'eval/precision_micro': 0.47619047619047616, '_wandb': {'runtime': 1814}, 'test/accuracy': 0.4953271028037383, 'eval/precision_weighted': 0.5177045177045176, '_timestamp': 1704651960.3539572, 'test/f1_micro': 0.4953271028037383, 'test/recall_macro': 0.5060880016722408, 'test/recall_micro': 0.4953271028037383, 'test/precision_macro': 0.5595812463661434, '_runtime': 1815.6618320941925, 'eval/loss': 9.066745542059747, 'eval/recall_macro': 0.4727272727272727}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 43, 'dt_min_samples_leaf': 5}",honest-surf-1267,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
72,"{'_wandb': {'runtime': 2138}, 'test/precision_macro': 0.4894828855355171, 'test/precision_weighted': 0.5047736818027029, 'eval/f1_macro': 0.5037878787878788, 'test/f1_micro': 0.5046728971962616, 'eval/recall_micro': 0.5238095238095238, 'eval/precision_micro': 0.5238095238095238, 'split': 10, '_timestamp': 1704652215.3926153, 'eval/accuracy': 0.5238095238095238, 'eval/loss': 4.90000908241297, 'eval/f1_micro': 0.5238095238095238, 'test/f1_weighted': 0.49203356677900745, '_runtime': 2139.4170043468475, 'test/loss': 6.669124739688368, 'test/recall_weighted': 0.5046728971962616, 'test/accuracy': 0.5046728971962616, 'eval/recall_weighted': 0.5238095238095238, 'eval/precision_weighted': 0.5061050061050061, 'test/f1_macro': 0.4808450554134698, 'eval/f1_weighted': 0.5088383838383839, 'eval/recall_macro': 0.5181818181818182, 'test/recall_macro': 0.496551724137931, 'test/precision_micro': 0.5046728971962616, '_step': 20, 'test/recall_micro': 0.5046728971962616, 'eval/precision_macro': 0.502039627039627}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 36, 'dt_min_samples_leaf': 7}",dutiful-wood-1266,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
73,"{'test/loss': 5.071376947140212, 'test/accuracy': 0.514018691588785, 'eval/recall_micro': 0.7142857142857143, 'test/recall_macro': 0.5060273777946191, 'test/recall_micro': 0.514018691588785, 'split': 10, 'eval/f1_micro': 0.7142857142857143, 'eval/precision_micro': 0.7142857142857143, 'eval/precision_weighted': 0.7273551844980417, 'eval/precision_macro': 0.7240800865800866, 'test/precision_weighted': 0.4870939029817535, 'test/f1_weighted': 0.4857698650991669, '_step': 20, 'test/precision_micro': 0.514018691588785, 'test/f1_macro': 0.476972486607375, 'eval/recall_macro': 0.715909090909091, '_runtime': 1643.2932043075562, 'eval/loss': 3.162876330579908, 'eval/accuracy': 0.7142857142857143, 'eval/f1_macro': 0.6945670995670996, 'test/f1_micro': 0.514018691588785, 'eval/recall_weighted': 0.7142857142857143, '_wandb': {'runtime': 1641}, '_timestamp': 1704651069.2769043, 'eval/f1_weighted': 0.6943496186353331, 'test/precision_macro': 0.4790127257799671, 'test/recall_weighted': 0.514018691588785}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 47, 'dt_min_samples_leaf': 9}",hearty-cherry-1265,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
74,"{'test/recall_micro': 0.5046728971962616, 'test/precision_macro': 0.5717657342657343, 'eval/accuracy': 0.47619047619047616, 'eval/recall_macro': 0.4727272727272727, 'eval/f1_weighted': 0.4626532887402452, 'eval/loss': 9.073595115213362, 'eval/f1_macro': 0.4591061112800243, 'eval/f1_micro': 0.47619047619047616, 'eval/recall_weighted': 0.47619047619047616, '_step': 20, 'test/f1_macro': 0.5106583072100312, 'test/f1_micro': 0.5046728971962616, 'eval/recall_micro': 0.47619047619047616, 'eval/precision_micro': 0.47619047619047616, 'split': 10, 'test/loss': 9.537921258864266, 'eval/precision_macro': 0.521780303030303, 'test/recall_weighted': 0.5046728971962616, 'test/precision_weighted': 0.5866152539049735, '_runtime': 1810.879375219345, '_timestamp': 1704650139.5222502, 'test/accuracy': 0.5046728971962616, 'test/f1_weighted': 0.5075557378490024, 'test/recall_macro': 0.5157033862876255, 'test/precision_micro': 0.5046728971962616, 'eval/precision_weighted': 0.5218253968253967, '_wandb': {'runtime': 1809}}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 42, 'dt_min_samples_leaf': 5}",volcanic-sun-1264,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
75,"{'test/recall_macro': 0.4870689655172414, 'split': 10, '_wandb': {'runtime': 2138}, 'test/f1_weighted': 0.4856047716755964, '_runtime': 2141.055356025696, 'eval/f1_weighted': 0.5566226490596238, 'test/precision_micro': 0.48598130841121495, 'eval/loss': 1.6817358767876234, 'eval/accuracy': 0.5476190476190477, 'eval/precision_weighted': 0.5853741496598639, 'test/precision_macro': 0.4827697262479871, 'test/accuracy': 0.48598130841121495, 'test/recall_micro': 0.48598130841121495, 'eval/recall_weighted': 0.5476190476190477, 'test/f1_macro': 0.4840151472492821, 'test/f1_micro': 0.48598130841121495, 'eval/precision_micro': 0.5476190476190477, 'test/precision_weighted': 0.4868060258551929, '_timestamp': 1704650070.48153, 'eval/f1_macro': 0.561401833460657, 'eval/f1_micro': 0.5476190476190477, 'eval/recall_macro': 0.5522727272727272, 'test/recall_weighted': 0.48598130841121495, 'test/loss': 5.4982487745869335, 'eval/recall_micro': 0.5476190476190477, 'eval/precision_macro': 0.5912337662337661, '_step': 20}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 35, 'dt_min_samples_leaf': 10}",volcanic-sponge-1263,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
76,"{'_timestamp': 1704649421.5858445, 'test/f1_micro': 0.3925233644859813, 'test/precision_macro': 0.4044701213818861, 'test/precision_micro': 0.3925233644859813, 'split': 10, '_runtime': 1642.980949163437, 'eval/loss': 2.822008149358489, 'eval/f1_weighted': 0.4672865523020802, 'eval/precision_micro': 0.47619047619047616, 'test/precision_weighted': 0.4093213609431311, 'test/accuracy': 0.3925233644859813, 'test/f1_macro': 0.37387741568776056, 'eval/recall_macro': 0.4795454545454545, 'eval/precision_macro': 0.4957792207792208, 'test/recall_micro': 0.3925233644859813, 'eval/recall_weighted': 0.47619047619047616, 'test/recall_macro': 0.38621400151572566, 'test/recall_weighted': 0.3925233644859813, '_wandb': {'runtime': 1641}, 'test/loss': 3.753219379030158, 'eval/accuracy': 0.47619047619047616, 'test/f1_weighted': 0.38007529048457184, '_step': 20, 'eval/f1_macro': 0.46823240165631463, 'eval/f1_micro': 0.47619047619047616, 'eval/recall_micro': 0.47619047619047616, 'eval/precision_weighted': 0.4983611626468769}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 46, 'dt_min_samples_leaf': 7}",sweet-snowflake-1262,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
77,"{'test/recall_weighted': 0.4953271028037383, 'test/loss': 8.955657314740515, 'eval/precision_macro': 0.4634878193701723, 'test/recall_micro': 0.4953271028037383, '_step': 20, 'eval/f1_micro': 0.4523809523809524, 'test/precision_weighted': 0.5540197387366161, 'split': 10, 'eval/f1_macro': 0.43914141414141417, 'test/f1_weighted': 0.5033048393529035, 'eval/precision_micro': 0.4523809523809524, 'eval/loss': 9.156793290443163, 'eval/f1_weighted': 0.44312169312169314, 'eval/accuracy': 0.4523809523809524, 'test/f1_macro': 0.5029452690166976, '_runtime': 1814.910009622574, '_timestamp': 1704648322.4244535, 'eval/precision_weighted': 0.4676314970432618, 'eval/recall_micro': 0.4523809523809524, 'test/precision_macro': 0.5423669467787114, 'test/f1_micro': 0.4953271028037383, 'eval/recall_macro': 0.45, 'test/recall_macro': 0.501228051839465, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_micro': 0.4953271028037383, '_wandb': {'runtime': 1813}, 'test/accuracy': 0.4953271028037383}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 41, 'dt_min_samples_leaf': 6}",sparkling-sea-1261,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
78,"{'test/accuracy': 0.5794392523364486, 'eval/recall_micro': 0.6190476190476191, 'test/recall_micro': 0.5794392523364486, 'test/loss': 5.626597179139547, '_step': 20, '_wandb': {'runtime': 1642}, 'eval/loss': 4.939221692650606, 'eval/accuracy': 0.6190476190476191, 'eval/f1_micro': 0.6190476190476191, 'eval/recall_macro': 0.625, 'eval/precision_weighted': 0.6610544217687074, '_timestamp': 1704647774.3126333, 'test/f1_macro': 0.5477863986868224, 'eval/f1_weighted': 0.6019274376417234, 'test/f1_weighted': 0.5580969949039805, '_runtime': 1643.693707227707, 'eval/f1_macro': 0.6029761904761906, 'test/recall_weighted': 0.5794392523364486, 'test/f1_micro': 0.5794392523364486, 'test/recall_macro': 0.5663445749652646, 'eval/precision_micro': 0.6190476190476191, 'eval/recall_weighted': 0.6190476190476191, 'test/precision_macro': 0.5436281460475009, 'split': 10, 'eval/precision_macro': 0.6553571428571429, 'test/precision_micro': 0.5794392523364486, 'test/precision_weighted': 0.5503192014497411}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 45, 'dt_min_samples_leaf': 6}",electric-vortex-1260,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
79,"{'test/f1_weighted': 0.5327468133298793, 'test/precision_macro': 0.5423533581428318, 'split': 10, 'test/f1_micro': 0.5327102803738317, 'eval/recall_macro': 0.6681818181818182, 'test/recall_macro': 0.5301724137931034, 'test/recall_weighted': 0.5327102803738317, 'eval/precision_weighted': 0.7040764790764791, 'eval/precision_macro': 0.7071969696969697, '_wandb': {'runtime': 2139}, 'eval/f1_macro': 0.6768202557676242, 'eval/f1_micro': 0.6666666666666666, 'test/f1_macro': 0.5302061122956646, 'eval/recall_micro': 0.6666666666666666, 'test/recall_micro': 0.5327102803738317, 'eval/recall_weighted': 0.6666666666666666, '_step': 20, 'eval/loss': 1.5585451351799664, 'test/precision_micro': 0.5327102803738317, '_runtime': 2140.438056230545, '_timestamp': 1704647923.4338622, 'test/loss': 6.710146324019213, 'eval/precision_micro': 0.6666666666666666, 'test/precision_weighted': 0.5459157901361542, 'eval/accuracy': 0.6666666666666666, 'test/accuracy': 0.5327102803738317, 'eval/f1_weighted': 0.6742803284156667}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 34, 'dt_min_samples_leaf': 9}",prime-fog-1259,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
80,"{'test/loss': 4.487080883485215, 'eval/recall_weighted': 0.5238095238095238, 'test/precision_macro': 0.4360543690180787, 'test/recall_weighted': 0.3925233644859813, '_step': 20, '_wandb': {'runtime': 1801}, 'eval/loss': 3.743560542395847, 'test/f1_weighted': 0.3980542483226914, 'eval/recall_macro': 0.5204545454545455, 'test/recall_macro': 0.40031877090301, 'eval/f1_macro': 0.49970145953118095, 'test/accuracy': 0.3925233644859813, 'test/f1_macro': 0.396983163605504, 'test/recall_micro': 0.3925233644859813, 'eval/precision_macro': 0.5137254901960784, 'eval/accuracy': 0.5238095238095238, '_timestamp': 1704646502.9707716, 'test/precision_weighted': 0.4506223351565528, 'split': 10, 'eval/f1_micro': 0.5238095238095238, 'test/precision_micro': 0.3925233644859813, 'test/f1_micro': 0.3925233644859813, 'eval/precision_micro': 0.5238095238095238, 'eval/precision_weighted': 0.515172735760971, '_runtime': 1802.606742620468, 'eval/f1_weighted': 0.5013163160000842, 'eval/recall_micro': 0.5238095238095238}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 40, 'dt_min_samples_leaf': 19}",eager-bush-1258,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
81,"{'eval/f1_macro': 0.6277722277722277, 'test/recall_micro': 0.5046728971962616, 'test/precision_macro': 0.4873803827751197, 'eval/accuracy': 0.6666666666666666, 'test/accuracy': 0.5046728971962616, '_timestamp': 1704646125.630434, 'eval/f1_weighted': 0.6243740386597529, 'eval/recall_weighted': 0.6666666666666666, 'test/precision_micro': 0.5046728971962616, '_runtime': 1652.2954931259155, 'test/f1_macro': 0.4829880197322058, 'eval/recall_micro': 0.6666666666666666, 'split': 10, 'test/loss': 5.968815693231811, 'test/f1_micro': 0.5046728971962616, 'eval/precision_macro': 0.6359848484848485, 'eval/f1_micro': 0.6666666666666666, 'eval/recall_macro': 0.6704545454545454, 'test/precision_weighted': 0.4947100120735143, 'test/f1_weighted': 0.48882074384356505, 'test/recall_macro': 0.5006907603890363, 'eval/precision_micro': 0.6666666666666666, 'eval/precision_weighted': 0.635064935064935, '_step': 20, '_wandb': {'runtime': 1651}, 'eval/loss': 3.1487041588148887, 'test/recall_weighted': 0.5046728971962616}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 44, 'dt_min_samples_leaf': 8}",lively-firefly-1257,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
82,"{'eval/f1_micro': 0.6428571428571429, 'test/f1_micro': 0.5514018691588785, 'eval/recall_micro': 0.6428571428571429, 'eval/precision_micro': 0.6428571428571429, 'eval/recall_weighted': 0.6428571428571429, '_runtime': 2153.179307460785, 'test/recall_weighted': 0.5514018691588785, 'test/loss': 6.370485034471854, 'eval/f1_weighted': 0.6535905420115947, 'test/f1_weighted': 0.5531779500037991, 'eval/precision_macro': 0.6875, 'test/precision_weighted': 0.5650159809038314, 'split': 10, 'eval/f1_macro': 0.6564805954279639, 'test/precision_macro': 0.5618189281982385, '_wandb': {'runtime': 2151}, 'test/accuracy': 0.5514018691588785, 'test/f1_macro': 0.5518905943369778, 'eval/recall_macro': 0.6454545454545455, 'eval/precision_weighted': 0.6845238095238095, '_step': 20, 'eval/loss': 1.5317544479965368, 'eval/accuracy': 0.6428571428571429, 'test/precision_micro': 0.5514018691588785, '_timestamp': 1704645777.9025586, 'test/recall_macro': 0.5512931034482759, 'test/recall_micro': 0.5514018691588785}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 33, 'dt_min_samples_leaf': 9}",honest-frost-1256,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
83,"{'test/f1_weighted': 0.4806806102373458, 'eval/recall_macro': 0.4477272727272727, 'test/precision_macro': 0.5056824681824682, 'split': 10, '_timestamp': 1704644695.4091594, 'test/f1_micro': 0.4766355140186916, 'eval/f1_weighted': 0.4750457875457875, 'eval/precision_macro': 0.5465909090909091, 'test/precision_weighted': 0.4982233234569683, '_runtime': 1818.389903306961, 'eval/f1_macro': 0.467263986013986, 'test/precision_micro': 0.4766355140186916, 'test/recall_weighted': 0.4766355140186916, 'test/loss': 9.67888862868644, 'eval/precision_weighted': 0.5595238095238095, 'eval/recall_micro': 0.4523809523809524, 'test/recall_micro': 0.4766355140186916, '_step': 20, '_wandb': {'runtime': 1816}, 'eval/loss': 7.524216909560439, 'eval/recall_weighted': 0.4523809523809524, 'eval/accuracy': 0.4523809523809524, 'test/accuracy': 0.4766355140186916, 'test/f1_macro': 0.4811464674812545, 'eval/f1_micro': 0.4523809523809524, 'test/recall_macro': 0.4717286789297659, 'eval/precision_micro': 0.4523809523809524}","{'dt_criterion': 'gini', 'dt_max_depth': 13, 'trial.number': 39, 'dt_min_samples_leaf': 6}",divine-field-1255,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
84,"{'_runtime': 1653.669689655304, 'test/accuracy': 0.5514018691588785, 'test/f1_weighted': 0.5343956748285327, 'test/recall_micro': 0.5514018691588785, 'test/precision_macro': 0.5244604494604495, 'test/f1_macro': 0.5253047391205286, 'eval/precision_macro': 0.5520833333333333, '_timestamp': 1704644468.9281726, 'eval/f1_micro': 0.5476190476190477, 'test/precision_micro': 0.5514018691588785, 'split': 10, 'eval/f1_macro': 0.5393724696356276, 'eval/f1_weighted': 0.5378735299787931, '_step': 20, 'test/loss': 5.0897691139468115, 'eval/recall_macro': 0.5522727272727272, 'eval/recall_micro': 0.5476190476190477, 'test/recall_weighted': 0.5514018691588785, 'test/precision_weighted': 0.5309956356685328, '_wandb': {'runtime': 1652}, 'eval/loss': 4.177994574472537, 'test/f1_micro': 0.5514018691588785, 'test/recall_macro': 0.5402456738663635, 'eval/recall_weighted': 0.5476190476190477, 'eval/accuracy': 0.5476190476190477, 'eval/precision_micro': 0.5476190476190477, 'eval/precision_weighted': 0.5532407407407407}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 43, 'dt_min_samples_leaf': 6}",pleasant-lake-1254,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
85,"{'eval/f1_macro': 0.9222855149965123, 'eval/steps_per_second': 5.833, 'eval/loss': 0.6750569343566895, 'eval/runtime': 0.3429, 'eval/recall_macro': 0.9217171717171716, 'train/train_runtime': 938.8011, '_wandb': {'runtime': 9442}, 'eval/recall_micro': 0.9285714285714286, 'test/total_time_in_seconds': 0.7709580120281316, 'eval/f1_weighted': 0.9269881865789794, 'train/train_samples_per_second': 40.797, 'eval/precision_weighted': 0.927579365079365, 'eval/precision_micro': 0.9285714285714286, 'train/train_loss': 0.052389336416623945, 'train/epoch': 100, 'train/total_flos': 9658434527639664.0, 'test/samples_per_second': 138.78836244080134, '_step': 1030, '_timestamp': 1704651361.839219, 'train/loss': 0, 'eval/accuracy': 0.9285714285714286, 'eval/f1_micro': 0.9285714285714286, 'test/accuracy': 0.5607476635514018, 'train/learning_rate': 1.049760290358763e-05, 'eval/precision_macro': 0.925189393939394, '_runtime': 9444.291846036913, 'eval/samples_per_second': 122.483, 'eval/recall_weighted': 0.9285714285714286, 'test/latency_in_seconds': 0.007205215065683473, 'train/train_steps_per_second': 1.278, 'train/global_step': 1200}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_15-38-39_erc-hpc-comp036', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 6.298561742152578e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",azure-glade-1253,Fine-Tuned LLM:bert-base-uncased,['preprocessed']
86,"{'_wandb': {'runtime': 2145}, '_runtime': 2146.7387273311615, '_timestamp': 1704643620.1897843, 'eval/f1_weighted': 0.5817700817700817, '_step': 20, 'test/loss': 8.867711798820455, 'eval/recall_weighted': 0.5714285714285714, 'test/recall_weighted': 0.5233644859813084, 'eval/f1_macro': 0.5858585858585859, 'test/f1_macro': 0.5193334729617296, 'eval/recall_macro': 0.575, 'eval/recall_micro': 0.5714285714285714, 'test/recall_macro': 0.5176724137931035, 'eval/precision_macro': 0.608440170940171, 'test/precision_macro': 0.5369133885438233, 'split': 10, 'eval/loss': 4.85482484784013, 'eval/accuracy': 0.5714285714285714, 'eval/f1_micro': 0.5714285714285714, 'test/accuracy': 0.5233644859813084, 'test/f1_micro': 0.5233644859813084, 'eval/precision_micro': 0.5714285714285714, 'test/precision_micro': 0.5233644859813084, 'test/f1_weighted': 0.5278059906831357, 'eval/precision_weighted': 0.6036833536833537, 'test/precision_weighted': 0.5491608779499881, 'test/recall_micro': 0.5233644859813084}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 32, 'dt_min_samples_leaf': 7}",ethereal-pond-1252,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
87,"{'test/accuracy': 0.4766355140186916, 'test/recall_macro': 0.46676455728179866, 'test/precision_weighted': 0.44702633814783344, 'eval/loss': 3.2129678510790067, 'test/f1_micro': 0.4766355140186916, 'eval/f1_weighted': 0.5403793066836544, 'test/precision_micro': 0.4766355140186916, 'test/recall_weighted': 0.4766355140186916, '_step': 20, 'test/loss': 5.406738202784642, '_timestamp': 1704642808.4424353, 'test/f1_macro': 0.43854966981152943, 'eval/recall_micro': 0.5952380952380952, 'split': 10, '_wandb': {'runtime': 1643}, 'eval/accuracy': 0.5952380952380952, 'eval/f1_micro': 0.5952380952380952, 'eval/precision_macro': 0.5755494505494505, 'test/f1_weighted': 0.44840495887685944, 'test/recall_micro': 0.4766355140186916, 'test/precision_macro': 0.43863636363636366, 'eval/recall_weighted': 0.5952380952380952, '_runtime': 1645.2173132896423, 'eval/f1_macro': 0.5448021181716834, 'eval/recall_macro': 0.6022727272727273, 'eval/precision_micro': 0.5952380952380952, 'eval/precision_weighted': 0.5765306122448979}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 42, 'dt_min_samples_leaf': 10}",comic-snowflake-1251,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
88,"{'test/precision_macro': 0.38726503521305167, 'test/loss': 7.339500139902025, 'test/f1_micro': 0.36448598130841114, 'eval/recall_micro': 0.4047619047619048, 'test/f1_weighted': 0.3592167334223409, 'eval/accuracy': 0.4047619047619048, 'eval/f1_micro': 0.4047619047619048, 'test/f1_macro': 0.3680952380952381, 'test/recall_macro': 0.3786841555183947, 'eval/precision_macro': 0.3824754901960784, 'eval/precision_weighted': 0.38779178338001874, 'test/precision_weighted': 0.3859972659159536, '_wandb': {'runtime': 1818}, '_runtime': 1819.4630851745603, 'eval/f1_weighted': 0.3752061430632859, 'test/accuracy': 0.3644859813084112, 'eval/precision_micro': 0.4047619047619048, 'test/recall_weighted': 0.3644859813084112, 'test/recall_micro': 0.3644859813084112, '_timestamp': 1704642872.4159992, 'eval/f1_macro': 0.3698593073593074, 'eval/recall_macro': 0.3977272727272728, '_step': 20, 'eval/recall_weighted': 0.4047619047619048, 'test/precision_micro': 0.3644859813084112, 'split': 10, 'eval/loss': 8.61185861102646}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 38, 'dt_min_samples_leaf': 12}",amber-wave-1250,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
89,"{'test/recall_weighted': 0.6074766355140186, '_step': 20, 'split': 10, '_wandb': {'runtime': 1640}, '_runtime': 1641.494791984558, 'test/recall_macro': 0.5940026209422762, 'eval/f1_macro': 0.5288081483733658, 'eval/f1_weighted': 0.524605828953655, 'test/accuracy': 0.6074766355140186, 'test/f1_micro': 0.6074766355140186, 'eval/recall_micro': 0.5714285714285714, 'test/precision_weighted': 0.5908301207417512, 'test/f1_macro': 0.5783472985947455, 'eval/precision_micro': 0.5714285714285714, 'test/precision_micro': 0.6074766355140186, '_timestamp': 1704641158.184813, 'test/f1_weighted': 0.5881071768555158, 'eval/precision_macro': 0.5700393356643356, 'test/precision_macro': 0.5861150721631665, 'eval/precision_weighted': 0.5721153846153846, 'eval/loss': 6.658765458623435, 'test/loss': 5.583747015787485, 'eval/accuracy': 0.5714285714285714, 'test/recall_micro': 0.6074766355140186, 'eval/recall_weighted': 0.5714285714285714, 'eval/f1_micro': 0.5714285714285714, 'eval/recall_macro': 0.5795454545454546}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 41, 'dt_min_samples_leaf': 6}",cerulean-star-1249,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
90,"{'test/f1_weighted': 0.5515065239258615, 'test/f1_macro': 0.5439836823360024, '_runtime': 2138.222603082657, 'eval/loss': 2.909377367112929, '_timestamp': 1704641468.3651402, 'eval/recall_micro': 0.7857142857142857, '_step': 20, 'eval/recall_macro': 0.7840909090909092, 'eval/precision_micro': 0.7857142857142857, 'test/loss': 8.82109860587684, 'eval/recall_weighted': 0.7857142857142857, 'test/precision_macro': 0.5611607142857142, 'split': 10, 'eval/f1_micro': 0.7857142857142857, '_wandb': {'runtime': 2136}, 'test/recall_weighted': 0.5420560747663551, 'test/recall_micro': 0.5420560747663551, 'eval/f1_macro': 0.793888888888889, 'test/recall_macro': 0.5387931034482758, 'test/precision_micro': 0.5420560747663551, 'eval/precision_weighted': 0.819882498453927, 'test/precision_weighted': 0.5733144192256342, 'eval/accuracy': 0.7857142857142857, 'test/f1_micro': 0.5420560747663551, 'eval/f1_weighted': 0.7946560846560847, 'eval/precision_macro': 0.8198051948051948, 'test/accuracy': 0.5420560747663551}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 31, 'dt_min_samples_leaf': 6}",dauntless-capybara-1248,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
91,"{'_timestamp': 1704641048.582142, 'test/recall_micro': 0.4205607476635514, 'test/precision_weighted': 0.4475170497600404, 'eval/f1_weighted': 0.4470324361628709, 'eval/recall_macro': 0.44545454545454544, 'split': 10, 'test/loss': 8.501144158396883, 'eval/accuracy': 0.4523809523809524, '_step': 20, '_wandb': {'runtime': 1803}, 'test/accuracy': 0.4205607476635514, 'eval/precision_micro': 0.4523809523809524, 'test/precision_macro': 0.44081081081081086, 'eval/loss': 7.581050911753956, 'test/f1_weighted': 0.4277802643545067, 'test/recall_macro': 0.4219533862876254, 'test/precision_micro': 0.4205607476635514, 'test/recall_weighted': 0.4205607476635514, 'eval/precision_weighted': 0.5010760073260074, 'eval/f1_micro': 0.4523809523809524, 'test/f1_micro': 0.4205607476635514, 'eval/precision_macro': 0.4920673076923077, 'eval/recall_weighted': 0.4523809523809524, 'eval/recall_micro': 0.4523809523809524, '_runtime': 1805.2466208934784, 'eval/f1_macro': 0.4402173913043478, 'test/f1_macro': 0.4253807072027896}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 37, 'dt_min_samples_leaf': 9}",vibrant-fog-1247,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
92,"{'test/recall_weighted': 0.411214953271028, 'test/precision_weighted': 0.4238927265339293, 'eval/accuracy': 0.5952380952380952, 'test/accuracy': 0.411214953271028, 'eval/f1_weighted': 0.5883266350018268, 'eval/recall_micro': 0.5952380952380952, '_step': 20, 'eval/f1_macro': 0.5899936061381075, 'eval/precision_micro': 0.5952380952380952, '_wandb': {'runtime': 1641}, 'eval/precision_macro': 0.6190476190476191, 'eval/recall_weighted': 0.5952380952380952, 'split': 10, 'eval/loss': 2.5393506287678713, 'test/loss': 3.958105566327085, 'eval/f1_micro': 0.5952380952380952, 'eval/precision_weighted': 0.6213151927437641, '_runtime': 1642.5389399528503, '_timestamp': 1704639512.088819, 'test/f1_macro': 0.4075359612444012, 'test/f1_micro': 0.411214953271028, 'test/f1_weighted': 0.412992069372785, 'eval/recall_macro': 0.6, 'test/recall_micro': 0.411214953271028, 'test/precision_macro': 0.4186594202898551, 'test/recall_macro': 0.4055947644309713, 'test/precision_micro': 0.411214953271028}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 40, 'dt_min_samples_leaf': 15}",light-frog-1246,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
93,"{'test/f1_macro': 0.5029452690166976, 'test/f1_micro': 0.4953271028037383, 'eval/f1_weighted': 0.44312169312169314, 'eval/precision_macro': 0.4634878193701723, 'eval/recall_weighted': 0.4523809523809524, 'test/loss': 9.588750797079683, 'eval/accuracy': 0.4523809523809524, 'eval/recall_micro': 0.4523809523809524, 'test/precision_micro': 0.4953271028037383, '_wandb': {'runtime': 1821}, 'test/recall_macro': 0.501228051839465, 'test/precision_macro': 0.5423669467787114, 'test/recall_weighted': 0.4953271028037383, '_runtime': 1823.0743401050568, 'eval/f1_micro': 0.4523809523809524, 'test/recall_micro': 0.4953271028037383, 'eval/loss': 9.968644319968446, '_step': 20, 'split': 10, '_timestamp': 1704639237.250133, 'eval/f1_macro': 0.43914141414141417, 'test/accuracy': 0.4953271028037383, 'test/f1_weighted': 0.5033048393529035, 'eval/recall_macro': 0.45, 'eval/precision_micro': 0.4523809523809524, 'eval/precision_weighted': 0.4676314970432618, 'test/precision_weighted': 0.5540197387366161}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 36, 'dt_min_samples_leaf': 6}",laced-durian-1245,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
94,"{'_wandb': {'runtime': 4552}, '_runtime': 4555.173055410385, 'eval/runtime': 0.3416, 'eval/accuracy': 1, 'train/train_loss': 1.7719963681569103e-09, '_step': 530, 'eval/f1_macro': 1, 'eval/f1_micro': 1, 'train/total_flos': 4377445413802968.0, 'eval/recall_micro': 1, 'test/total_time_in_seconds': 0.7722924950066954, '_timestamp': 1704641912.6863484, 'train/epoch': 50, 'eval/recall_macro': 1, 'test/latency_in_seconds': 0.007217686869221452, 'test/samples_per_second': 138.5485430608417, 'eval/loss': 0, 'eval/precision_macro': 1, 'eval/recall_weighted': 1, 'eval/f1_weighted': 1, 'train/global_step': 1200, 'train/learning_rate': 2.899382620410848e-06, 'eval/precision_weighted': 1, 'train/train_steps_per_second': 2.68, 'train/loss': 0, 'eval/precision_micro': 1, 'eval/samples_per_second': 122.954, 'test/accuracy': 0.5607476635514018, 'train/train_runtime': 447.7016, 'eval/steps_per_second': 8.782, 'train/train_samples_per_second': 42.774}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_14-22-39_erc-hpc-comp036', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.7396295722465088e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",polished-plasma-1244,Fine-Tuned LLM:bert-base-uncased,['preprocessed']
95,"{'test/recall_micro': 0.5420560747663551, 'test/f1_macro': 0.5436667136659326, 'test/recall_macro': 0.5387931034482758, 'test/f1_weighted': 0.5511628943396177, 'test/accuracy': 0.5420560747663551, 'split': 10, '_wandb': {'runtime': 2144}, 'eval/f1_macro': 0.793888888888889, 'eval/precision_weighted': 0.819882498453927, 'eval/recall_micro': 0.7857142857142857, 'test/precision_micro': 0.5420560747663551, 'test/loss': 9.48322192295434, 'eval/recall_macro': 0.7840909090909092, 'eval/accuracy': 0.7857142857142857, 'eval/f1_weighted': 0.7946560846560847, 'eval/precision_micro': 0.7857142857142857, '_step': 20, 'eval/loss': 2.900019210253176, 'test/f1_micro': 0.5420560747663551, 'test/precision_macro': 0.5636363636363636, 'eval/f1_micro': 0.7857142857142857, 'eval/precision_macro': 0.8198051948051948, 'eval/recall_weighted': 0.7857142857142857, 'test/recall_weighted': 0.5420560747663551, 'test/precision_weighted': 0.575998300764656, '_runtime': 2145.9537675380707, '_timestamp': 1704639324.5411675}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 30, 'dt_min_samples_leaf': 6}",happy-monkey-1243,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
96,"{'test/f1_macro': 0.3453781512605042, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_weighted': 0.3706536154999423, 'eval/loss': 2.708695347949494, 'test/precision_macro': 0.3661312372659824, 'eval/f1_macro': 0.4357517482517483, 'eval/precision_weighted': 0.4396825396825396, '_timestamp': 1704637865.232179, 'test/f1_micro': 0.34579439252336447, 'eval/precision_macro': 0.4386363636363636, 'eval/f1_weighted': 0.43864468864468864, 'test/f1_weighted': 0.34508058675183473, 'eval/recall_macro': 0.4477272727272727, 'test/recall_weighted': 0.34579439252336447, 'test/loss': 3.4003682261243804, 'eval/f1_micro': 0.4523809523809524, 'test/recall_micro': 0.34579439252336447, 'eval/precision_micro': 0.4523809523809524, 'split': 10, '_runtime': 1660.820415019989, 'test/recall_macro': 0.3506378678792472, 'eval/recall_micro': 0.4523809523809524, 'test/precision_micro': 0.34579439252336447, '_step': 20, '_wandb': {'runtime': 1659}, 'eval/accuracy': 0.4523809523809524, 'test/accuracy': 0.34579439252336447}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 39, 'dt_min_samples_leaf': 12}",lyric-wood-1242,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
97,"{'test/f1_weighted': 0.4710195412064571, 'test/recall_macro': 0.47669314381270905, 'eval/precision_micro': 0.4523809523809524, 'test/precision_weighted': 0.5113014884042921, 'eval/recall_micro': 0.4523809523809524, 'eval/precision_weighted': 0.4358701814058956, '_step': 20, 'eval/recall_macro': 0.44545454545454544, 'eval/precision_macro': 0.42931547619047616, '_wandb': {'runtime': 1878}, 'test/loss': 6.500355382701615, 'test/recall_micro': 0.4672897196261682, 'test/precision_macro': 0.5025462962962963, 'eval/accuracy': 0.4523809523809524, 'eval/f1_micro': 0.4523809523809524, 'eval/loss': 7.582068590432378, 'test/f1_micro': 0.4672897196261683, 'test/precision_micro': 0.4672897196261682, 'test/recall_weighted': 0.4672897196261682, 'split': 10, '_timestamp': 1704637407.8882344, 'test/accuracy': 0.4672897196261682, 'eval/f1_weighted': 0.42025699168556313, 'eval/recall_weighted': 0.4523809523809524, '_runtime': 1879.250506401062, 'eval/f1_macro': 0.4134920634920635, 'test/f1_macro': 0.47306818181818183}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 35, 'dt_min_samples_leaf': 8}",vibrant-deluge-1241,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
98,"{'eval/f1_micro': 0.5, 'eval/precision_weighted': 0.4928571428571428, '_timestamp': 1704637173.4610934, 'test/f1_macro': 0.4368506731050629, 'test/recall_macro': 0.44568965517241377, '_step': 20, 'eval/loss': 4.131324898771939, 'eval/f1_macro': 0.48902064119455424, 'test/precision_weighted': 0.4692891958017389, '_runtime': 2167.1186294555664, 'eval/f1_weighted': 0.4940293201162766, 'test/f1_weighted': 0.4525670848615635, 'eval/precision_macro': 0.4875, 'eval/precision_micro': 0.5, 'test/loss': 6.710037578238699, 'test/accuracy': 0.45794392523364486, 'test/recall_micro': 0.45794392523364486, 'test/recall_weighted': 0.45794392523364486, '_wandb': {'runtime': 2165}, 'eval/recall_macro': 0.49545454545454537, 'eval/recall_weighted': 0.5, 'eval/accuracy': 0.5, 'test/f1_micro': 0.45794392523364486, 'split': 10, 'eval/recall_micro': 0.5, 'test/precision_macro': 0.4495044429254955, 'test/precision_micro': 0.45794392523364486}","{'dt_criterion': 'gini', 'dt_max_depth': 17, 'trial.number': 29, 'dt_min_samples_leaf': 9}",glorious-deluge-1240,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
99,"{'_step': 20, 'test/recall_weighted': 0.48598130841121495, 'eval/precision_micro': 0.6428571428571429, 'test/precision_macro': 0.4581057227796358, 'test/f1_micro': 0.48598130841121495, 'eval/recall_macro': 0.6454545454545455, 'test/accuracy': 0.48598130841121495, 'test/f1_weighted': 0.4654943533448207, 'test/loss': 7.270044578733574, 'eval/precision_weighted': 0.6123931623931623, 'split': 10, '_runtime': 1667.0669844150543, '_timestamp': 1704636199.3838017, 'eval/accuracy': 0.6428571428571429, '_wandb': {'runtime': 1665}, 'eval/loss': 4.016915274390923, 'eval/f1_weighted': 0.5999416042894303, 'eval/recall_micro': 0.6428571428571429, 'test/recall_micro': 0.48598130841121495, 'eval/recall_weighted': 0.6428571428571429, 'eval/f1_micro': 0.6428571428571429, 'test/f1_macro': 0.4592999592999593, 'eval/precision_macro': 0.6121794871794872, 'test/precision_micro': 0.48598130841121495, 'test/precision_weighted': 0.4658008522697673, 'eval/f1_macro': 0.602118171683389, 'test/recall_macro': 0.48165340406719714}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 38, 'dt_min_samples_leaf': 8}",cool-bee-1239,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
100,"{'eval/f1_micro': 0.47619047619047616, 'test/f1_weighted': 0.4585305149668512, 'eval/recall_micro': 0.47619047619047616, 'test/recall_macro': 0.4446854096989966, '_step': 20, 'test/loss': 11.212660881754156, 'eval/accuracy': 0.47619047619047616, 'test/f1_macro': 0.4575155010394708, 'eval/loss': 7.496162981420063, 'test/precision_macro': 0.47682669082125606, 'test/precision_weighted': 0.47436114497268506, 'eval/f1_macro': 0.4636040936750876, 'test/precision_micro': 0.4485981308411215, 'split': 10, '_wandb': {'runtime': 1865}, '_timestamp': 1704635522.9763749, 'test/recall_micro': 0.4485981308411215, 'eval/precision_macro': 0.5226247436773752, 'test/recall_weighted': 0.4485981308411215, 'eval/precision_weighted': 0.531936985320444, '_runtime': 1866.473828792572, 'test/accuracy': 0.4485981308411215, 'test/f1_micro': 0.4485981308411215, 'eval/f1_weighted': 0.4685839853182653, 'eval/recall_macro': 0.475, 'eval/precision_micro': 0.47619047619047616, 'eval/recall_weighted': 0.47619047619047616}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 34, 'dt_min_samples_leaf': 5}",pious-cherry-1238,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
101,"{'test/precision_macro': 0.7581330515297906, 'eval/f1_weighted': 0.7842755035737492, 'eval/precision_macro': 0.8190972222222223, 'split': 10, 'test/f1_macro': 0.75710645840257, 'eval/recall_micro': 0.7857142857142857, 'test/recall_micro': 0.7663551401869159, 'test/precision_micro': 0.7663551401869159, 'eval/accuracy': 0.7857142857142857, 'eval/f1_macro': 0.7836744639376219, 'test/recall_macro': 0.7622660903910903, 'eval/precision_micro': 0.7857142857142857, 'eval/recall_weighted': 0.7857142857142857, 'eval/precision_weighted': 0.820271164021164, '_timestamp': 1704635244.1273851, 'eval/recall_macro': 0.7840909090909092, 'test/recall_weighted': 0.7663551401869159, 'test/precision_weighted': 0.7690313708670068, 'eval/loss': 2.306903856770925, 'test/loss': 1.3000381652461448, 'eval/f1_micro': 0.7857142857142857, '_step': 20, 'test/accuracy': 0.7663551401869159, 'test/f1_micro': 0.766355140186916, 'test/f1_weighted': 0.7643354464125794, '_wandb': {'runtime': 2149}, '_runtime': 2150.856367111206}","{'rf_max_depth': 24, 'trial.number': 29}",cerulean-planet-1237,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
102,"{'_step': 20, 'split': 10, 'eval/accuracy': 0.5952380952380952, 'test/recall_macro': 0.4956107111279525, 'test/precision_micro': 0.5046728971962616, 'test/f1_weighted': 0.46600550053119816, 'eval/precision_micro': 0.5952380952380952, 'eval/recall_weighted': 0.5952380952380952, 'eval/loss': 2.3651432413757645, '_timestamp': 1704634526.2097232, 'eval/f1_macro': 0.5448021181716834, 'eval/f1_micro': 0.5952380952380952, 'test/accuracy': 0.5046728971962616, '_runtime': 1674.1015691757202, 'test/loss': 5.106230994004882, 'test/f1_micro': 0.5046728971962616, 'eval/precision_macro': 0.5755494505494505, 'eval/precision_weighted': 0.5765306122448979, 'test/precision_weighted': 0.47515221140519986, 'test/f1_macro': 0.4568768655374546, 'eval/f1_weighted': 0.5403793066836544, 'test/precision_macro': 0.4692219118091211, '_wandb': {'runtime': 1672}, 'eval/recall_macro': 0.6022727272727273, 'eval/recall_micro': 0.5952380952380952, 'test/recall_micro': 0.5046728971962616, 'test/recall_weighted': 0.5046728971962616}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 37, 'dt_min_samples_leaf': 10}",clean-aardvark-1236,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
103,"{'_step': 20, 'test/loss': 8.550937944651622, 'test/recall_micro': 0.514018691588785, 'eval/precision_micro': 0.5714285714285714, 'test/precision_macro': 0.5307157435303889, 'test/recall_weighted': 0.514018691588785, '_runtime': 2180.1858279705048, 'eval/f1_weighted': 0.5817700817700817, 'split': 10, 'eval/f1_macro': 0.5858585858585859, 'eval/f1_micro': 0.5714285714285714, 'test/f1_macro': 0.5101037146248285, 'eval/recall_macro': 0.575, 'test/recall_macro': 0.5090517241379311, '_timestamp': 1704635000.883131, 'test/accuracy': 0.514018691588785, 'test/f1_weighted': 0.5177998975328503, '_wandb': {'runtime': 2178}, 'eval/recall_micro': 0.5714285714285714, 'eval/recall_weighted': 0.5714285714285714, 'eval/precision_weighted': 0.6036833536833537, 'eval/loss': 4.033319887169416, 'test/f1_micro': 0.514018691588785, 'test/precision_weighted': 0.5424419356924328, 'eval/accuracy': 0.5714285714285714, 'eval/precision_macro': 0.608440170940171, 'test/precision_micro': 0.514018691588785}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 28, 'dt_min_samples_leaf': 7}",magic-bush-1235,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
104,"{'eval/recall_micro': 1, 'eval/precision_weighted': 1, 'train/train_samples_per_second': 42.506, 'train/train_runtime': 450.5255, 'eval/precision_macro': 1, 'train/total_flos': 4377445413802968.0, 'eval/recall_macro': 1, 'train/global_step': 1200, 'test/total_time_in_seconds': 0.7725338340096641, '_wandb': {'runtime': 4566}, 'eval/loss': 0, '_timestamp': 1704637352.7615223, 'test/accuracy': 0.5607476635514018, 'test/latency_in_seconds': 0.007219942373922095, 'train/loss': 0, 'train/epoch': 50, 'test/samples_per_second': 138.50526059763678, 'eval/samples_per_second': 122.194, 'train/train_steps_per_second': 2.664, '_runtime': 4567.907225608826, 'eval/f1_micro': 1, 'eval/f1_weighted': 1, 'train/learning_rate': 1.4403138729227843e-06, 'eval/steps_per_second': 8.728, '_step': 530, 'eval/precision_micro': 1, 'eval/recall_weighted': 1, 'eval/runtime': 0.3437, 'eval/accuracy': 1, 'eval/f1_macro': 1, 'train/train_loss': 1.0488182776195269e-07}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_13-06-27_erc-hpc-comp036', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 8.641883237536707e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",glorious-vortex-1234,Fine-Tuned LLM:bert-base-uncased,['preprocessed']
105,"{'test/f1_weighted': 0.5041989608077726, 'test/recall_micro': 0.4953271028037383, 'test/precision_macro': 0.5445939582729643, 'test/f1_micro': 0.4953271028037383, 'test/recall_macro': 0.501228051839465, '_step': 20, 'split': 10, 'eval/loss': 9.159972609315176, 'eval/accuracy': 0.4523809523809524, 'test/f1_macro': 0.5038651824366109, '_wandb': {'runtime': 1855}, 'eval/precision_micro': 0.4523809523809524, 'test/precision_weighted': 0.5561843106562638, 'eval/f1_micro': 0.4523809523809524, 'eval/precision_weighted': 0.4811507936507936, 'eval/f1_weighted': 0.44623463420455894, 'test/recall_weighted': 0.4953271028037383, '_runtime': 1858.0927441120148, '_timestamp': 1704633651.9502, 'eval/f1_macro': 0.4417521075415812, 'eval/recall_micro': 0.4523809523809524, 'eval/precision_macro': 0.4759469696969697, 'test/loss': 9.278907043516872, 'test/accuracy': 0.4953271028037383, 'eval/recall_macro': 0.45, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_micro': 0.4953271028037383}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 33, 'dt_min_samples_leaf': 6}",polished-valley-1233,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
106,"{'eval/loss': 0.9475732471716308, 'eval/f1_macro': 0.589975845410628, 'eval/f1_micro': 0.5952380952380952, 'eval/precision_macro': 0.6016483516483517, 'test/loss': 1.7354195679949873, 'eval/precision_weighted': 0.6019099947671377, 'test/recall_weighted': 0.4766355140186916, '_runtime': 1673.6680963039398, 'test/f1_weighted': 0.4680341465388195, 'eval/recall_micro': 0.5952380952380952, 'test/recall_micro': 0.4766355140186916, 'test/precision_macro': 0.46164898320070735, '_wandb': {'runtime': 1672}, 'test/accuracy': 0.4766355140186916, 'test/recall_macro': 0.470040735126942, '_timestamp': 1704632845.7165742, 'test/f1_macro': 0.46291486291486295, 'eval/precision_micro': 0.5952380952380952, 'split': 10, 'eval/recall_macro': 0.6, 'eval/recall_weighted': 0.5952380952380952, '_step': 20, 'eval/accuracy': 0.5952380952380952, 'test/precision_micro': 0.4766355140186916, 'test/precision_weighted': 0.465120602890503, 'test/f1_micro': 0.4766355140186916, 'eval/f1_weighted': 0.5875316310098919}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 36, 'dt_min_samples_leaf': 18}",atomic-sunset-1232,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
107,"{'eval/f1_micro': 0.6904761904761905, 'test/f1_micro': 0.794392523364486, 'eval/recall_macro': 0.6886363636363637, '_wandb': {'runtime': 2151}, 'eval/loss': 0.7690200554159288, 'eval/f1_weighted': 0.6753154253154253, 'test/recall_macro': 0.7854020979020979, 'eval/recall_weighted': 0.6904761904761905, 'eval/precision_weighted': 0.6768518518518518, 'test/accuracy': 0.794392523364486, 'eval/recall_micro': 0.6904761904761905, '_step': 20, 'split': 10, '_runtime': 2152.7772564888, 'test/loss': 0.6464023315399008, 'eval/precision_macro': 0.6784722222222221, 'test/precision_weighted': 0.7888003120918635, '_timestamp': 1704633084.7492936, 'test/f1_macro': 0.7799048801532018, 'test/f1_weighted': 0.7891338693248722, 'test/recall_micro': 0.794392523364486, 'eval/precision_micro': 0.6904761904761905, 'test/recall_weighted': 0.794392523364486, 'eval/accuracy': 0.6904761904761905, 'test/precision_micro': 0.794392523364486, 'eval/f1_macro': 0.6754273504273505, 'test/precision_macro': 0.7794464609800362}","{'rf_max_depth': 26, 'trial.number': 28}",fresh-energy-1231,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
108,"{'_runtime': 2186.0539984703064, 'eval/f1_micro': 0.7619047619047619, 'test/f1_weighted': 0.5607772631348151, 'eval/precision_macro': 0.8, '_step': 20, '_wandb': {'runtime': 2184}, 'eval/f1_weighted': 0.7715303215303215, 'test/recall_macro': 0.5474137931034482, 'test/recall_weighted': 0.5514018691588785, 'test/f1_micro': 0.5514018691588785, 'eval/recall_macro': 0.7590909090909091, 'test/precision_micro': 0.5514018691588785, 'test/precision_weighted': 0.5829186389934053, 'eval/loss': 2.912181725104748, 'eval/accuracy': 0.7619047619047619, 'test/accuracy': 0.5514018691588785, 'test/f1_macro': 0.5525351400546061, 'split': 10, 'eval/recall_micro': 0.7619047619047619, 'test/recall_micro': 0.5514018691588785, 'eval/precision_micro': 0.7619047619047619, 'eval/recall_weighted': 0.7619047619047619, 'eval/f1_macro': 0.7702991452991452, 'test/precision_macro': 0.5700197790715031, 'eval/precision_weighted': 0.8, 'test/loss': 8.484242032146772, '_timestamp': 1704632815.4899344}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 27, 'dt_min_samples_leaf': 6}",icy-donkey-1230,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
109,"{'eval/precision_micro': 0.47619047619047616, 'test/recall_weighted': 0.4953271028037383, 'test/loss': 9.248500109387646, 'eval/accuracy': 0.47619047619047616, 'eval/recall_weighted': 0.47619047619047616, '_timestamp': 1704631786.0989125, 'eval/f1_macro': 0.4577926421404682, 'eval/precision_macro': 0.5141941391941391, 'test/precision_weighted': 0.5741120864706698, 'test/f1_macro': 0.5000136290454065, 'test/f1_micro': 0.4953271028037383, 'eval/precision_weighted': 0.5118175475318333, 'test/recall_macro': 0.5060880016722408, 'test/precision_macro': 0.5574814439946019, 'split': 10, '_runtime': 1845.574243545532, 'eval/f1_micro': 0.47619047619047616, 'eval/f1_weighted': 0.4598439241917503, '_step': 20, '_wandb': {'runtime': 1844}, 'test/recall_micro': 0.4953271028037383, 'eval/loss': 8.261744085688079, 'eval/recall_macro': 0.4727272727272727, 'test/precision_micro': 0.4953271028037383, 'test/accuracy': 0.4953271028037383, 'test/f1_weighted': 0.4978988437941167, 'eval/recall_micro': 0.47619047619047616}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 32, 'dt_min_samples_leaf': 5}",flowing-darkness-1229,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
110,"{'eval/loss': 5.00804006783861, 'eval/accuracy': 0.5714285714285714, 'eval/recall_weighted': 0.5714285714285714, 'test/precision_micro': 0.5981308411214953, 'test/recall_weighted': 0.5981308411214953, 'test/f1_micro': 0.5981308411214953, 'eval/f1_macro': 0.526946386946387, 'eval/f1_micro': 0.5714285714285714, 'test/f1_weighted': 0.581512888054944, 'test/precision_macro': 0.5803268422753717, 'test/precision_weighted': 0.5831228968941997, '_step': 20, 'test/f1_macro': 0.573938223938224, 'eval/f1_weighted': 0.5228327228327229, 'eval/recall_macro': 0.5795454545454546, 'eval/recall_micro': 0.5714285714285714, 'test/recall_micro': 0.5981308411214953, 'eval/precision_macro': 0.5663419913419914, '_wandb': {'runtime': 1676}, 'test/loss': 5.61508181763214, '_timestamp': 1704631166.330619, 'split': 10, '_runtime': 1678.258295297623, 'test/accuracy': 0.5981308411214953, 'test/recall_macro': 0.587177908298598, 'eval/precision_micro': 0.5714285714285714, 'eval/precision_weighted': 0.5685941043083901}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 35, 'dt_min_samples_leaf': 6}",fresh-universe-1228,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
111,"{'_runtime': 2152.67631316185, 'test/accuracy': 0.8130841121495327, '_wandb': {'runtime': 2150}, 'eval/f1_micro': 0.6666666666666666, 'test/f1_weighted': 0.8083390042543085, 'eval/recall_micro': 0.6666666666666666, 'eval/recall_weighted': 0.6666666666666666, 'test/loss': 0.99144864262627, 'eval/f1_weighted': 0.6545512942018913, 'test/recall_weighted': 0.8130841121495327, 'eval/f1_macro': 0.6544781070322866, 'eval/recall_macro': 0.6636363636363637, 'test/precision_macro': 0.8206582633053221, 'test/precision_micro': 0.8130841121495327, '_step': 20, 'eval/loss': 1.6701589929955425, 'split': 10, 'test/f1_macro': 0.8017200141428007, '_timestamp': 1704630926.118637, 'eval/accuracy': 0.6666666666666666, 'test/recall_micro': 0.8130841121495327, 'eval/precision_macro': 0.6823004201680672, 'eval/precision_micro': 0.6666666666666666, 'eval/precision_weighted': 0.6800970388155262, 'test/precision_weighted': 0.8208015916647033, 'test/f1_micro': 0.8130841121495327, 'test/recall_macro': 0.800972465034965}","{'rf_max_depth': 24, 'trial.number': 27}",iconic-dragon-1227,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
112,"{'eval/f1_micro': 0.7619047619047619, 'eval/recall_macro': 0.7613636363636365, 'eval/precision_weighted': 0.8072562358276644, '_runtime': 2174.7495889663696, 'eval/f1_macro': 0.7718394471026051, 'eval/recall_micro': 0.7619047619047619, 'test/recall_macro': 0.5387931034482758, 'test/recall_micro': 0.5420560747663551, 'split': 10, 'eval/precision_micro': 0.7619047619047619, 'test/precision_micro': 0.5420560747663551, '_step': 20, '_timestamp': 1704630624.883465, 'test/accuracy': 0.5420560747663551, 'eval/f1_weighted': 0.7722781701729071, 'test/f1_macro': 0.5427582602679981, 'test/f1_micro': 0.5420560747663551, 'test/f1_weighted': 0.5518403244189432, 'eval/precision_macro': 0.8065476190476191, 'test/precision_macro': 0.5629549214226633, 'test/precision_weighted': 0.5779554432101914, 'test/recall_weighted': 0.5420560747663551, '_wandb': {'runtime': 2173}, 'eval/loss': 2.92183565625018, 'test/loss': 7.871414050021896, 'eval/accuracy': 0.7619047619047619, 'eval/recall_weighted': 0.7619047619047619}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 26, 'dt_min_samples_leaf': 6}",lucky-dream-1226,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
113,"{'_timestamp': 1704629935.5745308, 'eval/f1_micro': 0.4523809523809524, 'test/precision_micro': 0.4953271028037383, 'eval/precision_weighted': 0.4676314970432618, 'test/precision_weighted': 0.5540197387366161, 'eval/accuracy': 0.4523809523809524, 'test/accuracy': 0.4953271028037383, 'eval/f1_weighted': 0.44312169312169314, 'eval/precision_macro': 0.4634878193701723, '_step': 20, 'test/recall_micro': 0.4953271028037383, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_macro': 0.5423669467787114, 'test/recall_weighted': 0.4953271028037383, 'test/f1_macro': 0.5029452690166976, 'test/f1_weighted': 0.5033048393529035, 'eval/f1_macro': 0.43914141414141417, 'test/recall_macro': 0.501228051839465, 'eval/precision_micro': 0.4523809523809524, '_runtime': 1816.4503407478333, 'eval/loss': 9.151480348745205, 'eval/recall_macro': 0.45, 'eval/recall_micro': 0.4523809523809524, 'split': 10, '_wandb': {'runtime': 1815}, 'test/loss': 8.302362878096622, 'test/f1_micro': 0.4953271028037383}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 31, 'dt_min_samples_leaf': 6}",laced-grass-1225,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
114,"{'eval/loss': 3.2082435637376547, 'eval/recall_macro': 0.6204545454545455, 'eval/recall_micro': 0.6190476190476191, 'test/precision_weighted': 0.47320606693171646, 'test/recall_weighted': 0.4953271028037383, '_wandb': {'runtime': 1656}, 'eval/accuracy': 0.6190476190476191, 'eval/f1_micro': 0.6190476190476191, 'test/f1_micro': 0.4953271028037383, 'test/recall_macro': 0.49058197549576854, '_step': 20, 'split': 10, 'eval/precision_macro': 0.5787878787878787, 'eval/recall_weighted': 0.6190476190476191, 'test/precision_micro': 0.4953271028037383, 'test/f1_macro': 0.4671954062197965, 'test/recall_micro': 0.4953271028037383, 'eval/precision_micro': 0.6190476190476191, 'test/precision_macro': 0.4656472009093493, '_runtime': 1657.6952929496765, 'eval/f1_macro': 0.583562271062271, 'eval/f1_weighted': 0.5818724925867782, 'eval/precision_weighted': 0.5782106782106782, 'test/loss': 7.919433523526004, '_timestamp': 1704629482.4042718, 'test/accuracy': 0.4953271028037383, 'test/f1_weighted': 0.4735850730835914}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 34, 'dt_min_samples_leaf': 8}",fiery-dream-1224,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
115,"{'test/accuracy': 0.7850467289719626, 'eval/f1_weighted': 0.782685881370092, 'eval/recall_macro': 0.7840909090909092, 'test/precision_weighted': 0.7848959757928308, '_timestamp': 1704628768.3261502, 'eval/f1_macro': 0.7829944178628389, '_wandb': {'runtime': 2125}, 'eval/precision_macro': 0.7872960372960373, 'eval/recall_weighted': 0.7857142857142857, 'test/precision_macro': 0.7696983966000193, 'eval/precision_weighted': 0.7851037851037852, 'test/f1_macro': 0.7640505680759919, 'eval/f1_micro': 0.7857142857142857, 'test/f1_weighted': 0.7791987172234282, '_step': 20, 'eval/recall_micro': 0.7857142857142857, 'test/recall_micro': 0.7850467289719626, 'test/recall_weighted': 0.7850467289719626, 'eval/accuracy': 0.7857142857142857, '_runtime': 2127.0949881076813, 'test/loss': 1.6133609978688297, 'split': 10, 'test/recall_macro': 0.7704873251748252, 'eval/precision_micro': 0.7857142857142857, 'test/precision_micro': 0.7850467289719626, 'eval/loss': 1.5160979249150015, 'test/f1_micro': 0.7850467289719625}","{'rf_max_depth': 32, 'trial.number': 26}",gallant-sun-1223,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
116,"{'test/precision_weighted': 0.5113014884042921, '_step': 20, '_wandb': {'runtime': 1800}, 'eval/f1_weighted': 0.42025699168556313, 'split': 10, 'eval/loss': 6.939134970100561, 'test/f1_micro': 0.4672897196261683, 'test/f1_weighted': 0.4710195412064571, 'eval/recall_micro': 0.4523809523809524, '_runtime': 1801.991545200348, '_timestamp': 1704628112.0631332, 'eval/f1_macro': 0.4134920634920635, 'eval/precision_macro': 0.42931547619047616, 'test/precision_micro': 0.4672897196261682, 'test/f1_macro': 0.47306818181818183, 'test/recall_macro': 0.47669314381270905, 'eval/precision_micro': 0.4523809523809524, 'test/precision_macro': 0.5025462962962963, 'test/recall_weighted': 0.4672897196261682, 'eval/recall_macro': 0.44545454545454544, 'test/recall_micro': 0.4672897196261682, 'eval/recall_weighted': 0.4523809523809524, 'test/accuracy': 0.4672897196261682, 'eval/precision_weighted': 0.4358701814058956, 'test/loss': 5.257745036349893, 'eval/accuracy': 0.4523809523809524, 'eval/f1_micro': 0.4523809523809524}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 30, 'dt_min_samples_leaf': 8}",dashing-hill-1222,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
117,"{'eval/accuracy': 0.7380952380952381, 'eval/f1_macro': 0.7486826039457619, 'test/f1_weighted': 0.5518403244189432, 'eval/precision_weighted': 0.787012987012987, 'test/loss': 9.151477168573637, 'test/recall_micro': 0.5420560747663551, '_runtime': 2159.2185118198395, 'test/f1_macro': 0.5427582602679981, 'test/precision_macro': 0.5629549214226633, 'eval/recall_weighted': 0.7380952380952381, 'test/precision_weighted': 0.5779554432101914, '_step': 20, 'split': 10, '_timestamp': 1704628444.2332768, 'test/f1_micro': 0.5420560747663551, 'eval/precision_micro': 0.7380952380952381, '_wandb': {'runtime': 2157}, 'eval/loss': 2.9781957423009326, 'eval/f1_micro': 0.7380952380952381, 'test/precision_micro': 0.5420560747663551, 'test/recall_weighted': 0.5420560747663551, 'eval/f1_weighted': 0.7495646931737157, 'eval/recall_macro': 0.7363636363636363, 'eval/recall_micro': 0.7380952380952381, 'test/recall_macro': 0.5387931034482758, 'eval/precision_macro': 0.7863636363636364, 'test/accuracy': 0.5420560747663551}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 25, 'dt_min_samples_leaf': 6}",lemon-sea-1221,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
118,"{'eval/accuracy': 0.5952380952380952, 'eval/recall_weighted': 0.5952380952380952, 'test/precision_micro': 0.5981308411214953, 'test/precision_weighted': 0.5710130441301414, 'eval/f1_micro': 0.5952380952380952, 'eval/recall_micro': 0.5952380952380952, 'test/loss': 6.2024398231285955, '_timestamp': 1704627820.418868, 'eval/f1_macro': 0.553949673514891, 'test/recall_weighted': 0.5981308411214953, 'split': 10, 'test/f1_macro': 0.5606812567224435, 'test/recall_macro': 0.586262157382847, 'eval/precision_macro': 0.5621794871794872, 'test/f1_micro': 0.5981308411214953, 'eval/recall_macro': 0.6045454545454545, 'eval/precision_micro': 0.5952380952380952, 'eval/f1_weighted': 0.5491130677466081, 'test/recall_micro': 0.5981308411214953, '_wandb': {'runtime': 1656}, '_runtime': 1657.8288280963898, 'test/accuracy': 0.5981308411214953, 'test/f1_weighted': 0.5701198508429409, '_step': 20, 'eval/loss': 5.661034536793448, 'test/precision_macro': 0.5664438502673796, 'eval/precision_weighted': 0.5623931623931624}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 33, 'dt_min_samples_leaf': 6}",wild-universe-1220,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
119,"{'test/f1_macro': 0.7650370804059328, 'test/recall_weighted': 0.7850467289719626, 'test/precision_weighted': 0.7798904286174668, 'eval/loss': 0.6978422303975227, 'eval/precision_macro': 0.8204365079365079, 'test/accuracy': 0.7850467289719626, 'test/precision_micro': 0.7850467289719626, 'eval/precision_weighted': 0.8204837490551776, 'eval/recall_weighted': 0.8095238095238095, 'test/loss': 0.6585015752389571, '_timestamp': 1704626636.4175286, 'eval/accuracy': 0.8095238095238095, 'eval/precision_micro': 0.8095238095238095, 'eval/f1_weighted': 0.8097076023391814, 'eval/recall_macro': 0.8045454545454545, 'test/recall_micro': 0.7850467289719626, 'test/precision_macro': 0.7629310344827587, '_wandb': {'runtime': 2124}, 'test/f1_micro': 0.7850467289719625, 'test/recall_macro': 0.7704873251748252, '_step': 20, 'split': 10, 'eval/f1_micro': 0.8095238095238095, 'test/f1_weighted': 0.7807608687722063, '_runtime': 2125.390656709671, 'eval/f1_macro': 0.8071929824561404, 'eval/recall_micro': 0.8095238095238095}","{'rf_max_depth': 17, 'trial.number': 25}",sage-snowflake-1219,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
120,"{'eval/f1_macro': 0.6574925074925075, 'eval/f1_weighted': 0.6541775684632828, 'test/f1_weighted': 0.5715148763353387, 'test/precision_weighted': 0.5738780096849138, '_wandb': {'runtime': 1655}, 'test/accuracy': 0.6074766355140186, 'eval/recall_micro': 0.6904761904761905, 'eval/precision_macro': 0.6747159090909092, 'eval/precision_micro': 0.6904761904761905, 'eval/precision_weighted': 0.6761363636363636, '_runtime': 1657.091649055481, 'split': 10, 'eval/recall_weighted': 0.6904761904761905, 'test/precision_macro': 0.568493633085418, 'test/precision_micro': 0.6074766355140186, '_step': 20, 'test/recall_micro': 0.6074766355140186, 'eval/accuracy': 0.6904761904761905, 'test/loss': 6.480100938264622, 'eval/f1_micro': 0.6904761904761905, 'eval/loss': 5.542510487584397, 'test/f1_micro': 0.6074766355140186, 'eval/recall_macro': 0.6977272727272728, 'test/f1_macro': 0.560572705802969, 'test/recall_weighted': 0.6074766355140186, '_timestamp': 1704626157.603349, 'test/recall_macro': 0.5940815649867375}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 32, 'dt_min_samples_leaf': 6}",zesty-pond-1218,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
121,"{'_step': 20, 'test/accuracy': 0.4766355140186916, 'eval/f1_weighted': 0.4733044733044732, 'eval/recall_weighted': 0.47619047619047616, 'test/precision_macro': 0.487962962962963, 'eval/precision_weighted': 0.4742063492063493, 'test/f1_micro': 0.4766355140186916, 'test/recall_micro': 0.4766355140186916, 'test/recall_weighted': 0.4766355140186916, 'test/loss': 4.321435920473417, 'test/f1_macro': 0.478598901098901, 'test/precision_micro': 0.4766355140186916, 'split': 10, '_wandb': {'runtime': 1837}, 'eval/precision_macro': 0.47064393939393945, '_timestamp': 1704626305.0957272, 'eval/accuracy': 0.47619047619047616, 'eval/f1_micro': 0.47619047619047616, 'test/f1_weighted': 0.475359967135668, 'eval/f1_macro': 0.4696969696969697, 'eval/recall_macro': 0.4727272727272728, 'test/recall_macro': 0.4863085284280937, 'eval/precision_micro': 0.47619047619047616, '_runtime': 1839.1627662181857, 'eval/loss': 3.6638990272632426, 'eval/recall_micro': 0.47619047619047616, 'test/precision_weighted': 0.4933887158186224}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 29, 'dt_min_samples_leaf': 12}",bumbling-disco-1217,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
122,"{'eval/recall_macro': 0.6863636363636364, 'eval/recall_micro': 0.6904761904761905, 'eval/accuracy': 0.6904761904761905, 'test/recall_macro': 0.5387931034482758, 'split': 10, 'eval/loss': 3.829528392697727, 'eval/f1_micro': 0.6904761904761905, '_step': 20, 'test/precision_micro': 0.5420560747663551, 'eval/precision_micro': 0.6904761904761905, 'eval/f1_weighted': 0.7008095635915185, 'test/recall_weighted': 0.5420560747663551, 'test/precision_weighted': 0.5779554432101914, 'test/f1_micro': 0.5420560747663551, 'eval/f1_macro': 0.6987259816207185, 'test/accuracy': 0.5420560747663551, 'test/f1_weighted': 0.5518403244189432, 'test/recall_micro': 0.5420560747663551, 'eval/recall_weighted': 0.6904761904761905, '_timestamp': 1704626278.1602223, '_runtime': 2160.153481245041, 'test/loss': 8.830646748377138, 'eval/precision_weighted': 0.7444755680049797, '_wandb': {'runtime': 2158}, 'eval/precision_macro': 0.7434640522875817, 'test/precision_macro': 0.5629549214226633, 'test/f1_macro': 0.5427582602679981}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 24, 'dt_min_samples_leaf': 6}",still-pine-1216,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
123,"{'eval/f1_macro': 0.6711038961038961, 'test/f1_micro': 0.7570093457943925, '_step': 20, 'split': 10, '_runtime': 1798.515188217163, 'test/loss': 0.6854652377839887, 'eval/f1_weighted': 0.675170068027211, 'eval/recall_macro': 0.6818181818181819, 'test/recall_micro': 0.7570093457943925, 'test/precision_weighted': 0.7442515947188845, 'test/recall_macro': 0.7536858974358974, 'test/precision_macro': 0.7436507936507937, 'eval/precision_weighted': 0.7408963585434174, '_timestamp': 1704625912.7458591, 'eval/accuracy': 0.6904761904761905, 'test/f1_macro': 0.7424208144796381, 'eval/recall_micro': 0.6904761904761905, 'eval/precision_micro': 0.6904761904761905, 'eval/loss': 1.6072919825062555, 'eval/precision_macro': 0.7435828877005348, '_wandb': {'runtime': 1797}, 'test/f1_weighted': 0.7444919017211487, 'test/precision_micro': 0.7570093457943925, 'eval/f1_micro': 0.6904761904761905, 'test/accuracy': 0.7570093457943925, 'eval/recall_weighted': 0.6904761904761905, 'test/recall_weighted': 0.7570093457943925}","{'rf_max_depth': 19, 'trial.number': 29}",volcanic-star-1215,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
124,"{'split': 10, 'test/f1_weighted': 0.5822857763691175, 'eval/f1_weighted': 0.6097469817966712, '_runtime': 1657.1688296794891, 'eval/f1_macro': 0.6149237718802937, 'test/f1_micro': 0.6074766355140186, 'test/recall_micro': 0.6074766355140186, 'eval/f1_micro': 0.6666666666666666, 'test/accuracy': 0.6074766355140186, 'eval/precision_macro': 0.6083333333333334, '_timestamp': 1704624494.4777756, 'eval/accuracy': 0.6666666666666666, 'eval/recall_micro': 0.6666666666666666, 'eval/precision_micro': 0.6666666666666666, '_step': 20, '_wandb': {'runtime': 1655}, 'test/f1_macro': 0.5749940020502082, 'test/precision_micro': 0.6074766355140186, 'eval/recall_macro': 0.675, 'test/precision_macro': 0.5905525846702318, 'test/recall_weighted': 0.6074766355140186, 'test/precision_weighted': 0.5921768537491462, 'eval/loss': 5.559879888173226, 'test/loss': 7.46778711734625, 'test/recall_macro': 0.5976735190097259, 'eval/recall_weighted': 0.6666666666666666, 'eval/precision_weighted': 0.6071428571428571}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 31, 'dt_min_samples_leaf': 6}",worldly-elevator-1214,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
125,"{'test/recall_macro': 0.47669314381270905, 'test/recall_micro': 0.4672897196261682, 'test/f1_weighted': 0.4702193400724776, 'test/recall_weighted': 0.4672897196261682, '_step': 20, 'eval/f1_macro': 0.4118107769423559, 'test/f1_macro': 0.4722448979591837, 'split': 10, '_runtime': 1845.1767129898071, 'eval/recall_weighted': 0.4523809523809524, 'eval/accuracy': 0.4523809523809524, 'test/precision_macro': 0.499194847020934, 'test/precision_micro': 0.4672897196261682, '_wandb': {'runtime': 1843}, 'eval/f1_micro': 0.4523809523809524, 'eval/recall_macro': 0.44545454545454544, 'test/loss': 7.13057357361822, '_timestamp': 1704624459.692076, 'eval/f1_weighted': 0.4180988184747582, 'test/accuracy': 0.4672897196261682, 'eval/precision_weighted': 0.4228316326530612, 'eval/precision_macro': 0.4174107142857143, 'eval/precision_micro': 0.4523809523809524, 'test/precision_weighted': 0.5080440049964634, 'eval/loss': 8.411959755712363, 'test/f1_micro': 0.4672897196261683, 'eval/recall_micro': 0.4523809523809524}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 28, 'dt_min_samples_leaf': 8}",valiant-bee-1213,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
126,"{'_step': 20, 'eval/f1_micro': 0.6666666666666666, 'test/f1_weighted': 0.7487376969522318, '_wandb': {'runtime': 2125}, '_runtime': 2127.236277103424, '_timestamp': 1704624505.8936172, 'eval/accuracy': 0.6666666666666666, 'eval/f1_macro': 0.6557572290409819, 'test/recall_macro': 0.7416958041958042, 'test/recall_weighted': 0.7570093457943925, 'test/f1_micro': 0.7570093457943925, 'eval/f1_weighted': 0.6573300841035395, 'eval/precision_micro': 0.6666666666666666, 'eval/precision_weighted': 0.6567460317460317, 'split': 10, 'test/precision_micro': 0.7570093457943925, 'test/f1_macro': 0.7374835984910613, 'eval/recall_macro': 0.6659090909090909, 'eval/recall_micro': 0.6666666666666666, 'test/recall_micro': 0.7570093457943925, 'eval/precision_macro': 0.6541666666666666, 'test/precision_macro': 0.7384632102177742, 'test/precision_weighted': 0.7451200654286853, 'eval/loss': 0.7930438680344627, 'test/loss': 0.6905047246838736, 'test/accuracy': 0.7570093457943925, 'eval/recall_weighted': 0.6666666666666666}","{'rf_max_depth': 23, 'trial.number': 24}",sweet-dew-1212,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
127,"{'eval/accuracy': 0.7619047619047619, 'test/f1_macro': 0.7665836634597246, 'test/f1_weighted': 0.7667214967375227, 'test/recall_micro': 0.7757009345794392, 'eval/recall_weighted': 0.7619047619047619, 'eval/recall_micro': 0.7619047619047619, '_runtime': 1800.248197555542, 'eval/loss': 0.6332894545768426, 'test/accuracy': 0.7757009345794392, 'test/f1_micro': 0.7757009345794392, 'eval/precision_micro': 0.7619047619047619, 'test/precision_micro': 0.7757009345794392, 'split': 10, '_wandb': {'runtime': 1797}, 'eval/precision_weighted': 0.7984360410830998, 'test/precision_weighted': 0.7748662224805855, 'test/loss': 1.638852035017663, 'eval/f1_macro': 0.7592940685045948, 'test/recall_weighted': 0.7757009345794392, '_timestamp': 1704624109.3006616, 'eval/f1_micro': 0.7619047619047619, 'eval/f1_weighted': 0.7618948164060948, 'test/recall_macro': 0.7803125, 'eval/precision_macro': 0.7971813725490196, 'test/precision_macro': 0.7712041467304626, '_step': 20, 'eval/recall_macro': 0.7568181818181818}","{'rf_max_depth': 25, 'trial.number': 28}",fresh-salad-1211,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
128,"{'test/f1_micro': 0.5514018691588785, 'eval/recall_micro': 0.7619047619047619, 'test/recall_micro': 0.5514018691588785, 'eval/precision_macro': 0.8, '_timestamp': 1704624113.426924, 'eval/accuracy': 0.7619047619047619, 'test/precision_macro': 0.5700197790715031, 'split': 10, 'test/accuracy': 0.5514018691588785, 'eval/precision_micro': 0.7619047619047619, 'test/loss': 8.497198054213314, 'test/precision_micro': 0.5514018691588785, 'test/precision_weighted': 0.5829186389934053, 'eval/f1_weighted': 0.7715303215303215, 'test/recall_macro': 0.5474137931034482, 'eval/recall_weighted': 0.7619047619047619, 'eval/precision_weighted': 0.8, 'test/f1_macro': 0.5525351400546061, 'test/recall_weighted': 0.5514018691588785, '_step': 20, 'eval/loss': 3.7772135218087697, 'eval/f1_micro': 0.7619047619047619, 'eval/recall_macro': 0.7590909090909091, '_wandb': {'runtime': 2155}, '_runtime': 2156.6407721042633, 'eval/f1_macro': 0.7702991452991452, 'test/f1_weighted': 0.5607772631348151}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 23, 'dt_min_samples_leaf': 6}",rare-galaxy-1210,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
129,"{'eval/f1_macro': 0.5883838383838385, 'eval/recall_micro': 0.5952380952380952, 'eval/precision_weighted': 0.5941043083900228, 'split': 10, 'test/f1_micro': 0.4672897196261683, 'test/recall_micro': 0.4672897196261682, 'test/precision_weighted': 0.4521984478329781, 'test/f1_macro': 0.45171320259531966, 'test/precision_macro': 0.44683592962290786, 'test/precision_micro': 0.4672897196261682, '_runtime': 1656.3103988170624, 'eval/accuracy': 0.5952380952380952, 'test/recall_macro': 0.4616134583806998, 'test/recall_weighted': 0.4672897196261682, '_wandb': {'runtime': 1654}, 'test/accuracy': 0.4672897196261682, 'eval/f1_weighted': 0.5860990860990862, 'eval/recall_weighted': 0.5952380952380952, '_step': 20, 'eval/loss': 2.455479850296938, 'eval/f1_micro': 0.5952380952380952, 'test/loss': 5.142460757786363, '_timestamp': 1704622832.5420618, 'eval/recall_macro': 0.6, 'test/f1_weighted': 0.45735988973366154, 'eval/precision_macro': 0.5936147186147187, 'eval/precision_micro': 0.5952380952380952}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 30, 'dt_min_samples_leaf': 11}",bright-sun-1209,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
130,"{'test/f1_micro': 0.4392523364485981, 'eval/precision_macro': 0.5226247436773752, 'test/precision_macro': 0.4696872820274355, 'split': 10, '_timestamp': 1704622610.1101367, 'eval/f1_micro': 0.47619047619047616, 'test/loss': 11.545124898201552, 'test/precision_weighted': 0.46806328456542384, 'eval/recall_micro': 0.47619047619047616, 'test/recall_micro': 0.4392523364485981, 'eval/recall_weighted': 0.47619047619047616, 'test/precision_micro': 0.4392523364485981, 'test/recall_weighted': 0.4392523364485981, 'eval/recall_macro': 0.475, 'test/recall_macro': 0.4338158444816054, 'eval/precision_micro': 0.47619047619047616, '_step': 20, '_runtime': 1844.7942497730255, 'test/accuracy': 0.4392523364485981, 'eval/f1_weighted': 0.4685839853182653, 'test/f1_weighted': 0.44981427042253913, 'test/f1_macro': 0.4474924792721403, '_wandb': {'runtime': 1843}, 'eval/accuracy': 0.47619047619047616, 'eval/f1_macro': 0.4636040936750876, 'eval/loss': 7.474911214628234, 'eval/precision_weighted': 0.531936985320444}","{'dt_criterion': 'gini', 'dt_max_depth': 16, 'trial.number': 27, 'dt_min_samples_leaf': 5}",dutiful-capybara-1208,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
131,"{'split': 10, 'eval/accuracy': 0.6904761904761905, 'eval/f1_micro': 0.6904761904761905, '_step': 20, '_wandb': {'runtime': 1795}, 'eval/recall_weighted': 0.6904761904761905, 'eval/precision_weighted': 0.7076719576719577, 'eval/f1_macro': 0.6886363636363636, 'eval/f1_weighted': 0.6963203463203463, 'test/precision_macro': 0.7121794871794872, 'test/recall_micro': 0.7289719626168224, 'test/precision_micro': 0.7289719626168224, 'test/precision_weighted': 0.7217289719626168, 'test/loss': 1.02995204767064, 'test/f1_micro': 0.7289719626168223, 'test/recall_weighted': 0.7289719626168224, '_runtime': 1796.9645566940308, 'eval/loss': 2.341940132213187, '_timestamp': 1704622304.6485908, 'test/recall_macro': 0.7248397435897436, 'test/accuracy': 0.7289719626168224, 'eval/recall_micro': 0.6904761904761905, 'eval/precision_micro': 0.6904761904761905, 'test/f1_macro': 0.7004564027590343, 'test/f1_weighted': 0.7080942230966825, 'eval/recall_macro': 0.6840909090909091, 'eval/precision_macro': 0.6986111111111112}","{'rf_max_depth': 16, 'trial.number': 27}",driven-serenity-1207,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
132,"{'test/loss': 0.6674017626338982, 'test/accuracy': 0.7757009345794392, 'split': 10, 'test/precision_macro': 0.7678571428571428, 'test/recall_weighted': 0.7757009345794392, 'eval/precision_weighted': 0.6848151848151848, '_timestamp': 1704622370.9377344, 'test/recall_macro': 0.7626748251748252, 'eval/recall_weighted': 0.6904761904761905, 'test/precision_micro': 0.7757009345794392, 'eval/loss': 0.7757431655090018, 'eval/recall_macro': 0.6909090909090909, 'eval/recall_micro': 0.6904761904761905, 'test/recall_micro': 0.7757009345794392, 'eval/precision_micro': 0.6904761904761905, '_wandb': {'runtime': 2125}, 'eval/precision_macro': 0.6812354312354312, '_step': 20, 'eval/f1_macro': 0.6714890501655206, 'test/f1_macro': 0.7538829151732378, 'test/f1_micro': 0.7757009345794392, '_runtime': 2126.3844084739685, 'eval/f1_micro': 0.6904761904761905, 'eval/f1_weighted': 0.6725432597281337, 'test/f1_weighted': 0.7635301868042297, 'test/precision_weighted': 0.7716955941255006, 'eval/accuracy': 0.6904761904761905}","{'rf_max_depth': 12, 'trial.number': 23}",celestial-puddle-1206,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
133,"{'test/loss': 5.186108696067126, 'eval/recall_micro': 0.6428571428571429, 'eval/recall_weighted': 0.6428571428571429, 'split': 10, '_runtime': 2159.8932077884674, 'test/f1_micro': 0.5046728971962616, 'eval/precision_macro': 0.6096153846153846, 'test/precision_micro': 0.5046728971962616, 'test/recall_weighted': 0.5046728971962616, 'test/precision_weighted': 0.4941255006675566, 'eval/accuracy': 0.6428571428571429, 'test/f1_weighted': 0.4964739379457931, 'eval/recall_macro': 0.6499999999999999, '_step': 20, '_wandb': {'runtime': 2158}, 'test/accuracy': 0.5046728971962616, 'test/f1_macro': 0.4995860314903688, 'test/recall_micro': 0.5046728971962616, '_timestamp': 1704621952.6748998, 'eval/f1_macro': 0.6148715415019763, 'eval/f1_micro': 0.6428571428571429, 'eval/precision_micro': 0.6428571428571429, 'test/precision_macro': 0.49642857142857144, 'eval/loss': 0.7857751120855804, 'eval/precision_weighted': 0.607967032967033, 'eval/f1_weighted': 0.6101778656126482, 'test/recall_macro': 0.5081896551724138}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 22, 'dt_min_samples_leaf': 11}",skilled-shadow-1205,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
134,"{'train/epoch': 10, 'eval/recall_micro': 1, 'test/samples_per_second': 128.73124010132585, '_runtime': 1018.9164698123932, 'eval/f1_macro': 1, 'eval/loss': 0, 'eval/f1_weighted': 1, 'train/train_loss': 2.483526717611539e-10, 'eval/recall_macro': 1, 'train/train_samples_per_second': 37.77, '_timestamp': 1704620646.128919, 'test/accuracy': 0.5887850467289719, 'eval/precision_macro': 1, 'eval/precision_weighted': 1, '_wandb': {'runtime': 1017}, 'eval/recall_weighted': 1, 'train/global_step': 240, 'test/latency_in_seconds': 0.007768122168425383, 'eval/precision_micro': 1, 'eval/steps_per_second': 8.167, 'test/total_time_in_seconds': 0.831189072021516, 'train/train_steps_per_second': 2.367, '_step': 110, 'eval/accuracy': 1, 'eval/f1_micro': 1, 'train/total_flos': 987128183238912.0, 'eval/runtime': 0.3673, 'train/train_runtime': 101.4028, 'eval/samples_per_second': 114.342}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_09-27-11_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.3722934572566398e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",iconic-galaxy-1204,Fine-Tuned LLM:microsoft/codebert-base,['preprocessed']
135,"{'eval/f1_micro': 0.6428571428571429, 'test/recall_macro': 0.5786361626878869, 'eval/precision_weighted': 0.5881301238444097, '_step': 20, 'eval/loss': 5.625518944489217, 'test/precision_macro': 0.5549204007621857, 'test/precision_weighted': 0.5596941146598974, 'eval/accuracy': 0.6428571428571429, 'test/f1_macro': 0.5537189748564961, 'eval/precision_macro': 0.5883699633699634, 'eval/recall_weighted': 0.6428571428571429, '_wandb': {'runtime': 1658}, 'test/loss': 6.8234355230279595, 'eval/f1_weighted': 0.5895198659173815, 'eval/recall_macro': 0.65, '_timestamp': 1704621170.9036007, 'test/accuracy': 0.5887850467289719, 'test/f1_micro': 0.5887850467289719, 'eval/f1_macro': 0.5936853002070394, 'test/precision_micro': 0.5887850467289719, 'test/recall_weighted': 0.5887850467289719, 'split': 10, 'test/f1_weighted': 0.5621654377124603, 'eval/recall_micro': 0.6428571428571429, 'test/recall_micro': 0.5887850467289719, '_runtime': 1659.7231287956238, 'eval/precision_micro': 0.6428571428571429}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 29, 'dt_min_samples_leaf': 6}",fearless-surf-1203,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
136,"{'eval/f1_weighted': 0.4613553113553114, 'eval/precision_micro': 0.47619047619047616, 'test/precision_macro': 0.5702214452214452, '_timestamp': 1704620760.3297195, 'eval/recall_micro': 0.47619047619047616, '_runtime': 1841.2552185058591, 'eval/f1_macro': 0.4582867132867132, 'eval/recall_weighted': 0.47619047619047616, 'test/loss': 10.501281098852443, 'eval/accuracy': 0.47619047619047616, 'test/recall_micro': 0.5046728971962616, 'test/recall_weighted': 0.5046728971962616, 'test/f1_micro': 0.5046728971962616, 'test/f1_weighted': 0.506869422883996, 'eval/precision_macro': 0.5184149184149184, 'test/precision_micro': 0.5046728971962616, '_step': 20, 'eval/loss': 9.88814444676976, 'eval/f1_micro': 0.47619047619047616, 'test/accuracy': 0.5046728971962616, '_wandb': {'runtime': 1838}, 'test/recall_macro': 0.5157033862876255, 'eval/precision_weighted': 0.5177045177045176, 'test/precision_weighted': 0.5851142626843562, 'split': 10, 'eval/recall_macro': 0.4727272727272727, 'test/f1_macro': 0.5099521946979574}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 26, 'dt_min_samples_leaf': 5}",stellar-tree-1202,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
137,"{'eval/f1_micro': 0.7380952380952381, 'test/recall_micro': 0.7383177570093458, 'test/f1_micro': 0.7383177570093457, 'eval/loss': 1.4730565814923546, 'test/accuracy': 0.7383177570093458, 'eval/recall_macro': 0.7295454545454546, 'test/recall_weighted': 0.7383177570093458, '_timestamp': 1704620501.8952382, 'eval/accuracy': 0.7380952380952381, 'test/f1_weighted': 0.7354336192077292, 'eval/precision_macro': 0.7286324786324786, 'eval/precision_micro': 0.7380952380952381, '_runtime': 1799.14413523674, 'eval/f1_macro': 0.7269736842105263, 'test/precision_macro': 0.752364812217547, 'test/precision_micro': 0.7383177570093458, 'eval/precision_weighted': 0.7342287342287341, '_step': 20, 'test/precision_weighted': 0.7520094841535117, 'split': 10, 'test/f1_macro': 0.7366077185226121, 'eval/f1_weighted': 0.7340225563909775, '_wandb': {'runtime': 1797}, 'test/loss': 1.9475307109435545, 'eval/recall_micro': 0.7380952380952381, 'test/recall_macro': 0.74125, 'eval/recall_weighted': 0.7380952380952381}","{'rf_max_depth': 24, 'trial.number': 26}",fine-eon-1201,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
138,"{'_step': 20, 'eval/loss': 1.543237330477569, 'test/loss': 1.2495676298298533, 'test/recall_macro': 0.7877946107591365, 'eval/precision_macro': 0.6971153846153846, 'eval/recall_weighted': 0.6666666666666666, '_runtime': 1627.4419660568235, 'eval/accuracy': 0.6666666666666666, 'eval/f1_weighted': 0.6737178090152918, 'test/recall_micro': 0.7757009345794392, 'eval/precision_micro': 0.6666666666666666, 'test/precision_weighted': 0.7949667094252031, 'split': 10, 'test/accuracy': 0.7757009345794392, 'eval/recall_macro': 0.6704545454545454, 'eval/recall_micro': 0.6666666666666666, 'eval/f1_micro': 0.6666666666666666, 'test/f1_macro': 0.7708241191213326, '_wandb': {'runtime': 1626}, 'test/f1_micro': 0.7757009345794392, 'test/f1_weighted': 0.7710783280355918, 'test/recall_weighted': 0.7757009345794392, '_timestamp': 1704619869.187047, 'eval/f1_macro': 0.6797768878718535, 'test/precision_micro': 0.7757009345794392, 'eval/precision_weighted': 0.6886446886446886, 'test/precision_macro': 0.783115468409586}","{'rf_max_depth': 14, 'trial.number': 29}",glorious-universe-1200,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
139,"{'_runtime': 2140.727629184723, 'eval/precision_macro': 0.604004329004329, 'test/precision_macro': 0.7787538402457758, 'test/recall_weighted': 0.7850467289719626, 'test/recall_micro': 0.7850467289719626, 'split': 10, 'test/f1_macro': 0.7761362374368371, 'eval/recall_macro': 0.615909090909091, 'eval/loss': 2.574556436041682, '_step': 20, '_wandb': {'runtime': 2139}, 'eval/f1_macro': 0.5927272727272727, 'eval/f1_weighted': 0.5941125541125541, 'eval/recall_micro': 0.6190476190476191, 'test/recall_macro': 0.7846918706293706, 'eval/precision_micro': 0.6190476190476191, 'test/precision_micro': 0.7850467289719626, 'eval/precision_weighted': 0.6026077097505669, 'test/precision_weighted': 0.7923180728426432, 'test/loss': 1.9756880730132456, 'eval/accuracy': 0.6190476190476191, 'test/accuracy': 0.7850467289719626, 'test/f1_weighted': 0.7823777623130282, 'eval/f1_micro': 0.6190476190476191, 'test/f1_micro': 0.7850467289719625, 'eval/recall_weighted': 0.6190476190476191, '_timestamp': 1704620240.0560682}","{'rf_max_depth': 22, 'trial.number': 22}",peach-night-1199,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
140,"{'_timestamp': 1704619506.1811082, 'eval/precision_macro': 0.6113636363636363, 'eval/precision_weighted': 0.6116161616161616, 'eval/f1_macro': 0.6028804528804528, 'test/accuracy': 0.4953271028037383, 'test/f1_micro': 0.4953271028037383, 'test/recall_micro': 0.4953271028037383, 'eval/precision_micro': 0.6428571428571429, 'test/recall_weighted': 0.4953271028037383, 'test/precision_micro': 0.4953271028037383, 'test/f1_macro': 0.4722662886331162, 'test/f1_weighted': 0.477493428943688, 'eval/recall_weighted': 0.6428571428571429, 'split': 10, 'eval/f1_micro': 0.6428571428571429, 'eval/recall_macro': 0.6454545454545455, 'test/precision_weighted': 0.48061891828311126, '_step': 20, '_runtime': 1670.231965303421, 'test/recall_macro': 0.49207007073386383, '_wandb': {'runtime': 1668}, 'test/loss': 7.268943802699403, 'eval/recall_micro': 0.6428571428571429, 'eval/loss': 4.828391343036011, 'eval/accuracy': 0.6428571428571429, 'eval/f1_weighted': 0.6006675863818719, 'test/precision_macro': 0.47372425629290615}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 28, 'dt_min_samples_leaf': 8}",classic-monkey-1198,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
141,"{'test/loss': 5.216519482241003, '_timestamp': 1704619787.5522718, 'test/precision_weighted': 0.4867601246105918, '_runtime': 2175.081016778946, 'eval/precision_weighted': 0.6190476190476191, 'eval/f1_micro': 0.6190476190476191, 'test/f1_weighted': 0.4897892747745339, 'eval/recall_macro': 0.625, 'test/recall_macro': 0.5004310344827586, 'test/recall_weighted': 0.5046728971962616, 'eval/accuracy': 0.6190476190476191, 'test/recall_micro': 0.5046728971962616, 'test/precision_macro': 0.4857456140350877, '_step': 20, 'eval/f1_macro': 0.6221187851050551, 'test/accuracy': 0.5046728971962616, 'test/f1_macro': 0.4875974013338041, 'eval/f1_weighted': 0.6162000851932203, 'eval/precision_macro': 0.625, 'eval/recall_weighted': 0.6190476190476191, '_wandb': {'runtime': 2173}, 'eval/loss': 0.8403034711898142, 'test/f1_micro': 0.5046728971962616, 'eval/precision_micro': 0.6190476190476191, 'split': 10, 'eval/recall_micro': 0.6190476190476191, 'test/precision_micro': 0.5046728971962616}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 21, 'dt_min_samples_leaf': 12}",denim-morning-1197,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
142,"{'_wandb': {'runtime': 1845}, 'eval/loss': 9.073595115213362, 'eval/f1_macro': 0.4591061112800243, 'test/precision_macro': 0.5717657342657343, 'test/precision_weighted': 0.5866152539049735, 'test/accuracy': 0.5046728971962616, 'test/f1_macro': 0.5106583072100312, 'test/recall_macro': 0.5157033862876255, 'eval/recall_weighted': 0.47619047619047616, 'eval/accuracy': 0.47619047619047616, 'eval/precision_micro': 0.47619047619047616, 'eval/recall_micro': 0.47619047619047616, '_runtime': 1846.5993905067444, '_timestamp': 1704618912.4102445, 'eval/f1_weighted': 0.4626532887402452, 'eval/precision_macro': 0.521780303030303, 'eval/precision_weighted': 0.5218253968253967, '_step': 20, 'test/loss': 10.176777383439967, 'eval/recall_macro': 0.4727272727272727, 'test/f1_micro': 0.5046728971962616, 'test/f1_weighted': 0.5075557378490024, 'test/precision_micro': 0.5046728971962616, 'split': 10, 'eval/f1_micro': 0.47619047619047616, 'test/recall_micro': 0.5046728971962616, 'test/recall_weighted': 0.5046728971962616}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 25, 'dt_min_samples_leaf': 5}",vibrant-elevator-1196,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
143,"{'test/recall_micro': 0.719626168224299, 'test/precision_macro': 0.7016465053763441, 'test/f1_weighted': 0.703316488890803, 'eval/precision_micro': 0.7380952380952381, 'test/f1_macro': 0.6999594640723673, 'eval/precision_weighted': 0.7587301587301587, 'eval/loss': 0.7229891600086736, '_runtime': 1798.2688508033752, 'test/loss': 1.347662311365839, 'eval/accuracy': 0.7380952380952381, 'test/recall_macro': 0.7210176282051282, 'split': 10, 'eval/f1_weighted': 0.7405372405372405, 'eval/recall_macro': 0.7318181818181818, 'eval/recall_weighted': 0.7380952380952381, 'test/precision_micro': 0.719626168224299, '_wandb': {'runtime': 1796}, '_timestamp': 1704618697.7842078, 'eval/f1_micro': 0.7380952380952381, 'test/accuracy': 0.719626168224299, 'eval/precision_macro': 0.7583333333333333, '_step': 20, 'eval/f1_macro': 0.7371794871794871, 'eval/recall_micro': 0.7380952380952381, 'test/recall_weighted': 0.719626168224299, 'test/precision_weighted': 0.7086649582956487, 'test/f1_micro': 0.7196261682242989}","{'rf_max_depth': 19, 'trial.number': 25}",northern-yogurt-1195,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
144,"{'test/recall_micro': 0.7757009345794392, 'eval/recall_weighted': 0.6904761904761905, 'test/accuracy': 0.7757009345794392, '_wandb': {'runtime': 1625}, 'eval/f1_micro': 0.6904761904761905, 'test/precision_weighted': 0.7934190031152646, 'eval/loss': 4.036662006205997, 'eval/precision_macro': 0.6958333333333333, 'test/precision_macro': 0.7835847701149425, 'eval/accuracy': 0.6904761904761905, 'test/f1_micro': 0.7757009345794392, 'test/recall_macro': 0.7900434863213555, '_runtime': 1628.076431274414, 'eval/f1_weighted': 0.6809523809523809, 'test/f1_weighted': 0.7627867205190428, 'eval/recall_macro': 0.6954545454545454, 'eval/precision_weighted': 0.6952380952380951, 'eval/f1_macro': 0.6833333333333332, 'split': 10, 'test/loss': 1.6131039163161651, 'test/f1_macro': 0.7650868523510032, 'eval/recall_micro': 0.6904761904761905, 'eval/precision_micro': 0.6904761904761905, 'test/precision_micro': 0.7757009345794392, '_step': 20, 'test/recall_weighted': 0.7757009345794392, '_timestamp': 1704618235.5479374}","{'rf_max_depth': 18, 'trial.number': 28}",lucky-mountain-1194,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
145,"{'test/accuracy': 0.616822429906542, '_runtime': 1670.6522805690763, 'eval/loss': 5.410002403380293, 'test/loss': 8.372242453449125, 'eval/f1_macro': 0.709853896103896, 'test/f1_micro': 0.616822429906542, 'test/precision_micro': 0.616822429906542, 'test/precision_weighted': 0.6010356300256017, '_timestamp': 1704617831.542755, 'test/recall_micro': 0.616822429906542, 'eval/precision_micro': 0.7380952380952381, 'eval/precision_weighted': 0.7164605236033808, '_wandb': {'runtime': 1669}, 'eval/f1_micro': 0.7380952380952381, 'test/f1_weighted': 0.6040506643821889, 'eval/accuracy': 0.7380952380952381, 'test/recall_macro': 0.6088914677276747, 'eval/recall_weighted': 0.7380952380952381, 'eval/precision_macro': 0.7176406926406926, '_step': 20, 'test/f1_macro': 0.5966652886867851, 'eval/recall_macro': 0.7431818181818182, 'test/recall_weighted': 0.616822429906542, 'split': 10, 'eval/f1_weighted': 0.7059322820037106, 'test/precision_macro': 0.5948522826058323, 'eval/recall_micro': 0.7380952380952381}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 27, 'dt_min_samples_leaf': 5}",playful-brook-1193,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
146,"{'_timestamp': 1704618095.048438, '_wandb': {'runtime': 2141}, 'eval/loss': 0.7147683122548011, 'test/loss': 0.6736054745933054, 'test/precision_macro': 0.7628383190883191, 'eval/f1_micro': 0.6904761904761905, 'test/f1_weighted': 0.7690033097951595, 'test/recall_macro': 0.7601617132867133, 'eval/accuracy': 0.6904761904761905, 'eval/precision_micro': 0.6904761904761905, 'test/precision_micro': 0.7663551401869159, 'split': 10, 'eval/f1_macro': 0.6809250398724083, 'eval/recall_micro': 0.6904761904761905, 'test/recall_micro': 0.7663551401869159, 'test/accuracy': 0.7663551401869159, 'test/f1_macro': 0.7582827832292596, 'eval/precision_weighted': 0.6859410430839002, 'eval/recall_weighted': 0.6904761904761905, 'test/precision_weighted': 0.778298319887105, '_step': 20, '_runtime': 2142.9257321357727, 'test/f1_micro': 0.766355140186916, 'eval/precision_macro': 0.6869588744588744, 'eval/f1_weighted': 0.6824394319131161, 'eval/recall_macro': 0.6863636363636364, 'test/recall_weighted': 0.7663551401869159}","{'rf_max_depth': 20, 'trial.number': 21}",hardy-moon-1192,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
147,"{'eval/f1_macro': 0.6148715415019763, 'test/f1_weighted': 0.4964739379457931, 'eval/recall_macro': 0.6499999999999999, 'test/recall_macro': 0.5081896551724138, 'eval/precision_macro': 0.6096153846153846, 'test/precision_micro': 0.5046728971962616, '_step': 20, '_runtime': 2173.6502726078033, 'eval/accuracy': 0.6428571428571429, 'test/f1_micro': 0.5046728971962616, 'eval/recall_micro': 0.6428571428571429, 'eval/precision_weighted': 0.607967032967033, 'test/recall_micro': 0.5046728971962616, 'test/loss': 5.5051576175756916, 'test/f1_macro': 0.4995860314903688, 'test/recall_weighted': 0.5046728971962616, 'test/precision_weighted': 0.4941255006675566, 'eval/loss': 0.7809972383841006, 'test/accuracy': 0.5046728971962616, 'eval/precision_micro': 0.6428571428571429, 'eval/recall_weighted': 0.6428571428571429, 'test/precision_macro': 0.49642857142857144, 'split': 10, '_wandb': {'runtime': 2172}, 'eval/f1_micro': 0.6428571428571429, '_timestamp': 1704617607.8398826, 'eval/f1_weighted': 0.6101778656126482}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 20, 'dt_min_samples_leaf': 11}",worthy-plasma-1191,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
148,"{'_timestamp': 1704617059.3754375, 'eval/accuracy': 0.47619047619047616, 'test/f1_micro': 0.5046728971962616, 'eval/recall_macro': 0.4727272727272727, '_runtime': 1849.9087314605713, 'test/f1_weighted': 0.5075557378490024, 'test/recall_weighted': 0.5046728971962616, 'eval/precision_weighted': 0.5218253968253967, '_step': 20, 'eval/recall_micro': 0.47619047619047616, 'test/recall_micro': 0.5046728971962616, 'test/f1_macro': 0.5106583072100312, 'test/precision_macro': 0.5717657342657343, 'split': 10, 'eval/loss': 9.068282173515405, 'test/loss': 9.85496228552704, 'eval/f1_micro': 0.47619047619047616, '_wandb': {'runtime': 1848}, 'eval/precision_micro': 0.47619047619047616, 'eval/recall_weighted': 0.47619047619047616, 'eval/f1_macro': 0.4591061112800243, 'test/recall_macro': 0.5157033862876255, 'test/precision_micro': 0.5046728971962616, 'test/accuracy': 0.5046728971962616, 'eval/f1_weighted': 0.4626532887402452, 'eval/precision_macro': 0.521780303030303, 'test/precision_weighted': 0.5866152539049735}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 24, 'dt_min_samples_leaf': 5}",celestial-waterfall-1190,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
149,"{'_step': 20, '_timestamp': 1704616891.6169214, 'test/accuracy': 0.7850467289719626, 'test/f1_micro': 0.7850467289719625, '_runtime': 1798.9269235134125, 'eval/recall_micro': 0.7619047619047619, 'test/recall_macro': 0.7905128205128205, 'test/recall_micro': 0.7850467289719626, 'eval/precision_macro': 0.7445054945054945, 'test/precision_macro': 0.7918750000000001, '_wandb': {'runtime': 1797}, 'eval/f1_macro': 0.7116958041958042, 'test/f1_macro': 0.7849336826337534, 'eval/f1_weighted': 0.7166150516150517, 'test/f1_weighted': 0.7823403373114448, 'test/loss': 0.6743514330102753, 'eval/loss': 1.477347610075166, 'eval/precision_weighted': 0.7442438513867086, 'test/precision_weighted': 0.791658878504673, 'split': 10, 'eval/accuracy': 0.7619047619047619, 'eval/precision_micro': 0.7619047619047619, 'test/precision_micro': 0.7850467289719626, 'eval/f1_micro': 0.7619047619047619, 'eval/recall_macro': 0.7545454545454546, 'eval/recall_weighted': 0.7619047619047619, 'test/recall_weighted': 0.7850467289719626}","{'rf_max_depth': 16, 'trial.number': 24}",sweet-silence-1189,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
150,"{'_step': 20, '_wandb': {'runtime': 1626}, 'eval/loss': 0.8253118927553137, 'test/f1_macro': 0.6545242304728229, 'eval/precision_macro': 0.6684294871794872, 'eval/precision_weighted': 0.6710927960927962, 'test/f1_weighted': 0.648201488531394, 'eval/recall_macro': 0.6454545454545455, 'test/recall_macro': 0.6929428430945818, 'eval/precision_micro': 0.6428571428571429, 'eval/recall_weighted': 0.6428571428571429, '_timestamp': 1704616603.099935, 'test/f1_micro': 0.6728971962616822, 'test/precision_micro': 0.6728971962616822, 'test/recall_weighted': 0.6728971962616822, 'test/precision_weighted': 0.6757717209933068, 'eval/recall_micro': 0.6428571428571429, 'test/recall_micro': 0.6728971962616822, 'test/precision_macro': 0.6684637047540274, '_runtime': 1627.688451051712, 'eval/accuracy': 0.6428571428571429, 'test/accuracy': 0.6728971962616822, 'split': 10, 'test/loss': 0.8779182252610804, 'eval/f1_micro': 0.6428571428571429, 'eval/f1_macro': 0.6326143790849674, 'eval/f1_weighted': 0.6323685029567384}","{'rf_max_depth': 8, 'trial.number': 27}",volcanic-universe-1188,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
151,"{'test/accuracy': 0.5887850467289719, 'eval/precision_weighted': 1, '_step': 520, 'eval/f1_weighted': 1, 'train/train_loss': 2.669790662620149e-10, 'eval/recall_macro': 1, 'train/learning_rate': 1.039480760233218e-06, 'train/train_samples_per_second': 38.755, 'train/loss': 0, 'eval/recall_micro': 1, 'eval/precision_macro': 1, 'eval/recall_weighted': 1, 'eval/samples_per_second': 124.335, 'eval/f1_macro': 1, '_runtime': 4942.021897792816, 'train/total_flos': 5029123075033824.0, 'eval/f1_micro': 1, 'train/train_runtime': 494.1322, 'test/latency_in_seconds': 0.008023559570064438, 'eval/loss': 0, '_timestamp': 1704619621.395141, 'train/epoch': 50, 'eval/runtime': 0.3378, 'eval/accuracy': 1, 'test/samples_per_second': 124.63296262309284, 'eval/steps_per_second': 5.921, 'train/train_steps_per_second': 1.214, '_wandb': {'runtime': 4940}, 'train/global_step': 600, 'eval/precision_micro': 1, 'test/total_time_in_seconds': 0.8585208739968948}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_08-04-41_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 6.236884561399307e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",light-sea-1187,Fine-Tuned LLM:microsoft/codebert-base,['preprocessed']
152,"{'eval/accuracy': 0.42857142857142855, 'test/f1_weighted': 0.5370716510903426, 'eval/precision_weighted': 0.4312169312169312, 'eval/f1_micro': 0.42857142857142855, 'test/accuracy': 0.5514018691588785, 'test/f1_micro': 0.5514018691588785, 'split': 10, 'test/f1_macro': 0.5307017543859649, 'eval/f1_weighted': 0.4259740259740259, 'eval/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.4305555555555556, 'test/precision_micro': 0.5514018691588785, 'test/recall_macro': 0.5437665782493368, 'test/precision_weighted': 0.5324464877901718, '_runtime': 1670.3960728645325, 'eval/loss': 5.168278411978132, 'eval/f1_macro': 0.4272727272727273, '_wandb': {'runtime': 1669}, 'eval/recall_macro': 0.4318181818181818, 'eval/recall_weighted': 0.42857142857142855, 'test/loss': 5.708582158921319, 'eval/precision_micro': 0.42857142857142855, 'test/precision_macro': 0.5279737903225806, '_step': 20, '_timestamp': 1704616155.7927618, 'test/recall_micro': 0.5514018691588785, 'test/recall_weighted': 0.5514018691588785}","{'dt_criterion': 'gini', 'dt_max_depth': 17, 'trial.number': 26, 'dt_min_samples_leaf': 7}",neat-capybara-1186,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
153,"{'split': 10, 'test/f1_macro': 0.7760930809105251, 'test/recall_macro': 0.782888986013986, 'test/f1_micro': 0.7850467289719625, 'eval/f1_micro': 0.6904761904761905, 'eval/precision_micro': 0.6904761904761905, '_step': 20, '_runtime': 2143.052902698517, 'test/accuracy': 0.7850467289719626, 'eval/recall_macro': 0.6840909090909091, 'eval/recall_micro': 0.6904761904761905, 'test/precision_micro': 0.7850467289719626, 'eval/loss': 1.616186073322604, 'eval/f1_macro': 0.6698717948717948, 'test/recall_micro': 0.7850467289719626, 'eval/precision_macro': 0.6840909090909091, 'test/recall_weighted': 0.7850467289719626, 'test/f1_weighted': 0.7820235108760444, 'test/precision_macro': 0.7782578291273944, 'eval/precision_weighted': 0.6856421356421356, 'test/loss': 1.6357098154079748, 'eval/f1_weighted': 0.6739926739926739, 'eval/recall_weighted': 0.6904761904761905, '_wandb': {'runtime': 2141}, '_timestamp': 1704615946.8807187, 'eval/accuracy': 0.6904761904761905, 'test/precision_weighted': 0.7887769767818529}","{'rf_max_depth': 22, 'trial.number': 20}",comic-butterfly-1185,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
154,"{'eval/recall_macro': 0.45, '_timestamp': 1704615204.7218082, 'eval/accuracy': 0.4523809523809524, 'test/accuracy': 0.4953271028037383, 'test/recall_weighted': 0.4953271028037383, 'test/precision_weighted': 0.5540197387366161, 'test/f1_micro': 0.4953271028037383, 'test/recall_macro': 0.501228051839465, 'eval/precision_micro': 0.4523809523809524, '_wandb': {'runtime': 1841}, 'eval/loss': 9.151480348745205, 'eval/f1_weighted': 0.44312169312169314, 'test/precision_macro': 0.5423669467787114, 'split': 10, 'eval/f1_micro': 0.4523809523809524, 'eval/recall_weighted': 0.4523809523809524, 'test/loss': 8.953571860989916, 'test/f1_weighted': 0.5033048393529035, 'test/recall_micro': 0.4953271028037383, 'eval/precision_macro': 0.4634878193701723, 'eval/f1_macro': 0.43914141414141417, 'eval/recall_micro': 0.4523809523809524, 'test/precision_micro': 0.4953271028037383, 'eval/precision_weighted': 0.4676314970432618, '_step': 20, '_runtime': 1842.4093301296232, 'test/f1_macro': 0.5029452690166976}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 23, 'dt_min_samples_leaf': 6}",whole-oath-1184,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
155,"{'_timestamp': 1704614970.3210068, 'eval/precision_weighted': 0.7978767264481551, '_runtime': 1627.1325538158417, 'test/recall_macro': 0.7648650473150522, 'test/f1_micro': 0.7476635514018691, 'eval/recall_macro': 0.7931818181818181, 'eval/accuracy': 0.7857142857142857, 'test/f1_weighted': 0.7062303238520651, 'eval/recall_weighted': 0.7857142857142857, 'test/precision_weighted': 0.7832746097589418, 'eval/loss': 0.7509733047629744, 'test/loss': 1.6490897026330844, 'eval/f1_macro': 0.7794397759103642, 'eval/precision_macro': 0.800865800865801, 'test/recall_weighted': 0.7476635514018691, '_wandb': {'runtime': 1625}, 'eval/f1_micro': 0.7857142857142857, 'test/precision_macro': 0.7723234180035651, 'test/recall_micro': 0.7476635514018691, 'eval/precision_micro': 0.7857142857142857, '_step': 20, 'split': 10, 'test/accuracy': 0.7476635514018691, 'test/f1_macro': 0.7116841935920883, 'eval/f1_weighted': 0.7734720554888623, 'eval/recall_micro': 0.7857142857142857, 'test/precision_micro': 0.7476635514018691}","{'rf_max_depth': 11, 'trial.number': 26}",true-hill-1183,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
156,"{'eval/precision_macro': 0.7880952380952381, 'test/precision_micro': 0.7757009345794392, 'eval/loss': 1.4954661744490805, 'test/f1_micro': 0.7757009345794392, 'eval/recall_micro': 0.7857142857142857, 'eval/precision_micro': 0.7857142857142857, 'eval/recall_weighted': 0.7857142857142857, 'test/precision_macro': 0.777904622259461, 'eval/precision_weighted': 0.7930839002267573, '_wandb': {'runtime': 1799}, '_runtime': 1801.3372910022736, '_timestamp': 1704615085.743276, 'test/recall_macro': 0.773301282051282, 'test/loss': 1.6079924281664657, 'eval/accuracy': 0.7857142857142857, 'eval/f1_micro': 0.7857142857142857, 'test/f1_macro': 0.7607645403377111, 'eval/f1_weighted': 0.783233082706767, 'test/recall_micro': 0.7757009345794392, 'test/recall_weighted': 0.7757009345794392, '_step': 20, 'eval/recall_macro': 0.7795454545454545, 'split': 10, 'eval/f1_macro': 0.7778947368421052, 'test/accuracy': 0.7757009345794392, 'test/f1_weighted': 0.7649199558135049, 'test/precision_weighted': 0.7826555315852874}","{'rf_max_depth': 15, 'trial.number': 23}",sunny-energy-1182,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
157,"{'_wandb': {'runtime': 2173}, 'eval/f1_macro': 0.4639863547758285, 'eval/precision_micro': 0.4523809523809524, 'test/precision_macro': 0.4450266971777269, 'test/f1_micro': 0.4672897196261683, 'test/recall_micro': 0.4672897196261682, '_step': 20, '_runtime': 2174.995362997055, 'eval/f1_micro': 0.4523809523809524, 'test/f1_macro': 0.4468384054295958, 'eval/precision_weighted': 0.49862444977991194, 'split': 10, 'test/loss': 6.177612618753297, 'eval/accuracy': 0.4523809523809524, 'eval/f1_weighted': 0.4623596027104798, 'eval/loss': 1.8518351562789712, 'test/accuracy': 0.4672897196261682, 'eval/recall_micro': 0.4523809523809524, 'test/recall_weighted': 0.4672897196261682, '_timestamp': 1704615428.957249, 'test/f1_weighted': 0.45570172241239065, 'eval/recall_macro': 0.4568181818181818, 'test/recall_macro': 0.4581896551724138, 'eval/precision_macro': 0.49721638655462186, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_micro': 0.4672897196261682, 'test/precision_weighted': 0.4544214660992179}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 19, 'dt_min_samples_leaf': 16}",sweet-valley-1181,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
158,"{'test/loss': 7.239808924604833, '_timestamp': 1704614480.209487, 'test/recall_macro': 0.5344511810029051, 'test/recall_weighted': 0.5420560747663551, 'eval/precision_weighted': 0.5445578231292517, 'eval/recall_macro': 0.4590909090909091, 'eval/f1_micro': 0.4523809523809524, 'test/accuracy': 0.5420560747663551, 'test/f1_macro': 0.5406116871634112, 'test/f1_weighted': 0.5476330523059495, '_step': 20, '_runtime': 1670.886929988861, 'eval/f1_weighted': 0.4526077097505668, 'test/precision_macro': 0.5600540503557745, 'eval/f1_macro': 0.4547619047619048, 'eval/precision_micro': 0.4523809523809524, 'test/precision_weighted': 0.5661622904613558, 'split': 10, '_wandb': {'runtime': 1669}, 'eval/loss': 6.71860028226416, 'eval/accuracy': 0.4523809523809524, 'eval/precision_macro': 0.5392857142857143, 'test/precision_micro': 0.5420560747663551, 'test/f1_micro': 0.5420560747663551, 'eval/recall_micro': 0.4523809523809524, 'test/recall_micro': 0.5420560747663551, 'eval/recall_weighted': 0.4523809523809524}","{'dt_criterion': 'gini', 'dt_max_depth': 14, 'trial.number': 25, 'dt_min_samples_leaf': 6}",colorful-mountain-1180,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
159,"{'test/precision_macro': 0.7734136830911025, 'test/recall_weighted': 0.7663551401869159, '_step': 20, '_wandb': {'runtime': 1625}, 'eval/loss': 0.683441302076529, 'test/f1_macro': 0.7491494415854816, '_timestamp': 1704613337.983404, 'test/recall_macro': 0.7850147506891716, 'test/precision_weighted': 0.7788435863202218, 'test/f1_weighted': 0.7421649142564385, 'eval/precision_micro': 0.7857142857142857, 'eval/f1_weighted': 0.7801639174188192, 'split': 10, '_runtime': 1626.841715812683, 'eval/accuracy': 0.7857142857142857, 'test/f1_micro': 0.766355140186916, 'eval/recall_macro': 0.7909090909090908, 'eval/recall_micro': 0.7857142857142857, 'eval/recall_weighted': 0.7857142857142857, 'test/precision_micro': 0.7663551401869159, 'eval/precision_macro': 0.8326648841354723, 'test/loss': 1.0326160203109742, 'eval/f1_micro': 0.7857142857142857, 'test/accuracy': 0.7663551401869159, 'test/recall_micro': 0.7663551401869159, 'eval/f1_macro': 0.7817389582095464, 'eval/precision_weighted': 0.834500466853408}","{'rf_max_depth': 14, 'trial.number': 25}",usual-valley-1179,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
160,"{'_runtime': 2143.735934495926, '_timestamp': 1704613797.3383555, 'eval/f1_macro': 0.6719576719576719, 'eval/recall_weighted': 0.6904761904761905, 'test/accuracy': 0.719626168224299, 'eval/recall_micro': 0.6904761904761905, 'test/precision_macro': 0.7028079710144928, '_step': 20, 'test/f1_weighted': 0.7004356982736116, 'test/recall_micro': 0.719626168224299, 'eval/precision_macro': 0.6840503246753247, 'test/loss': 0.8402639280094916, 'eval/accuracy': 0.6904761904761905, 'test/f1_micro': 0.7196261682242989, 'eval/precision_micro': 0.6904761904761905, 'eval/loss': 0.8260669052248889, 'eval/f1_weighted': 0.6699420508944318, 'test/precision_micro': 0.719626168224299, 'test/recall_weighted': 0.719626168224299, 'eval/precision_weighted': 0.6814509894867038, 'test/precision_weighted': 0.7194805634565894, '_wandb': {'runtime': 2142}, 'test/f1_macro': 0.6858900842109797, 'split': 10, 'eval/f1_micro': 0.6904761904761905, 'eval/recall_macro': 0.6909090909090909, 'test/recall_macro': 0.7069493006993006}","{'rf_max_depth': 10, 'trial.number': 19}",rare-aardvark-1178,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
161,"{'test/accuracy': 0.48598130841121495, 'test/f1_micro': 0.48598130841121495, '_wandb': {'runtime': 1829}, '_runtime': 1830.5234982967377, 'eval/precision_micro': 0.4523809523809524, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_weighted': 0.4958799227325004, 'eval/accuracy': 0.4523809523809524, 'eval/f1_weighted': 0.43365357839042046, 'eval/f1_macro': 0.42616959064327486, 'eval/f1_micro': 0.4523809523809524, 'test/precision_micro': 0.48598130841121495, 'test/recall_micro': 0.48598130841121495, 'eval/precision_macro': 0.4253472222222222, 'eval/precision_weighted': 0.4317129629629629, '_step': 20, 'eval/recall_macro': 0.44318181818181823, 'test/recall_macro': 0.48871237458193983, 'test/loss': 8.360693029081805, 'test/f1_weighted': 0.4865846860141006, 'test/precision_macro': 0.48821833930704905, 'test/recall_weighted': 0.48598130841121495, 'split': 10, 'eval/loss': 7.661976918507546, '_timestamp': 1704613357.9509065, 'test/f1_macro': 0.4843859649122807, 'eval/recall_micro': 0.4523809523809524}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 22, 'dt_min_samples_leaf': 7}",quiet-sun-1177,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
162,"{'split': 10, 'eval/precision_micro': 0.7142857142857143, 'test/precision_macro': 0.6754646215853112, 'eval/f1_macro': 0.6988770053475936, 'test/accuracy': 0.6822429906542056, 'eval/precision_weighted': 0.7091836734693877, '_wandb': {'runtime': 1798}, 'eval/f1_micro': 0.7142857142857143, 'test/precision_weighted': 0.6780953497034709, '_runtime': 1800.085212469101, '_timestamp': 1704613279.6689565, 'eval/recall_macro': 0.7068181818181819, 'test/loss': 0.7191671059971576, 'test/f1_micro': 0.6822429906542056, 'test/recall_macro': 0.688613782051282, 'test/recall_weighted': 0.6822429906542056, '_step': 20, 'eval/f1_weighted': 0.7038655462184874, 'test/f1_weighted': 0.676395878265037, 'test/recall_micro': 0.6822429906542056, 'eval/recall_weighted': 0.7142857142857143, 'test/precision_micro': 0.6822429906542056, 'eval/accuracy': 0.7142857142857143, 'test/f1_macro': 0.6782051282051282, 'eval/recall_micro': 0.7142857142857143, 'eval/precision_macro': 0.7068181818181818, 'eval/loss': 0.7306901865511832}","{'rf_max_depth': 24, 'trial.number': 22}",restful-spaceship-1176,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
163,"{'test/precision_macro': 0.4936966438579342, 'eval/f1_weighted': 0.408843537414966, 'split': 10, 'eval/f1_micro': 0.4047619047619048, 'eval/recall_macro': 0.40681818181818186, 'test/precision_micro': 0.5233644859813084, 'test/precision_weighted': 0.5000151652186623, '_step': 20, 'eval/recall_micro': 0.4047619047619048, 'eval/precision_weighted': 0.417027417027417, '_timestamp': 1704612799.1025646, 'eval/recall_weighted': 0.4047619047619048, 'test/loss': 5.129237944721314, 'eval/loss': 5.171721084756513, 'eval/f1_macro': 0.40974025974025974, 'test/accuracy': 0.5233644859813084, 'test/f1_micro': 0.5233644859813084, 'test/recall_weighted': 0.5233644859813084, '_runtime': 1669.936613559723, 'test/f1_macro': 0.5006608050180096, 'test/recall_micro': 0.5233644859813084, '_wandb': {'runtime': 1668}, 'test/f1_weighted': 0.5075038856013432, 'test/recall_macro': 0.5161085322723253, 'eval/precision_macro': 0.41666666666666663, 'eval/accuracy': 0.4047619047619048, 'eval/precision_micro': 0.4047619047619048}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 24, 'dt_min_samples_leaf': 9}",divine-shadow-1175,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
164,"{'test/precision_weighted': 0.4544214660992179, '_step': 20, 'split': 10, 'test/recall_micro': 0.4672897196261682, 'eval/recall_weighted': 0.4523809523809524, 'eval/precision_weighted': 0.49862444977991194, 'eval/recall_micro': 0.4523809523809524, '_runtime': 2175.624844789505, 'eval/accuracy': 0.4523809523809524, 'eval/f1_macro': 0.4639863547758285, 'test/precision_macro': 0.4450266971777269, 'eval/loss': 1.8518351562789712, 'test/f1_macro': 0.4468384054295958, 'eval/precision_micro': 0.4523809523809524, '_timestamp': 1704613249.0198998, 'eval/f1_micro': 0.4523809523809524, 'eval/f1_weighted': 0.4623596027104798, '_wandb': {'runtime': 2173}, 'test/loss': 6.177612618753297, 'test/accuracy': 0.4672897196261682, 'test/f1_weighted': 0.45570172241239065, 'eval/recall_macro': 0.4568181818181818, 'test/precision_micro': 0.4672897196261682, 'test/recall_weighted': 0.4672897196261682, 'test/f1_micro': 0.4672897196261683, 'test/recall_macro': 0.4581896551724138, 'eval/precision_macro': 0.49721638655462186}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 18, 'dt_min_samples_leaf': 16}",mild-wood-1174,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
165,"{'eval/f1_micro': 0.5952380952380952, 'test/f1_macro': 0.8249283924095954, 'eval/precision_micro': 0.5952380952380952, 'eval/loss': 1.6787304401600265, 'test/loss': 0.6263672711168876, 'test/accuracy': 0.822429906542056, 'test/recall_micro': 0.822429906542056, '_step': 20, 'split': 10, 'eval/accuracy': 0.5952380952380952, 'eval/f1_weighted': 0.5757727652464495, '_wandb': {'runtime': 1625}, '_timestamp': 1704611706.3180103, 'eval/precision_weighted': 0.5703325774754346, 'eval/recall_micro': 0.5952380952380952, 'test/precision_macro': 0.8227093596059113, 'eval/recall_macro': 0.6045454545454545, 'test/recall_macro': 0.8286491834727797, 'test/f1_micro': 0.822429906542056, 'eval/recall_weighted': 0.5952380952380952, 'test/precision_micro': 0.822429906542056, 'test/precision_weighted': 0.8226858800239399, '_runtime': 1628.3439633846283, 'eval/f1_macro': 0.5828947368421051, 'test/f1_weighted': 0.8218245881727014, 'eval/precision_macro': 0.5757936507936507, 'test/recall_weighted': 0.822429906542056}","{'rf_max_depth': 16, 'trial.number': 24}",apricot-leaf-1173,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
166,"{'test/accuracy': 0.48598130841121495, 'test/recall_micro': 0.48598130841121495, 'split': 10, 'test/recall_weighted': 0.48598130841121495, 'eval/f1_macro': 0.42616959064327486, '_step': 20, 'eval/f1_micro': 0.4523809523809524, 'test/loss': 9.007656635598671, 'eval/recall_macro': 0.44318181818181823, 'eval/recall_micro': 0.4523809523809524, 'test/precision_macro': 0.48821833930704905, 'test/precision_weighted': 0.4958799227325004, 'eval/f1_weighted': 0.43365357839042046, 'eval/loss': 8.489660717166, 'test/precision_micro': 0.48598130841121495, 'eval/precision_weighted': 0.4317129629629629, '_wandb': {'runtime': 1843}, '_timestamp': 1704611520.9401357, 'eval/accuracy': 0.4523809523809524, 'test/f1_micro': 0.48598130841121495, 'test/f1_weighted': 0.4865846860141006, 'eval/precision_micro': 0.4523809523809524, '_runtime': 1845.8289268016815, 'test/recall_macro': 0.48871237458193983, 'eval/precision_macro': 0.4253472222222222, 'eval/recall_weighted': 0.4523809523809524, 'test/f1_macro': 0.4843859649122807}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 21, 'dt_min_samples_leaf': 7}",bumbling-salad-1172,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
167,"{'eval/recall_macro': 0.7090909090909091, 'test/precision_micro': 0.7476635514018691, 'test/recall_weighted': 0.7476635514018691, 'eval/precision_weighted': 0.7235492681921253, 'test/recall_macro': 0.7512820512820513, '_wandb': {'runtime': 1798}, 'eval/loss': 0.7105209037403025, 'eval/f1_macro': 0.7049624060150375, '_step': 20, 'split': 10, '_runtime': 1800.2799558639526, 'eval/f1_micro': 0.7142857142857143, 'eval/precision_micro': 0.7142857142857143, 'eval/accuracy': 0.7142857142857143, 'eval/recall_weighted': 0.7142857142857143, 'test/precision_macro': 0.7473027599103674, 'test/accuracy': 0.7476635514018691, 'test/f1_weighted': 0.7453889136132127, 'test/loss': 1.0207728391770894, 'test/f1_macro': 0.7476851851851852, 'test/recall_micro': 0.7476635514018691, 'test/precision_weighted': 0.7461837365911558, '_timestamp': 1704611474.8717668, 'test/f1_micro': 0.7476635514018691, 'eval/f1_weighted': 0.7098890082348729, 'eval/recall_micro': 0.7142857142857143, 'eval/precision_macro': 0.7182088744588744}","{'rf_max_depth': 32, 'trial.number': 21}",balmy-grass-1171,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
168,"{'test/recall_weighted': 0.7850467289719626, 'test/precision_weighted': 0.7821617228768794, '_step': 20, 'eval/recall_micro': 0.6904761904761905, 'test/precision_macro': 0.7762123745819398, 'test/precision_micro': 0.7850467289719626, 'split': 10, '_wandb': {'runtime': 2142}, 'eval/f1_weighted': 0.6750399809046426, 'eval/precision_weighted': 0.6749080945509517, 'eval/recall_weighted': 0.6904761904761905, 'eval/f1_micro': 0.6904761904761905, 'test/f1_macro': 0.778936122357175, 'test/recall_macro': 0.7846918706293706, 'test/recall_micro': 0.7850467289719626, 'eval/precision_macro': 0.6733856421356421, 'eval/accuracy': 0.6904761904761905, 'eval/precision_micro': 0.6904761904761905, 'test/f1_weighted': 0.7819423949281303, 'eval/recall_macro': 0.6886363636363637, 'test/loss': 1.938442824137456, 'test/accuracy': 0.7850467289719626, 'test/f1_micro': 0.7850467289719625, 'eval/f1_macro': 0.6736340852130326, '_runtime': 2144.793922662735, 'eval/loss': 1.598314229325625, '_timestamp': 1704611648.8861015}","{'rf_max_depth': 21, 'trial.number': 18}",iconic-wildflower-1170,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
169,"{'test/precision_micro': 0.5700934579439252, 'split': 10, 'eval/f1_macro': 0.4551966873706004, 'eval/f1_weighted': 0.4530217884255151, 'test/recall_micro': 0.5700934579439252, '_timestamp': 1704611124.756636, 'eval/f1_micro': 0.4523809523809524, 'eval/recall_macro': 0.4590909090909091, 'test/recall_weighted': 0.5700934579439252, '_step': 20, 'eval/recall_micro': 0.4523809523809524, 'test/recall_macro': 0.5605066628773525, '_runtime': 1670.667309999466, 'test/accuracy': 0.5700934579439252, 'test/precision_macro': 0.5723041474654378, 'test/precision_weighted': 0.5797654219963535, 'test/f1_macro': 0.5640551304894665, 'test/f1_weighted': 0.5726132275168554, 'eval/precision_micro': 0.4523809523809524, '_wandb': {'runtime': 1669}, 'eval/accuracy': 0.4523809523809524, 'test/f1_micro': 0.5700934579439252, 'eval/precision_weighted': 0.5456043956043957, 'eval/loss': 7.542613826641013, 'test/loss': 6.872792793939511, 'eval/recall_weighted': 0.4523809523809524, 'eval/precision_macro': 0.5403846153846154}","{'dt_criterion': 'gini', 'dt_max_depth': 12, 'trial.number': 23, 'dt_min_samples_leaf': 6}",tough-waterfall-1169,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
170,"{'eval/recall_macro': 0.37727272727272726, 'test/recall_micro': 0.3644859813084112, 'eval/precision_macro': 0.36666666666666664, 'test/precision_macro': 0.3423405567300916, 'eval/loss': 1.9738083783166989, 'test/loss': 2.643368958400499, 'test/f1_micro': 0.36448598130841114, 'eval/recall_micro': 0.380952380952381, 'split': 10, '_runtime': 2173.0099132061005, 'eval/f1_weighted': 0.358462615815557, '_wandb': {'runtime': 2171}, 'test/recall_weighted': 0.3644859813084112, 'eval/precision_weighted': 0.37222222222222223, '_timestamp': 1704611068.2520502, 'eval/f1_micro': 0.380952380952381, 'test/f1_macro': 0.34742291500739564, 'test/precision_micro': 0.3644859813084112, '_step': 20, 'test/accuracy': 0.3644859813084112, 'eval/precision_micro': 0.380952380952381, 'test/f1_weighted': 0.3422358874676608, 'test/recall_macro': 0.3711206896551724, 'eval/recall_weighted': 0.380952380952381, 'eval/accuracy': 0.380952380952381, 'eval/f1_macro': 0.35410067873303175, 'test/precision_weighted': 0.33959350075411804}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 17, 'dt_min_samples_leaf': 28}",crisp-frog-1168,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
171,"{'eval/f1_macro': 0.7074481658692184, 'test/accuracy': 0.794392523364486, 'eval/precision_macro': 0.7083333333333334, 'test/loss': 0.6020197724005929, 'eval/accuracy': 0.7142857142857143, 'test/f1_macro': 0.7853473750713296, 'eval/recall_macro': 0.725, 'test/recall_macro': 0.8034707444664765, '_wandb': {'runtime': 1624}, 'eval/f1_micro': 0.7142857142857143, 'eval/f1_weighted': 0.6969347611452874, 'eval/loss': 0.7702455512182811, '_timestamp': 1704610072.768371, 'split': 10, 'test/f1_micro': 0.794392523364486, 'test/f1_weighted': 0.7829756568987991, 'eval/recall_weighted': 0.7142857142857143, '_step': 20, 'eval/recall_micro': 0.7142857142857143, 'test/recall_micro': 0.794392523364486, 'eval/precision_micro': 0.7142857142857143, 'test/precision_weighted': 0.8138316924050844, '_runtime': 1625.819241285324, 'test/precision_macro': 0.808322192513369, 'test/recall_weighted': 0.794392523364486, 'eval/precision_weighted': 0.6984126984126985, 'test/precision_micro': 0.794392523364486}","{'rf_max_depth': 21, 'trial.number': 23}",swift-lion-1167,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
172,"{'test/loss': 0.6961409660554646, 'eval/f1_macro': 0.702892156862745, '_runtime': 1800.9950697422028, '_timestamp': 1704609669.4922256, 'eval/f1_micro': 0.7142857142857143, 'eval/precision_micro': 0.7142857142857143, 'test/precision_micro': 0.7476635514018691, '_step': 20, 'eval/accuracy': 0.7142857142857143, '_wandb': {'runtime': 1799}, 'eval/recall_macro': 0.7068181818181819, 'test/precision_weighted': 0.7482697105888858, 'split': 10, 'test/f1_weighted': 0.7407499289604391, 'eval/recall_micro': 0.7142857142857143, 'test/recall_macro': 0.7516666666666666, 'test/recall_micro': 0.7476635514018691, 'eval/precision_macro': 0.720467032967033, 'test/precision_macro': 0.7437325934413341, 'eval/loss': 1.5018017872374858, 'test/accuracy': 0.7476635514018691, 'test/f1_micro': 0.7476635514018691, 'eval/f1_weighted': 0.7064845938375349, 'eval/recall_weighted': 0.7142857142857143, 'eval/precision_weighted': 0.7199110413396128, 'test/f1_macro': 0.7402042174583159, 'test/recall_weighted': 0.7476635514018691}","{'rf_max_depth': 21, 'trial.number': 20}",youthful-gorge-1166,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
173,"{'split': 10, 'test/f1_micro': 0.36448598130841114, 'eval/precision_macro': 0.5081699346405228, 'test/precision_weighted': 0.3616192118148438, '_runtime': 1847.4053888320925, 'eval/accuracy': 0.5238095238095238, 'test/f1_macro': 0.3629035452564864, 'eval/f1_weighted': 0.5023073556908143, 'test/recall_micro': 0.3644859813084112, 'eval/loss': 5.232866537438332, 'test/accuracy': 0.3644859813084112, 'eval/precision_weighted': 0.5069055399937753, '_step': 20, 'eval/f1_micro': 0.5238095238095238, 'eval/precision_micro': 0.5238095238095238, 'test/f1_weighted': 0.35462227182952855, 'test/precision_micro': 0.3644859813084112, 'test/recall_weighted': 0.3644859813084112, 'test/loss': 6.148776915496741, '_timestamp': 1704609667.346747, 'eval/f1_macro': 0.5016708437761069, 'eval/recall_macro': 0.5204545454545455, 'eval/recall_micro': 0.5238095238095238, 'test/recall_macro': 0.3786841555183946, 'eval/recall_weighted': 0.5238095238095238, 'test/precision_macro': 0.362892248697383, '_wandb': {'runtime': 1846}}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 20, 'dt_min_samples_leaf': 14}",smart-smoke-1165,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
174,"{'_wandb': {'runtime': 1669}, 'test/precision_weighted': 0.5621948456527895, 'test/loss': 8.477924844990609, 'test/accuracy': 0.5607476635514018, 'test/f1_macro': 0.5533934302318377, 'eval/f1_weighted': 0.4659643179093981, 'test/f1_weighted': 0.5591818715467735, '_runtime': 1670.5135436058044, 'eval/accuracy': 0.47619047619047616, 'eval/precision_micro': 0.47619047619047616, 'eval/loss': 8.263090998818758, 'eval/precision_macro': 0.47302350427350426, '_timestamp': 1704609449.546337, 'eval/recall_macro': 0.484090909090909, 'eval/recall_micro': 0.47619047619047616, 'test/recall_macro': 0.5549845269672856, 'test/recall_micro': 0.5607476635514018, 'test/precision_macro': 0.5561742424242424, 'test/precision_micro': 0.5607476635514018, 'test/recall_weighted': 0.5607476635514018, 'split': 10, 'eval/f1_macro': 0.4711046390680258, 'test/f1_micro': 0.5607476635514018, 'eval/recall_weighted': 0.47619047619047616, 'eval/precision_weighted': 0.47067053317053315, '_step': 20, 'eval/f1_micro': 0.47619047619047616}","{'dt_criterion': 'gini', 'dt_max_depth': 16, 'trial.number': 22, 'dt_min_samples_leaf': 5}",bright-wood-1164,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
175,"{'test/precision_macro': 0.7909562211981567, 'split': 10, 'eval/accuracy': 0.7142857142857143, 'test/loss': 0.5922334035691041, 'eval/recall_weighted': 0.7142857142857143, 'test/recall_weighted': 0.8037383177570093, '_wandb': {'runtime': 2141}, 'eval/loss': 1.5613680615264365, 'test/f1_macro': 0.7912242291552636, 'eval/precision_macro': 0.7118055555555556, 'test/precision_weighted': 0.8006847840130927, '_runtime': 2142.6803255081177, 'eval/f1_macro': 0.7036437246963563, 'test/precision_micro': 0.8037383177570093, 'eval/recall_micro': 0.7142857142857143, 'test/recall_macro': 0.7967657342657343, 'test/recall_micro': 0.8037383177570093, 'test/accuracy': 0.8037383177570093, 'test/f1_weighted': 0.7994594751281828, 'test/f1_micro': 0.8037383177570093, 'eval/f1_weighted': 0.7028147291305187, 'eval/precision_micro': 0.7142857142857143, '_step': 20, 'eval/f1_micro': 0.7142857142857143, 'eval/precision_weighted': 0.7102513227513227, '_timestamp': 1704609499.5351615, 'eval/recall_macro': 0.7136363636363636}","{'rf_max_depth': 21, 'trial.number': 17}",northern-rain-1163,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
176,"{'_step': 20, 'test/loss': 1.359823178435589, 'eval/recall_macro': 0.7477272727272727, 'test/recall_micro': 0.7383177570093458, 'test/recall_weighted': 0.7383177570093458, 'split': 10, 'eval/accuracy': 0.7380952380952381, 'eval/f1_macro': 0.7332251082251082, 'eval/f1_micro': 0.7380952380952381, 'eval/loss': 1.7035355196748998, '_timestamp': 1704608442.1962075, 'eval/f1_weighted': 0.7260874046588333, 'eval/recall_micro': 0.7380952380952381, 'eval/precision_micro': 0.7380952380952381, 'eval/recall_weighted': 0.7380952380952381, 'test/f1_macro': 0.7279597709229629, 'test/f1_weighted': 0.7252112196485496, 'test/recall_macro': 0.7511662515516436, 'eval/precision_macro': 0.7267676767676768, 'test/accuracy': 0.7383177570093458, 'test/f1_micro': 0.7383177570093457, 'test/precision_weighted': 0.7502249167472339, '_wandb': {'runtime': 1623}, '_runtime': 1625.2710225582125, 'test/precision_micro': 0.7383177570093458, 'test/precision_macro': 0.7425466954022989, 'eval/precision_weighted': 0.7220538720538721}","{'rf_max_depth': 32, 'trial.number': 22}",neat-darkness-1162,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
177,"{'_timestamp': 1704608890.2822626, 'test/recall_micro': 0.514018691588785, 'eval/loss': 0.58875888309703, 'eval/f1_macro': 0.7613532348658207, '_step': 20, 'test/accuracy': 0.514018691588785, 'test/precision_weighted': 0.5229664243682935, 'eval/precision_micro': 0.7619047619047619, 'test/precision_macro': 0.513425925925926, 'eval/accuracy': 0.7619047619047619, 'eval/f1_micro': 0.7619047619047619, 'eval/recall_micro': 0.7619047619047619, 'test/recall_macro': 0.5206896551724138, 'split': 10, 'eval/f1_weighted': 0.7630900373463302, 'eval/precision_macro': 0.7708333333333333, 'test/precision_micro': 0.514018691588785, '_wandb': {'runtime': 2173}, '_runtime': 2176.9372475147247, 'test/f1_weighted': 0.511003694999305, 'test/f1_micro': 0.514018691588785, 'eval/recall_macro': 0.7613636363636365, 'eval/recall_weighted': 0.7619047619047619, 'test/recall_weighted': 0.514018691588785, 'test/loss': 8.584747374782312, 'test/f1_macro': 0.5085982359045313, 'eval/precision_weighted': 0.7738095238095238}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 16, 'dt_min_samples_leaf': 5}",silvery-universe-1161,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
178,"{'test/f1_macro': 0.5615646987392408, 'test/f1_micro': 0.5700934579439252, 'eval/recall_micro': 0.5238095238095238, 'eval/precision_micro': 0.5238095238095238, 'eval/loss': 6.566900310298587, 'test/accuracy': 0.5700934579439252, 'eval/recall_macro': 0.5295454545454545, 'eval/precision_macro': 0.5661421911421911, 'test/recall_weighted': 0.5700934579439252, 'test/loss': 8.46250185520599, 'test/recall_micro': 0.5700934579439252, 'test/precision_micro': 0.5700934579439252, 'test/recall_macro': 0.5645999115826702, 'test/precision_macro': 0.5624242424242424, 'eval/precision_weighted': 0.5669608169608169, '_runtime': 1669.7081894874573, 'eval/accuracy': 0.5238095238095238, 'eval/f1_micro': 0.5238095238095238, '_step': 20, 'split': 10, 'test/precision_weighted': 0.5680203908241291, '_wandb': {'runtime': 1668}, '_timestamp': 1704607774.6845517, 'eval/f1_macro': 0.5311167945439045, 'eval/f1_weighted': 0.5281126943531036, 'test/f1_weighted': 0.5669968854027831, 'eval/recall_weighted': 0.5238095238095238}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 21, 'dt_min_samples_leaf': 5}",lilac-blaze-1160,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
179,"{'eval/f1_micro': 0.7142857142857143, 'test/accuracy': 0.7476635514018691, 'test/f1_weighted': 0.7412251361374665, 'eval/precision_macro': 0.6708916083916084, 'eval/recall_weighted': 0.7142857142857143, 'eval/loss': 1.490800942961377, 'test/loss': 0.6696978463160933, 'test/precision_weighted': 0.7479950278532296, 'eval/precision_weighted': 0.6802503052503052, 'test/precision_macro': 0.7414408866995074, 'test/recall_weighted': 0.7476635514018691, '_step': 20, 'split': 10, 'eval/f1_weighted': 0.6899585921325051, 'test/precision_micro': 0.7476635514018691, '_timestamp': 1704607863.6989653, 'eval/f1_macro': 0.6800889328063241, 'test/recall_micro': 0.7476635514018691, '_wandb': {'runtime': 1799}, '_runtime': 1801.4288964271543, 'eval/recall_macro': 0.7045454545454546, 'eval/accuracy': 0.7142857142857143, 'test/f1_macro': 0.7397606085464985, 'test/recall_macro': 0.7516666666666666, 'eval/precision_micro': 0.7142857142857143, 'test/f1_micro': 0.7476635514018691, 'eval/recall_micro': 0.7142857142857143}","{'rf_max_depth': 30, 'trial.number': 19}",sparkling-flower-1159,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
180,"{'eval/loss': 7.682631693929088, 'test/precision_weighted': 0.4956317064728279, 'test/recall_micro': 0.48598130841121495, 'eval/precision_macro': 0.4357638888888889, 'eval/f1_macro': 0.4298245614035088, 'eval/f1_weighted': 0.43776106934001663, 'eval/recall_macro': 0.44318181818181823, 'test/precision_micro': 0.48598130841121495, 'test/recall_weighted': 0.48598130841121495, '_step': 20, 'eval/accuracy': 0.4523809523809524, '_wandb': {'runtime': 1841}, 'test/precision_macro': 0.487962962962963, 'eval/precision_weighted': 0.4432870370370371, 'split': 10, 'test/accuracy': 0.48598130841121495, 'eval/recall_weighted': 0.4523809523809524, 'eval/f1_micro': 0.4523809523809524, 'eval/recall_micro': 0.4523809523809524, 'test/f1_macro': 0.48465759988205814, 'test/f1_weighted': 0.486848705050146, 'test/recall_macro': 0.48871237458193983, '_runtime': 1843.0977873802185, 'test/loss': 8.37508971170748, 'eval/precision_micro': 0.4523809523809524, '_timestamp': 1704607814.9092224, 'test/f1_micro': 0.48598130841121495}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 19, 'dt_min_samples_leaf': 7}",prime-yogurt-1158,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
181,"{'test/f1_macro': 0.7099080418999653, 'test/precision_micro': 0.7289719626168224, 'eval/precision_weighted': 0.7003779289493576, '_wandb': {'runtime': 2140}, '_timestamp': 1704607351.826434, 'eval/f1_weighted': 0.6841651640413249, 'test/f1_weighted': 0.7199593382029773, 'eval/loss': 0.8228616391918473, 'test/accuracy': 0.7289719626168224, 'test/recall_macro': 0.7200065559440559, 'eval/precision_micro': 0.6904761904761905, 'test/recall_weighted': 0.7289719626168224, '_runtime': 2142.2297880649567, 'eval/f1_macro': 0.6858559397259087, 'eval/precision_macro': 0.7056998556998557, 'eval/recall_weighted': 0.6904761904761905, 'split': 10, 'eval/accuracy': 0.6904761904761905, 'test/f1_micro': 0.7289719626168223, 'eval/recall_macro': 0.6886363636363636, 'test/loss': 1.3691909210153954, 'eval/f1_micro': 0.6904761904761905, 'eval/recall_micro': 0.6904761904761905, 'test/recall_micro': 0.7289719626168224, 'test/precision_macro': 0.7097379887627566, 'test/precision_weighted': 0.7211988036182937, '_step': 20}","{'rf_max_depth': 32, 'trial.number': 16}",misunderstood-capybara-1157,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
182,"{'eval/loss': 2.492804197674462, 'test/accuracy': 0.7663551401869159, 'eval/recall_weighted': 0.6904761904761905, 'test/precision_macro': 0.7923463465298143, '_step': 20, 'eval/f1_macro': 0.6987340145234882, 'test/f1_weighted': 0.7443257676902536, 'eval/recall_macro': 0.6977272727272728, '_wandb': {'runtime': 1626}, '_runtime': 1627.8129839897156, 'test/f1_micro': 0.766355140186916, 'eval/recall_micro': 0.6904761904761905, 'test/precision_micro': 0.7663551401869159, 'test/precision_weighted': 0.8089068252619656, 'split': 10, 'test/loss': 2.279074351277272, 'test/f1_macro': 0.7427995391705069, 'eval/f1_weighted': 0.6908128073541607, 'eval/precision_macro': 0.718939393939394, 'eval/f1_micro': 0.6904761904761905, '_timestamp': 1704606812.683769, 'eval/accuracy': 0.6904761904761905, 'test/recall_macro': 0.7770525019748191, 'eval/precision_micro': 0.6904761904761905, 'test/recall_weighted': 0.7663551401869159, 'test/recall_micro': 0.7663551401869159, 'eval/precision_weighted': 0.7106962481962482}","{'rf_max_depth': 20, 'trial.number': 21}",genial-vortex-1156,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
183,"{'eval/accuracy': 1, 'train/train_loss': 4.656612484499334e-11, 'train/train_steps_per_second': 2.38, 'train/train_samples_per_second': 37.985, 'train/loss': 0, 'eval/f1_weighted': 1, 'eval/precision_macro': 1, 'eval/recall_weighted': 1, '_wandb': {'runtime': 10114}, '_timestamp': 1704614673.8405952, 'eval/runtime': 0.3539, 'eval/recall_micro': 1, 'test/latency_in_seconds': 0.007595120214913736, '_runtime': 10115.775079250336, 'train/global_step': 2400, 'train/learning_rate': 6.839445843930423e-06, 'eval/loss': 0, 'eval/recall_macro': 1, '_step': 1050, 'eval/f1_macro': 1, 'eval/f1_micro': 1, 'eval/samples_per_second': 118.673, 'test/samples_per_second': 131.66348546220578, 'train/epoch': 100, 'test/accuracy': 0.5887850467289719, 'eval/steps_per_second': 8.477, 'eval/precision_weighted': 1, 'train/total_flos': 9832620257451264.0, 'train/train_runtime': 1008.3017, 'eval/precision_micro': 1, 'test/total_time_in_seconds': 0.8126778629957698}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_05-16-01_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 4.103667506358254e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",effortless-silence-1155,Fine-Tuned LLM:microsoft/codebert-base,['preprocessed']
184,"{'_wandb': {'runtime': 2172}, 'eval/accuracy': 0.380952380952381, 'eval/f1_macro': 0.35410067873303175, 'test/accuracy': 0.3644859813084112, 'test/loss': 2.643368958400499, 'test/precision_micro': 0.3644859813084112, '_timestamp': 1704606708.7163634, 'eval/recall_macro': 0.37727272727272726, 'test/recall_micro': 0.3644859813084112, 'eval/f1_micro': 0.380952380952381, 'test/recall_macro': 0.3711206896551724, 'eval/precision_weighted': 0.37222222222222223, 'split': 10, '_runtime': 2173.897703409195, 'eval/precision_micro': 0.380952380952381, 'eval/recall_micro': 0.380952380952381, 'test/recall_weighted': 0.3644859813084112, '_step': 20, 'test/f1_micro': 0.36448598130841114, 'test/f1_weighted': 0.3422358874676608, 'eval/precision_macro': 0.36666666666666664, 'test/precision_weighted': 0.33959350075411804, 'eval/loss': 1.9738083783166989, 'test/f1_macro': 0.34742291500739564, 'eval/f1_weighted': 0.358462615815557, 'eval/recall_weighted': 0.380952380952381, 'test/precision_macro': 0.3423405567300916}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 15, 'dt_min_samples_leaf': 28}",restful-silence-1154,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
185,"{'_runtime': 1670.631476163864, 'test/f1_micro': 0.4953271028037383, 'eval/recall_weighted': 0.5, '_step': 20, 'eval/f1_micro': 0.5, 'test/f1_weighted': 0.4909996853215533, 'eval/recall_micro': 0.5, 'eval/f1_macro': 0.490530303030303, 'eval/precision_macro': 0.4917582417582418, 'eval/precision_micro': 0.5, 'eval/precision_weighted': 0.49136577708006274, 'test/loss': 3.869137846812564, 'test/recall_macro': 0.49386604774535814, 'eval/accuracy': 0.5, 'eval/f1_weighted': 0.48899711399711393, 'test/recall_micro': 0.4953271028037383, 'test/recall_weighted': 0.4953271028037383, 'split': 10, '_wandb': {'runtime': 1669}, '_timestamp': 1704606100.551262, 'test/accuracy': 0.4953271028037383, 'test/f1_macro': 0.48565978963474465, 'test/precision_weighted': 0.5131772120170445, 'test/precision_macro': 0.5031130268199234, 'test/precision_micro': 0.4953271028037383, 'eval/loss': 3.5647951722475257, 'eval/recall_macro': 0.5022727272727273}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 20, 'dt_min_samples_leaf': 11}",dulcet-voice-1153,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
186,"{'eval/accuracy': 0.8809523809523809, 'test/accuracy': 0.7289719626168224, 'eval/f1_weighted': 0.881907148824442, 'test/recall_weighted': 0.7289719626168224, '_step': 20, '_timestamp': 1704606057.044329, 'test/f1_macro': 0.709746524129319, 'eval/precision_micro': 0.8809523809523809, '_wandb': {'runtime': 1800}, 'test/recall_macro': 0.7353926282051282, '_runtime': 1801.9238739013672, 'test/loss': 0.77170448164735, 'test/precision_micro': 0.7289719626168224, 'eval/precision_weighted': 0.8848003848003849, 'test/precision_weighted': 0.7174268192613815, 'split': 10, 'eval/recall_macro': 0.8772727272727272, 'eval/precision_macro': 0.8813131313131313, 'eval/recall_weighted': 0.8809523809523809, 'eval/f1_macro': 0.8782752335383914, 'eval/recall_micro': 0.8809523809523809, 'test/f1_weighted': 0.709716839522661, 'eval/f1_micro': 0.8809523809523809, 'test/f1_micro': 0.7289719626168223, 'test/recall_micro': 0.7289719626168224, 'test/precision_macro': 0.7121079035062301, 'eval/loss': 1.4798706349278412}","{'rf_max_depth': 13, 'trial.number': 18}",comfy-voice-1152,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
187,"{'_timestamp': 1704605966.9272397, 'test/f1_macro': 0.33998844820947244, '_step': 20, 'eval/precision_micro': 0.3333333333333333, 'eval/precision_weighted': 0.3258563074352548, '_wandb': {'runtime': 1793}, 'eval/recall_micro': 0.3333333333333333, 'test/precision_macro': 0.35240084670231725, 'test/precision_weighted': 0.35675904176453926, 'eval/loss': 2.207428288934816, 'test/accuracy': 0.35514018691588783, 'test/recall_weighted': 0.35514018691588783, 'test/loss': 4.894267198965886, 'eval/accuracy': 0.3333333333333333, 'eval/f1_weighted': 0.30511076225361944, 'eval/recall_macro': 0.32727272727272727, 'test/recall_micro': 0.35514018691588783, 'split': 10, 'eval/precision_macro': 0.3254385964912281, 'eval/f1_macro': 0.3015567765567765, 'test/f1_weighted': 0.3350120016266072, 'test/precision_micro': 0.35514018691588783, '_runtime': 1795.2179296016693, 'test/f1_micro': 0.35514018691588783, 'test/recall_macro': 0.3672658862876254, 'eval/recall_weighted': 0.3333333333333333, 'eval/f1_micro': 0.3333333333333333}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 18, 'dt_min_samples_leaf': 15}",whole-disco-1151,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
188,"{'eval/precision_micro': 0.6666666666666666, 'test/loss': 1.3566552820447446, 'eval/accuracy': 0.6666666666666666, 'test/f1_micro': 0.7102803738317757, '_runtime': 1627.0221338272097, 'eval/recall_macro': 0.675, 'eval/precision_weighted': 0.6514041514041514, '_step': 20, 'eval/f1_micro': 0.6666666666666666, 'eval/f1_weighted': 0.6539065053939195, 'eval/recall_weighted': 0.6666666666666666, 'test/precision_macro': 0.7298062865497076, '_wandb': {'runtime': 1625}, 'test/accuracy': 0.7102803738317757, 'test/recall_macro': 0.7279026817236544, 'eval/loss': 0.7882119431773986, '_timestamp': 1704605179.8511868, 'test/recall_micro': 0.7102803738317757, 'eval/precision_macro': 0.6569541569541569, 'eval/recall_micro': 0.6666666666666666, 'test/precision_micro': 0.7102803738317757, 'test/recall_weighted': 0.7102803738317757, 'test/precision_weighted': 0.7388677105536426, 'eval/f1_macro': 0.6606927397545246, 'test/f1_macro': 0.6807054152826371, 'test/f1_weighted': 0.6751989853519532, 'split': 10}","{'rf_max_depth': 32, 'trial.number': 20}",atomic-blaze-1150,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
189,"{'_timestamp': 1704605204.9401927, 'eval/recall_macro': 0.759090909090909, '_step': 20, 'eval/precision_macro': 0.7569444444444444, 'eval/f1_micro': 0.7619047619047619, 'test/f1_weighted': 0.7989218440656047, 'test/recall_micro': 0.8037383177570093, 'test/precision_micro': 0.8037383177570093, 'test/recall_weighted': 0.8037383177570093, 'eval/f1_macro': 0.7538433534428958, 'eval/recall_micro': 0.7619047619047619, 'test/recall_macro': 0.809222027972028, 'eval/recall_weighted': 0.7619047619047619, '_wandb': {'runtime': 2140}, 'eval/loss': 0.7004820931459805, 'test/loss': 1.0012145416380838, 'test/accuracy': 0.8037383177570093, 'eval/f1_weighted': 0.757387044686816, 'split': 10, 'eval/accuracy': 0.7619047619047619, 'test/f1_macro': 0.8008323987595292, 'test/precision_macro': 0.8029223111658457, 'eval/precision_weighted': 0.7612433862433863, '_runtime': 2142.7588696479797, 'eval/precision_micro': 0.7619047619047619, 'test/f1_micro': 0.8037383177570093, 'test/precision_weighted': 0.8054891195924067}","{'rf_max_depth': 32, 'trial.number': 15}",azure-serenity-1149,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
190,"{'eval/loss': 6.998923997414127, '_timestamp': 1704604425.4818234, 'test/recall_macro': 0.5427718832891246, 'test/precision_macro': 0.5376778394019773, 'test/recall_weighted': 0.5514018691588785, 'eval/f1_micro': 0.380952380952381, 'test/precision_micro': 0.5514018691588785, 'split': 10, 'eval/f1_macro': 0.3769841269841269, 'eval/recall_macro': 0.38409090909090904, 'eval/recall_weighted': 0.380952380952381, '_step': 20, '_wandb': {'runtime': 1669}, '_runtime': 1670.694191455841, 'test/recall_micro': 0.5514018691588785, 'eval/precision_micro': 0.380952380952381, 'eval/accuracy': 0.380952380952381, 'eval/precision_weighted': 0.382034632034632, 'test/precision_weighted': 0.5450590337796267, 'test/f1_micro': 0.5514018691588785, 'eval/f1_weighted': 0.3756613756613756, 'test/f1_weighted': 0.5480206656490675, 'eval/recall_micro': 0.380952380952381, 'eval/precision_macro': 0.3814935064935064, 'test/loss': 3.805856364655185, 'test/accuracy': 0.5514018691588785, 'test/f1_macro': 0.5400081001494724}","{'dt_criterion': 'gini', 'dt_max_depth': 8, 'trial.number': 19, 'dt_min_samples_leaf': 7}",swept-wildflower-1148,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
191,"{'eval/f1_macro': 0.7276411136536994, 'test/f1_macro': 0.7508029441284712, 'eval/recall_weighted': 0.7380952380952381, 'eval/precision_weighted': 0.7335164835164835, 'eval/f1_weighted': 0.7313800806363735, 'test/precision_weighted': 0.7901285798482061, '_step': 20, 'split': 10, '_wandb': {'runtime': 1798}, 'test/loss': 1.0177226678244176, 'eval/precision_micro': 0.7380952380952381, '_runtime': 1799.8277914524078, 'eval/recall_macro': 0.7318181818181818, 'test/recall_macro': 0.7625, 'eval/precision_macro': 0.7323717948717948, 'test/recall_micro': 0.7570093457943925, 'test/precision_macro': 0.7901383526383526, 'test/precision_micro': 0.7570093457943925, 'test/f1_weighted': 0.7494711137097707, '_timestamp': 1704604250.9841084, 'eval/recall_micro': 0.7380952380952381, 'eval/loss': 1.479460278079459, 'eval/f1_micro': 0.7380952380952381, 'test/f1_micro': 0.7570093457943925, 'test/recall_weighted': 0.7570093457943925, 'eval/accuracy': 0.7380952380952381, 'test/accuracy': 0.7570093457943925}","{'rf_max_depth': 22, 'trial.number': 17}",scarlet-flower-1147,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
192,"{'_timestamp': 1704604165.1292512, 'eval/accuracy': 0.4523809523809524, 'eval/precision_weighted': 0.4317129629629629, '_wandb': {'runtime': 1783}, 'test/loss': 9.009097296157806, 'eval/f1_macro': 0.42616959064327486, 'test/recall_macro': 0.48871237458193983, 'eval/loss': 8.4859904628844, 'eval/f1_micro': 0.4523809523809524, 'eval/precision_micro': 0.4523809523809524, '_step': 20, 'test/recall_micro': 0.48598130841121495, 'eval/recall_weighted': 0.4523809523809524, 'test/f1_micro': 0.48598130841121495, 'test/f1_macro': 0.4843859649122807, 'test/f1_weighted': 0.4865846860141006, 'eval/precision_macro': 0.4253472222222222, 'test/recall_weighted': 0.48598130841121495, 'test/precision_weighted': 0.4958799227325004, 'split': 10, 'eval/recall_micro': 0.4523809523809524, 'test/precision_micro': 0.48598130841121495, 'eval/f1_weighted': 0.43365357839042046, 'test/accuracy': 0.48598130841121495, 'eval/recall_macro': 0.44318181818181823, 'test/precision_macro': 0.48821833930704905, '_runtime': 1785.5603342056274}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 17, 'dt_min_samples_leaf': 7}",silver-river-1146,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
193,"{'test/loss': 6.544721567576533, 'test/f1_micro': 0.4392523364485981, 'eval/recall_macro': 0.615909090909091, 'test/precision_weighted': 0.4886837168793756, 'eval/accuracy': 0.6190476190476191, 'test/accuracy': 0.4392523364485981, 'test/f1_macro': 0.4345321257085963, 'eval/precision_macro': 0.6924019607843137, 'eval/recall_weighted': 0.6190476190476191, '_runtime': 2177.7714896202087, 'eval/f1_weighted': 0.6323398924787307, 'eval/recall_micro': 0.6190476190476191, 'test/recall_macro': 0.4517241379310345, '_wandb': {'runtime': 2175}, 'test/f1_weighted': 0.4314993688275711, 'test/recall_micro': 0.4392523364485981, 'eval/precision_micro': 0.6190476190476191, 'eval/precision_weighted': 0.6856909430438842, '_step': 20, 'split': 10, 'eval/f1_macro': 0.633677383997077, 'eval/f1_micro': 0.6190476190476191, 'test/precision_macro': 0.48080197132616487, 'test/recall_weighted': 0.4392523364485981, 'eval/loss': 0.757675074688319, '_timestamp': 1704604530.2569857, 'test/precision_micro': 0.4392523364485981}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 14, 'dt_min_samples_leaf': 5}",polished-river-1145,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
194,"{'eval/recall_micro': 0.6190476190476191, 'test/recall_micro': 0.7663551401869159, 'test/precision_micro': 0.7663551401869159, 'eval/f1_weighted': 0.6067951372299198, 'test/f1_weighted': 0.760316527775267, 'eval/accuracy': 0.6190476190476191, 'eval/f1_macro': 0.6085841694537346, 'eval/loss': 0.9222118963166184, 'test/recall_macro': 0.780182993180829, '_step': 20, '_runtime': 1626.1903057098389, 'test/loss': 0.7585125417440298, 'test/precision_macro': 0.7804659498207885, 'eval/recall_weighted': 0.6190476190476191, 'test/recall_weighted': 0.7663551401869159, '_timestamp': 1704603547.0044086, 'test/accuracy': 0.7663551401869159, 'test/f1_macro': 0.759488118264714, 'test/f1_micro': 0.766355140186916, 'eval/recall_macro': 0.625, 'eval/precision_macro': 0.6864583333333334, 'eval/precision_weighted': 0.691468253968254, 'split': 10, '_wandb': {'runtime': 1624}, 'eval/precision_micro': 0.6190476190476191, 'eval/f1_micro': 0.6190476190476191, 'test/precision_weighted': 0.7957659196730645}","{'rf_max_depth': 10, 'trial.number': 19}",classic-durian-1144,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
195,"{'eval/recall_macro': 0.2818181818181818, '_wandb': {'runtime': 1668}, 'eval/f1_macro': 0.27608543417366943, 'eval/f1_micro': 0.2857142857142857, 'eval/precision_micro': 0.2857142857142857, 'split': 10, 'eval/recall_weighted': 0.2857142857142857, 'test/accuracy': 0.4485981308411215, 'test/f1_micro': 0.4485981308411215, 'test/recall_macro': 0.4434208033345965, 'test/precision_macro': 0.4499158249158249, 'test/recall_weighted': 0.4485981308411215, 'test/precision_weighted': 0.4585732716573837, '_step': 20, 'eval/loss': 1.3064415103627407, 'eval/accuracy': 0.2857142857142857, 'test/f1_macro': 0.44122222138887435, 'test/recall_micro': 0.4485981308411215, 'test/precision_micro': 0.4485981308411215, '_runtime': 1671.267192363739, '_timestamp': 1704602748.6621184, 'eval/precision_weighted': 0.29488602458527263, 'test/loss': 1.7657780003641337, 'eval/f1_weighted': 0.27767773776177135, 'test/f1_weighted': 0.44804460713576505, 'eval/recall_micro': 0.2857142857142857, 'eval/precision_macro': 0.2955513784461153}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 18, 'dt_min_samples_leaf': 25}",valiant-plant-1143,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
196,"{'split': 10, '_wandb': {'runtime': 2142}, 'eval/f1_macro': 0.5621212121212121, 'test/precision_weighted': 0.734645116038161, 'eval/loss': 1.770847436588662, 'eval/f1_micro': 0.5952380952380952, 'test/recall_micro': 0.7476635514018691, '_runtime': 2144.7179408073425, 'eval/recall_weighted': 0.5952380952380952, '_step': 20, 'test/precision_macro': 0.730012104953216, 'test/precision_micro': 0.7476635514018691, 'test/loss': 1.0887664384790663, 'eval/accuracy': 0.5952380952380952, 'test/f1_macro': 0.7307888070401974, 'eval/recall_micro': 0.5952380952380952, '_timestamp': 1704603057.4540029, 'test/accuracy': 0.7476635514018691, 'eval/recall_macro': 0.5977272727272727, 'test/recall_weighted': 0.7476635514018691, 'test/f1_weighted': 0.7374936610660623, 'test/recall_macro': 0.7395934505309505, 'eval/precision_weighted': 0.5759637188208616, 'test/f1_micro': 0.7476635514018691, 'eval/f1_weighted': 0.5607503607503608, 'eval/precision_macro': 0.5744047619047619, 'eval/precision_micro': 0.5952380952380952}","{'rf_max_depth': 14, 'trial.number': 14}",sparkling-smoke-1142,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
197,"{'_step': 20, 'eval/f1_macro': 0.7939744079449962, 'eval/precision_macro': 0.7984432234432235, '_wandb': {'runtime': 1800}, 'test/loss': 1.6144988861872047, 'eval/f1_micro': 0.8095238095238095, 'test/accuracy': 0.7383177570093458, 'test/f1_micro': 0.7383177570093457, 'eval/recall_macro': 0.8068181818181819, 'test/recall_macro': 0.7402483974358974, 'eval/accuracy': 0.8095238095238095, 'eval/precision_micro': 0.8095238095238095, 'eval/loss': 1.5038293541027312, 'eval/precision_weighted': 0.799616256759114, 'test/precision_weighted': 0.7263699747811898, 'test/precision_micro': 0.7383177570093458, 'test/f1_macro': 0.732545254411853, 'test/f1_weighted': 0.729520632935439, 'eval/recall_micro': 0.8095238095238095, 'test/recall_micro': 0.7383177570093458, 'split': 10, '_runtime': 1801.4459691047668, '_timestamp': 1704602446.527168, 'eval/f1_weighted': 0.796132089199316, 'eval/recall_weighted': 0.8095238095238095, 'test/precision_macro': 0.7305158730158731, 'test/recall_weighted': 0.7383177570093458}","{'rf_max_depth': 22, 'trial.number': 16}",fast-frost-1141,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
198,"{'_runtime': 1784.6737298965454, 'test/loss': 9.266216437100066, 'eval/accuracy': 0.4523809523809524, 'eval/f1_macro': 0.4417521075415812, 'test/f1_micro': 0.4953271028037383, 'test/f1_weighted': 0.5041989608077726, 'eval/recall_macro': 0.45, 'split': 10, 'test/precision_micro': 0.4953271028037383, 'eval/precision_weighted': 0.4811507936507936, '_timestamp': 1704602375.123185, 'test/accuracy': 0.4953271028037383, 'eval/f1_micro': 0.4523809523809524, 'test/f1_macro': 0.5038651824366109, 'eval/precision_macro': 0.4759469696969697, '_wandb': {'runtime': 1783}, 'eval/precision_micro': 0.4523809523809524, 'eval/f1_weighted': 0.44623463420455894, 'eval/loss': 9.155631619867702, 'test/recall_micro': 0.4953271028037383, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_macro': 0.5445939582729643, 'test/precision_weighted': 0.5561843106562638, 'eval/recall_micro': 0.4523809523809524, 'test/recall_macro': 0.501228051839465, 'test/recall_weighted': 0.4953271028037383, '_step': 20}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 16, 'dt_min_samples_leaf': 6}",stilted-violet-1140,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
199,"{'eval/loss': 1.5524739707100874, 'eval/f1_micro': 0.7619047619047619, 'test/precision_macro': 0.8022925350511558, '_step': 20, 'test/precision_micro': 0.8037383177570093, 'test/loss': 2.257859773093366, '_timestamp': 1704601912.7957375, 'eval/accuracy': 0.7619047619047619, 'test/f1_weighted': 0.7999143748576039, 'test/accuracy': 0.8037383177570093, 'eval/precision_weighted': 0.7511544011544011, 'eval/f1_macro': 0.7582251082251082, 'eval/precision_micro': 0.7619047619047619, 'test/recall_weighted': 0.8037383177570093, 'test/precision_weighted': 0.8061818941612691, '_wandb': {'runtime': 1625}, 'test/f1_micro': 0.8037383177570093, 'eval/recall_macro': 0.7704545454545454, 'test/recall_micro': 0.8037383177570093, 'eval/precision_macro': 0.7545454545454546, 'test/f1_macro': 0.8032141890728395, 'eval/recall_micro': 0.7619047619047619, 'eval/recall_weighted': 0.7619047619047619, 'split': 10, '_runtime': 1627.185616493225, 'eval/f1_weighted': 0.7522778808493095, 'test/recall_macro': 0.8146657518015186}","{'rf_max_depth': 29, 'trial.number': 18}",earnest-water-1139,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
200,"{'eval/loss': 1.570687774789064, 'eval/precision_macro': 0.6924019607843137, 'eval/f1_micro': 0.6190476190476191, 'test/f1_weighted': 0.4314993688275711, 'test/recall_macro': 0.4517241379310345, 'test/precision_macro': 0.48080197132616487, 'eval/precision_weighted': 0.6856909430438842, 'test/accuracy': 0.4392523364485981, 'eval/recall_micro': 0.6190476190476191, 'test/precision_weighted': 0.4886837168793756, 'eval/accuracy': 0.6190476190476191, 'test/recall_micro': 0.4392523364485981, 'split': 10, 'test/f1_micro': 0.4392523364485981, '_runtime': 2175.2047975063324, 'test/f1_macro': 0.4345321257085963, 'eval/recall_macro': 0.615909090909091, 'test/loss': 6.544721567576533, '_timestamp': 1704602347.1155057, 'eval/f1_macro': 0.633677383997077, 'eval/f1_weighted': 0.6323398924787307, 'test/precision_micro': 0.4392523364485981, '_step': 20, '_wandb': {'runtime': 2173}, 'eval/precision_micro': 0.6190476190476191, 'eval/recall_weighted': 0.6190476190476191, 'test/recall_weighted': 0.4392523364485981}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 13, 'dt_min_samples_leaf': 5}",swift-violet-1138,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
201,"{'eval/f1_macro': 1, 'train/epoch': 50, 'train/learning_rate': 2.526629654473182e-07, 'test/latency_in_seconds': 0.007629400943884643, 'train/global_step': 600, 'train/train_loss': 8.371089847969415e-09, 'eval/recall_micro': 1, 'eval/recall_weighted': 1, 'eval/accuracy': 1, 'eval/runtime': 0.337, 'test/accuracy': 0.5887850467289719, 'eval/recall_macro': 1, 'eval/precision_micro': 1, 'train/train_steps_per_second': 1.214, '_wandb': {'runtime': 4943}, 'train/train_runtime': 494.1764, 'train/train_samples_per_second': 38.751, '_runtime': 4944.412005901337, '_timestamp': 1704604551.599905, 'eval/f1_weighted': 1, '_step': 520, 'eval/precision_macro': 1, 'eval/steps_per_second': 5.935, 'eval/samples_per_second': 124.644, 'test/samples_per_second': 131.0718898318683, 'test/total_time_in_seconds': 0.8163459009956568, 'eval/loss': 2.838316248698902e-09, 'eval/f1_micro': 1, 'train/total_flos': 5029123075033824.0, 'eval/precision_weighted': 1, 'train/loss': 0}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_03-53-31_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.5159777926839089e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",neat-butterfly-1137,Fine-Tuned LLM:microsoft/codebert-base,['preprocessed']
202,"{'eval/loss': 3.598796609182955, 'eval/recall_weighted': 0.4047619047619048, 'test/recall_weighted': 0.5233644859813084, 'eval/f1_micro': 0.4047619047619048, 'test/f1_weighted': 0.5053986511930437, 'test/recall_macro': 0.5188992042440319, 'eval/f1_macro': 0.39238095238095233, 'test/accuracy': 0.5233644859813084, '_step': 20, '_wandb': {'runtime': 1668}, 'test/loss': 3.5070417634473157, 'test/precision_micro': 0.5233644859813084, 'split': 10, '_runtime': 1670.175392150879, 'test/precision_macro': 0.4957973678601875, 'test/f1_micro': 0.5233644859813084, 'eval/f1_weighted': 0.3917913832199546, 'eval/precision_micro': 0.4047619047619048, 'eval/accuracy': 0.4047619047619048, 'eval/recall_macro': 0.40454545454545454, 'eval/precision_macro': 0.3879419191919192, 'eval/recall_micro': 0.4047619047619048, 'eval/precision_weighted': 0.38666426166426165, 'test/precision_weighted': 0.5001224992231756, '_timestamp': 1704601071.2126482, 'test/f1_macro': 0.5009157509157509, 'test/recall_micro': 0.5233644859813084}","{'dt_criterion': 'gini', 'dt_max_depth': 9, 'trial.number': 17, 'dt_min_samples_leaf': 7}",fallen-aardvark-1136,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
203,"{'eval/loss': 0.6567238052670898, 'eval/f1_weighted': 0.8291156462585034, 'test/precision_weighted': 0.7083775884728136, 'split': 10, 'eval/recall_macro': 0.8272727272727273, 'eval/recall_weighted': 0.8333333333333334, '_step': 20, '_timestamp': 1704600640.597354, '_runtime': 1801.7635798454285, 'test/accuracy': 0.719626168224299, 'eval/recall_micro': 0.8333333333333334, 'eval/precision_micro': 0.8333333333333334, 'test/precision_macro': 0.7014154736624147, 'test/recall_micro': 0.719626168224299, 'eval/precision_weighted': 0.836734693877551, 'test/recall_macro': 0.7235897435897436, 'test/recall_weighted': 0.719626168224299, 'test/f1_macro': 0.6949971735443753, 'test/f1_weighted': 0.6972702250070001, '_wandb': {'runtime': 1800}, 'test/loss': 1.1273621827076328, 'eval/accuracy': 0.8333333333333334, 'eval/f1_macro': 0.8247619047619047, 'eval/f1_micro': 0.8333333333333334, 'test/f1_micro': 0.7196261682242989, 'eval/precision_macro': 0.8339285714285715, 'test/precision_micro': 0.719626168224299}","{'rf_max_depth': 12, 'trial.number': 15}",soft-plasma-1135,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
204,"{'_runtime': 1785.9491863250732, 'test/recall_macro': 0.3225334448160535, 'eval/recall_weighted': 0.35714285714285715, 'test/precision_micro': 0.34579439252336447, 'eval/f1_weighted': 0.2359717577108882, 'eval/recall_macro': 0.3636363636363637, 'split': 10, 'eval/f1_macro': 0.23690078037904128, 'eval/precision_macro': 0.19037356321839083, 'test/precision_weighted': 0.3643227686850378, '_wandb': {'runtime': 1784}, 'test/f1_micro': 0.34579439252336447, 'test/recall_micro': 0.34579439252336447, '_step': 20, 'eval/accuracy': 0.35714285714285715, 'eval/f1_micro': 0.35714285714285715, 'test/recall_weighted': 0.34579439252336447, 'eval/precision_micro': 0.35714285714285715, 'eval/loss': 3.690589082023141, 'test/f1_macro': 0.2849702380952381, 'eval/precision_weighted': 0.19122879036672144, 'test/loss': 3.2849213738703393, '_timestamp': 1704600586.2382524, 'test/accuracy': 0.34579439252336447, 'test/f1_weighted': 0.2919336893635959, 'eval/recall_micro': 0.35714285714285715, 'test/precision_macro': 0.3680104942722102}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 15, 'dt_min_samples_leaf': 5}",giddy-valley-1134,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
205,"{'test/f1_weighted': 0.6894546866034273, 'eval/precision_macro': 0.659375, 'test/recall_weighted': 0.7102803738317757, 'eval/loss': 0.7679222100673557, 'eval/f1_macro': 0.6520955165692007, 'test/precision_macro': 0.6582602752639517, 'split': 10, '_wandb': {'runtime': 2141}, '_timestamp': 1704600908.029588, 'eval/f1_micro': 0.6666666666666666, 'test/accuracy': 0.7102803738317757, 'test/f1_micro': 0.7102803738317757, '_step': 20, 'test/loss': 1.0543134572781547, 'eval/recall_weighted': 0.6666666666666666, '_runtime': 2142.791980981827, 'eval/accuracy': 0.6666666666666666, 'test/f1_macro': 0.6686484991569738, 'eval/f1_weighted': 0.6479624988396918, 'test/recall_micro': 0.7102803738317757, 'test/precision_weighted': 0.6756539765438886, 'eval/recall_macro': 0.6681818181818182, 'eval/recall_micro': 0.6666666666666666, 'test/recall_macro': 0.686680506993007, 'eval/precision_micro': 0.6666666666666666, 'test/precision_micro': 0.7102803738317757, 'eval/precision_weighted': 0.6532738095238095}","{'rf_max_depth': 18, 'trial.number': 13}",electric-glade-1133,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
206,"{'test/recall_micro': 0.6261682242990654, 'test/loss': 1.0957655555021724, 'test/f1_micro': 0.6261682242990654, 'eval/recall_micro': 0.5238095238095238, 'test/precision_weighted': 0.6323140449892787, 'test/f1_macro': 0.6140376096771446, 'eval/f1_weighted': 0.4927170868347339, 'eval/precision_macro': 0.4818181818181818, 'test/precision_macro': 0.6294304653679654, 'test/recall_weighted': 0.6261682242990654, 'eval/f1_macro': 0.49622994652406416, 'test/recall_macro': 0.6409627847366639, 'eval/loss': 1.1023127355398028, 'eval/recall_macro': 0.5295454545454545, 'eval/precision_micro': 0.5238095238095238, 'test/precision_micro': 0.6261682242990654, 'eval/precision_weighted': 0.4801587301587302, '_wandb': {'runtime': 1624}, 'eval/f1_micro': 0.5238095238095238, 'test/accuracy': 0.6261682242990654, 'eval/recall_weighted': 0.5238095238095238, 'eval/accuracy': 0.5238095238095238, 'test/f1_weighted': 0.607745131055281, '_step': 20, '_timestamp': 1704600280.787997, 'split': 10, '_runtime': 1626.1195220947266}","{'rf_max_depth': 6, 'trial.number': 17}",misunderstood-firefly-1132,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
207,"{'eval/precision_micro': 0.5714285714285714, 'eval/precision_weighted': 0.5993450993450994, 'eval/loss': 0.9261239138096188, '_timestamp': 1704600167.2677448, 'eval/accuracy': 0.5714285714285714, 'eval/f1_macro': 0.5854010025062656, 'test/recall_macro': 0.4275862068965517, '_runtime': 2174.916399717331, 'test/precision_macro': 0.4369399641577061, 'test/precision_weighted': 0.4363087461896627, 'split': 10, '_step': 20, 'test/f1_macro': 0.42406519304737333, 'test/loss': 5.294393730988487, 'eval/recall_macro': 0.575, 'test/recall_micro': 0.4299065420560747, 'eval/precision_macro': 0.6021756021756022, 'test/f1_micro': 0.4299065420560747, 'eval/recall_micro': 0.5714285714285714, 'eval/recall_weighted': 0.5714285714285714, 'test/precision_micro': 0.4299065420560747, 'test/recall_weighted': 0.4299065420560747, '_wandb': {'runtime': 2173}, 'test/f1_weighted': 0.4243185860680821, 'eval/f1_micro': 0.5714285714285714, 'test/accuracy': 0.4299065420560747, 'eval/f1_weighted': 0.5821279388948563}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 12, 'dt_min_samples_leaf': 13}",proud-eon-1131,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
208,"{'eval/recall_weighted': 0.4047619047619048, 'test/precision_micro': 0.48598130841121495, 'test/recall_weighted': 0.48598130841121495, 'test/loss': 4.1641711939284285, 'eval/f1_macro': 0.4179216583658635, 'eval/f1_micro': 0.4047619047619048, 'eval/f1_weighted': 0.41626624105019583, 'eval/recall_macro': 0.40681818181818186, 'test/recall_micro': 0.48598130841121495, 'eval/accuracy': 0.4047619047619048, 'eval/recall_micro': 0.4047619047619048, 'split': 10, '_timestamp': 1704599396.4822478, 'test/precision_weighted': 0.501622514229499, 'test/f1_macro': 0.4815065967275056, 'test/f1_weighted': 0.48503204548154927, 'eval/precision_macro': 0.44883241758241754, 'test/recall_macro': 0.4845506504989264, 'eval/precision_micro': 0.4047619047619048, '_wandb': {'runtime': 1668}, '_runtime': 1669.5131747722626, 'test/accuracy': 0.48598130841121495, 'test/f1_micro': 0.48598130841121495, '_step': 20, 'eval/loss': 2.9246165749339617, 'test/precision_macro': 0.4956954887218046, 'eval/precision_weighted': 0.44744243851386706}","{'dt_criterion': 'gini', 'dt_max_depth': 16, 'trial.number': 16, 'dt_min_samples_leaf': 13}",peach-wave-1130,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
209,"{'eval/accuracy': 0.6904761904761905, 'test/f1_micro': 0.8130841121495327, 'eval/f1_weighted': 0.676984126984127, 'eval/recall_macro': 0.6795454545454546, 'eval/recall_micro': 0.6904761904761905, 'test/recall_weighted': 0.8130841121495327, 'test/loss': 1.5768205050209516, '_timestamp': 1704598833.978104, 'test/f1_macro': 0.8046475754902271, 'test/precision_micro': 0.8130841121495327, 'split': 10, 'eval/f1_micro': 0.6904761904761905, 'test/accuracy': 0.8130841121495327, 'test/f1_weighted': 0.8088369651166566, 'eval/precision_micro': 0.6904761904761905, 'eval/precision_weighted': 0.701530612244898, '_wandb': {'runtime': 1799}, 'test/recall_macro': 0.8133653846153845, 'eval/recall_weighted': 0.6904761904761905, 'eval/f1_macro': 0.6708333333333333, 'test/precision_macro': 0.8052681992337165, 'test/precision_weighted': 0.8136749382318186, '_step': 20, '_runtime': 1800.9699847698212, 'eval/loss': 0.7550152162543257, 'test/recall_micro': 0.8130841121495327, 'eval/precision_macro': 0.7008928571428571}","{'rf_max_depth': 32, 'trial.number': 14}",drawn-darkness-1129,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
210,"{'eval/recall_macro': 0.6772727272727272, 'test/recall_weighted': 0.7663551401869159, '_runtime': 1627.198898077011, 'test/loss': 1.9486492501899104, 'eval/precision_micro': 0.6666666666666666, 'test/precision_micro': 0.7663551401869159, '_timestamp': 1704598649.705377, 'eval/f1_macro': 0.6514599317988066, 'eval/recall_micro': 0.6666666666666666, 'test/recall_micro': 0.7663551401869159, 'eval/precision_weighted': 0.6456043956043956, '_step': 20, '_wandb': {'runtime': 1625}, 'eval/precision_macro': 0.6519230769230768, 'test/precision_macro': 0.792741136858784, 'eval/accuracy': 0.6666666666666666, 'test/f1_micro': 0.766355140186916, 'test/precision_weighted': 0.8000144379473682, 'test/recall_macro': 0.7803104496139027, 'eval/recall_weighted': 0.6666666666666666, 'eval/f1_weighted': 0.6427302805180043, 'split': 10, 'test/accuracy': 0.7663551401869159, 'eval/f1_micro': 0.6666666666666666, 'test/f1_weighted': 0.7407784917839605, 'eval/loss': 1.5900837877455427, 'test/f1_macro': 0.745789942771367}","{'rf_max_depth': 17, 'trial.number': 16}",decent-firebrand-1128,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
211,"{'_timestamp': 1704598796.0770493, '_wandb': {'runtime': 1780}, 'eval/f1_micro': 0.30952380952380953, 'test/recall_macro': 0.45746237458193983, 'eval/f1_macro': 0.2863029269678886, 'test/f1_macro': 0.43497370969973714, 'eval/recall_micro': 0.30952380952380953, 'test/recall_micro': 0.4485981308411215, 'eval/precision_micro': 0.30952380952380953, 'test/precision_macro': 0.47548994415321894, 'split': 10, 'test/loss': 6.611005717064028, 'test/accuracy': 0.4485981308411215, 'test/precision_weighted': 0.4768769478410085, '_step': 20, 'eval/recall_macro': 0.30227272727272725, 'test/recall_weighted': 0.4485981308411215, 'test/f1_weighted': 0.4315462395042474, 'eval/accuracy': 0.30952380952380953, 'test/f1_micro': 0.4485981308411215, 'eval/f1_weighted': 0.2915330383361074, 'test/precision_micro': 0.4485981308411215, '_runtime': 1781.885038137436, 'eval/loss': 6.224223840712481, 'eval/precision_macro': 0.28422619047619047, 'eval/recall_weighted': 0.30952380952380953, 'eval/precision_weighted': 0.2875566893424036}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 14, 'dt_min_samples_leaf': 5}",morning-salad-1127,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
212,"{'eval/loss': 0.7948057308698564, 'test/accuracy': 0.7663551401869159, 'test/f1_macro': 0.7547723519234509, 'eval/precision_macro': 0.7327922077922078, '_wandb': {'runtime': 2141}, 'eval/recall_micro': 0.7142857142857143, '_runtime': 2142.707892179489, '_timestamp': 1704598760.7123222, 'eval/f1_macro': 0.7115966386554622, 'test/recall_weighted': 0.7663551401869159, 'eval/precision_weighted': 0.7308905380333952, '_step': 20, 'test/f1_micro': 0.766355140186916, 'eval/precision_micro': 0.7142857142857143, 'test/precision_weighted': 0.7693280331543113, 'test/recall_micro': 0.7663551401869159, 'test/precision_macro': 0.7577951460304402, 'split': 10, 'test/loss': 0.6615457947540789, 'eval/f1_weighted': 0.7122689075630251, 'eval/accuracy': 0.7142857142857143, 'eval/f1_micro': 0.7142857142857143, 'test/f1_weighted': 0.7623332549156348, 'eval/recall_macro': 0.7113636363636364, 'test/recall_macro': 0.761909965034965, 'eval/recall_weighted': 0.7142857142857143, 'test/precision_micro': 0.7663551401869159}","{'rf_max_depth': 16, 'trial.number': 12}",crisp-river-1126,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
213,"{'_step': 20, 'split': 10, 'eval/f1_macro': 0.4689151747655584, 'eval/precision_micro': 0.47619047619047616, 'eval/accuracy': 0.47619047619047616, 'test/precision_weighted': 0.5555542968627081, '_timestamp': 1704597722.59375, 'test/accuracy': 0.5514018691588785, 'test/f1_micro': 0.5514018691588785, 'test/recall_macro': 0.5453691423519009, 'test/precision_micro': 0.5514018691588785, 'test/recall_weighted': 0.5514018691588785, 'eval/precision_weighted': 0.4908424908424909, 'eval/loss': 6.75329354682437, 'test/f1_weighted': 0.5509229584280473, 'test/recall_micro': 0.5514018691588785, 'test/precision_macro': 0.5505387205387205, '_wandb': {'runtime': 1668}, 'test/f1_macro': 0.5454304672688748, 'eval/recall_micro': 0.47619047619047616, 'test/loss': 7.259261896813334, 'eval/recall_macro': 0.484090909090909, '_runtime': 1670.8123059272766, 'eval/f1_micro': 0.47619047619047616, 'eval/f1_weighted': 0.4649332196646775, 'eval/precision_macro': 0.4903846153846154, 'eval/recall_weighted': 0.47619047619047616}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 15, 'dt_min_samples_leaf': 5}",daily-plasma-1125,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
214,"{'test/f1_micro': 0.40186915887850466, 'eval/recall_micro': 0.3333333333333333, 'test/recall_micro': 0.40186915887850466, 'test/loss': 1.3491565834290358, 'test/accuracy': 0.40186915887850466, 'test/f1_macro': 0.32746935832732516, 'eval/recall_macro': 0.33181818181818185, 'test/precision_micro': 0.40186915887850466, 'eval/precision_weighted': 0.25396825396825395, '_timestamp': 1704597987.701867, 'test/f1_weighted': 0.35501350996233383, 'split': 10, 'eval/accuracy': 0.3333333333333333, 'eval/f1_macro': 0.2678787878787879, 'eval/precision_macro': 0.25757575757575757, 'eval/recall_weighted': 0.3333333333333333, 'test/precision_macro': 0.3265534332688588, 'test/precision_weighted': 0.354020544478389, '_step': 20, 'test/recall_macro': 0.3706896551724138, 'test/recall_weighted': 0.40186915887850466, '_wandb': {'runtime': 2172}, 'eval/loss': 1.3941003355932122, 'eval/f1_micro': 0.3333333333333333, 'eval/f1_weighted': 0.2666666666666667, 'eval/precision_micro': 0.3333333333333333, '_runtime': 2173.653263092041}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 11, 'dt_min_samples_leaf': 33}",breezy-monkey-1124,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
215,"{'test/loss': 0.8769926463508154, 'test/f1_micro': 0.7009345794392523, 'eval/recall_macro': 0.5545454545454546, 'eval/precision_macro': 0.6225108225108226, '_wandb': {'runtime': 1625}, 'eval/loss': 1.0357116366707873, 'eval/recall_weighted': 0.5476190476190477, '_runtime': 1626.635397195816, 'eval/f1_weighted': 0.5234177004134987, 'eval/recall_micro': 0.5476190476190477, 'test/recall_micro': 0.7009345794392523, 'test/recall_weighted': 0.7009345794392523, 'eval/f1_micro': 0.5476190476190477, 'test/precision_weighted': 0.7005610826382608, '_step': 20, '_timestamp': 1704597017.6076305, 'eval/f1_macro': 0.5257790616246498, 'test/accuracy': 0.7009345794392523, 'test/f1_weighted': 0.6632803725495795, 'eval/precision_weighted': 0.6254071325499896, 'eval/accuracy': 0.5476190476190477, 'test/recall_macro': 0.7193852670438974, 'eval/precision_micro': 0.5476190476190477, 'test/f1_macro': 0.674423961469864, 'test/precision_micro': 0.7009345794392523, 'split': 10, 'test/precision_macro': 0.7010304659498208}","{'rf_max_depth': 8, 'trial.number': 15}",summer-totem-1123,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
216,"{'_runtime': 1800.5067341327667, 'test/accuracy': 0.7570093457943925, 'test/f1_micro': 0.7570093457943925, 'eval/recall_macro': 0.7318181818181819, 'eval/precision_macro': 0.7210622710622712, 'split': 10, 'test/precision_macro': 0.7555443548387097, 'eval/precision_weighted': 0.7227455084597942, 'eval/f1_micro': 0.7380952380952381, 'eval/recall_weighted': 0.7380952380952381, 'test/precision_weighted': 0.7596472716309919, 'eval/f1_macro': 0.720726768968457, 'eval/f1_weighted': 0.7247949904599521, 'test/recall_micro': 0.7570093457943925, 'eval/loss': 2.3652815911182272, 'test/f1_weighted': 0.7464342393631761, 'test/precision_micro': 0.7570093457943925, '_timestamp': 1704597028.4071672, 'eval/accuracy': 0.7380952380952381, 'eval/recall_micro': 0.7380952380952381, 'eval/precision_micro': 0.7380952380952381, '_step': 20, '_wandb': {'runtime': 1799}, 'test/f1_macro': 0.7440953504043126, 'test/loss': 0.6823223942859419, 'test/recall_macro': 0.757676282051282, 'test/recall_weighted': 0.7570093457943925}","{'rf_max_depth': 28, 'trial.number': 13}",electric-resonance-1122,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
217,"{'eval/accuracy': 0.4523809523809524, 'test/accuracy': 0.4953271028037383, 'test/f1_macro': 0.5029452690166976, 'eval/precision_weighted': 0.4676314970432618, 'eval/loss': 9.139988569059508, 'eval/f1_weighted': 0.44312169312169314, 'test/precision_micro': 0.4953271028037383, 'test/precision_weighted': 0.5540197387366161, '_runtime': 1782.1292593479156, 'test/loss': 9.250530168091458, 'test/f1_micro': 0.4953271028037383, 'test/recall_macro': 0.501228051839465, 'eval/precision_micro': 0.4523809523809524, 'test/recall_weighted': 0.4953271028037383, 'eval/f1_macro': 0.43914141414141417, 'eval/f1_micro': 0.4523809523809524, 'split': 10, '_timestamp': 1704597009.0039604, 'test/f1_weighted': 0.5033048393529035, 'test/recall_micro': 0.4953271028037383, 'eval/precision_macro': 0.4634878193701723, 'eval/recall_weighted': 0.4523809523809524, '_wandb': {'runtime': 1780}, 'eval/recall_macro': 0.45, 'eval/recall_micro': 0.4523809523809524, 'test/precision_macro': 0.5423669467787114, '_step': 20}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 13, 'dt_min_samples_leaf': 6}",wise-bird-1121,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
218,"{'eval/loss': 2.838316248698902e-09, '_timestamp': 1704599600.8278174, 'eval/f1_macro': 1, 'train/total_flos': 5029123075033824.0, 'eval/recall_micro': 1, 'eval/precision_micro': 1, 'train/train_samples_per_second': 38.795, '_step': 520, 'train/learning_rate': 1.9447421562500233e-07, 'eval/steps_per_second': 5.932, 'eval/samples_per_second': 124.566, 'test/samples_per_second': 130.4083793382791, '_wandb': {'runtime': 4944}, 'eval/runtime': 0.3372, 'eval/recall_weighted': 1, 'test/total_time_in_seconds': 0.8204994229890872, 'train/loss': 0, 'train/train_loss': 8.756836867481372e-09, 'train/train_runtime': 493.6221, 'eval/precision_weighted': 1, 'test/latency_in_seconds': 0.007668218906440067, '_runtime': 4947.719468355179, 'train/epoch': 50, 'eval/accuracy': 1, 'test/accuracy': 0.5887850467289719, 'eval/precision_macro': 1, 'eval/f1_micro': 1, 'eval/f1_weighted': 1, 'eval/recall_macro': 1, 'train/global_step': 600, 'train/train_steps_per_second': 1.216}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_02-30-56_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.166845293750014e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",pleasant-microwave-1120,Fine-Tuned LLM:microsoft/codebert-base,['preprocessed']
219,"{'eval/loss': 1.591269495048102, 'eval/f1_macro': 0.7550438596491227, 'eval/f1_micro': 0.7619047619047619, 'test/recall_macro': 0.7217548076923077, 'eval/precision_weighted': 0.7567969067969068, '_step': 20, 'eval/f1_weighted': 0.7567878028404342, 'test/f1_weighted': 0.7247034293395935, 'test/recall_micro': 0.7289719626168224, '_wandb': {'runtime': 2142}, 'eval/precision_micro': 0.7619047619047619, 'test/precision_weighted': 0.7238181572463693, 'test/f1_macro': 0.7161642780345604, 'split': 10, 'eval/accuracy': 0.7619047619047619, 'test/accuracy': 0.7289719626168224, 'eval/recall_macro': 0.759090909090909, 'eval/precision_macro': 0.755982905982906, '_runtime': 2143.977069377899, 'eval/recall_weighted': 0.7619047619047619, 'test/precision_micro': 0.7289719626168224, 'test/recall_weighted': 0.7289719626168224, 'test/loss': 2.351477014545685, 'test/f1_micro': 0.7289719626168223, '_timestamp': 1704596612.5542064, 'eval/recall_micro': 0.7619047619047619, 'test/precision_macro': 0.7137764182424917}","{'rf_max_depth': 28, 'trial.number': 11}",lucky-morning-1119,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
220,"{'eval/precision_macro': 0.432012432012432, '_wandb': {'runtime': 1668}, '_timestamp': 1704596046.741484, 'eval/accuracy': 0.42857142857142855, 'eval/precision_micro': 0.42857142857142855, 'eval/recall_weighted': 0.42857142857142855, 'test/f1_weighted': 0.5581242826692902, 'test/recall_weighted': 0.5700934579439252, 'test/precision_weighted': 0.5545829738130633, '_runtime': 1670.074646949768, 'eval/loss': 6.808483975327743, 'eval/f1_macro': 0.4277432712215321, 'eval/f1_micro': 0.42857142857142855, 'test/loss': 5.013426129911746, 'eval/recall_micro': 0.42857142857142855, '_step': 20, 'split': 10, 'test/f1_macro': 0.5504385964912281, 'eval/f1_weighted': 0.4264221630681258, 'test/recall_macro': 0.5610079575596817, 'test/precision_macro': 0.5489780311457175, 'test/precision_micro': 0.5700934579439252, 'eval/precision_weighted': 0.4326044326044326, 'test/accuracy': 0.5700934579439252, 'test/f1_micro': 0.5700934579439252, 'eval/recall_macro': 0.4318181818181818, 'test/recall_micro': 0.5700934579439252}","{'dt_criterion': 'gini', 'dt_max_depth': 16, 'trial.number': 14, 'dt_min_samples_leaf': 7}",blooming-yogurt-1118,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
221,"{'split': 10, '_runtime': 1628.686917066574, 'test/loss': 1.3286713365960072, 'eval/precision_macro': 0.5756410256410256, 'test/recall_micro': 0.7850467289719626, '_step': 20, 'eval/loss': 1.6210567429495255, 'eval/f1_micro': 0.5952380952380952, 'test/accuracy': 0.7850467289719626, 'test/f1_weighted': 0.7807559502805496, 'test/recall_macro': 0.7890092252260966, 'test/precision_macro': 0.780952380952381, 'eval/f1_macro': 0.572401425805316, 'eval/f1_weighted': 0.5639171088255757, 'eval/recall_micro': 0.5952380952380952, 'eval/recall_weighted': 0.5952380952380952, 'eval/accuracy': 0.5952380952380952, 'test/f1_micro': 0.7850467289719625, 'test/precision_micro': 0.7850467289719626, 'test/precision_weighted': 0.7909879839786382, '_wandb': {'runtime': 1627}, 'test/f1_macro': 0.7777057834483101, 'eval/recall_macro': 0.6045454545454545, 'eval/precision_micro': 0.5952380952380952, 'test/recall_weighted': 0.7850467289719626, '_timestamp': 1704595386.546196, 'eval/precision_weighted': 0.568864468864469}","{'rf_max_depth': 17, 'trial.number': 14}",wild-armadillo-1117,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
222,"{'test/recall_macro': 0.4008620689655173, 'eval/precision_micro': 0.380952380952381, 'split': 10, 'eval/accuracy': 0.380952380952381, 'test/precision_micro': 0.3925233644859813, 'test/precision_weighted': 0.29738063449678936, 'eval/f1_micro': 0.380952380952381, 'test/accuracy': 0.3925233644859813, 'test/loss': 1.9444063495789423, 'test/f1_macro': 0.33819163292847504, 'eval/recall_macro': 0.3772727272727273, 'eval/precision_macro': 0.2868131868131868, '_runtime': 2176.1428937911987, 'eval/loss': 1.3215199717165658, '_step': 20, 'eval/recall_micro': 0.380952380952381, 'test/recall_weighted': 0.3925233644859813, 'test/recall_micro': 0.3925233644859813, 'eval/precision_weighted': 0.28948194662480375, '_wandb': {'runtime': 2174}, 'test/f1_weighted': 0.33299279831498224, 'test/f1_micro': 0.3925233644859813, 'eval/f1_weighted': 0.32891224717311673, 'eval/recall_weighted': 0.380952380952381, 'test/precision_macro': 0.30017006802721086, '_timestamp': 1704595807.9279797, 'eval/f1_macro': 0.32581939799331106}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 10, 'dt_min_samples_leaf': 46}",classic-dawn-1116,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
223,"{'test/precision_weighted': 0.4132210454275168, '_timestamp': 1704595222.2354016, 'eval/f1_micro': 0.380952380952381, 'test/recall_micro': 0.35514018691588783, 'split': 10, '_wandb': {'runtime': 1783}, 'test/loss': 7.938120685062276, 'test/accuracy': 0.35514018691588783, 'eval/loss': 10.959001379822562, 'eval/recall_weighted': 0.380952380952381, 'eval/precision_weighted': 0.40061813186813183, 'test/f1_macro': 0.3636479591836735, 'test/recall_macro': 0.36366011705685614, '_runtime': 1784.440723657608, 'eval/accuracy': 0.380952380952381, 'eval/precision_macro': 0.39158653846153846, 'test/precision_macro': 0.40620423169267705, 'eval/precision_micro': 0.380952380952381, 'test/precision_micro': 0.35514018691588783, 'test/recall_weighted': 0.35514018691588783, '_step': 20, 'test/f1_micro': 0.35514018691588783, 'test/f1_weighted': 0.3611529658592409, 'eval/recall_micro': 0.380952380952381, 'eval/f1_macro': 0.3594504830917874, 'eval/f1_weighted': 0.3671353807223372, 'eval/recall_macro': 0.37272727272727274}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 12, 'dt_min_samples_leaf': 10}",pleasant-mountain-1115,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
224,"{'test/precision_micro': 0.7289719626168224, '_timestamp': 1704595223.1880877, 'eval/recall_micro': 0.7619047619047619, 'test/recall_micro': 0.7289719626168224, 'test/f1_weighted': 0.7162151197418346, 'eval/precision_macro': 0.7789321789321789, '_runtime': 1800.2884137630465, 'eval/loss': 3.939858016720542, 'test/f1_macro': 0.7121124158860008, 'test/loss': 0.6986266467490114, 'eval/accuracy': 0.7619047619047619, 'eval/f1_macro': 0.7546757164404223, 'eval/f1_micro': 0.7619047619047619, 'test/accuracy': 0.7289719626168224, 'test/recall_macro': 0.7262580128205128, 'test/recall_weighted': 0.7289719626168224, 'split': 10, 'test/f1_micro': 0.7289719626168223, 'eval/f1_weighted': 0.7579329167564461, 'eval/recall_weighted': 0.7619047619047619, 'eval/precision_weighted': 0.7804645090359376, 'test/precision_weighted': 0.7144644037167401, '_wandb': {'runtime': 1798}, 'eval/recall_macro': 0.7568181818181818, 'eval/precision_micro': 0.7619047619047619, '_step': 20, 'test/precision_macro': 0.709505772005772}","{'rf_max_depth': 28, 'trial.number': 12}",dainty-plasma-1114,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
225,"{'_wandb': {'runtime': 1681}, 'eval/f1_weighted': 0.5481405376796027, 'test/recall_micro': 0.5700934579439252, 'eval/precision_macro': 0.5619755244755245, 'eval/precision_micro': 0.5476190476190477, 'eval/recall_micro': 0.5476190476190477, 'test/precision_macro': 0.5685460372960374, 'test/precision_micro': 0.5700934579439252, 'eval/precision_weighted': 0.5625957375957376, '_runtime': 1682.4880735874176, 'test/loss': 7.173537523771165, '_timestamp': 1704594370.9008496, 'eval/accuracy': 0.5476190476190477, 'split': 10, 'test/accuracy': 0.5700934579439252, 'test/f1_weighted': 0.5693405910427224, '_step': 20, 'eval/recall_weighted': 0.5476190476190477, 'test/precision_weighted': 0.5743851164411913, 'eval/loss': 5.727836230714063, 'eval/f1_micro': 0.5476190476190477, 'eval/recall_macro': 0.5522727272727272, 'test/recall_macro': 0.5654011936339522, 'test/f1_macro': 0.5642066192390969, 'eval/f1_macro': 0.5502342813555627, 'test/f1_micro': 0.5700934579439252, 'test/recall_weighted': 0.5700934579439252}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 13, 'dt_min_samples_leaf': 5}",jolly-wave-1113,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
226,"{'_step': 20, '_runtime': 2156.7505769729614, '_timestamp': 1704594464.106576, 'eval/precision_weighted': 0.6747587924058512, 'eval/loss': 1.571317766957549, 'test/accuracy': 0.7289719626168224, 'test/precision_weighted': 0.7255162737605656, 'eval/f1_macro': 0.6496019460415746, 'eval/f1_weighted': 0.6485804848255091, 'eval/recall_micro': 0.6666666666666666, 'test/recall_micro': 0.7289719626168224, '_wandb': {'runtime': 2155}, 'test/f1_micro': 0.7289719626168223, 'eval/recall_macro': 0.665909090909091, 'split': 10, 'eval/f1_micro': 0.6666666666666666, 'test/f1_macro': 0.7063099822727551, 'eval/recall_weighted': 0.6666666666666666, 'test/recall_macro': 0.7200611888111889, 'eval/precision_macro': 0.6756535947712418, 'test/precision_macro': 0.7087191953490766, 'eval/precision_micro': 0.6666666666666666, 'test/precision_micro': 0.7289719626168224, 'test/loss': 1.7272826086638522, 'eval/accuracy': 0.6666666666666666, 'test/f1_weighted': 0.7185593914121982, 'test/recall_weighted': 0.7289719626168224}","{'rf_max_depth': 28, 'trial.number': 10}",devout-pine-1112,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
227,"{'test/f1_weighted': 0.7651809384189814, 'test/precision_micro': 0.7757009345794392, '_step': 20, 'eval/loss': 1.6750862942404232, 'eval/f1_micro': 0.6190476190476191, 'test/f1_macro': 0.7718394024276378, 'eval/recall_macro': 0.6272727272727272, 'eval/recall_weighted': 0.6190476190476191, 'test/recall_weighted': 0.7757009345794392, 'eval/f1_macro': 0.5866726475279107, 'test/recall_macro': 0.787341712208412, 'test/recall_micro': 0.7757009345794392, 'eval/precision_macro': 0.5725694444444445, 'split': 10, 'eval/f1_weighted': 0.5775850611376926, 'eval/recall_micro': 0.6190476190476191, 'eval/precision_weighted': 0.5634589947089947, 'test/precision_weighted': 0.7663767739702319, 'test/loss': 0.701990645908548, '_timestamp': 1704593752.759895, 'test/accuracy': 0.7757009345794392, 'test/precision_macro': 0.7679398148148149, '_runtime': 1644.188505411148, 'eval/precision_micro': 0.6190476190476191, '_wandb': {'runtime': 1641}, 'eval/accuracy': 0.6190476190476191, 'test/f1_micro': 0.7757009345794392}","{'rf_max_depth': 15, 'trial.number': 13}",lunar-flower-1111,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
228,"{'eval/recall_macro': 0.3954545454545455, 'test/recall_weighted': 0.38317757009345793, 'test/loss': 8.575791368664564, 'eval/accuracy': 0.4047619047619048, 'eval/f1_micro': 0.4047619047619048, 'eval/f1_macro': 0.3843137254901961, 'eval/recall_micro': 0.4047619047619048, 'eval/precision_macro': 0.40729166666666666, 'eval/recall_weighted': 0.4047619047619048, 'test/f1_micro': 0.383177570093458, 'test/precision_weighted': 0.4035858337432366, '_step': 20, 'eval/f1_weighted': 0.3930905695611578, 'test/precision_micro': 0.38317757009345793, 'eval/precision_weighted': 0.4171626984126984, 'eval/loss': 9.249566661972864, 'test/recall_macro': 0.3852947324414716, 'test/precision_macro': 0.4013815789473684, '_wandb': {'runtime': 1807}, '_runtime': 1808.8130009174347, '_timestamp': 1704593433.462592, 'test/f1_macro': 0.3860119047619047, 'test/f1_weighted': 0.3861704494882065, 'test/recall_micro': 0.38317757009345793, 'split': 10, 'test/accuracy': 0.38317757009345793, 'eval/precision_micro': 0.4047619047619048}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 11, 'dt_min_samples_leaf': 10}",crisp-dragon-1110,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
229,"{'eval/f1_macro': 0.854202205117537, '_wandb': {'runtime': 1822}, 'eval/loss': 2.2534317910762716, '_timestamp': 1704593418.5918453, 'test/f1_weighted': 0.7181905291501961, 'test/precision_weighted': 0.7212616586853319, 'eval/f1_weighted': 0.8557807562384221, 'test/precision_micro': 0.7289719626168224, 'test/accuracy': 0.7289719626168224, 'test/precision_macro': 0.7185914078779324, 'test/recall_weighted': 0.7289719626168224, '_step': 20, 'eval/precision_weighted': 0.8564814814814815, 'test/f1_micro': 0.7289719626168223, 'eval/recall_macro': 0.8545454545454545, 'eval/recall_micro': 0.8571428571428571, 'split': 10, '_runtime': 1825.057379245758, 'test/loss': 1.06752460111066, 'eval/accuracy': 0.8571428571428571, 'eval/precision_micro': 0.8571428571428571, 'eval/f1_micro': 0.8571428571428571, 'test/f1_macro': 0.7194155430363114, 'test/recall_macro': 0.7346233974358974, 'test/recall_micro': 0.7289719626168224, 'eval/precision_macro': 0.8559343434343434, 'eval/recall_weighted': 0.8571428571428571}","{'rf_max_depth': 31, 'trial.number': 11}",major-shadow-1109,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
230,"{'eval/recall_macro': 0.4159090909090909, 'eval/precision_micro': 0.42857142857142855, 'eval/precision_weighted': 0.3733623078861174, 'split': 10, '_runtime': 2195.774467945099, 'eval/loss': 1.221653050169166, 'eval/f1_micro': 0.42857142857142855, 'test/precision_weighted': 0.2719366562824507, 'test/loss': 1.3519066770334645, 'eval/accuracy': 0.42857142857142855, 'eval/f1_macro': 0.3538011695906432, '_step': 20, 'test/f1_macro': 0.27304505960800163, 'eval/f1_weighted': 0.362712336396547, 'test/f1_micro': 0.34579439252336447, 'eval/recall_weighted': 0.42857142857142855, 'test/f1_weighted': 0.2767858323120124, 'test/recall_macro': 0.33448275862068966, 'test/recall_micro': 0.34579439252336447, 'test/accuracy': 0.34579439252336447, 'test/precision_micro': 0.34579439252336447, '_wandb': {'runtime': 2194}, '_timestamp': 1704593625.260423, 'eval/precision_macro': 0.3649140211640211, 'eval/recall_micro': 0.42857142857142855, 'test/precision_macro': 0.27152777777777776, 'test/recall_weighted': 0.34579439252336447}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 9, 'dt_min_samples_leaf': 8}",brisk-dream-1108,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
231,"{'eval/recall_macro': 0.6613636363636364, 'test/recall_weighted': 0.6728971962616822, 'test/precision_weighted': 0.6779723391872926, '_wandb': {'runtime': 2180}, 'test/loss': 11.78998008055234, 'eval/f1_macro': 0.6354079643553328, 'test/f1_micro': 0.6728971962616822, 'eval/f1_micro': 0.6666666666666666, 'eval/recall_micro': 0.6666666666666666, 'eval/precision_weighted': 0.6911139455782314, 'eval/loss': 12.014551129705715, 'test/f1_weighted': 0.6579798259440681, 'test/recall_micro': 0.6728971962616822, '_step': 20, 'split': 10, '_timestamp': 1704593304.4648628, 'test/accuracy': 0.6728971962616822, 'test/recall_macro': 0.6676282051282051, 'eval/accuracy': 0.6666666666666666, 'test/f1_macro': 0.6545715878324575, 'test/precision_micro': 0.6728971962616822, '_runtime': 2181.546422719955, 'eval/f1_weighted': 0.6395883889618224, 'eval/precision_macro': 0.6897321428571428, 'eval/precision_micro': 0.6666666666666666, 'eval/recall_weighted': 0.6666666666666666, 'test/precision_macro': 0.6775412087912088}","{'n_neighbours': 1, 'trial.number': 9}",logical-cloud-1107,KNeighbours,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
232,"{'_wandb': {'runtime': 1685}, '_runtime': 1686.4897301197052, '_timestamp': 1704592681.399212, 'test/recall_weighted': 0.5700934579439252, 'eval/loss': 7.411193669216788, 'test/loss': 8.136675713977871, 'test/recall_micro': 0.5700934579439252, 'eval/precision_macro': 0.5439560439560439, 'eval/recall_weighted': 0.5238095238095238, 'test/f1_macro': 0.5642066192390969, 'test/f1_micro': 0.5700934579439252, 'eval/precision_micro': 0.5238095238095238, 'test/precision_weighted': 0.5743851164411913, 'test/recall_macro': 0.5654011936339522, 'eval/precision_weighted': 0.5437181865753294, 'eval/accuracy': 0.5238095238095238, 'test/accuracy': 0.5700934579439252, 'eval/recall_macro': 0.5295454545454545, 'eval/recall_micro': 0.5238095238095238, '_step': 20, 'test/f1_weighted': 0.5693405910427224, 'test/precision_micro': 0.5700934579439252, 'split': 10, 'eval/f1_macro': 0.5268994290733421, 'eval/f1_micro': 0.5238095238095238, 'eval/f1_weighted': 0.5236945019553715, 'test/precision_macro': 0.5685460372960374}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 12, 'dt_min_samples_leaf': 5}",avid-yogurt-1106,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
233,"{'test/precision_macro': 0.3610907208733295, 'test/accuracy': 0.34579439252336447, 'test/f1_macro': 0.348361919286603, 'eval/f1_weighted': 0.29707792207792205, 'test/recall_macro': 0.34745530460576163, 'eval/precision_weighted': 0.3144586894586895, 'test/precision_weighted': 0.3681776844312399, '_wandb': {'runtime': 1646}, 'eval/loss': 1.352786599311416, 'eval/precision_micro': 0.2857142857142857, 'test/loss': 1.3301115468046052, 'eval/f1_micro': 0.2857142857142857, '_step': 20, 'test/f1_micro': 0.34579439252336447, 'test/f1_weighted': 0.35061937359596934, 'eval/recall_weighted': 0.2857142857142857, 'split': 10, 'eval/accuracy': 0.2857142857142857, 'test/recall_weighted': 0.34579439252336447, 'eval/recall_macro': 0.2863636363636364, 'test/precision_micro': 0.34579439252336447, 'eval/f1_macro': 0.29734848484848486, 'eval/recall_micro': 0.2857142857142857, 'test/recall_micro': 0.34579439252336447, '_runtime': 1647.7972235679626, '_timestamp': 1704592104.0178137, 'eval/precision_macro': 0.3143696581196581}","{'rf_max_depth': 2, 'trial.number': 12}",light-moon-1105,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
234,"{'test/f1_weighted': 0.41944190362563794, 'test/recall_micro': 0.4299065420560747, 'eval/recall_weighted': 0.5714285714285714, 'split': 10, 'test/f1_macro': 0.4167730496453901, '_step': 20, '_timestamp': 1704592301.237237, 'eval/recall_micro': 0.5714285714285714, 'test/recall_macro': 0.4333883708883709, 'eval/precision_micro': 0.5714285714285714, 'test/precision_macro': 0.44855072463768114, 'eval/accuracy': 0.5714285714285714, 'eval/f1_macro': 0.5535876001393243, 'eval/f1_micro': 0.5714285714285714, 'eval/f1_weighted': 0.5562306148513045, 'test/accuracy': 0.4299065420560747, 'test/f1_micro': 0.4299065420560747, 'eval/recall_macro': 0.5727272727272728, '_runtime': 2162.4274849891663, 'eval/loss': 1.2665237616643603, 'test/precision_weighted': 0.4618176892861981, '_wandb': {'runtime': 2161}, 'test/loss': 1.2755302396467043, 'eval/precision_macro': 0.6223086124401914, 'test/precision_micro': 0.4299065420560747, 'test/recall_weighted': 0.4299065420560747, 'eval/precision_weighted': 0.6300125313283208}","{'rf_max_depth': 3, 'trial.number': 9}",trim-wave-1104,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
235,"{'test/recall_micro': 0.2803738317757009, 'test/f1_macro': 0.19798249878463783, 'eval/f1_weighted': 0.16904761904761903, 'eval/recall_macro': 0.29545454545454547, 'eval/recall_micro': 0.2857142857142857, '_wandb': {'runtime': 1827}, 'eval/loss': 1.3920095489277684, 'test/loss': 2.256783044620941, 'eval/precision_macro': 0.1907894736842105, 'test/precision_micro': 0.2803738317757009, 'eval/accuracy': 0.2857142857142857, 'test/accuracy': 0.2803738317757009, 'test/recall_macro': 0.2972408026755853, '_timestamp': 1704591620.408235, 'test/precision_weighted': 0.19561776148101775, 'split': 10, 'eval/f1_micro': 0.2857142857142857, 'test/recall_weighted': 0.2803738317757009, 'test/f1_weighted': 0.18088678276593712, 'eval/precision_micro': 0.2857142857142857, 'eval/recall_weighted': 0.2857142857142857, 'test/precision_macro': 0.21961722488038277, '_step': 20, 'eval/f1_macro': 0.17083333333333334, 'test/f1_micro': 0.2803738317757009, '_runtime': 1829.0779509544373, 'eval/precision_weighted': 0.19360902255639095}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 10, 'dt_min_samples_leaf': 5}",faithful-microwave-1103,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
236,"{'eval/f1_macro': 0.7463454419976159, 'test/f1_macro': 0.7987937239610791, 'test/recall_weighted': 0.8037383177570093, '_step': 20, '_wandb': {'runtime': 1844}, 'test/precision_macro': 0.7982286634460548, 'eval/precision_weighted': 0.7535714285714286, 'split': 10, '_timestamp': 1704591589.118735, 'eval/precision_micro': 0.7619047619047619, 'eval/recall_weighted': 0.7619047619047619, 'test/precision_micro': 0.8037383177570093, 'test/precision_weighted': 0.8050626815356601, 'test/f1_micro': 0.8037383177570093, 'eval/recall_micro': 0.7619047619047619, 'test/recall_macro': 0.8087099358974359, 'eval/precision_macro': 0.7458333333333332, 'eval/accuracy': 0.7619047619047619, 'eval/loss': 0.6346363677075187, 'test/loss': 1.29878869576834, 'test/accuracy': 0.8037383177570093, '_runtime': 1847.6140739917755, 'eval/f1_micro': 0.7619047619047619, 'eval/f1_weighted': 0.7539876732423316, 'test/f1_weighted': 0.799636220428583, 'eval/recall_macro': 0.7545454545454546, 'test/recall_micro': 0.8037383177570093}","{'rf_max_depth': 28, 'trial.number': 10}",iconic-thunder-1102,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
237,"{'train/train_steps_per_second': 2.377, 'eval/recall_micro': 1, 'train/train_runtime': 504.8583, 'eval/steps_per_second': 8.582, 'train/loss': 0, 'test/accuracy': 0.5887850467289719, 'eval/recall_macro': 1, 'train/train_samples_per_second': 37.931, '_timestamp': 1704594645.645198, 'eval/f1_macro': 1, 'train/total_flos': 4917360536253984.0, 'train/train_loss': 5.0999220964816544e-09, 'eval/loss': 2.838316248698902e-09, 'train/epoch': 50, 'eval/runtime': 0.3496, 'test/samples_per_second': 128.6188783112561, 'test/total_time_in_seconds': 0.8319152009789832, '_step': 530, 'train/learning_rate': 7.736954533411297e-07, 'eval/recall_weighted': 1, 'eval/f1_micro': 1, 'train/global_step': 1200, 'eval/precision_micro': 1, 'eval/precision_weighted': 1, '_wandb': {'runtime': 5065}, '_runtime': 5066.63085603714, 'eval/accuracy': 1, 'eval/f1_weighted': 1, 'test/latency_in_seconds': 0.007774908420364328, 'eval/precision_macro': 1, 'eval/samples_per_second': 120.143}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan07_01-06-21_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 4.642172720046779e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",dark-cloud-1101,Fine-Tuned LLM:microsoft/codebert-base,['preprocessed']
238,"{'test/f1_weighted': 0.5880321798277691, 'eval/precision_weighted': 0.5509331937903367, 'split': 10, 'eval/precision_micro': 0.5238095238095238, 'test/precision_weighted': 0.5931366141646517, '_runtime': 1695.1118993759155, 'eval/loss': 6.594029697993549, 'eval/f1_micro': 0.5238095238095238, 'test/precision_macro': 0.5885780885780886, 'eval/f1_weighted': 0.527490223142397, 'test/recall_macro': 0.5854332449160036, 'test/recall_weighted': 0.5887850467289719, 'test/precision_micro': 0.5887850467289719, '_wandb': {'runtime': 1693}, 'test/accuracy': 0.5887850467289719, 'test/f1_micro': 0.5887850467289719, 'test/recall_micro': 0.5887850467289719, '_timestamp': 1704590988.612615, 'eval/f1_macro': 0.531280193236715, 'test/f1_macro': 0.5842066192390969, 'eval/recall_macro': 0.5295454545454545, 'eval/recall_micro': 0.5238095238095238, 'eval/recall_weighted': 0.5238095238095238, '_step': 20, 'test/loss': 7.461098762548608, 'eval/accuracy': 0.5238095238095238, 'eval/precision_macro': 0.5522893772893773}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 11, 'dt_min_samples_leaf': 5}",eternal-terrain-1100,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
239,"{'eval/accuracy': 0.5238095238095238, 'eval/loss': 9.654550014942096, 'eval/f1_macro': 0.5375438596491228, 'test/recall_macro': 0.43846264367816096, 'eval/precision_macro': 0.6349206349206349, '_timestamp': 1704590941.600071, 'test/f1_micro': 0.4392523364485981, 'test/recall_micro': 0.4392523364485981, 'test/precision_micro': 0.4392523364485981, 'test/precision_weighted': 0.4161868065803137, '_runtime': 1994.9030709266665, 'eval/f1_micro': 0.5238095238095238, 'eval/f1_weighted': 0.5360735171261487, 'test/loss': 9.101605501745077, 'test/f1_macro': 0.4159423376907385, 'eval/recall_macro': 0.5272727272727272, 'eval/recall_micro': 0.5238095238095238, 'eval/precision_micro': 0.5238095238095238, 'eval/recall_weighted': 0.5238095238095238, 'split': 10, 'eval/precision_weighted': 0.6386999244142102, '_wandb': {'runtime': 1993}, 'test/accuracy': 0.4392523364485981, 'test/recall_weighted': 0.4392523364485981, '_step': 20, 'test/f1_weighted': 0.4139726629175247, 'test/precision_macro': 0.42182748538011694}","{'n_neighbours': 2, 'trial.number': 9}",drawn-dust-1099,KNeighbours,"['pre-trained:openai-gpt', 'preprocessed']"
240,"{'eval/f1_macro': 0.3125, 'eval/f1_weighted': 0.31547619047619047, 'eval/recall_macro': 0.32954545454545453, 'test/recall_macro': 0.401798433048433, 'test/precision_micro': 0.40186915887850466, 'eval/f1_micro': 0.3333333333333333, 'split': 10, 'test/loss': 3.1442918366728407, 'test/f1_weighted': 0.3924853923528774, 'eval/recall_weighted': 0.3333333333333333, 'eval/precision_weighted': 0.3429905295451514, 'test/recall_micro': 0.40186915887850466, 'eval/precision_micro': 0.3333333333333333, 'test/recall_weighted': 0.40186915887850466, 'test/precision_weighted': 0.39750879961160335, '_wandb': {'runtime': 2211}, '_runtime': 2213.132242679596, 'test/accuracy': 0.40186915887850466, 'test/f1_micro': 0.40186915887850466, 'test/precision_macro': 0.3971049783549783, '_step': 20, 'eval/loss': 5.321343960816416, '_timestamp': 1704591117.7750566, 'eval/accuracy': 0.3333333333333333, 'test/f1_macro': 0.3923749309010503, 'eval/recall_micro': 0.3333333333333333, 'eval/precision_macro': 0.33984593837535015}","{'n_neighbours': 7, 'trial.number': 8}",lyric-wildflower-1098,KNeighbours,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
241,"{'_runtime': 1658.3026893138883, 'eval/precision_weighted': 0.6927873713588, 'eval/f1_micro': 0.6904761904761905, 'test/recall_micro': 0.7757009345794392, 'test/precision_weighted': 0.8115298970164281, 'eval/f1_weighted': 0.682017734630084, 'eval/recall_micro': 0.6904761904761905, 'test/f1_weighted': 0.7602773770600222, 'eval/recall_macro': 0.6954545454545454, 'eval/precision_macro': 0.6982600732600732, 'test/precision_micro': 0.7757009345794392, 'split': 10, 'test/f1_micro': 0.7757009345794392, 'eval/recall_weighted': 0.6904761904761905, 'eval/loss': 0.8590808739044313, 'test/loss': 0.9856378323601148, 'eval/accuracy': 0.6904761904761905, 'test/f1_macro': 0.7615039436827363, 'test/recall_macro': 0.7866822637068562, 'test/recall_weighted': 0.7757009345794392, '_wandb': {'runtime': 1657}, '_timestamp': 1704590450.2829792, 'test/accuracy': 0.7757009345794392, 'eval/precision_micro': 0.6904761904761905, 'test/precision_macro': 0.801005911300029, '_step': 20, 'eval/f1_macro': 0.6868225551090001}","{'rf_max_depth': 12, 'trial.number': 11}",dark-pond-1097,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
242,"{'eval/f1_macro': 0.3802564102564102, 'eval/recall_micro': 0.380952380952381, 'test/precision_micro': 0.34579439252336447, '_runtime': 2207.3898746967316, 'eval/f1_micro': 0.380952380952381, 'eval/recall_macro': 0.3863636363636363, 'test/recall_macro': 0.34612068965517245, 'test/loss': 2.3147276710747127, 'test/f1_macro': 0.3103852034855363, 'test/f1_micro': 0.34579439252336447, 'eval/precision_weighted': 0.4634353741496599, 'test/accuracy': 0.34579439252336447, 'test/f1_weighted': 0.3091070191232026, 'test/precision_macro': 0.30056642442225967, '_timestamp': 1704590485.3800006, 'eval/accuracy': 0.380952380952381, 'test/precision_weighted': 0.30024836259999543, 'test/recall_micro': 0.34579439252336447, 'eval/precision_micro': 0.380952380952381, 'eval/recall_weighted': 0.380952380952381, 'test/recall_weighted': 0.34579439252336447, '_step': 20, 'split': 10, '_wandb': {'runtime': 2206}, 'eval/loss': 2.1661021208477016, 'eval/f1_weighted': 0.37960927960927954, 'eval/precision_macro': 0.4571428571428572}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 8, 'dt_min_samples_leaf': 8}",solar-puddle-1096,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
243,"{'test/recall_micro': 0.35514018691588783, 'eval/recall_weighted': 0.42857142857142855, 'eval/loss': 1.3036925675309472, 'eval/recall_macro': 0.4272727272727273, 'eval/precision_weighted': 0.35141424991049053, '_timestamp': 1704590133.4436083, 'test/f1_macro': 0.35330627330627334, 'test/recall_macro': 0.3745002104377104, 'test/recall_weighted': 0.35514018691588783, '_step': 20, 'split': 10, '_wandb': {'runtime': 2170}, 'test/loss': 1.3152436515771224, 'test/accuracy': 0.35514018691588783, 'test/f1_weighted': 0.3504273874367332, 'test/f1_micro': 0.35514018691588783, 'eval/precision_macro': 0.34680451127819545, 'test/precision_micro': 0.35514018691588783, 'eval/f1_weighted': 0.3676841676841677, 'eval/recall_micro': 0.42857142857142855, 'test/precision_weighted': 0.5992174505664191, 'eval/accuracy': 0.42857142857142855, 'eval/f1_macro': 0.36495726495726494, 'eval/f1_micro': 0.42857142857142855, 'eval/precision_micro': 0.42857142857142855, 'test/precision_macro': 0.5611082780894101, '_runtime': 2173.0785303115845}","{'rf_max_depth': 2, 'trial.number': 8}",comic-plasma-1095,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
244,"{'test/f1_micro': 0.4205607476635514, 'test/f1_weighted': 0.4132137651385458, 'eval/f1_micro': 0.35714285714285715, 'eval/precision_micro': 0.35714285714285715, 'eval/precision_weighted': 0.2954695767195767, 'test/precision_weighted': 0.4233392649469657, 'eval/precision_macro': 0.28708964646464646, '_timestamp': 1704589785.6806197, 'test/accuracy': 0.4205607476635514, 'eval/recall_micro': 0.35714285714285715, 'test/precision_macro': 0.41587331334332833, 'test/precision_micro': 0.4205607476635514, 'test/recall_weighted': 0.4205607476635514, '_step': 20, 'eval/loss': 5.368143925812516, 'test/loss': 4.764666346235897, 'eval/f1_weighted': 0.31996658312447784, 'test/recall_micro': 0.4205607476635514, 'split': 10, 'test/recall_macro': 0.4255591555183946, '_wandb': {'runtime': 1845}, 'eval/recall_weighted': 0.35714285714285715, 'eval/f1_macro': 0.310207336523126, 'eval/accuracy': 0.35714285714285715, 'test/f1_macro': 0.41228374262943046, '_runtime': 1846.902455806732, 'eval/recall_macro': 0.34545454545454546}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 9, 'dt_min_samples_leaf': 10}",prime-dream-1094,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
245,"{'split': 10, 'test/recall_micro': 0.719626168224299, 'test/precision_macro': 0.7146551724137931, 'test/f1_weighted': 0.7038776435178072, 'test/recall_weighted': 0.719626168224299, 'eval/precision_weighted': 0.6504938513867085, 'test/loss': 1.3414908589909442, 'eval/f1_weighted': 0.639174188193796, 'eval/recall_micro': 0.6666666666666666, 'eval/f1_micro': 0.6666666666666666, 'test/precision_micro': 0.719626168224299, 'eval/loss': 0.8558728310781889, 'eval/accuracy': 0.6666666666666666, 'eval/f1_macro': 0.6320125272331154, 'test/accuracy': 0.719626168224299, '_step': 20, '_timestamp': 1704589736.7649636, 'eval/precision_macro': 0.6485233516483516, 'eval/recall_weighted': 0.6666666666666666, 'eval/precision_micro': 0.6666666666666666, 'test/precision_weighted': 0.717198410140724, '_runtime': 1862.5409526824951, 'test/f1_macro': 0.7046374327050509, 'test/f1_micro': 0.7196261682242989, 'test/recall_macro': 0.7250080128205129, '_wandb': {'runtime': 1861}, 'eval/recall_macro': 0.6545454545454545}","{'rf_max_depth': 15, 'trial.number': 9}",decent-pyramid-1093,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
246,"{'_runtime': 1684.4025304317474, 'test/f1_micro': 0.5607476635514018, 'eval/recall_macro': 0.5522727272727272, 'eval/precision_micro': 0.5476190476190477, 'test/precision_weighted': 0.5616340979892381, 'eval/f1_weighted': 0.5481405376796027, 'test/precision_micro': 0.5607476635514018, 'test/recall_weighted': 0.5607476635514018, 'eval/recall_micro': 0.5476190476190477, 'test/recall_micro': 0.5607476635514018, 'eval/loss': 6.542385562270464, 'test/accuracy': 0.5607476635514018, 'test/recall_macro': 0.5549845269672856, 'eval/f1_macro': 0.5502342813555627, 'test/precision_macro': 0.5549242424242424, 'eval/accuracy': 0.5476190476190477, 'eval/precision_macro': 0.5619755244755245, '_wandb': {'runtime': 1681}, '_timestamp': 1704589287.9365764, 'eval/f1_micro': 0.5476190476190477, 'test/f1_weighted': 0.5585935632596466, 'eval/recall_weighted': 0.5476190476190477, '_step': 20, 'split': 10, 'test/loss': 8.47315077374046, 'test/f1_macro': 0.552505938966988, 'eval/precision_weighted': 0.5625957375957376}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 10, 'dt_min_samples_leaf': 5}",hopeful-bird-1092,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
247,"{'_wandb': {'runtime': 1626}, 'eval/precision_weighted': 0.9005875077303649, 'eval/loss': 0.6068265580371676, 'test/accuracy': 0.8504672897196262, 'eval/recall_weighted': 0.8809523809523809, 'test/recall_weighted': 0.8504672897196262, 'eval/precision_macro': 0.900974025974026, 'test/precision_micro': 0.8504672897196262, 'eval/recall_micro': 0.8809523809523809, 'test/f1_weighted': 0.8335771511515471, 'eval/recall_macro': 0.8863636363636364, '_step': 20, 'split': 10, 'test/loss': 0.6639055391916173, '_timestamp': 1704588787.6041777, 'test/f1_micro': 0.850467289719626, 'eval/f1_weighted': 0.8688648792850474, 'test/recall_micro': 0.8504672897196262, 'test/precision_weighted': 0.8652468698705787, '_runtime': 1627.6604363918304, 'eval/accuracy': 0.8809523809523809, 'eval/f1_macro': 0.8726610644257704, 'eval/f1_micro': 0.8809523809523809, 'test/f1_macro': 0.8394148647601333, 'test/recall_macro': 0.8598200899550226, 'eval/precision_micro': 0.8809523809523809, 'test/precision_macro': 0.8644785039521883}","{'rf_max_depth': 12, 'trial.number': 10}",blooming-voice-1091,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
248,"{'eval/accuracy': 0.7142857142857143, 'test/precision_micro': 0.7102803738317757, '_wandb': {'runtime': 1990}, '_timestamp': 1704588940.387976, 'test/precision_macro': 0.6981263904338153, 'eval/precision_weighted': 0.713326356183499, 'split': 10, '_runtime': 1992.095607995987, 'test/f1_macro': 0.6966702777527009, 'eval/f1_weighted': 0.7032227032227032, 'test/recall_weighted': 0.7102803738317757, 'test/loss': 10.442553785632072, 'eval/f1_micro': 0.7142857142857143, 'test/accuracy': 0.7102803738317757, 'test/f1_weighted': 0.6840909442455628, 'eval/f1_macro': 0.7078282828282829, 'test/f1_micro': 0.7102803738317757, 'eval/recall_macro': 0.7204545454545455, 'eval/recall_micro': 0.7142857142857143, 'eval/precision_micro': 0.7142857142857143, 'test/precision_weighted': 0.6924741145405591, 'test/recall_micro': 0.7102803738317757, 'eval/precision_macro': 0.7157509157509158, '_step': 20, 'eval/loss': 10.298186682604902, 'test/recall_macro': 0.7286206896551723, 'eval/recall_weighted': 0.7142857142857143}","{'n_neighbours': 1, 'trial.number': 8}",northern-cherry-1090,KNeighbours,"['pre-trained:openai-gpt', 'preprocessed']"
249,"{'test/precision_weighted': 0.3349333679216696, 'eval/f1_macro': 0.34160229748465043, 'test/precision_macro': 0.34145764609151336, 'test/precision_micro': 0.35514018691588783, 'test/recall_micro': 0.35514018691588783, 'eval/precision_micro': 0.35714285714285715, '_step': 20, 'eval/f1_micro': 0.35714285714285715, 'eval/precision_macro': 0.359375, 'test/recall_weighted': 0.35514018691588783, 'eval/loss': 6.767677619778968, 'test/f1_macro': 0.3405970413677031, 'eval/recall_weighted': 0.35714285714285715, 'eval/precision_weighted': 0.3645833333333333, 'eval/accuracy': 0.35714285714285715, 'eval/f1_weighted': 0.3460845617708363, 'test/recall_macro': 0.3605769230769231, '_timestamp': 1704588896.4072392, 'test/f1_weighted': 0.3345323611963125, 'test/loss': 5.481858530440475, 'eval/recall_micro': 0.35714285714285715, 'test/accuracy': 0.35514018691588783, 'test/f1_micro': 0.35514018691588783, 'eval/recall_macro': 0.35227272727272724, 'split': 10, '_wandb': {'runtime': 2199}, '_runtime': 2201.2530121803284}","{'n_neighbours': 4, 'trial.number': 7}",apricot-plant-1089,KNeighbours,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
250,"{'_runtime': 1735.95423412323, 'test/f1_micro': 0.2523364485981308, 'test/recall_weighted': 0.2523364485981308, 'test/precision_weighted': 0.25741024921318706, 'eval/loss': 6.819992490667925, 'eval/f1_micro': 0.30952380952380953, 'test/f1_macro': 0.2526200686106347, 'test/recall_micro': 0.2523364485981308, 'eval/precision_micro': 0.30952380952380953, 'test/precision_macro': 0.2537256495821568, '_step': 20, 'eval/f1_weighted': 0.29867724867724865, 'test/f1_weighted': 0.2465527965245828, 'eval/recall_macro': 0.3143939393939394, 'test/recall_macro': 0.266765873015873, 'eval/recall_weighted': 0.30952380952380953, 'test/loss': 8.549260077279945, 'test/accuracy': 0.2523364485981308, '_wandb': {'runtime': 1734}, 'eval/recall_micro': 0.30952380952380953, 'split': 10, '_timestamp': 1704588264.041865, 'eval/f1_macro': 0.30601851851851847, 'eval/precision_weighted': 0.3057823129251701, 'eval/accuracy': 0.30952380952380953, 'eval/precision_macro': 0.31666666666666665, 'test/precision_micro': 0.2523364485981308}","{'n_neighbours': 4, 'trial.number': 9}",hearty-dust-1088,KNeighbours,"['pre-trained:bert-base-uncased', 'preprocessed']"
251,"{'eval/f1_weighted': 0.3548627700801614, 'eval/precision_micro': 0.380952380952381, 'eval/recall_weighted': 0.380952380952381, 'test/precision_micro': 0.4485981308411215, '_step': 20, 'eval/accuracy': 0.380952380952381, 'test/f1_weighted': 0.4126181087288854, 'eval/recall_macro': 0.37727272727272726, 'test/recall_micro': 0.4485981308411215, 'split': 10, '_runtime': 2174.2924387454987, 'test/f1_macro': 0.410318501246802, 'eval/recall_micro': 0.380952380952381, 'eval/f1_macro': 0.351644370122631, 'eval/f1_micro': 0.380952380952381, 'eval/precision_weighted': 0.3487179487179487, 'test/precision_weighted': 0.4097139620504106, 'eval/loss': 1.1639296438957984, 'test/recall_weighted': 0.4485981308411215, 'eval/precision_macro': 0.34615384615384615, 'test/loss': 1.3403308861661638, '_timestamp': 1704588273.515977, 'test/accuracy': 0.4485981308411215, 'test/f1_micro': 0.4485981308411215, '_wandb': {'runtime': 2172}, 'test/recall_macro': 0.44870689655172413, 'test/precision_macro': 0.4037878787878788}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 7, 'dt_min_samples_leaf': 31}",easy-grass-1087,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
252,"{'_step': 20, 'test/f1_micro': 0.36448598130841114, 'eval/f1_micro': 0.21428571428571427, 'test/f1_macro': 0.356879010469436, 'eval/recall_micro': 0.21428571428571427, 'eval/precision_micro': 0.21428571428571427, '_runtime': 1847.5627999305725, '_timestamp': 1704587934.233913, 'eval/f1_macro': 0.2028425006366183, 'eval/precision_macro': 0.1991341991341991, 'test/precision_weighted': 0.3774012140005507, 'eval/loss': 1.398617728161888, 'test/accuracy': 0.3644859813084112, 'test/f1_weighted': 0.36734479700278067, 'eval/recall_macro': 0.21818181818181817, 'test/precision_micro': 0.3644859813084112, 'split': 10, 'eval/accuracy': 0.21428571428571427, 'eval/recall_weighted': 0.21428571428571427, '_wandb': {'runtime': 1846}, 'test/loss': 1.363581455384174, 'test/precision_macro': 0.3655041195363776, 'test/recall_weighted': 0.3644859813084112, 'eval/precision_weighted': 0.19794887652030513, 'eval/f1_weighted': 0.20031345871682008, 'test/recall_macro': 0.35618729096989965, 'test/recall_micro': 0.3644859813084112}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 8, 'dt_min_samples_leaf': 81}",northern-vortex-1086,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
253,"{'_timestamp': 1704587866.324981, 'eval/f1_macro': 0.6372742200328407, 'eval/f1_micro': 0.6666666666666666, 'eval/precision_micro': 0.6666666666666666, 'test/precision_micro': 0.6915887850467289, 'test/precision_weighted': 0.6827891734433791, '_runtime': 1861.2478709220889, 'eval/loss': 0.8489951140819937, 'test/loss': 1.2055178599934062, 'test/f1_micro': 0.6915887850467289, 'eval/recall_weighted': 0.6666666666666666, 'test/recall_weighted': 0.6915887850467289, 'split': 10, 'test/recall_micro': 0.6915887850467289, '_step': 20, 'eval/accuracy': 0.6666666666666666, 'test/accuracy': 0.6915887850467289, 'eval/f1_weighted': 0.6431308155446086, 'eval/precision_macro': 0.6902777777777779, 'test/precision_macro': 0.6806277056277057, '_wandb': {'runtime': 1859}, 'test/f1_weighted': 0.6736783088246332, 'eval/recall_micro': 0.6666666666666666, 'test/recall_macro': 0.6935897435897436, 'eval/precision_weighted': 0.6910052910052911, 'test/f1_macro': 0.6726986708443037, 'eval/recall_macro': 0.6568181818181819}","{'rf_max_depth': 10, 'trial.number': 8}",lilac-serenity-1085,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
254,"{'eval/recall_macro': 0.3704545454545455, 'test/precision_micro': 0.38317757009345793, 'test/recall_weighted': 0.38317757009345793, 'test/loss': 2.599004057283187, 'eval/f1_micro': 0.35714285714285715, 'test/recall_micro': 0.38317757009345793, 'eval/precision_micro': 0.35714285714285715, 'split': 10, '_wandb': {'runtime': 1670}, 'eval/f1_macro': 0.3005952380952381, 'test/f1_macro': 0.31660514667872836, 'eval/f1_weighted': 0.2908163265306123, 'test/accuracy': 0.38317757009345793, '_step': 20, 'eval/loss': 1.1763696688230223, 'test/recall_macro': 0.36825028419856, 'eval/precision_macro': 0.2583333333333333, 'eval/precision_weighted': 0.2507936507936508, '_runtime': 1672.8124873638153, 'eval/recall_micro': 0.35714285714285715, 'test/precision_macro': 0.28174603174603174, '_timestamp': 1704587596.9502234, 'eval/accuracy': 0.35714285714285715, 'test/f1_micro': 0.383177570093458, 'test/f1_weighted': 0.32884842191587577, 'eval/recall_weighted': 0.35714285714285715, 'test/precision_weighted': 0.29215249962913514}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 9, 'dt_min_samples_leaf': 58}",wild-sun-1084,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
255,"{'eval/recall_micro': 0.5, 'split': 10, '_runtime': 2141.557504415512, 'test/precision_weighted': 0.4810919063255512, 'eval/loss': 1.2984894885177831, 'test/precision_micro': 0.411214953271028, 'test/recall_weighted': 0.411214953271028, 'eval/precision_weighted': 0.5383975812547241, 'eval/precision_micro': 0.5, 'eval/accuracy': 0.5, 'eval/f1_weighted': 0.46540496540496534, 'eval/recall_macro': 0.4954545454545454, 'test/recall_macro': 0.42915128852628853, 'test/accuracy': 0.411214953271028, 'test/precision_macro': 0.464452776952777, '_wandb': {'runtime': 2140}, 'test/loss': 1.327807113969392, '_timestamp': 1704587953.6992254, 'eval/f1_macro': 0.45940170940170943, 'eval/recall_weighted': 0.5, '_step': 20, 'eval/f1_micro': 0.5, 'test/f1_micro': 0.411214953271028, 'test/f1_weighted': 0.3618775033377838, 'test/f1_macro': 0.3744608516483516, 'test/recall_micro': 0.411214953271028, 'eval/precision_macro': 0.5341269841269841}","{'rf_max_depth': 2, 'trial.number': 7}",glowing-fog-1083,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
256,"{'_timestamp': 1704587152.44993, 'eval/accuracy': 0.7380952380952381, 'test/recall_weighted': 0.8130841121495327, 'eval/loss': 0.7166799045906513, 'test/accuracy': 0.8130841121495327, 'eval/recall_macro': 0.7454545454545454, 'test/recall_micro': 0.8130841121495327, 'eval/recall_weighted': 0.7380952380952381, 'split': 10, '_step': 20, '_wandb': {'runtime': 1625}, 'eval/f1_micro': 0.7380952380952381, 'test/f1_micro': 0.8130841121495327, 'test/f1_macro': 0.8013013901212659, 'eval/f1_weighted': 0.7311894454751597, 'test/f1_weighted': 0.7986753905137837, 'test/precision_weighted': 0.8161576043217199, 'test/loss': 0.6251832361976806, 'eval/precision_micro': 0.7380952380952381, 'test/precision_macro': 0.8150149065474143, 'eval/precision_weighted': 0.7293650793650793, 'eval/precision_macro': 0.7333333333333334, 'test/precision_micro': 0.8130841121495327, '_runtime': 1626.6923260688782, 'eval/f1_macro': 0.7367965367965368, 'eval/recall_micro': 0.7380952380952381, 'test/recall_macro': 0.8172476261869065}","{'rf_max_depth': 24, 'trial.number': 9}",electric-sponge-1082,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
257,"{'eval/f1_macro': 0.7078282828282829, 'eval/f1_micro': 0.7142857142857143, 'test/f1_micro': 0.7102803738317757, 'test/recall_macro': 0.7286206896551723, 'test/f1_macro': 0.6966702777527009, 'test/f1_weighted': 0.6840909442455628, 'eval/recall_macro': 0.7204545454545455, 'eval/recall_weighted': 0.7142857142857143, '_runtime': 1994.0640046596527, '_timestamp': 1704586939.911203, 'test/precision_weighted': 0.6924741145405591, 'eval/loss': 10.298186682604902, 'eval/accuracy': 0.7142857142857143, 'test/recall_micro': 0.7102803738317757, 'eval/f1_weighted': 0.7032227032227032, 'eval/precision_macro': 0.7157509157509158, 'eval/precision_micro': 0.7142857142857143, 'test/accuracy': 0.7102803738317757, 'test/recall_weighted': 0.7102803738317757, 'split': 10, 'test/precision_micro': 0.7102803738317757, 'eval/precision_weighted': 0.713326356183499, '_step': 20, '_wandb': {'runtime': 1992}, 'test/loss': 10.442553785632072, 'eval/recall_micro': 0.7142857142857143, 'test/precision_macro': 0.6981263904338153}","{'n_neighbours': 1, 'trial.number': 7}",glad-plasma-1081,KNeighbours,"['pre-trained:openai-gpt', 'preprocessed']"
258,"{'_wandb': {'runtime': 1735}, 'eval/f1_macro': 0.27970085470085465, 'eval/f1_micro': 0.2857142857142857, 'eval/precision_macro': 0.27305194805194805, 'split': 10, 'test/f1_weighted': 0.2958911848064361, 'eval/loss': 5.4265438245984345, '_timestamp': 1704586522.89743, 'eval/accuracy': 0.2857142857142857, 'eval/recall_weighted': 0.2857142857142857, 'eval/precision_weighted': 0.2683982683982684, 'test/loss': 4.805876080293411, 'test/accuracy': 0.308411214953271, 'eval/recall_macro': 0.29217171717171714, 'eval/recall_micro': 0.2857142857142857, 'test/recall_weighted': 0.308411214953271, 'test/f1_micro': 0.308411214953271, '_runtime': 1736.9582378864288, 'eval/f1_weighted': 0.2741554741554741, 'test/recall_micro': 0.308411214953271, 'test/precision_micro': 0.308411214953271, 'test/precision_weighted': 0.3014572790070555, '_step': 20, 'test/precision_macro': 0.3031641139657444, 'test/f1_macro': 0.3076570101724901, 'test/recall_macro': 0.32992724867724865, 'eval/precision_micro': 0.2857142857142857}","{'n_neighbours': 7, 'trial.number': 8}",fallen-waterfall-1080,KNeighbours,"['pre-trained:bert-base-uncased', 'preprocessed']"
259,"{'eval/precision_macro': 1, '_timestamp': 1704589573.852246, 'train/loss': 0, 'eval/accuracy': 1, 'test/accuracy': 0.5981308411214953, 'train/total_flos': 4917360536253984.0, 'eval/recall_micro': 1, 'train/train_runtime': 505.1828, 'test/latency_in_seconds': 0.007637031159035112, 'eval/f1_macro': 1, 'eval/f1_micro': 1, 'test/samples_per_second': 130.94093492298168, 'train/learning_rate': 2.868709937846571e-07, '_runtime': 5071.967868089676, 'train/train_loss': 2.2306626685046164e-08, 'eval/recall_macro': 1, 'eval/precision_micro': 1, 'eval/recall_weighted': 1, 'test/total_time_in_seconds': 0.8171623340167571, '_wandb': {'runtime': 5070}, 'eval/runtime': 0.3805, '_step': 530, 'eval/loss': 2.838316248698902e-09, 'train/epoch': 50, 'train/global_step': 1200, 'eval/samples_per_second': 110.37, 'train/train_steps_per_second': 2.375, 'eval/f1_weighted': 1, 'eval/steps_per_second': 7.884, 'eval/precision_weighted': 1, 'train/train_samples_per_second': 37.907}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan06_23-41-46_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.7212259627079428e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",young-bush-1079,Fine-Tuned LLM:microsoft/codebert-base,['preprocessed']
260,"{'split': 10, 'eval/precision_weighted': 0.42857142857142855, 'test/recall_weighted': 0.4299065420560747, 'eval/f1_weighted': 0.4143064633260712, 'eval/recall_micro': 0.42857142857142855, 'eval/f1_micro': 0.42857142857142855, 'test/accuracy': 0.4299065420560747, 'test/precision_micro': 0.4299065420560747, '_timestamp': 1704586690.7741735, 'eval/f1_macro': 0.41138344226579526, 'eval/recall_macro': 0.425, 'test/recall_micro': 0.4299065420560747, 'eval/precision_macro': 0.425, 'test/precision_weighted': 0.40055512613308975, 'eval/loss': 9.938559233321431, 'test/f1_macro': 0.40533870891013746, 'test/f1_micro': 0.4299065420560747, 'test/loss': 8.597567577611743, '_step': 20, '_runtime': 2201.9096846580505, 'test/precision_macro': 0.40239059186427606, 'eval/accuracy': 0.42857142857142855, 'eval/recall_weighted': 0.42857142857142855, 'test/recall_macro': 0.4328347578347579, 'eval/precision_micro': 0.42857142857142855, '_wandb': {'runtime': 2200}, 'test/f1_weighted': 0.4025627243250741}","{'n_neighbours': 3, 'trial.number': 6}",fallen-breeze-1078,KNeighbours,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
261,"{'eval/precision_micro': 0.3333333333333333, 'test/precision_micro': 0.411214953271028, 'split': 10, 'eval/f1_macro': 0.27219479541460967, 'test/f1_micro': 0.411214953271028, 'eval/recall_micro': 0.3333333333333333, '_step': 20, 'test/accuracy': 0.411214953271028, 'eval/f1_weighted': 0.264835379386463, 'eval/f1_micro': 0.3333333333333333, 'test/recall_micro': 0.411214953271028, 'test/precision_weighted': 0.3286376707404745, 'eval/precision_macro': 0.2685185185185185, 'test/precision_macro': 0.31990384615384615, 'eval/loss': 1.3638368531853244, '_timestamp': 1704585917.797763, 'eval/accuracy': 0.3333333333333333, 'test/recall_macro': 0.39532019704433496, 'test/loss': 1.382717602889172, 'eval/recall_weighted': 0.3333333333333333, 'test/recall_weighted': 0.411214953271028, 'eval/precision_weighted': 0.26366843033509696, '_runtime': 1669.793995141983, 'test/f1_macro': 0.34357298474945536, 'test/f1_weighted': 0.35471667379308947, 'eval/recall_macro': 0.34545454545454546, '_wandb': {'runtime': 1668}}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 8, 'dt_min_samples_leaf': 77}",swift-water-1077,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
262,"{'_runtime': 1846.152604818344, 'eval/f1_micro': 0.30952380952380953, 'test/f1_weighted': 0.15602674448672008, '_step': 20, 'test/loss': 1.4281967055603824, 'test/f1_micro': 0.2616822429906542, 'eval/precision_weighted': 0.18262548262548264, '_timestamp': 1704586077.9798188, 'test/f1_macro': 0.1715415019762846, 'test/recall_micro': 0.2616822429906542, 'test/precision_macro': 0.1478448275862069, 'test/recall_weighted': 0.2616822429906542, 'test/precision_weighted': 0.13693200128907507, 'eval/f1_weighted': 0.185515873015873, 'eval/precision_macro': 0.17432432432432432, 'eval/loss': 1.3321115904857546, 'eval/f1_macro': 0.17708333333333334, 'test/recall_macro': 0.2955685618729097, 'eval/recall_micro': 0.30952380952380953, 'test/accuracy': 0.2616822429906542, 'eval/recall_macro': 0.29545454545454547, 'eval/precision_micro': 0.30952380952380953, 'eval/recall_weighted': 0.30952380952380953, 'split': 10, '_wandb': {'runtime': 1844}, 'eval/accuracy': 0.30952380952380953, 'test/precision_micro': 0.2616822429906542}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 7, 'dt_min_samples_leaf': 29}",prime-snowflake-1076,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
263,"{'eval/precision_macro': 0.4979166666666667, 'test/loss': 1.3091774318341225, 'eval/f1_micro': 0.5, 'test/f1_weighted': 0.46076038693517735, '_runtime': 1862.0640151500704, '_timestamp': 1704585998.765768, 'eval/recall_macro': 0.4886363636363637, 'test/precision_weighted': 0.4895015576323987, '_wandb': {'runtime': 1860}, 'test/f1_micro': 0.45794392523364486, 'eval/recall_weighted': 0.5, 'test/precision_micro': 0.45794392523364486, '_step': 20, 'eval/f1_macro': 0.47804232804232794, 'test/recall_macro': 0.4604967948717949, 'eval/accuracy': 0.5, 'eval/f1_weighted': 0.4865205341395817, 'test/precision_macro': 0.47570512820512817, 'eval/loss': 1.274001993026647, 'eval/recall_micro': 0.5, 'eval/precision_weighted': 0.5033730158730159, 'split': 10, 'eval/precision_micro': 0.5, 'test/recall_weighted': 0.45794392523364486, 'test/accuracy': 0.45794392523364486, 'test/f1_macro': 0.456349563785161, 'test/recall_micro': 0.45794392523364486}","{'rf_max_depth': 3, 'trial.number': 7}",toasty-yogurt-1075,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
264,"{'test/accuracy': 0.38317757009345793, 'test/f1_weighted': 0.3836694540088539, 'eval/precision_macro': 0.39125874125874127, 'test/f1_micro': 0.383177570093458, 'eval/recall_micro': 0.35714285714285715, 'test/precision_micro': 0.38317757009345793, 'eval/recall_weighted': 0.35714285714285715, 'eval/loss': 1.3933960946945485, '_timestamp': 1704586093.280749, 'eval/f1_macro': 0.3563017598343685, 'split': 10, 'test/f1_macro': 0.37976406533575313, 'eval/precision_weighted': 0.3960705960705961, 'eval/precision_micro': 0.35714285714285715, 'eval/f1_weighted': 0.35818421571527154, 'test/recall_micro': 0.38317757009345793, 'test/precision_macro': 0.37942230183609493, 'test/recall_weighted': 0.38317757009345793, 'test/loss': 1.356376052099668, 'eval/accuracy': 0.35714285714285715, 'eval/f1_micro': 0.35714285714285715, 'eval/recall_macro': 0.3568181818181818, 'test/recall_macro': 0.3806034482758621, 'test/precision_weighted': 0.384573370554679, '_step': 20, '_wandb': {'runtime': 2171}, '_runtime': 2173.29426240921}","{'dt_criterion': 'gini', 'dt_max_depth': 8, 'trial.number': 6, 'dt_min_samples_leaf': 82}",jumping-dream-1074,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
265,"{'test/f1_micro': 0.8037383177570093, 'test/f1_weighted': 0.7971697415252164, 'eval/recall_micro': 0.8571428571428571, 'test/recall_micro': 0.8037383177570093, 'eval/precision_macro': 0.8748917748917748, '_step': 20, 'test/f1_macro': 0.8001968903503431, 'eval/recall_weighted': 0.8571428571428571, 'test/precision_micro': 0.8037383177570093, 'test/recall_weighted': 0.8037383177570093, '_runtime': 1625.792664527893, 'eval/f1_macro': 0.8531424715635241, 'eval/f1_micro': 0.8571428571428571, 'eval/recall_macro': 0.8613636363636363, 'eval/accuracy': 0.8571428571428571, 'test/precision_macro': 0.8207369193196992, 'eval/loss': 0.6364857242463451, '_timestamp': 1704585521.4731054, 'test/accuracy': 0.8037383177570093, 'eval/precision_weighted': 0.871098742527314, 'split': 10, '_wandb': {'runtime': 1624}, 'test/loss': 0.6199764122386076, 'eval/precision_micro': 0.8571428571428571, 'eval/f1_weighted': 0.8485361756038446, 'test/recall_macro': 0.8154526567361481, 'test/precision_weighted': 0.8271654883438653}","{'rf_max_depth': 28, 'trial.number': 8}",devout-shape-1073,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
266,"{'eval/precision_weighted': 0.42174881648565854, 'eval/accuracy': 0.35714285714285715, 'test/f1_weighted': 0.395619897348999, 'test/accuracy': 0.411214953271028, 'eval/recall_micro': 0.35714285714285715, 'eval/recall_weighted': 0.35714285714285715, 'test/f1_macro': 0.4019041011409189, 'test/f1_micro': 0.411214953271028, 'test/recall_macro': 0.4233642514892515, 'test/precision_weighted': 0.4238196665321204, 'test/loss': 1.3455290472189765, 'eval/precision_macro': 0.42490696438064857, 'eval/f1_weighted': 0.3479727169382341, '_wandb': {'runtime': 2139}, '_timestamp': 1704585806.937684, 'eval/recall_macro': 0.3590909090909091, 'test/recall_micro': 0.411214953271028, 'eval/precision_micro': 0.35714285714285715, 'split': 10, 'eval/loss': 1.3784447321504585, 'eval/f1_macro': 0.34855317096696403, 'test/precision_macro': 0.4201661129568106, 'test/recall_weighted': 0.411214953271028, '_runtime': 2141.0981969833374, 'eval/f1_micro': 0.35714285714285715, 'test/precision_micro': 0.411214953271028, '_step': 20}","{'rf_max_depth': 2, 'trial.number': 6}",usual-dust-1072,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
267,"{'eval/loss': 1.7029895715836574e-08, 'eval/runtime': 0.3465, 'eval/precision_macro': 1, 'eval/accuracy': 1, 'eval/recall_macro': 1, '_timestamp': 1704584497.2581854, 'train/epoch': 10, 'test/accuracy': 0.5981308411214953, 'train/train_steps_per_second': 1.208, '_wandb': {'runtime': 996}, 'eval/f1_micro': 1, 'train/total_flos': 1007601879877632.0, 'train/train_loss': 8.610227268945891e-08, 'train/global_step': 120, 'eval/recall_weighted': 1, 'eval/steps_per_second': 5.771, 'test/latency_in_seconds': 0.007677274953332407, '_runtime': 998.1905553340912, 'eval/f1_macro': 1, 'train/train_runtime': 99.3735, 'eval/recall_micro': 1, 'eval/precision_micro': 1, 'train/train_samples_per_second': 38.541, '_step': 110, 'eval/samples_per_second': 121.197, 'eval/f1_weighted': 1, 'eval/precision_weighted': 1, 'test/samples_per_second': 130.25455074602203, 'test/total_time_in_seconds': 0.8214684200065676}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan06_23-25-01_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.2662649426007015e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",driven-waterfall-1071,Fine-Tuned LLM:microsoft/codebert-base,['preprocessed']
268,"{'test/f1_weighted': 0.3275730663827073, 'eval/precision_macro': 0.25249750249750247, 'split': 10, '_runtime': 1735.6313812732697, 'eval/loss': 6.194096163179255, '_timestamp': 1704584780.4862242, 'eval/f1_macro': 0.25920634920634916, 'eval/recall_micro': 0.2619047619047619, 'test/precision_weighted': 0.3449751183396043, 'eval/f1_micro': 0.2619047619047619, 'eval/f1_weighted': 0.2514134542705971, 'test/precision_micro': 0.3364485981308411, '_wandb': {'runtime': 1734}, 'test/accuracy': 0.3364485981308411, 'test/f1_micro': 0.3364485981308411, 'eval/precision_micro': 0.2619047619047619, 'test/recall_weighted': 0.3364485981308411, '_step': 20, 'eval/accuracy': 0.2619047619047619, 'eval/recall_macro': 0.2713383838383838, 'eval/recall_weighted': 0.2619047619047619, 'eval/precision_weighted': 0.24620617477760337, 'test/loss': 5.414523837729601, 'test/f1_macro': 0.33550221708116446, 'test/recall_macro': 0.3570767195767196, 'test/recall_micro': 0.3364485981308411, 'test/precision_macro': 0.34045815295815296}","{'n_neighbours': 6, 'trial.number': 7}",lyric-breeze-1070,KNeighbours,"['pre-trained:bert-base-uncased', 'preprocessed']"
269,"{'_step': 20, 'test/loss': 5.233005493676646, 'test/precision_macro': 0.32809485350204154, 'test/recall_weighted': 0.3364485981308411, 'eval/accuracy': 0.380952380952381, 'eval/f1_macro': 0.3893891402714932, 'test/recall_micro': 0.3364485981308411, 'eval/precision_macro': 0.4412202380952381, '_runtime': 1997.589421749115, 'test/f1_micro': 0.3364485981308411, 'eval/loss': 8.266692153000362, 'eval/f1_weighted': 0.3868692092221504, 'test/f1_weighted': 0.32386049004290074, 'eval/recall_weighted': 0.380952380952381, '_timestamp': 1704584941.2432067, 'eval/precision_weighted': 0.4389172335600907, '_wandb': {'runtime': 1996}, 'test/f1_macro': 0.3263057096019942, 'test/recall_macro': 0.33645114942528737, 'test/precision_weighted': 0.3230490596546581, 'split': 10, 'test/accuracy': 0.3364485981308411, 'eval/recall_macro': 0.3840909090909091, 'test/precision_micro': 0.3364485981308411, 'eval/f1_micro': 0.380952380952381, 'eval/recall_micro': 0.380952380952381, 'eval/precision_micro': 0.380952380952381}","{'n_neighbours': 4, 'trial.number': 6}",decent-armadillo-1069,KNeighbours,"['pre-trained:openai-gpt', 'preprocessed']"
270,"{'eval/loss': 1.4058345137561123, 'eval/f1_macro': 0.22727272727272724, 'eval/precision_macro': 0.2162796442687747, 'test/recall_weighted': 0.3644859813084112, 'eval/precision_weighted': 0.21247412008281577, 'test/precision_weighted': 0.28251354157896214, 'eval/accuracy': 0.2619047619047619, 'test/precision_micro': 0.3644859813084112, 'eval/f1_weighted': 0.22294372294372297, 'test/f1_weighted': 0.31407037437719854, 'eval/precision_micro': 0.2619047619047619, '_runtime': 1668.5833904743197, 'test/loss': 1.4067288810479557, 'eval/recall_micro': 0.2619047619047619, 'test/precision_macro': 0.2734834834834835, 'test/f1_macro': 0.3041248795965777, 'test/f1_micro': 0.36448598130841114, '_wandb': {'runtime': 1667}, 'eval/recall_macro': 0.2681818181818182, '_step': 20, 'test/accuracy': 0.3644859813084112, 'test/recall_macro': 0.3529035619552861, 'test/recall_micro': 0.3644859813084112, 'split': 10, '_timestamp': 1704584244.5333474, 'eval/f1_micro': 0.2619047619047619, 'eval/recall_weighted': 0.2619047619047619}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 7, 'dt_min_samples_leaf': 86}",earthy-oath-1068,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
271,"{'eval/precision_weighted': 1, 'train/train_steps_per_second': 2.357, 'eval/runtime': 0.3491, 'eval/f1_weighted': 1, 'train/train_runtime': 101.8399, 'eval/recall_weighted': 1, '_wandb': {'runtime': 1016}, '_timestamp': 1704583494.1347544, 'train/epoch': 10, 'eval/accuracy': 1, 'eval/f1_macro': 1, 'test/accuracy': 0.6448598130841121, 'eval/samples_per_second': 120.297, 'eval/loss': 3.630151240940904e-06, 'eval/recall_micro': 1, 'eval/precision_macro': 1, 'eval/f1_micro': 1, 'train/global_step': 240, 'test/samples_per_second': 129.7887048231214, 'train/total_flos': 987128183238912.0, 'eval/recall_macro': 1, 'eval/precision_micro': 1, 'test/latency_in_seconds': 0.007704830719767329, '_runtime': 1018.7483003139496, 'train/train_loss': 0.020347102483113607, '_step': 110, 'eval/steps_per_second': 8.593, 'test/total_time_in_seconds': 0.8244168870151043, 'train/train_samples_per_second': 37.608}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan06_23-07-57_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 2.5121849341984204e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",tough-butterfly-1067,Fine-Tuned LLM:microsoft/codebert-base,['preprocessed']
272,"{'eval/f1_weighted': 0.3107600991726628, 'eval/recall_micro': 0.35714285714285715, 'eval/recall_weighted': 0.35714285714285715, 'test/precision_weighted': 0.2593761986285351, 'eval/f1_micro': 0.35714285714285715, 'test/f1_macro': 0.22578463203463203, 'test/recall_weighted': 0.2616822429906542, 'eval/accuracy': 0.35714285714285715, 'test/f1_weighted': 0.23101509082817495, 'test/f1_micro': 0.2616822429906542, 'eval/loss': 1.3415413109202, 'test/recall_micro': 0.2616822429906542, 'eval/precision_macro': 0.28226495726495726, 'eval/precision_micro': 0.35714285714285715, 'split': 10, 'test/recall_macro': 0.2693091555183946, 'test/precision_macro': 0.24135072572572572, 'test/precision_micro': 0.2616822429906542, '_runtime': 1850.4926309585571, 'test/loss': 2.105494137743541, 'eval/f1_macro': 0.3062040181097906, 'test/accuracy': 0.2616822429906542, '_step': 20, 'eval/precision_weighted': 0.28512413512413515, '_wandb': {'runtime': 1848}, 'eval/recall_macro': 0.35, '_timestamp': 1704584227.901969}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 6, 'dt_min_samples_leaf': 52}",serene-cherry-1066,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
273,"{'eval/precision_weighted': 0.7843537414965986, 'test/precision_weighted': 0.717512238540276, 'test/precision_macro': 0.7098214285714286, 'test/precision_micro': 0.719626168224299, 'test/f1_weighted': 0.7063705075853381, 'eval/recall_macro': 0.7818181818181817, 'test/recall_weighted': 0.719626168224299, '_runtime': 1861.1343965530396, 'eval/loss': 0.7711437596731782, '_wandb': {'runtime': 1859}, 'test/loss': 0.7410191000071414, 'eval/f1_macro': 0.7771428571428571, 'test/recall_micro': 0.719626168224299, '_step': 20, 'split': 10, 'eval/recall_weighted': 0.7857142857142857, 'eval/accuracy': 0.7857142857142857, 'eval/f1_micro': 0.7857142857142857, 'eval/precision_micro': 0.7857142857142857, 'eval/f1_weighted': 0.7792290249433107, 'eval/precision_macro': 0.7839285714285715, 'eval/recall_micro': 0.7857142857142857, 'test/f1_macro': 0.7023222236967953, 'test/f1_micro': 0.7196261682242989, 'test/recall_macro': 0.7206330128205128, '_timestamp': 1704584131.6641386, 'test/accuracy': 0.719626168224299}","{'rf_max_depth': 18, 'trial.number': 6}",firm-firebrand-1065,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
274,"{'eval/recall_macro': 0.6613636363636364, 'test/loss': 11.78998008055234, 'eval/accuracy': 0.6666666666666666, 'eval/f1_macro': 0.6354079643553328, 'test/precision_macro': 0.6775412087912088, '_wandb': {'runtime': 2209}, 'test/f1_micro': 0.6728971962616822, 'test/recall_micro': 0.6728971962616822, 'eval/loss': 12.014551129705715, 'eval/precision_macro': 0.6897321428571428, '_timestamp': 1704584480.3997073, 'test/accuracy': 0.6728971962616822, 'eval/f1_weighted': 0.6395883889618224, 'test/precision_micro': 0.6728971962616822, 'eval/precision_weighted': 0.6911139455782314, 'test/f1_macro': 0.6545715878324575, 'eval/recall_micro': 0.6666666666666666, 'test/recall_macro': 0.6676282051282051, 'split': 10, 'eval/precision_micro': 0.6666666666666666, 'test/recall_weighted': 0.6728971962616822, 'test/precision_weighted': 0.6779723391872926, '_runtime': 2210.9589943885803, 'eval/f1_micro': 0.6666666666666666, 'test/f1_weighted': 0.6579798259440681, '_step': 20, 'eval/recall_weighted': 0.6666666666666666}","{'n_neighbours': 1, 'trial.number': 5}",leafy-oath-1064,KNeighbours,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
275,"{'eval/loss': 1.620786049120878, 'eval/f1_macro': 0.7583333333333333, 'eval/recall_macro': 0.7636363636363637, 'test/precision_macro': 0.7416258169934641, 'split': 10, 'test/accuracy': 0.7383177570093458, 'test/recall_weighted': 0.7383177570093458, '_wandb': {'runtime': 1625}, '_runtime': 1626.5091652870178, 'test/loss': 1.3214915936496006, 'eval/f1_micro': 0.7619047619047619, 'test/f1_weighted': 0.7236630248209946, 'eval/recall_weighted': 0.7619047619047619, '_step': 20, 'eval/recall_micro': 0.7619047619047619, 'test/recall_micro': 0.7383177570093458, 'eval/precision_micro': 0.7619047619047619, 'eval/f1_weighted': 0.7567460317460318, 'test/recall_macro': 0.7543209242153117, 'eval/precision_macro': 0.7960927960927962, 'eval/precision_weighted': 0.7931856503285074, '_timestamp': 1704583891.0776112, 'test/f1_macro': 0.7296739281442913, 'test/precision_weighted': 0.7444261193574004, 'eval/accuracy': 0.7619047619047619, 'test/f1_micro': 0.7383177570093457, 'test/precision_micro': 0.7383177570093458}","{'rf_max_depth': 26, 'trial.number': 7}",curious-bush-1063,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
276,"{'_runtime': 2207.8378756046295, 'test/recall_micro': 0.3925233644859813, 'test/recall_weighted': 0.3925233644859813, 'eval/f1_macro': 0.5345238095238095, 'test/precision_macro': 0.36799107142857146, 'test/precision_micro': 0.3925233644859813, 'test/accuracy': 0.3925233644859813, 'eval/f1_weighted': 0.5385487528344671, 'test/f1_weighted': 0.3798747202869446, 'eval/precision_weighted': 0.5632129774986918, '_timestamp': 1704583915.5777557, 'test/f1_micro': 0.3925233644859813, 'eval/loss': 1.996395394085274, 'eval/f1_micro': 0.5476190476190477, 'test/f1_macro': 0.3686572597372983, 'eval/recall_weighted': 0.5476190476190477, 'eval/accuracy': 0.5476190476190477, 'eval/recall_macro': 0.5431818181818182, 'eval/precision_micro': 0.5476190476190477, 'test/precision_weighted': 0.3749115487316422, '_step': 20, 'split': 10, 'test/recall_macro': 0.37758620689655176, 'eval/precision_macro': 0.560989010989011, '_wandb': {'runtime': 2206}, 'test/loss': 2.229940722068905, 'eval/recall_micro': 0.5476190476190477}","{'dt_criterion': 'gini', 'dt_max_depth': 9, 'trial.number': 5, 'dt_min_samples_leaf': 20}",misunderstood-shadow-1062,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
277,"{'eval/precision_macro': 0.575, 'eval/recall_weighted': 0.4523809523809524, 'test/f1_weighted': 0.31239132797217994, 'eval/loss': 1.31607646965258, 'eval/f1_weighted': 0.4297344744349353, 'test/loss': 1.3365583161448369, 'test/accuracy': 0.3177570093457944, '_step': 20, 'split': 10, 'eval/f1_macro': 0.4276036866359447, 'test/recall_macro': 0.3307939167314168, 'test/recall_micro': 0.3177570093457944, 'test/precision_micro': 0.3177570093457944, 'eval/precision_weighted': 0.5809523809523809, 'test/precision_weighted': 0.3828996876217732, '_wandb': {'runtime': 2180}, '_timestamp': 1704583661.2702515, 'test/precision_macro': 0.3711551606288448, 'eval/accuracy': 0.4523809523809524, 'eval/recall_micro': 0.4523809523809524, 'eval/recall_macro': 0.45, '_runtime': 2181.403901576996, 'eval/f1_micro': 0.4523809523809524, 'eval/precision_micro': 0.4523809523809524, 'test/recall_weighted': 0.3177570093457944, 'test/f1_macro': 0.3152252906976744, 'test/f1_micro': 0.3177570093457944}","{'rf_max_depth': 2, 'trial.number': 5}",copper-disco-1061,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
278,"{'eval/loss': 6.603610507744101, 'eval/accuracy': 0.47619047619047616, 'test/f1_macro': 0.3369934655381017, 'eval/recall_macro': 0.48207070707070704, 'test/recall_macro': 0.3430886243386243, 'eval/precision_macro': 0.4973214285714286, '_timestamp': 1704583037.059718, 'eval/f1_micro': 0.47619047619047616, 'test/f1_weighted': 0.3389313721331305, '_runtime': 1772.1069929599762, '_step': 20, '_wandb': {'runtime': 1770}, 'test/precision_micro': 0.3364485981308411, 'test/precision_weighted': 0.37021347184938247, 'test/loss': 9.047365601578718, 'test/accuracy': 0.3364485981308411, 'test/precision_macro': 0.35459947522765856, 'split': 10, 'test/f1_micro': 0.3364485981308411, 'test/recall_micro': 0.3364485981308411, 'test/recall_weighted': 0.3364485981308411, 'eval/f1_weighted': 0.4734895952001215, 'eval/recall_micro': 0.47619047619047616, 'eval/recall_weighted': 0.47619047619047616, 'eval/precision_weighted': 0.48460884353741496, 'eval/f1_macro': 0.48267211589580017, 'eval/precision_micro': 0.47619047619047616}","{'n_neighbours': 3, 'trial.number': 6}",peach-durian-1060,KNeighbours,"['pre-trained:bert-base-uncased', 'preprocessed']"
279,"{'_wandb': {'runtime': 2038}, 'eval/accuracy': 0.7142857142857143, 'eval/f1_weighted': 0.7032227032227032, 'eval/precision_macro': 0.7157509157509158, 'eval/precision_micro': 0.7142857142857143, 'split': 10, 'test/loss': 10.442553785632072, 'eval/f1_macro': 0.7078282828282829, 'test/f1_macro': 0.6966702777527009, 'eval/recall_macro': 0.7204545454545455, 'test/recall_micro': 0.7102803738317757, 'eval/loss': 10.298186682604902, 'test/f1_micro': 0.7102803738317757, 'eval/recall_weighted': 0.7142857142857143, 'test/precision_weighted': 0.6924741145405591, '_runtime': 2039.2250084877016, 'test/recall_weighted': 0.7102803738317757, 'eval/precision_weighted': 0.713326356183499, 'eval/f1_micro': 0.7142857142857143, 'eval/recall_micro': 0.7142857142857143, '_step': 20, 'test/accuracy': 0.7102803738317757, 'test/f1_weighted': 0.6840909442455628, 'test/recall_macro': 0.7286206896551723, 'test/precision_macro': 0.6981263904338153, 'test/precision_micro': 0.7102803738317757, '_timestamp': 1704582937.6089835}","{'n_neighbours': 1, 'trial.number': 5}",happy-dream-1059,KNeighbours,"['pre-trained:openai-gpt', 'preprocessed']"
280,"{'test/f1_weighted': 0.5556484669617969, 'eval/f1_macro': 0.4323593073593074, 'eval/recall_macro': 0.42954545454545456, 'test/precision_macro': 0.5486004437617341, '_runtime': 1715.855216741562, '_timestamp': 1704582568.488175, 'eval/precision_macro': 0.4363636363636364, 'test/precision_micro': 0.5607476635514018, 'eval/precision_micro': 0.42857142857142855, 'test/precision_weighted': 0.5539875548919866, 'eval/f1_micro': 0.42857142857142855, 'test/f1_macro': 0.5503550543024227, 'split': 10, 'eval/f1_weighted': 0.43197278911564624, 'test/accuracy': 0.5607476635514018, 'test/f1_micro': 0.5607476635514018, 'test/recall_macro': 0.5556713401540988, 'eval/recall_weighted': 0.42857142857142855, 'test/recall_weighted': 0.5607476635514018, '_step': 20, 'eval/accuracy': 0.42857142857142855, 'test/loss': 4.790832068938802, 'eval/recall_micro': 0.42857142857142855, 'test/recall_micro': 0.5607476635514018, 'eval/precision_weighted': 0.43658008658008657, '_wandb': {'runtime': 1714}, 'eval/loss': 5.966631725728743}","{'dt_criterion': 'gini', 'dt_max_depth': 14, 'trial.number': 6, 'dt_min_samples_leaf': 9}",treasured-puddle-1058,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
281,"{'eval/accuracy': 0.6904761904761905, 'test/f1_macro': 0.7309718969555036, 'eval/f1_weighted': 0.6713250517598344, 'test/recall_macro': 0.7492669995647337, 'test/recall_weighted': 0.7383177570093458, 'test/precision_macro': 0.7360765550239234, 'test/precision_micro': 0.7383177570093458, '_wandb': {'runtime': 1674}, '_runtime': 1676.3343379497528, 'eval/recall_micro': 0.6904761904761905, 'eval/precision_weighted': 0.7185668498168498, 'test/loss': 1.3595182697690835, '_timestamp': 1704582258.555837, 'eval/f1_micro': 0.6904761904761905, 'test/accuracy': 0.7383177570093458, 'eval/recall_weighted': 0.6904761904761905, 'eval/recall_macro': 0.6954545454545454, 'test/recall_micro': 0.7383177570093458, 'split': 10, 'eval/loss': 0.7636080899860664, 'eval/precision_macro': 0.7204326923076924, 'eval/precision_micro': 0.6904761904761905, 'test/precision_weighted': 0.7409518699041572, '_step': 20, 'eval/f1_macro': 0.6757246376811594, 'test/f1_weighted': 0.7282825187681937, 'test/f1_micro': 0.7383177570093457}","{'rf_max_depth': 22, 'trial.number': 6}",desert-dust-1057,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
282,"{'_wandb': {'runtime': 1883}, '_timestamp': 1704582370.3207653, 'eval/f1_micro': 0.30952380952380953, 'test/f1_weighted': 0.2721183800623053, 'eval/recall_macro': 0.30454545454545456, 'test/loss': 2.100112157616852, 'test/accuracy': 0.308411214953271, 'eval/f1_weighted': 0.27138945246714674, 'test/precision_macro': 0.27938876376376376, 'test/precision_micro': 0.308411214953271, 'test/precision_weighted': 0.29324651754558295, 'split': 10, 'eval/loss': 1.4658072013896255, 'test/f1_macro': 0.2708333333333333, 'eval/precision_macro': 0.247140522875817, 'eval/precision_micro': 0.30952380952380953, 'eval/recall_weighted': 0.30952380952380953, 'test/recall_weighted': 0.308411214953271, 'test/recall_macro': 0.3173860785953177, 'test/recall_micro': 0.308411214953271, '_runtime': 1884.3398473262787, 'eval/accuracy': 0.30952380952380953, 'eval/recall_micro': 0.30952380952380953, 'eval/precision_weighted': 0.24832710862122628, '_step': 20, 'eval/f1_macro': 0.2686229462545252, 'test/f1_micro': 0.308411214953271}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 5, 'dt_min_samples_leaf': 49}",wild-pond-1056,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
283,"{'_wandb': {'runtime': 1902}, 'eval/accuracy': 0.6428571428571429, 'eval/precision_micro': 0.6428571428571429, 'test/precision_micro': 0.5700934579439252, '_step': 20, 'eval/f1_micro': 0.6428571428571429, 'test/f1_micro': 0.5700934579439252, 'test/recall_micro': 0.5700934579439252, 'test/f1_macro': 0.5753346429713555, 'eval/recall_micro': 0.6428571428571429, 'eval/precision_weighted': 0.6455026455026455, 'test/precision_weighted': 0.5732205904168521, 'split': 10, '_timestamp': 1704582264.6239772, 'eval/precision_macro': 0.6388888888888888, 'test/precision_macro': 0.5750793650793651, 'test/recall_weighted': 0.5700934579439252, 'test/loss': 1.07383951140579, 'eval/f1_macro': 0.6363636363636364, 'test/accuracy': 0.5700934579439252, 'eval/f1_weighted': 0.6417748917748918, 'test/f1_weighted': 0.569853931667978, '_runtime': 1903.8637220859528, 'eval/loss': 1.094333390781974, 'eval/recall_macro': 0.6386363636363637, 'test/recall_macro': 0.5788701923076923, 'eval/recall_weighted': 0.6428571428571429}","{'rf_max_depth': 6, 'trial.number': 5}",neat-sun-1055,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
284,"{'eval/f1_weighted': 0.2833333333333333, 'test/f1_weighted': 0.3912645432004578, 'eval/recall_weighted': 0.30952380952380953, 'test/recall_weighted': 0.40186915887850466, 'test/recall_macro': 0.40436253561253566, 'test/recall_micro': 0.40186915887850466, 'eval/precision_macro': 0.3206766917293233, '_step': 20, 'eval/f1_micro': 0.30952380952380953, 'test/f1_micro': 0.40186915887850466, 'eval/precision_weighted': 0.3260830648048693, 'test/precision_weighted': 0.4031219246153618, '_wandb': {'runtime': 2252}, 'eval/loss': 5.338125327545262, 'test/f1_macro': 0.393265306122449, 'test/loss': 2.54941245899271, 'eval/f1_macro': 0.2791666666666667, 'test/precision_macro': 0.4038061534017045, 'eval/accuracy': 0.30952380952380953, '_runtime': 2253.9149177074432, 'eval/recall_micro': 0.30952380952380953, 'eval/precision_micro': 0.30952380952380953, 'eval/recall_macro': 0.30454545454545456, 'test/precision_micro': 0.40186915887850466, 'split': 10, '_timestamp': 1704582263.2059207, 'test/accuracy': 0.40186915887850466}","{'n_neighbours': 8, 'trial.number': 4}",generous-shape-1054,KNeighbours,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
285,"{'_wandb': {'runtime': 1746}, 'eval/loss': 7.179024370085147, 'test/accuracy': 0.3644859813084112, 'test/recall_weighted': 0.3644859813084112, 'eval/precision_weighted': 0.6179653679653679, 'test/loss': 9.794752682305022, '_timestamp': 1704581258.4412365, 'test/f1_weighted': 0.35280512000544073, 'test/precision_macro': 0.42691745036572626, '_runtime': 1747.866283416748, 'test/f1_macro': 0.362286891608432, 'eval/precision_macro': 0.6363636363636364, 'eval/recall_weighted': 0.5476190476190477, 'test/precision_weighted': 0.4502391624918211, 'eval/f1_weighted': 0.5393424036281178, 'test/recall_macro': 0.3846230158730159, 'test/f1_micro': 0.36448598130841114, 'eval/recall_macro': 0.534469696969697, 'test/precision_micro': 0.3644859813084112, '_step': 20, 'eval/f1_micro': 0.5476190476190477, 'eval/precision_micro': 0.5476190476190477, 'split': 10, 'eval/accuracy': 0.5476190476190477, 'eval/f1_macro': 0.5369047619047619, 'eval/recall_micro': 0.5476190476190477, 'test/recall_micro': 0.3644859813084112}","{'n_neighbours': 2, 'trial.number': 5}",robust-galaxy-1053,KNeighbours,"['pre-trained:bert-base-uncased', 'preprocessed']"
286,"{'test/precision_macro': 0.33653609831029185, 'test/precision_micro': 0.3364485981308411, 'test/recall_weighted': 0.3364485981308411, 'split': 10, 'test/accuracy': 0.3364485981308411, 'eval/recall_micro': 0.3333333333333333, 'eval/recall_macro': 0.32954545454545453, 'test/loss': 1.3657580393717244, 'eval/f1_macro': 0.31552287581699345, 'eval/f1_weighted': 0.3182228446934329, 'eval/f1_micro': 0.3333333333333333, 'test/f1_weighted': 0.3362132225683628, 'eval/recall_weighted': 0.3333333333333333, 'eval/accuracy': 0.3333333333333333, 'test/f1_micro': 0.3364485981308411, 'eval/precision_weighted': 0.3147675736961451, 'test/recall_macro': 0.33749999999999997, 'test/recall_micro': 0.3364485981308411, '_runtime': 2211.0361833572388, '_wandb': {'runtime': 2209}, 'eval/loss': 1.3224380475144313, 'test/f1_macro': 0.33185185185185184, 'eval/precision_micro': 0.3333333333333333, 'test/precision_weighted': 0.345216704710223, '_step': 20, '_timestamp': 1704581702.5186083, 'eval/precision_macro': 0.31279761904761905}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 4, 'dt_min_samples_leaf': 89}",fancy-salad-1052,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
287,"{'_wandb': {'runtime': 2185}, 'test/loss': 14.055872517848078, 'test/precision_weighted': 0.3614936874897524, 'eval/precision_micro': 0.2619047619047619, 'eval/f1_macro': 0.2548872180451128, 'test/accuracy': 0.35514018691588783, 'test/f1_weighted': 0.34786061677919405, 'eval/precision_macro': 0.2526785714285714, 'split': 10, 'test/f1_micro': 0.35514018691588783, 'eval/recall_micro': 0.2619047619047619, 'test/recall_weighted': 0.35514018691588783, 'test/precision_micro': 0.35514018691588783, 'eval/precision_weighted': 0.25314625850340133, 'eval/accuracy': 0.2619047619047619, 'eval/f1_weighted': 0.2543262919202769, 'eval/recall_weighted': 0.2619047619047619, 'test/precision_macro': 0.356359649122807, '_runtime': 2186.685430765152, 'eval/f1_micro': 0.2619047619047619, 'test/f1_macro': 0.34462382513981205, 'test/recall_macro': 0.35410544727636184, 'test/recall_micro': 0.35514018691588783, '_step': 20, 'eval/loss': 16.145364556585378, '_timestamp': 1704581527.8788168, 'eval/recall_macro': 0.26363636363636367}","{'smoothing': 0.09336616254576446, 'trial.number': 4}",ancient-fire-1051,Bernolli,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
288,"{'eval/recall_micro': 0.6428571428571429, 'eval/precision_macro': 0.6210622710622711, 'split': 10, '_wandb': {'runtime': 2169}, 'eval/recall_macro': 0.6409090909090909, '_step': 20, 'test/recall_macro': 0.7445367132867133, 'test/precision_macro': 0.7515035786774917, 'eval/f1_macro': 0.6238700025464731, 'test/f1_micro': 0.7476635514018691, 'test/f1_weighted': 0.7450534923757993, 'test/loss': 1.038851792732442, 'eval/f1_micro': 0.6428571428571429, '_timestamp': 1704581475.2559817, 'test/accuracy': 0.7476635514018691, 'test/precision_micro': 0.7476635514018691, 'eval/recall_weighted': 0.6428571428571429, 'eval/loss': 0.8763764333575923, 'eval/f1_weighted': 0.6250575987970945, 'test/recall_micro': 0.7476635514018691, 'test/precision_weighted': 0.7626088354247639, 'eval/precision_micro': 0.6428571428571429, 'test/recall_weighted': 0.7476635514018691, 'eval/precision_weighted': 0.6211582068724925, '_runtime': 2170.979483604431, 'eval/accuracy': 0.6428571428571429, 'test/f1_macro': 0.7384594298245614}","{'rf_max_depth': 14, 'trial.number': 4}",glorious-moon-1050,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
289,"{'test/precision_micro': 0.37383177570093457, 'split': 10, 'test/f1_weighted': 0.3195307940293124, 'eval/recall_micro': 0.30952380952380953, 'eval/recall_weighted': 0.30952380952380953, 'eval/precision_weighted': 0.2891604010025063, '_runtime': 1694.3202726840973, 'eval/f1_micro': 0.30952380952380953, 'test/accuracy': 0.37383177570093457, 'eval/f1_weighted': 0.2705215419501134, 'test/recall_macro': 0.370519925476822, 'test/recall_weighted': 0.37383177570093457, 'eval/loss': 2.940786429384483, 'test/loss': 2.306846750207937, 'test/f1_micro': 0.37383177570093457, 'eval/accuracy': 0.30952380952380953, 'eval/precision_macro': 0.2907894736842105, 'eval/recall_macro': 0.3113636363636364, 'test/precision_macro': 0.4199481074481075, 'eval/precision_micro': 0.30952380952380953, 'test/precision_weighted': 0.41851813814430633, '_step': 20, '_wandb': {'runtime': 1692}, '_timestamp': 1704580844.6658816, 'eval/f1_macro': 0.2723809523809524, 'test/f1_macro': 0.31417306017153585, 'test/recall_micro': 0.37383177570093457}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 5, 'dt_min_samples_leaf': 14}",comic-salad-1049,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
290,"{'eval/recall_weighted': 0.380952380952381, 'test/f1_weighted': 0.32386049004290074, 'eval/recall_macro': 0.3840909090909091, 'eval/precision_micro': 0.380952380952381, '_runtime': 1958.861167192459, '_step': 20, 'eval/loss': 8.266692153000362, 'eval/f1_macro': 0.3893891402714932, 'test/accuracy': 0.3364485981308411, 'test/recall_macro': 0.33645114942528737, 'test/precision_macro': 0.32809485350204154, 'split': 10, '_wandb': {'runtime': 1957}, '_timestamp': 1704580894.0073571, 'test/f1_micro': 0.3364485981308411, 'eval/recall_micro': 0.380952380952381, 'test/loss': 5.233005493676646, 'eval/accuracy': 0.380952380952381, 'eval/f1_micro': 0.380952380952381, 'test/recall_micro': 0.3364485981308411, 'test/precision_micro': 0.3364485981308411, 'eval/precision_weighted': 0.4389172335600907, 'eval/precision_macro': 0.4412202380952381, 'test/precision_weighted': 0.3230490596546581, 'test/f1_macro': 0.3263057096019942, 'eval/f1_weighted': 0.3868692092221504, 'test/recall_weighted': 0.3364485981308411}","{'n_neighbours': 4, 'trial.number': 4}",swept-snow-1048,KNeighbours,"['pre-trained:openai-gpt', 'preprocessed']"
291,"{'eval/accuracy': 0.7380952380952381, 'test/f1_micro': 0.766355140186916, 'eval/loss': 1.571402396350992, '_timestamp': 1704580577.5928092, 'test/recall_micro': 0.7663551401869159, '_runtime': 1650.4818291664124, 'test/recall_weighted': 0.7663551401869159, 'eval/recall_micro': 0.7380952380952381, 'test/precision_micro': 0.7663551401869159, 'eval/precision_weighted': 0.7476393976393977, 'test/precision_weighted': 0.769247886070316, 'test/precision_macro': 0.7619047619047619, 'split': 10, 'eval/f1_macro': 0.7467105263157894, 'eval/f1_micro': 0.7380952380952381, 'test/accuracy': 0.7663551401869159, 'test/f1_weighted': 0.7591422128227582, 'test/recall_macro': 0.7769250455417452, 'eval/recall_weighted': 0.7380952380952381, 'test/f1_macro': 0.7605566898723278, 'eval/recall_macro': 0.7431818181818182, 'eval/precision_micro': 0.7380952380952381, '_step': 20, '_wandb': {'runtime': 1649}, 'test/loss': 1.6494031886283171, 'eval/f1_weighted': 0.7409147869674184, 'eval/precision_macro': 0.754059829059829}","{'rf_max_depth': 23, 'trial.number': 5}",usual-grass-1047,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
292,"{'eval/precision_weighted': 0.19387755102040816, '_step': 20, 'split': 10, '_wandb': {'runtime': 1988}, 'test/f1_macro': 0.2451271813073055, 'test/recall_weighted': 0.27102803738317754, 'test/recall_macro': 0.27193910256410253, 'eval/recall_weighted': 0.30952380952380953, 'test/precision_macro': 0.3450534759358289, 'eval/f1_micro': 0.30952380952380953, 'test/f1_micro': 0.27102803738317754, 'test/f1_weighted': 0.2468246136325314, 'eval/recall_micro': 0.30952380952380953, 'eval/accuracy': 0.30952380952380953, 'eval/f1_macro': 0.22756410256410253, 'eval/f1_weighted': 0.22649572649572644, 'eval/loss': 7.8117577951024755, 'eval/precision_macro': 0.19642857142857145, '_runtime': 1989.4393031597135, 'test/loss': 7.979568739609443, '_timestamp': 1704580788.456299, 'test/accuracy': 0.27102803738317754, 'test/precision_weighted': 0.34302064071167976, 'eval/recall_macro': 0.3068181818181818, 'eval/precision_micro': 0.30952380952380953, 'test/recall_micro': 0.27102803738317754, 'test/precision_micro': 0.27102803738317754}","{'smoothing': 0.5169684274040345, 'trial.number': 4}",autumn-resonance-1046,Bernolli,"['pre-trained:openai-gpt', 'preprocessed']"
293,"{'_timestamp': 1704580480.8112912, 'eval/precision_micro': 0.42857142857142855, 'test/recall_weighted': 0.411214953271028, 'eval/precision_weighted': 0.4245323129251701, 'test/f1_micro': 0.411214953271028, 'eval/f1_weighted': 0.4119627649039414, 'test/recall_micro': 0.411214953271028, 'eval/precision_macro': 0.41741071428571425, 'eval/recall_micro': 0.42857142857142855, '_step': 20, '_runtime': 1893.4053161144257, 'eval/recall_macro': 0.4204545454545455, 'eval/recall_weighted': 0.42857142857142855, 'test/precision_micro': 0.411214953271028, 'test/loss': 9.143526397282317, 'test/recall_macro': 0.4141408862876254, 'eval/loss': 8.403717543000132, 'eval/accuracy': 0.42857142857142855, 'eval/f1_macro': 0.4047831253713607, 'test/f1_weighted': 0.41750829062405787, 'test/precision_weighted': 0.4353384310393656, 'split': 10, 'test/accuracy': 0.411214953271028, 'test/precision_macro': 0.4292424242424243, '_wandb': {'runtime': 1892}, 'eval/f1_micro': 0.42857142857142855, 'test/f1_macro': 0.4163306451612904}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 4, 'dt_min_samples_leaf': 9}",misunderstood-sea-1045,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
294,"{'split': 10, 'test/precision_micro': 0.7102803738317757, 'eval/precision_weighted': 0.7413832199546485, 'test/f1_macro': 0.6913817816366542, 'test/recall_micro': 0.7102803738317757, 'eval/precision_macro': 0.7413690476190476, 'test/precision_weighted': 0.7438393606617907, 'test/loss': 0.8699680567477682, '_timestamp': 1704580354.2407105, 'test/accuracy': 0.7102803738317757, 'test/f1_weighted': 0.6873066291132959, 'test/recall_macro': 0.7144230769230769, 'eval/accuracy': 0.7380952380952381, 'eval/f1_weighted': 0.726923024876989, 'eval/recall_weighted': 0.7380952380952381, 'test/precision_macro': 0.7501852501852502, 'test/recall_weighted': 0.7102803738317757, '_runtime': 1899.114345550537, 'eval/f1_micro': 0.7380952380952381, 'test/f1_micro': 0.7102803738317757, 'eval/recall_macro': 0.7295454545454545, 'eval/precision_micro': 0.7380952380952381, '_wandb': {'runtime': 1897}, 'eval/loss': 0.8506717354202344, 'eval/f1_macro': 0.7225501125756879, 'eval/recall_micro': 0.7380952380952381, '_step': 20}","{'rf_max_depth': 8, 'trial.number': 4}",glamorous-waterfall-1044,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
295,"{'_step': 20, '_timestamp': 1704580003.2886522, 'test/f1_weighted': 0.3579960390367861, 'eval/precision_micro': 0.2857142857142857, 'test/precision_macro': 0.36025641025641025, 'eval/precision_macro': 0.2965811965811966, 'test/precision_micro': 0.3644859813084112, 'test/recall_weighted': 0.3644859813084112, 'eval/precision_weighted': 0.2999185999185999, '_runtime': 2238.5199761390686, 'test/loss': 4.045090990527715, 'eval/f1_macro': 0.2765028164055624, 'eval/f1_weighted': 0.2784459057342352, 'test/recall_micro': 0.3644859813084112, 'eval/recall_micro': 0.2857142857142857, 'test/recall_macro': 0.3677706552706552, 'eval/loss': 5.305711289022573, 'eval/recall_macro': 0.2840909090909091, 'eval/recall_weighted': 0.2857142857142857, 'split': 10, '_wandb': {'runtime': 2237}, 'test/f1_micro': 0.36448598130841114, 'test/precision_weighted': 0.3579199616582795, 'eval/f1_micro': 0.2857142857142857, 'test/accuracy': 0.3644859813084112, 'eval/accuracy': 0.2857142857142857, 'test/f1_macro': 0.36084069866793667}","{'n_neighbours': 6, 'trial.number': 3}",soft-dawn-1043,KNeighbours,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
296,"{'test/accuracy': 0.6915887850467289, 'test/f1_micro': 0.6915887850467289, 'eval/recall_macro': 0.7672979797979798, 'eval/precision_micro': 0.7619047619047619, 'test/loss': 11.11626693309221, 'eval/f1_macro': 0.7462606837606838, 'eval/recall_micro': 0.7619047619047619, 'test/precision_micro': 0.6915887850467289, 'eval/f1_weighted': 0.7417582417582418, 'test/recall_macro': 0.6937169312169311, 'eval/precision_macro': 0.7793650793650794, 'eval/precision_weighted': 0.7775510204081633, 'split': 10, 'test/f1_weighted': 0.667061970635204, 'test/precision_macro': 0.7212475633528265, 'eval/loss': 8.581822235504083, 'eval/f1_micro': 0.7619047619047619, 'test/recall_weighted': 0.6915887850467289, '_wandb': {'runtime': 1758}, 'eval/accuracy': 0.7619047619047619, 'test/recall_micro': 0.6915887850467289, 'test/precision_weighted': 0.7311581133519155, 'eval/recall_weighted': 0.7619047619047619, '_step': 20, '_runtime': 1759.5708000659945, '_timestamp': 1704579505.950645, 'test/f1_macro': 0.6625410558359368}","{'n_neighbours': 1, 'trial.number': 4}",dashing-glitter-1042,KNeighbours,"['pre-trained:bert-base-uncased', 'preprocessed']"
297,"{'eval/f1_micro': 0.2619047619047619, 'test/accuracy': 0.21495327102803735, 'test/f1_weighted': 0.07606038820992093, 'test/precision_macro': 0.053738317757009345, 'test/precision_micro': 0.21495327102803735, 'split': 10, 'test/loss': 1.4027429453646243, '_timestamp': 1704579283.7563064, 'eval/f1_macro': 0.10377358490566038, 'test/f1_macro': 0.08846153846153847, 'eval/f1_weighted': 0.10871518418688232, 'eval/recall_weighted': 0.2619047619047619, '_wandb': {'runtime': 1714}, '_runtime': 1715.5090544223783, 'eval/precision_micro': 0.2619047619047619, 'test/recall_weighted': 0.21495327102803735, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.06547619047619048, 'eval/accuracy': 0.2619047619047619, 'test/recall_micro': 0.21495327102803735, '_step': 20, 'eval/loss': 1.3879993356368792, 'test/precision_weighted': 0.046204908725652895, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.2619047619047619, 'test/f1_micro': 0.21495327102803735, 'eval/precision_weighted': 0.06859410430839002}","{'smoothing': 0.8109692829382592, 'trial.number': 4}",fanciful-flower-1041,Bernolli,"['pre-trained:bert-base-uncased', 'preprocessed']"
298,"{'test/recall_macro': 0.39532019704433496, 'test/recall_weighted': 0.411214953271028, '_timestamp': 1704579146.9007533, 'eval/accuracy': 0.3333333333333333, 'test/f1_micro': 0.411214953271028, 'test/f1_weighted': 0.35471667379308947, 'eval/loss': 1.3638368531853244, 'eval/f1_macro': 0.27219479541460967, 'eval/f1_micro': 0.3333333333333333, 'eval/precision_micro': 0.3333333333333333, '_step': 20, '_wandb': {'runtime': 1696}, 'test/accuracy': 0.411214953271028, 'eval/precision_macro': 0.2685185185185185, '_runtime': 1697.7104322910309, 'eval/recall_weighted': 0.3333333333333333, 'test/f1_macro': 0.34357298474945536, 'eval/recall_micro': 0.3333333333333333, 'test/recall_micro': 0.411214953271028, 'split': 10, 'test/loss': 1.382717602889172, 'eval/recall_macro': 0.34545454545454546, 'test/precision_weighted': 0.3286376707404745, 'eval/f1_weighted': 0.264835379386463, 'test/precision_macro': 0.31990384615384615, 'test/precision_micro': 0.411214953271028, 'eval/precision_weighted': 0.26366843033509696}","{'dt_criterion': 'gini', 'dt_max_depth': 11, 'trial.number': 4, 'dt_min_samples_leaf': 72}",rose-wood-1040,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
299,"{'eval/loss': 1.3976302836879515, 'test/recall_macro': 0.3836206896551724, '_runtime': 2216.3274445533752, '_timestamp': 1704579486.2105377, 'test/precision_micro': 0.37383177570093457, 'split': 10, '_wandb': {'runtime': 2214}, 'eval/f1_micro': 0.3333333333333333, 'eval/recall_weighted': 0.3333333333333333, 'eval/f1_macro': 0.2684587813620072, 'test/f1_macro': 0.3216705556995938, 'test/f1_micro': 0.37383177570093457, 'test/recall_weighted': 0.37383177570093457, 'eval/precision_weighted': 0.24586167800453515, 'test/precision_weighted': 0.2874003163824766, 'eval/f1_weighted': 0.2717187233316266, 'test/f1_weighted': 0.31972276808683003, 'eval/recall_macro': 0.32954545454545453, 'eval/recall_micro': 0.3333333333333333, 'test/recall_micro': 0.37383177570093457, 'eval/precision_macro': 0.24226190476190476, 'test/loss': 1.4008344389730671, 'eval/accuracy': 0.3333333333333333, '_step': 20, 'test/accuracy': 0.37383177570093457, 'eval/precision_micro': 0.3333333333333333, 'test/precision_macro': 0.28551943884100495}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 3, 'dt_min_samples_leaf': 60}",worthy-pine-1039,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
300,"{'eval/f1_macro': 0.4932659932659932, '_wandb': {'runtime': 1653}, '_runtime': 1655.1143941879272, 'eval/f1_micro': 0.5476190476190477, 'eval/recall_weighted': 0.5476190476190477, 'eval/precision_weighted': 0.4320436507936507, '_timestamp': 1704578922.1422482, 'eval/precision_macro': 0.44270833333333326, 'test/f1_macro': 0.7002652519893899, 'eval/recall_micro': 0.5476190476190477, 'test/precision_macro': 0.7425166034155598, 'split': 10, 'test/loss': 1.161547494885655, 'eval/accuracy': 0.5476190476190477, 'test/precision_weighted': 0.7544782670378976, 'test/accuracy': 0.7289719626168224, 'test/f1_micro': 0.7289719626168223, 'eval/f1_weighted': 0.4821228154561488, 'eval/recall_macro': 0.5590909090909091, 'test/recall_macro': 0.7417828384194999, '_step': 20, 'test/f1_weighted': 0.698328884922504, 'test/recall_micro': 0.7289719626168224, 'eval/precision_micro': 0.5476190476190477, 'test/recall_weighted': 0.7289719626168224, 'eval/loss': 1.879328029592256, 'test/precision_micro': 0.7289719626168224}","{'rf_max_depth': 9, 'trial.number': 4}",earthy-monkey-1038,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
301,"{'test/f1_micro': 0.35514018691588783, '_wandb': {'runtime': 2193}, 'eval/recall_micro': 0.2619047619047619, 'split': 10, 'test/loss': 14.034616454392529, 'eval/f1_macro': 0.2548872180451128, '_step': 20, 'eval/precision_macro': 0.2526785714285714, 'eval/precision_micro': 0.2619047619047619, 'test/recall_weighted': 0.35514018691588783, 'eval/precision_weighted': 0.25314625850340133, '_runtime': 2194.579057455063, '_timestamp': 1704579337.4913626, 'eval/accuracy': 0.2619047619047619, 'eval/f1_micro': 0.2619047619047619, 'test/f1_macro': 0.34462382513981205, 'eval/f1_weighted': 0.2543262919202769, 'eval/recall_macro': 0.26363636363636367, 'test/accuracy': 0.35514018691588783, 'test/recall_macro': 0.35410544727636184, 'test/f1_weighted': 0.34786061677919405, 'test/precision_macro': 0.356359649122807, 'test/precision_micro': 0.35514018691588783, 'test/precision_weighted': 0.3614936874897524, 'eval/loss': 16.112226515533763, 'test/recall_micro': 0.35514018691588783, 'eval/recall_weighted': 0.2619047619047619}","{'smoothing': 0.4541980681314084, 'trial.number': 3}",autumn-universe-1037,Bernolli,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
302,"{'test/accuracy': 0.7757009345794392, 'test/f1_micro': 0.7757009345794392, 'test/f1_weighted': 0.7732305714717487, 'eval/precision_micro': 0.8095238095238095, 'test/precision_micro': 0.7757009345794392, 'eval/precision_weighted': 0.8134662956091528, '_runtime': 2176.138683319092, 'test/loss': 0.6295845834901603, '_wandb': {'runtime': 2174}, 'eval/f1_macro': 0.8052130325814537, 'test/recall_weighted': 0.7757009345794392, 'eval/accuracy': 0.8095238095238095, 'eval/f1_micro': 0.8095238095238095, 'eval/recall_macro': 0.8113636363636364, 'eval/recall_micro': 0.8095238095238095, 'eval/precision_macro': 0.8157467532467533, 'test/precision_macro': 0.7634188833347318, 'eval/loss': 0.6305911525457235, '_timestamp': 1704579299.1027784, 'test/recall_macro': 0.7697770979020979, 'eval/recall_weighted': 0.8095238095238095, 'split': 10, 'test/f1_macro': 0.7640710935275516, 'test/recall_micro': 0.7757009345794392, 'test/precision_weighted': 0.7763407848214705, '_step': 20, 'eval/f1_weighted': 0.802859529776823}","{'rf_max_depth': 29, 'trial.number': 3}",golden-fire-1036,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
303,"{'eval/f1_macro': 0.5375438596491228, 'eval/recall_weighted': 0.5238095238095238, '_wandb': {'runtime': 2024}, 'eval/loss': 9.654550014942096, 'eval/accuracy': 0.5238095238095238, 'test/f1_micro': 0.4392523364485981, 'eval/recall_macro': 0.5272727272727272, 'eval/precision_macro': 0.6349206349206349, 'test/precision_macro': 0.42182748538011694, '_runtime': 2026.1710166931152, '_timestamp': 1704578930.0826998, 'eval/f1_micro': 0.5238095238095238, 'eval/precision_micro': 0.5238095238095238, 'test/precision_micro': 0.4392523364485981, 'test/precision_weighted': 0.4161868065803137, 'eval/f1_weighted': 0.5360735171261487, 'eval/precision_weighted': 0.6386999244142102, 'test/loss': 9.101605501745077, 'test/accuracy': 0.4392523364485981, '_step': 20, 'split': 10, 'test/recall_micro': 0.4392523364485981, 'test/recall_weighted': 0.4392523364485981, 'test/f1_macro': 0.4159423376907385, 'test/f1_weighted': 0.4139726629175247, 'eval/recall_micro': 0.5238095238095238, 'test/recall_macro': 0.43846264367816096}","{'n_neighbours': 2, 'trial.number': 3}",zany-waterfall-1035,KNeighbours,"['pre-trained:openai-gpt', 'preprocessed']"
304,"{'test/f1_macro': 0.2451271813073055, 'test/recall_micro': 0.27102803738317754, 'eval/precision_weighted': 0.19387755102040816, 'test/recall_weighted': 0.27102803738317754, 'test/precision_weighted': 0.34302064071167976, 'split': 10, 'eval/f1_macro': 0.22756410256410253, 'test/f1_micro': 0.27102803738317754, 'eval/precision_micro': 0.30952380952380953, 'test/precision_micro': 0.27102803738317754, 'eval/accuracy': 0.30952380952380953, 'test/recall_macro': 0.27193910256410253, 'eval/recall_weighted': 0.30952380952380953, 'eval/recall_micro': 0.30952380952380953, '_step': 20, '_wandb': {'runtime': 1987}, 'eval/recall_macro': 0.3068181818181818, '_timestamp': 1704578794.121488, 'eval/f1_weighted': 0.22649572649572644, 'test/accuracy': 0.27102803738317754, '_runtime': 1988.3327300548551, 'test/loss': 7.993675015103491, 'eval/f1_micro': 0.30952380952380953, 'test/precision_macro': 0.3450534759358289, 'eval/loss': 7.831429718020714, 'test/f1_weighted': 0.2468246136325314, 'eval/precision_macro': 0.19642857142857145}","{'smoothing': 0.3775695579679243, 'trial.number': 3}",lemon-brook-1034,Bernolli,"['pre-trained:openai-gpt', 'preprocessed']"
305,"{'eval/precision_macro': 0.31097560975609756, 'eval/precision_micro': 0.2619047619047619, 'eval/recall_weighted': 0.2619047619047619, 'eval/f1_weighted': 0.1370214752567694, 'eval/recall_micro': 0.2619047619047619, 'test/recall_micro': 0.2616822429906542, 'test/precision_micro': 0.2616822429906542, '_step': 20, 'eval/f1_macro': 0.13970588235294118, '_runtime': 1896.9651424884796, 'test/precision_weighted': 0.23208401580113697, 'eval/accuracy': 0.2619047619047619, 'test/recall_macro': 0.274247491638796, '_wandb': {'runtime': 1895}, 'test/loss': 1.4101395617624106, 'test/f1_weighted': 0.15624084144713277, 'test/recall_weighted': 0.2616822429906542, '_timestamp': 1704578581.9204383, 'eval/f1_micro': 0.2619047619047619, 'test/f1_micro': 0.2616822429906542, 'eval/precision_weighted': 0.3199767711962834, 'eval/loss': 1.36197715339401, 'test/f1_macro': 0.16898954703832753, 'eval/recall_macro': 0.2727272727272727, 'test/precision_macro': 0.2618556701030928, 'split': 10, 'test/accuracy': 0.2616822429906542}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 3, 'dt_min_samples_leaf': 22}",dutiful-sun-1033,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
306,"{'test/precision_micro': 0.4299065420560747, 'split': 10, 'eval/f1_micro': 0.4523809523809524, 'test/accuracy': 0.4299065420560747, 'test/recall_micro': 0.4299065420560747, 'eval/precision_weighted': 0.5100108225108225, 'test/loss': 1.24128176718628, '_timestamp': 1704578450.036708, 'eval/f1_macro': 0.4388039496735149, 'test/f1_macro': 0.397526743744422, 'test/recall_macro': 0.4218429487179487, 'eval/precision_macro': 0.5042613636363636, '_runtime': 1908.2191290855408, 'test/f1_micro': 0.4299065420560747, 'eval/f1_weighted': 0.4392039982102094, 'test/precision_weighted': 0.42843064794284297, 'eval/loss': 1.2696642869978487, 'eval/recall_macro': 0.4545454545454546, 'eval/recall_micro': 0.4523809523809524, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_macro': 0.4224973310339164, '_wandb': {'runtime': 1906}, 'test/f1_weighted': 0.4059699700817384, '_step': 20, 'eval/accuracy': 0.4523809523809524, 'eval/precision_micro': 0.4523809523809524, 'test/recall_weighted': 0.4299065420560747}","{'rf_max_depth': 3, 'trial.number': 3}",devout-flower-1032,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
307,"{'test/recall_macro': 0.3147486772486773, 'test/precision_micro': 0.29906542056074764, 'eval/f1_micro': 0.2857142857142857, 'eval/accuracy': 0.2857142857142857, 'test/f1_macro': 0.2956341274917386, 'test/recall_weighted': 0.29906542056074764, '_step': 20, '_runtime': 1757.3975565433502, 'eval/loss': 3.824732870260994, 'test/accuracy': 0.29906542056074764, '_wandb': {'runtime': 1756}, 'eval/f1_weighted': 0.27093425262761645, '_timestamp': 1704577741.5490165, 'eval/f1_macro': 0.2801695444143957, 'test/f1_micro': 0.29906542056074764, 'eval/precision_weighted': 0.264506327006327, 'split': 10, 'eval/precision_macro': 0.27058566433566433, 'test/f1_weighted': 0.292772251926991, 'test/precision_weighted': 0.3230704912947904, 'test/precision_macro': 0.3102453102453102, 'eval/recall_macro': 0.2991161616161616, 'eval/recall_micro': 0.2857142857142857, 'test/recall_micro': 0.29906542056074764, 'eval/precision_micro': 0.2857142857142857, 'eval/recall_weighted': 0.2857142857142857, 'test/loss': 4.569562405376529}","{'n_neighbours': 9, 'trial.number': 3}",serene-cloud-1031,KNeighbours,"['pre-trained:bert-base-uncased', 'preprocessed']"
308,"{'eval/f1_weighted': 0.10871518418688232, 'eval/precision_micro': 0.2619047619047619, 'test/precision_macro': 0.053738317757009345, 'test/recall_weighted': 0.21495327102803735, 'test/precision_weighted': 0.046204908725652895, 'split': 10, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.06547619047619048, 'test/precision_micro': 0.21495327102803735, 'eval/accuracy': 0.2619047619047619, 'test/accuracy': 0.21495327102803735, 'test/f1_macro': 0.08846153846153847, 'test/recall_micro': 0.21495327102803735, 'eval/loss': 1.3870975112944013, 'test/loss': 1.4000096289628827, 'eval/f1_micro': 0.2619047619047619, 'eval/recall_macro': 0.25, '_runtime': 1711.5100603103638, 'test/f1_weighted': 0.07606038820992093, 'eval/precision_weighted': 0.06859410430839002, '_wandb': {'runtime': 1710}, 'test/f1_micro': 0.21495327102803735, 'eval/recall_micro': 0.2619047619047619, '_step': 20, '_timestamp': 1704577562.4066112, 'eval/f1_macro': 0.10377358490566038, 'eval/recall_weighted': 0.2619047619047619}","{'smoothing': 0.6835975578073693, 'trial.number': 3}",woven-night-1030,Bernolli,"['pre-trained:bert-base-uncased', 'preprocessed']"
309,"{'eval/loss': 1.3870837449656892, 'eval/f1_micro': 0.2857142857142857, 'test/f1_weighted': 0.28004332680937827, 'eval/precision_micro': 0.2857142857142857, 'test/precision_macro': 0.26352201257861635, '_step': 20, 'test/f1_macro': 0.2727916802638133, 'eval/precision_weighted': 0.207010582010582, 'eval/accuracy': 0.2857142857142857, 'split': 10, 'test/loss': 1.4081203339347153, 'eval/f1_macro': 0.23990568818155025, 'test/precision_weighted': 0.27357902780226884, '_wandb': {'runtime': 1683}, 'test/precision_micro': 0.3364485981308411, 'eval/precision_macro': 0.21180555555555555, 'test/f1_micro': 0.3364485981308411, 'eval/recall_macro': 0.2909090909090909, '_runtime': 1685.3438432216644, 'test/recall_micro': 0.3364485981308411, 'eval/recall_weighted': 0.2857142857142857, 'test/recall_weighted': 0.3364485981308411, 'eval/recall_micro': 0.2857142857142857, 'test/accuracy': 0.3364485981308411, 'eval/f1_weighted': 0.2350497522911316, 'test/recall_macro': 0.3312571049640015, '_timestamp': 1704577442.2757852}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 3, 'dt_min_samples_leaf': 37}",cool-dust-1029,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
310,"{'_wandb': {'runtime': 1639}, 'eval/f1_macro': 0.5837218337218337, 'test/f1_micro': 0.6542056074766355, 'test/precision_micro': 0.6542056074766355, 'test/recall_weighted': 0.6542056074766355, 'eval/loss': 1.156111009804711, 'eval/f1_weighted': 0.5746845746845747, 'split': 10, 'test/recall_macro': 0.6664994115845303, 'eval/recall_weighted': 0.5952380952380952, 'test/f1_macro': 0.6332980827489416, 'eval/recall_micro': 0.5952380952380952, 'test/recall_micro': 0.6542056074766355, '_timestamp': 1704577261.7719207, 'test/f1_weighted': 0.6278839073392141, 'eval/precision_macro': 0.5957792207792207, '_step': 20, 'eval/f1_micro': 0.5952380952380952, 'eval/recall_macro': 0.6068181818181818, 'test/precision_macro': 0.6779569892473117, '_runtime': 1640.817182779312, 'test/loss': 1.1164095359280028, 'eval/accuracy': 0.5952380952380952, 'test/accuracy': 0.6542056074766355, 'eval/precision_micro': 0.5952380952380952, 'eval/precision_weighted': 0.5884353741496599, 'test/precision_weighted': 0.6836498844337253}","{'rf_max_depth': 5, 'trial.number': 3}",restful-shadow-1028,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
311,"{'test/precision_micro': 0.514018691588785, '_step': 20, '_wandb': {'runtime': 2234}, 'eval/loss': 10.61175326428678, 'test/f1_micro': 0.514018691588785, 'eval/recall_macro': 0.43181818181818177, 'test/recall_macro': 0.5128027065527065, 'eval/precision_micro': 0.42857142857142855, '_timestamp': 1704577759.1097317, 'eval/accuracy': 0.42857142857142855, 'eval/f1_micro': 0.42857142857142855, 'eval/precision_macro': 0.44047619047619047, 'test/precision_macro': 0.5198667073667074, '_runtime': 2235.747396707535, 'eval/f1_macro': 0.3943706293706294, 'eval/precision_weighted': 0.4433106575963719, 'test/accuracy': 0.514018691588785, 'test/f1_macro': 0.4966108452950559, 'eval/f1_weighted': 0.39258741258741264, 'eval/recall_micro': 0.42857142857142855, 'test/precision_weighted': 0.5214588111784373, 'split': 10, 'test/f1_weighted': 0.4983449080842097, 'eval/recall_weighted': 0.42857142857142855, 'test/loss': 10.701674226962895, 'test/recall_micro': 0.514018691588785, 'test/recall_weighted': 0.514018691588785}","{'n_neighbours': 2, 'trial.number': 2}",upbeat-wood-1027,KNeighbours,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
312,"{'eval/f1_macro': 0.3814814814814815, 'eval/recall_macro': 0.37727272727272726, 'test/precision_micro': 0.2897196261682243, '_step': 20, 'test/accuracy': 0.2897196261682243, 'eval/f1_weighted': 0.38536155202821865, 'eval/precision_macro': 0.428125, 'test/recall_macro': 0.29827586206896556, 'eval/precision_micro': 0.380952380952381, 'eval/loss': 2.9290617558341348, 'test/loss': 1.9658069338645008, '_timestamp': 1704577263.685562, 'eval/recall_weighted': 0.380952380952381, 'test/precision_macro': 0.316687123851758, 'test/recall_weighted': 0.2897196261682243, 'test/precision_weighted': 0.32803124047140464, '_wandb': {'runtime': 2189}, 'test/f1_weighted': 0.27550028993193526, 'eval/recall_micro': 0.380952380952381, 'split': 10, '_runtime': 2191.092987060547, 'eval/precision_weighted': 0.4321853741496599, 'eval/accuracy': 0.380952380952381, 'eval/f1_micro': 0.380952380952381, 'test/f1_macro': 0.27352181916135404, 'test/f1_micro': 0.2897196261682243, 'test/recall_micro': 0.2897196261682243}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 2, 'dt_min_samples_leaf': 8}",light-wind-1026,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
313,"{'test/precision_macro': 0.356359649122807, '_timestamp': 1704577137.643748, 'eval/accuracy': 0.2619047619047619, 'eval/f1_macro': 0.2548872180451128, 'eval/f1_micro': 0.2619047619047619, 'test/recall_micro': 0.35514018691588783, 'eval/precision_macro': 0.2526785714285714, 'eval/recall_weighted': 0.2619047619047619, 'test/f1_weighted': 0.34786061677919405, 'eval/recall_micro': 0.2619047619047619, 'test/recall_weighted': 0.35514018691588783, 'test/recall_macro': 0.35410544727636184, 'test/precision_weighted': 0.3614936874897524, 'test/f1_macro': 0.34462382513981205, 'test/f1_micro': 0.35514018691588783, 'test/loss': 14.053373240558498, 'eval/f1_weighted': 0.2543262919202769, 'eval/precision_micro': 0.2619047619047619, 'test/precision_micro': 0.35514018691588783, 'split': 10, '_wandb': {'runtime': 2173}, 'eval/loss': 16.141461551812974, 'eval/recall_macro': 0.26363636363636367, '_step': 20, 'eval/precision_weighted': 0.25314625850340133, '_runtime': 2174.9677431583405, 'test/accuracy': 0.35514018691588783}","{'smoothing': 0.1352364107912094, 'trial.number': 2}",splendid-water-1025,Bernolli,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
314,"{'_step': 20, 'eval/recall_macro': 0.6000000000000001, 'eval/precision_weighted': 0.5572205572205572, 'eval/accuracy': 0.5952380952380952, 'test/f1_weighted': 0.7191586472112956, 'test/recall_micro': 0.719626168224299, 'test/recall_weighted': 0.719626168224299, 'test/f1_macro': 0.7073186492877963, 'test/recall_macro': 0.7135639245014246, '_runtime': 2157.3667306900024, 'eval/recall_weighted': 0.5952380952380952, 'test/precision_macro': 0.7168025362318841, 'test/precision_micro': 0.719626168224299, '_timestamp': 1704577118.1000538, 'eval/f1_micro': 0.5952380952380952, 'eval/f1_weighted': 0.5672678162173961, 'eval/recall_micro': 0.5952380952380952, 'eval/f1_macro': 0.5709988540870894, 'test/f1_micro': 0.7196261682242989, 'test/precision_weighted': 0.7363774888256807, 'split': 10, '_wandb': {'runtime': 2156}, 'test/loss': 0.9532654228939412, 'eval/loss': 1.1197580221926529, 'test/accuracy': 0.719626168224299, 'eval/precision_macro': 0.5594405594405594, 'eval/precision_micro': 0.5952380952380952}","{'rf_max_depth': 7, 'trial.number': 2}",pretty-durian-1024,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
315,"{'test/loss': 9.101605501745077, '_timestamp': 1704576899.3919926, 'eval/f1_micro': 0.5238095238095238, 'eval/recall_micro': 0.5238095238095238, 'test/precision_weighted': 0.4161868065803137, 'eval/accuracy': 0.5238095238095238, 'eval/recall_weighted': 0.5238095238095238, 'test/precision_macro': 0.42182748538011694, '_step': 20, '_runtime': 2005.7432146072388, 'test/f1_macro': 0.4159423376907385, 'test/recall_micro': 0.4392523364485981, 'eval/precision_macro': 0.6349206349206349, 'test/recall_weighted': 0.4392523364485981, 'split': 10, 'eval/loss': 9.654550014942096, 'test/accuracy': 0.4392523364485981, 'eval/f1_weighted': 0.5360735171261487, 'test/recall_macro': 0.43846264367816096, 'test/precision_micro': 0.4392523364485981, '_wandb': {'runtime': 2004}, 'eval/f1_macro': 0.5375438596491228, 'test/f1_weighted': 0.4139726629175247, 'eval/precision_weighted': 0.6386999244142102, 'test/f1_micro': 0.4392523364485981, 'eval/recall_macro': 0.5272727272727272, 'eval/precision_micro': 0.5238095238095238}","{'n_neighbours': 2, 'trial.number': 2}",treasured-durian-1023,KNeighbours,"['pre-trained:openai-gpt', 'preprocessed']"
316,"{'_wandb': {'runtime': 1984}, 'eval/accuracy': 0.30952380952380953, 'test/accuracy': 0.27102803738317754, 'eval/recall_weighted': 0.30952380952380953, '_step': 20, 'eval/f1_macro': 0.22756410256410253, 'test/f1_macro': 0.2451271813073055, 'test/f1_micro': 0.27102803738317754, 'test/recall_micro': 0.27102803738317754, 'test/recall_weighted': 0.27102803738317754, '_runtime': 1985.3457794189453, 'test/loss': 7.986041655921491, '_timestamp': 1704576801.9225874, 'eval/recall_micro': 0.30952380952380953, 'eval/loss': 7.820797330495832, 'test/f1_weighted': 0.2468246136325314, 'test/recall_macro': 0.27193910256410253, 'eval/precision_macro': 0.19642857142857145, 'test/precision_macro': 0.3450534759358289, 'split': 10, 'eval/f1_micro': 0.30952380952380953, 'eval/precision_micro': 0.30952380952380953, 'test/precision_micro': 0.27102803738317754, 'eval/precision_weighted': 0.19387755102040816, 'test/precision_weighted': 0.34302064071167976, 'eval/f1_weighted': 0.22649572649572644, 'eval/recall_macro': 0.3068181818181818}","{'smoothing': 0.45270900806209213, 'trial.number': 2}",copper-sea-1022,Bernolli,"['pre-trained:openai-gpt', 'preprocessed']"
317,"{'_timestamp': 1704576679.3671443, 'test/recall_micro': 0.308411214953271, 'eval/f1_macro': 0.2686229462545252, 'eval/recall_micro': 0.30952380952380953, 'split': 10, '_wandb': {'runtime': 1935}, 'eval/f1_micro': 0.30952380952380953, 'test/f1_micro': 0.308411214953271, 'eval/f1_weighted': 0.27138945246714674, '_step': 20, 'eval/loss': 1.463493778807396, 'test/recall_weighted': 0.308411214953271, '_runtime': 1936.7932803630829, 'test/recall_macro': 0.3173860785953177, 'eval/precision_micro': 0.30952380952380953, 'eval/recall_weighted': 0.30952380952380953, 'test/precision_macro': 0.27938876376376376, 'eval/precision_weighted': 0.24832710862122628, 'test/loss': 2.0541128767642225, 'eval/recall_macro': 0.30454545454545456, 'eval/accuracy': 0.30952380952380953, 'test/f1_macro': 0.2708333333333333, 'test/accuracy': 0.308411214953271, 'test/precision_weighted': 0.29324651754558295, 'test/precision_micro': 0.308411214953271, 'test/f1_weighted': 0.2721183800623053, 'eval/precision_macro': 0.247140522875817}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 2, 'dt_min_samples_leaf': 50}",lyric-smoke-1021,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
318,"{'eval/loss': 1.179684439450514, 'test/loss': 1.111030836826016, 'eval/f1_macro': 0.5201320470717022, 'test/f1_micro': 0.5794392523364486, 'eval/f1_weighted': 0.5253896577788202, 'test/recall_micro': 0.5794392523364486, 'eval/precision_micro': 0.5476190476190477, 'eval/recall_weighted': 0.5476190476190477, 'test/precision_weighted': 0.573110235889594, '_step': 20, 'split': 10, '_wandb': {'runtime': 1899}, 'test/recall_macro': 0.5889022435897435, 'test/precision_micro': 0.5794392523364486, 'eval/f1_micro': 0.5476190476190477, 'eval/recall_macro': 0.5386363636363636, 'eval/precision_weighted': 0.5407407407407407, '_timestamp': 1704576534.4913642, 'eval/accuracy': 0.5476190476190477, 'test/accuracy': 0.5794392523364486, 'test/f1_macro': 0.571715595722602, 'test/f1_weighted': 0.5680955680161256, 'test/precision_macro': 0.5719613317439405, 'eval/recall_micro': 0.5476190476190477, 'test/recall_weighted': 0.5794392523364486, '_runtime': 1900.9400973320007, 'eval/precision_macro': 0.538888888888889}","{'rf_max_depth': 5, 'trial.number': 2}",likely-eon-1020,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
319,"{'eval/recall_weighted': 0.5476190476190477, 'eval/f1_macro': 0.5369047619047619, 'test/f1_weighted': 0.35280512000544073, 'eval/recall_micro': 0.5476190476190477, 'test/recall_macro': 0.3846230158730159, 'eval/precision_macro': 0.6363636363636364, '_timestamp': 1704575978.9933617, 'test/f1_micro': 0.36448598130841114, 'test/precision_macro': 0.42691745036572626, 'eval/precision_weighted': 0.6179653679653679, '_runtime': 1813.5570316314695, 'eval/f1_micro': 0.5476190476190477, 'split': 10, 'eval/precision_micro': 0.5476190476190477, 'test/recall_weighted': 0.3644859813084112, 'eval/accuracy': 0.5476190476190477, '_step': 20, 'test/accuracy': 0.3644859813084112, 'test/f1_macro': 0.362286891608432, 'eval/recall_macro': 0.534469696969697, 'test/recall_micro': 0.3644859813084112, '_wandb': {'runtime': 1812}, 'test/precision_micro': 0.3644859813084112, 'eval/loss': 7.179024370085147, 'test/loss': 9.794752682305022, 'eval/f1_weighted': 0.5393424036281178, 'test/precision_weighted': 0.4502391624918211}","{'n_neighbours': 2, 'trial.number': 2}",pious-field-1019,KNeighbours,"['pre-trained:bert-base-uncased', 'preprocessed']"
320,"{'_wandb': {'runtime': 1767}, 'eval/loss': 1.386478185713207, 'eval/accuracy': 0.2619047619047619, 'test/recall_macro': 0.25, 'test/precision_macro': 0.053738317757009345, 'test/recall_weighted': 0.21495327102803735, 'eval/f1_micro': 0.2619047619047619, 'test/f1_weighted': 0.07606038820992093, 'eval/precision_weighted': 0.06859410430839002, '_step': 20, 'split': 10, '_runtime': 1768.6700365543363, 'eval/f1_macro': 0.10377358490566038, 'test/f1_macro': 0.08846153846153847, 'test/precision_micro': 0.21495327102803735, '_timestamp': 1704575846.2152803, 'test/f1_micro': 0.21495327102803735, 'eval/precision_micro': 0.2619047619047619, 'test/precision_weighted': 0.046204908725652895, 'test/recall_micro': 0.21495327102803735, 'eval/recall_weighted': 0.2619047619047619, 'test/loss': 1.3978070993805405, 'test/accuracy': 0.21495327102803735, 'eval/f1_weighted': 0.10871518418688232, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.2619047619047619, 'eval/precision_macro': 0.06547619047619048}","{'smoothing': 0.5742967965413607, 'trial.number': 2}",prime-deluge-1018,Bernolli,"['pre-trained:bert-base-uncased', 'preprocessed']"
321,"{'_timestamp': 1704575751.479885, 'eval/precision_micro': 0.5, 'eval/accuracy': 0.5, 'test/precision_micro': 0.38317757009345793, 'eval/precision_weighted': 0.5182539682539683, 'split': 10, '_runtime': 1741.8698410987854, 'test/f1_weighted': 0.37090022166380626, 'eval/recall_weighted': 0.5, 'test/precision_macro': 0.3979353549786986, '_step': 20, 'test/accuracy': 0.38317757009345793, 'test/recall_weighted': 0.38317757009345793, 'test/loss': 3.470431078547015, 'test/recall_macro': 0.3772854300871542, 'eval/loss': 2.7954658344651206, 'eval/recall_macro': 0.5045454545454545, 'test/precision_weighted': 0.4022626165503975, 'eval/f1_micro': 0.5, 'test/f1_macro': 0.36524316022514686, 'eval/f1_weighted': 0.4872412008281573, 'eval/recall_micro': 0.5, 'eval/f1_macro': 0.4891847826086956, 'test/f1_micro': 0.383177570093458, 'eval/precision_macro': 0.5166666666666667, '_wandb': {'runtime': 1740}, 'test/recall_micro': 0.38317757009345793}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 2, 'dt_min_samples_leaf': 9}",rich-rain-1017,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
322,"{'test/loss': 0.6689345377896989, 'test/f1_macro': 0.7847870349988995, 'eval/recall_micro': 0.7619047619047619, 'test/precision_weighted': 0.8309801958166444, '_wandb': {'runtime': 1697}, 'eval/f1_micro': 0.7619047619047619, 'test/recall_weighted': 0.794392523364486, 'eval/f1_macro': 0.7613636363636364, 'test/accuracy': 0.794392523364486, 'test/recall_micro': 0.794392523364486, 'test/f1_micro': 0.794392523364486, 'eval/recall_weighted': 0.7619047619047619, 'test/f1_weighted': 0.7840267763283764, '_step': 20, 'eval/accuracy': 0.7619047619047619, 'eval/precision_micro': 0.7619047619047619, 'test/precision_macro': 0.8170386904761905, '_runtime': 1698.3463957309723, 'eval/f1_weighted': 0.7545454545454545, 'eval/recall_macro': 0.7704545454545454, 'test/recall_macro': 0.8090808426431946, 'eval/precision_weighted': 0.753968253968254, 'split': 10, 'eval/loss': 1.4901704449164284, '_timestamp': 1704575615.8725677, 'eval/precision_macro': 0.759090909090909, 'test/precision_micro': 0.794392523364486}","{'rf_max_depth': 12, 'trial.number': 2}",daily-durian-1016,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
323,"{'eval/recall_micro': 0.6666666666666666, 'test/precision_weighted': 0.6779723391872926, 'test/accuracy': 0.6728971962616822, 'test/f1_macro': 0.6545715878324575, 'eval/f1_weighted': 0.6395883889618224, 'test/recall_macro': 0.6676282051282051, '_wandb': {'runtime': 2291}, 'eval/f1_macro': 0.6354079643553328, 'eval/f1_micro': 0.6666666666666666, '_timestamp': 1704575518.4806082, 'test/precision_macro': 0.6775412087912088, 'eval/precision_weighted': 0.6911139455782314, 'eval/precision_macro': 0.6897321428571428, 'test/loss': 11.78998008055234, 'test/recall_micro': 0.6728971962616822, 'eval/recall_weighted': 0.6666666666666666, 'split': 10, '_runtime': 2293.1164343357086, 'eval/loss': 12.014551129705715, 'test/f1_micro': 0.6728971962616822, 'eval/recall_macro': 0.6613636363636364, 'test/precision_micro': 0.6728971962616822, 'eval/precision_micro': 0.6666666666666666, 'test/recall_weighted': 0.6728971962616822, '_step': 20, 'eval/accuracy': 0.6666666666666666, 'test/f1_weighted': 0.6579798259440681}","{'n_neighbours': 1, 'trial.number': 1}",brisk-blaze-1015,KNeighbours,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
324,"{'split': 10, '_runtime': 2260.855084657669, 'eval/recall_micro': 0.47619047619047616, '_wandb': {'runtime': 2256}, 'test/f1_macro': 0.35951129250309577, 'test/f1_weighted': 0.3603113077603655, 'eval/recall_macro': 0.4795454545454545, 'test/recall_macro': 0.3719827586206896, '_timestamp': 1704575065.0989106, 'eval/f1_macro': 0.47911892029539094, 'test/f1_micro': 0.37383177570093457, 'test/precision_macro': 0.39739583333333334, 'test/precision_micro': 0.37383177570093457, 'test/precision_weighted': 0.401382398753894, 'eval/loss': 2.0196123792716714, 'eval/accuracy': 0.47619047619047616, 'test/recall_micro': 0.37383177570093457, 'eval/f1_micro': 0.47619047619047616, 'test/accuracy': 0.37383177570093457, 'eval/precision_macro': 0.4906135531135531, 'eval/precision_micro': 0.47619047619047616, 'test/recall_weighted': 0.37383177570093457, 'eval/precision_weighted': 0.4864817721960578, 'test/loss': 4.189319393994361, '_step': 20, 'eval/f1_weighted': 0.47557811003189165, 'eval/recall_weighted': 0.47619047619047616}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 1, 'dt_min_samples_leaf': 17}",sleek-glitter-1014,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
325,"{'_wandb': {'runtime': 2093}, 'eval/loss': 9.654550014942096, 'eval/f1_macro': 0.5375438596491228, 'eval/recall_micro': 0.5238095238095238, 'test/recall_macro': 0.43846264367816096, '_timestamp': 1704574889.106679, 'eval/f1_micro': 0.5238095238095238, 'test/accuracy': 0.4392523364485981, 'test/f1_macro': 0.4159423376907385, 'test/precision_micro': 0.4392523364485981, 'test/f1_weighted': 0.4139726629175247, 'eval/precision_macro': 0.6349206349206349, '_runtime': 2095.2744369506836, 'eval/recall_weighted': 0.5238095238095238, 'test/recall_weighted': 0.4392523364485981, 'test/recall_micro': 0.4392523364485981, 'eval/precision_micro': 0.5238095238095238, 'eval/precision_weighted': 0.6386999244142102, 'test/loss': 9.101605501745077, 'eval/recall_macro': 0.5272727272727272, 'test/precision_weighted': 0.4161868065803137, '_step': 20, 'split': 10, 'eval/accuracy': 0.5238095238095238, 'test/f1_micro': 0.4392523364485981, 'eval/f1_weighted': 0.5360735171261487, 'test/precision_macro': 0.42182748538011694}","{'n_neighbours': 2, 'trial.number': 1}",vague-sea-1013,KNeighbours,"['pre-trained:openai-gpt', 'preprocessed']"
326,"{'_step': 20, 'eval/accuracy': 0.30952380952380953, 'eval/f1_weighted': 0.22082679225536367, 'test/precision_macro': 0.3450534759358289, '_runtime': 2052.7412390708923, 'test/accuracy': 0.27102803738317754, 'eval/recall_micro': 0.30952380952380953, 'test/recall_macro': 0.27193910256410253, '_timestamp': 1704574811.3252192, 'eval/recall_weighted': 0.30952380952380953, 'eval/precision_weighted': 0.1830550401978973, 'eval/f1_macro': 0.2216117216117216, 'test/f1_macro': 0.2451271813073055, 'eval/recall_macro': 0.3068181818181818, 'test/recall_micro': 0.27102803738317754, 'test/precision_weighted': 0.34302064071167976, 'test/loss': 7.97268800698694, 'test/f1_micro': 0.27102803738317754, 'eval/precision_macro': 0.18506493506493504, 'split': 10, '_wandb': {'runtime': 2051}, 'eval/precision_micro': 0.30952380952380953, 'test/recall_weighted': 0.27102803738317754, 'eval/loss': 7.80212779592254, 'eval/f1_micro': 0.30952380952380953, 'test/f1_weighted': 0.2468246136325314, 'test/precision_micro': 0.27102803738317754}","{'smoothing': 0.5858192984461318, 'trial.number': 1}",classic-river-1012,Bernolli,"['pre-trained:openai-gpt', 'preprocessed']"
327,"{'test/accuracy': 0.27102803738317754, 'eval/precision_macro': 0.1726190476190476, 'eval/loss': 1.506821669165177, '_timestamp': 1704574736.4526308, 'test/f1_micro': 0.27102803738317754, 'eval/f1_weighted': 0.19152661064425772, 'eval/precision_weighted': 0.17290249433106575, 'split': 10, '_runtime': 1998.843782663345, 'eval/recall_macro': 0.23863636363636365, 'test/precision_micro': 0.27102803738317754, 'test/recall_weighted': 0.27102803738317754, '_wandb': {'runtime': 1997}, 'test/loss': 1.4135838160605378, 'test/f1_macro': 0.23090161649944255, 'eval/recall_micro': 0.23809523809523808, 'test/recall_micro': 0.27102803738317754, '_step': 20, 'eval/accuracy': 0.23809523809523808, 'eval/f1_micro': 0.23809523809523808, 'test/precision_macro': 0.19787576764320952, 'test/precision_weighted': 0.18498472475868696, 'eval/f1_macro': 0.19191176470588237, 'test/f1_weighted': 0.2149381635566113, 'eval/precision_micro': 0.23809523809523808, 'eval/recall_weighted': 0.23809523809523808, 'test/recall_macro': 0.29264214046822745}","{'dt_criterion': 'gini', 'dt_max_depth': 14, 'trial.number': 1, 'dt_min_samples_leaf': 96}",blooming-waterfall-1011,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
328,"{'_step': 20, 'eval/accuracy': 0.5476190476190477, 'eval/f1_weighted': 0.5323832981468449, 'test/f1_macro': 0.5132313636008218, 'eval/recall_macro': 0.5454545454545454, 'eval/precision_macro': 0.5747076023391813, 'test/precision_micro': 0.5233644859813084, 'eval/loss': 1.2499096463034247, 'eval/f1_macro': 0.5272167487684729, 'test/precision_weighted': 0.5439272466884235, 'split': 10, '_runtime': 2224.826242208481, '_timestamp': 1704574956.0463722, 'test/accuracy': 0.5233644859813084, 'test/f1_weighted': 0.514848113485377, 'eval/recall_weighted': 0.5476190476190477, 'eval/f1_micro': 0.5476190476190477, 'test/recall_macro': 0.5275976916601917, 'test/recall_micro': 0.5233644859813084, 'test/recall_weighted': 0.5233644859813084, '_wandb': {'runtime': 2223}, 'test/loss': 1.1992050314602998, 'test/f1_micro': 0.5233644859813084, 'eval/precision_micro': 0.5476190476190477, 'test/precision_macro': 0.532128104471558, 'eval/precision_weighted': 0.5801448064605959, 'eval/recall_micro': 0.5476190476190477}","{'rf_max_depth': 4, 'trial.number': 1}",ethereal-river-1010,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
329,"{'eval/f1_macro': 0.2548872180451128, 'test/accuracy': 0.35514018691588783, 'test/recall_micro': 0.35514018691588783, 'test/precision_macro': 0.356359649122807, '_timestamp': 1704574957.2395892, 'eval/recall_macro': 0.26363636363636367, 'test/precision_micro': 0.35514018691588783, 'eval/precision_weighted': 0.25314625850340133, 'split': 10, 'test/f1_macro': 0.34462382513981205, 'eval/precision_micro': 0.2619047619047619, 'test/precision_weighted': 0.3614936874897524, 'test/f1_weighted': 0.34786061677919405, 'eval/precision_macro': 0.2526785714285714, 'test/loss': 14.049842617038008, 'eval/recall_micro': 0.2619047619047619, '_runtime': 2240.5025272369385, 'test/f1_micro': 0.35514018691588783, 'eval/recall_weighted': 0.2619047619047619, 'test/recall_weighted': 0.35514018691588783, '_step': 20, '_wandb': {'runtime': 2239}, 'eval/loss': 16.135950955561004, 'eval/accuracy': 0.2619047619047619, 'eval/f1_micro': 0.2619047619047619, 'eval/f1_weighted': 0.2543262919202769, 'test/recall_macro': 0.35410544727636184}","{'smoothing': 0.19463542273364, 'trial.number': 1}",blooming-mountain-1009,Bernolli,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
330,"{'test/f1_micro': 0.7196261682242989, 'test/recall_micro': 0.719626168224299, 'test/precision_weighted': 0.726974417067875, 'eval/accuracy': 0.7619047619047619, 'test/f1_macro': 0.7128879892037786, 'test/recall_macro': 0.726426282051282, '_timestamp': 1704574628.5819647, 'eval/f1_micro': 0.7619047619047619, 'eval/recall_micro': 0.7619047619047619, 'test/recall_weighted': 0.719626168224299, 'eval/f1_macro': 0.7552043544690603, 'test/f1_weighted': 0.7142091389509, '_runtime': 1960.925857782364, 'split': 10, 'eval/f1_weighted': 0.7592082287460439, '_step': 20, 'test/accuracy': 0.719626168224299, 'eval/recall_weighted': 0.7619047619047619, 'eval/precision_weighted': 0.7741060526774813, 'test/loss': 1.7363252864242094, 'eval/loss': 1.5236919770300748, 'eval/precision_macro': 0.7716575091575092, 'eval/precision_micro': 0.7619047619047619, 'test/precision_macro': 0.7174747474747474, 'test/precision_micro': 0.719626168224299, '_wandb': {'runtime': 1959}, 'eval/recall_macro': 0.7568181818181818}","{'rf_max_depth': 18, 'trial.number': 1}",dainty-salad-1008,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
331,"{'eval/loss': 6.13684156886443, 'eval/f1_micro': 0.3333333333333333, 'test/recall_micro': 0.2803738317757009, '_timestamp': 1704574160.4102874, 'eval/precision_macro': 0.3578754578754579, 'test/precision_macro': 0.28755352715798965, 'test/f1_micro': 0.2803738317757009, 'test/f1_weighted': 0.2719681658493156, 'eval/recall_macro': 0.34494949494949495, 'eval/recall_micro': 0.3333333333333333, 'eval/precision_weighted': 0.33992673992673994, 'split': 10, 'eval/f1_macro': 0.34505837359098235, 'eval/f1_weighted': 0.3305009201748333, 'test/recall_weighted': 0.2803738317757009, 'test/loss': 7.006824356665502, 'test/f1_macro': 0.27997170544340355, 'eval/recall_weighted': 0.3333333333333333, 'eval/precision_micro': 0.3333333333333333, 'test/precision_micro': 0.2803738317757009, 'test/precision_weighted': 0.2930844912892646, '_runtime': 1757.083238363266, 'eval/accuracy': 0.3333333333333333, 'test/recall_macro': 0.29930555555555555, '_step': 20, '_wandb': {'runtime': 1755}, 'test/accuracy': 0.2803738317757009}","{'n_neighbours': 5, 'trial.number': 1}",flowing-forest-1007,KNeighbours,"['pre-trained:bert-base-uncased', 'preprocessed']"
332,"{'test/recall_micro': 0.21495327102803735, 'eval/precision_weighted': 0.06859410430839002, '_timestamp': 1704574072.2460551, 'test/accuracy': 0.21495327102803735, 'test/f1_micro': 0.21495327102803735, 'eval/precision_micro': 0.2619047619047619, 'test/precision_weighted': 0.046204908725652895, '_step': 20, '_runtime': 1714.800891160965, 'eval/recall_weighted': 0.2619047619047619, 'split': 10, 'test/f1_weighted': 0.07606038820992093, 'eval/f1_micro': 0.2619047619047619, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.2619047619047619, 'eval/precision_macro': 0.06547619047619048, 'test/loss': 1.3890180587190637, 'eval/accuracy': 0.2619047619047619, 'test/recall_weighted': 0.21495327102803735, 'test/recall_macro': 0.25, 'test/precision_micro': 0.21495327102803735, 'eval/f1_macro': 0.10377358490566038, 'eval/f1_weighted': 0.10871518418688232, 'test/f1_macro': 0.08846153846153847, 'test/precision_macro': 0.053738317757009345, '_wandb': {'runtime': 1713}, 'eval/loss': 1.3855733985570051}","{'smoothing': 0.04076215645292114, 'trial.number': 1}",glorious-dust-1006,Bernolli,"['pre-trained:bert-base-uncased', 'preprocessed']"
333,"{'split': 10, 'test/precision_micro': 0.27102803738317754, '_wandb': {'runtime': 1691}, 'eval/precision_macro': 0.15625, 'eval/f1_micro': 0.30952380952380953, 'test/f1_macro': 0.17803268384663734, 'test/recall_macro': 0.26795977011494254, 'eval/recall_weighted': 0.30952380952380953, 'eval/loss': 1.3490770364695868, 'eval/f1_macro': 0.2063894523326572, 'eval/f1_weighted': 0.20641359992272773, 'test/recall_micro': 0.27102803738317754, 'test/accuracy': 0.27102803738317754, 'test/f1_weighted': 0.1803779436902671, 'eval/precision_micro': 0.30952380952380953, 'test/recall_weighted': 0.27102803738317754, 'eval/precision_weighted': 0.15674603174603177, 'test/loss': 1.3978350666711672, 'eval/recall_macro': 0.31136363636363634, 'test/precision_macro': 0.13333333333333333, 'eval/recall_micro': 0.30952380952380953, '_step': 20, '_runtime': 1693.1271965503693, '_timestamp': 1704574004.5184436, 'eval/accuracy': 0.30952380952380953, 'test/f1_micro': 0.27102803738317754, 'test/precision_weighted': 0.135202492211838}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 1, 'dt_min_samples_leaf': 19}",hardy-microwave-1005,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
334,"{'eval/accuracy': 1, 'eval/f1_micro': 1, 'test/accuracy': 0.5794392523364486, 'eval/samples_per_second': 111.65, 'eval/steps_per_second': 7.975, 'train/train_samples_per_second': 37.883, '_wandb': {'runtime': 10197}, 'train/epoch': 100, 'train/train_runtime': 1011.0159, 'eval/recall_weighted': 1, 'eval/loss': 0.006649297662079334, 'train/total_flos': 9832620257451264.0, 'eval/precision_micro': 1, 'train/train_steps_per_second': 2.374, 'eval/runtime': 0.3762, 'eval/f1_macro': 1, 'train/train_loss': 0.0016266863997346566, 'test/latency_in_seconds': 0.007756799607696534, 'test/total_time_in_seconds': 0.8299775580235291, 'train/loss': 0.0001, 'eval/recall_macro': 1, 'train/learning_rate': 5.371980259835688e-07, 'eval/precision_macro': 1, '_step': 1050, 'eval/precision_weighted': 1, '_runtime': 10197.783886671066, '_timestamp': 1704582469.190209, 'train/global_step': 2400, 'test/samples_per_second': 128.9191484343323, 'eval/f1_weighted': 1, 'eval/recall_micro': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan06_20-17-51_erc-hpc-comp054', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 3.2231881559014127e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",fine-thunder-1004,Fine-Tuned LLM:microsoft/codebert-base,['preprocessed']
335,"{'eval/recall_weighted': 0.5476190476190477, 'eval/precision_weighted': 0.5563114134542706, 'split': 10, 'eval/loss': 1.2095921358351598, 'eval/accuracy': 0.5476190476190477, 'test/f1_micro': 0.5233644859813084, 'eval/f1_macro': 0.5461497326203208, 'eval/recall_micro': 0.5476190476190477, 'test/precision_micro': 0.5233644859813084, 'test/precision_weighted': 0.5222694232040027, '_timestamp': 1704573912.5582347, 'eval/f1_weighted': 0.5429997453526865, 'test/f1_weighted': 0.5140252362627293, 'test/recall_micro': 0.5233644859813084, '_runtime': 1649.8634326457975, 'test/precision_macro': 0.5203703703703704, 'test/accuracy': 0.5233644859813084, 'test/f1_macro': 0.5201330532212886, 'eval/recall_macro': 0.55, '_wandb': {'runtime': 1648}, 'test/recall_macro': 0.5382434790669182, 'eval/precision_micro': 0.5476190476190477, 'test/recall_weighted': 0.5233644859813084, '_step': 20, 'test/loss': 1.2024731496220489, 'eval/f1_micro': 0.5476190476190477, 'eval/precision_macro': 0.560515873015873}","{'rf_max_depth': 4, 'trial.number': 1}",hardy-flower-1003,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
336,"{'_timestamp': 1704571099.326681, 'split': 10, 'test/recall_weighted': 0.4392523364485981, 'eval/precision_macro': 0.434981684981685, 'test/precision_weighted': 0.4363265510842125, 'test/f1_macro': 0.4217649017649018, 'eval/f1_macro': 0.4140878090366581, 'test/accuracy': 0.4392523364485981, 'eval/f1_weighted': 0.4094487070190395, 'test/recall_micro': 0.4392523364485981, 'test/precision_macro': 0.43618962432915925, '_step': 20, 'test/recall_macro': 0.4381918656056587, 'eval/precision_micro': 0.4047619047619048, 'test/loss': 2.837323073773418, 'eval/f1_micro': 0.4047619047619048, 'test/f1_weighted': 0.4224946393170692, 'eval/precision_weighted': 0.4295307866736438, 'eval/accuracy': 0.4047619047619048, 'eval/recall_macro': 0.40909090909090906, 'eval/recall_micro': 0.4047619047619048, 'test/precision_micro': 0.4392523364485981, '_runtime': 3.730895757675171, 'eval/loss': 2.123255758589357, 'test/f1_micro': 0.4392523364485981, 'eval/recall_weighted': 0.4047619047619048, '_wandb': {'runtime': 2}}","{'dt_criterion': 'gini', 'dt_max_depth': 19, 'trial.number': 99, 'dt_min_samples_leaf': 14}",rose-mountain-1001,DecisionTree,"['TfIdf', 'preprocessed']"
337,"{'test/loss': 3.0183641265880983, 'eval/recall_macro': 0.5477272727272727, 'test/precision_micro': 0.48598130841121495, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.5065826330532213, 'eval/precision_macro': 0.5639880952380952, 'eval/precision_weighted': 0.5559807256235827, '_runtime': 3.636756896972656, 'eval/loss': 4.289102914614636, 'test/recall_weighted': 0.48598130841121495, '_timestamp': 1704571089.986102, 'test/f1_weighted': 0.4886486401503798, 'eval/recall_micro': 0.5476190476190477, 'test/recall_macro': 0.4877291482463896, 'eval/recall_weighted': 0.5476190476190477, 'test/precision_macro': 0.5323464912280702, '_step': 20, 'split': 10, 'eval/accuracy': 0.5476190476190477, 'eval/f1_micro': 0.5476190476190477, 'eval/precision_micro': 0.5476190476190477, 'test/precision_weighted': 0.5419535989506477, 'test/accuracy': 0.48598130841121495, 'test/f1_macro': 0.48444053894795536, 'test/f1_micro': 0.48598130841121495, 'eval/f1_weighted': 0.500826997465653, 'test/recall_micro': 0.48598130841121495}","{'dt_criterion': 'gini', 'dt_max_depth': 14, 'trial.number': 98, 'dt_min_samples_leaf': 5}",glowing-water-1000,DecisionTree,"['TfIdf', 'preprocessed']"
338,"{'eval/loss': 1.2223993360249084, 'eval/f1_weighted': 0.3223622782446312, 'test/f1_weighted': 0.2756387186674081, 'test/recall_micro': 0.35514018691588783, 'test/accuracy': 0.35514018691588783, 'test/precision_micro': 0.35514018691588783, '_step': 20, 'eval/accuracy': 0.4047619047619048, 'eval/recall_micro': 0.4047619047619048, 'test/recall_macro': 0.367816091954023, 'test/precision_macro': 0.4624640804597701, 'test/precision_weighted': 0.4801066172521216, 'split': 10, 'eval/f1_micro': 0.4047619047619048, '_wandb': {'runtime': 1}, '_runtime': 3.3432838916778564, 'eval/recall_weighted': 0.4047619047619048, 'test/recall_weighted': 0.35514018691588783, 'eval/f1_macro': 0.32598039215686275, 'eval/recall_macro': 0.4, 'eval/precision_macro': 0.47619047619047616, 'test/loss': 1.900285265929594, '_timestamp': 1704571079.474433, 'eval/precision_micro': 0.4047619047619048, 'eval/precision_weighted': 0.4614512471655329, 'test/f1_macro': 0.27686436625390115, 'test/f1_micro': 0.35514018691588783}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 97, 'dt_min_samples_leaf': 7}",vivid-field-999,DecisionTree,"['TfIdf', 'preprocessed']"
339,"{'test/precision_macro': 0.5540086776079984, 'test/recall_weighted': 0.5607476635514018, 'eval/precision_weighted': 0.4415249433106576, '_step': 20, 'test/loss': 4.048073738939526, '_timestamp': 1704571069.6989338, 'test/f1_micro': 0.5607476635514018, 'test/precision_micro': 0.5607476635514018, 'split': 10, 'eval/recall_macro': 0.45227272727272727, 'eval/precision_macro': 0.4425595238095238, 'eval/recall_weighted': 0.4523809523809524, 'test/f1_macro': 0.5506683375104428, 'eval/f1_macro': 0.4381616835177206, 'eval/precision_micro': 0.4523809523809524, 'test/precision_weighted': 0.5607448427117436, '_wandb': {'runtime': 2}, 'test/recall_macro': 0.5561057078298457, 'test/recall_micro': 0.5607476635514018, 'eval/accuracy': 0.4523809523809524, 'eval/f1_micro': 0.4523809523809524, 'test/accuracy': 0.5607476635514018, 'eval/f1_weighted': 0.4376361512584423, 'eval/loss': 5.900310222039303, 'test/f1_weighted': 0.556497161907885, 'eval/recall_micro': 0.4523809523809524, '_runtime': 3.833117723464966}","{'dt_criterion': 'gini', 'dt_max_depth': 19, 'trial.number': 96, 'dt_min_samples_leaf': 7}",spring-music-998,DecisionTree,"['TfIdf', 'preprocessed']"
340,"{'split': 10, 'test/accuracy': 0.514018691588785, 'eval/f1_macro': 0.4434046345811052, 'eval/recall_macro': 0.47954545454545455, 'eval/recall_micro': 0.47619047619047616, 'test/precision_macro': 0.4766799292661362, 'test/precision_micro': 0.514018691588785, 'test/precision_weighted': 0.4832316947205764, 'test/f1_micro': 0.514018691588785, 'test/loss': 3.5935456294926755, 'test/f1_weighted': 0.464972834957472, 'test/recall_micro': 0.514018691588785, 'eval/precision_weighted': 0.45069519035684447, 'eval/loss': 4.294003991635338, 'test/f1_macro': 0.45998413686769846, 'test/recall_weighted': 0.514018691588785, '_step': 20, 'eval/f1_weighted': 0.43816314404549705, 'test/recall_macro': 0.513574516160723, 'eval/recall_weighted': 0.47619047619047616, 'eval/f1_micro': 0.47619047619047616, 'eval/precision_macro': 0.456453634085213, 'eval/precision_micro': 0.47619047619047616, '_wandb': {'runtime': 2}, '_runtime': 3.839560031890869, '_timestamp': 1704571059.472488, 'eval/accuracy': 0.47619047619047616}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 95, 'dt_min_samples_leaf': 6}",scarlet-bush-997,DecisionTree,"['TfIdf', 'preprocessed']"
341,"{'split': 10, '_runtime': 3.9661858081817623, 'eval/accuracy': 0.47619047619047616, 'eval/recall_macro': 0.47954545454545455, 'eval/precision_micro': 0.47619047619047616, 'test/precision_weighted': 0.5126026621353724, '_step': 20, 'test/loss': 3.021736793646291, 'test/f1_micro': 0.4953271028037383, 'eval/f1_weighted': 0.4149659863945578, '_wandb': {'runtime': 2}, 'test/accuracy': 0.4953271028037383, 'eval/recall_weighted': 0.47619047619047616, 'test/f1_macro': 0.4472522725565322, 'test/precision_macro': 0.5042087542087542, 'eval/loss': 5.997263540662166, 'eval/f1_micro': 0.47619047619047616, 'test/recall_micro': 0.4953271028037383, 'eval/precision_macro': 0.40340909090909094, '_timestamp': 1704571049.374308, 'eval/recall_micro': 0.47619047619047616, 'eval/precision_weighted': 0.393939393939394, 'eval/f1_macro': 0.4220779220779221, 'test/f1_weighted': 0.4531699241088637, 'test/recall_macro': 0.49569456724629135, 'test/precision_micro': 0.4953271028037383, 'test/recall_weighted': 0.4953271028037383}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 94, 'dt_min_samples_leaf': 5}",good-fire-996,DecisionTree,"['TfIdf', 'preprocessed']"
342,"{'test/loss': 4.904706053093356, 'test/recall_macro': 0.46291138618724825, 'test/f1_macro': 0.45133415435139573, 'eval/recall_macro': 0.45681818181818185, 'eval/precision_macro': 0.49615384615384617, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_macro': 0.49924242424242427, '_wandb': {'runtime': 2}, '_timestamp': 1704571039.1465695, 'eval/f1_micro': 0.4523809523809524, 'split': 10, '_runtime': 3.968989372253418, 'eval/f1_macro': 0.4547619047619048, 'test/accuracy': 0.45794392523364486, 'test/f1_weighted': 0.4503567975691727, 'eval/accuracy': 0.4523809523809524, 'eval/precision_micro': 0.4523809523809524, 'test/precision_micro': 0.45794392523364486, 'eval/f1_weighted': 0.44982993197278903, 'eval/recall_micro': 0.4523809523809524, '_step': 20, 'eval/loss': 5.930371234819657, 'eval/precision_weighted': 0.4888278388278388, 'test/f1_micro': 0.45794392523364486, 'test/recall_micro': 0.45794392523364486, 'test/recall_weighted': 0.45794392523364486, 'test/precision_weighted': 0.5062022090059473}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 93, 'dt_min_samples_leaf': 6}",cosmic-rain-995,DecisionTree,"['TfIdf', 'preprocessed']"
343,"{'test/loss': 1.3877434012967198, 'eval/f1_micro': 0.35714285714285715, 'test/f1_macro': 0.386001585955656, 'eval/recall_micro': 0.35714285714285715, 'test/recall_weighted': 0.4205607476635514, 'test/accuracy': 0.4205607476635514, 'eval/recall_macro': 0.35909090909090907, '_step': 20, '_timestamp': 1704571031.7482443, 'eval/accuracy': 0.35714285714285715, 'eval/precision_micro': 0.35714285714285715, 'test/precision_weighted': 0.39918540035362465, 'eval/loss': 1.443315568366891, 'test/f1_weighted': 0.3958241246058959, 'test/recall_micro': 0.4205607476635514, 'test/precision_macro': 0.3914695945945946, '_runtime': 3.566469192504883, 'eval/f1_weighted': 0.3418686288792589, 'test/precision_micro': 0.4205607476635514, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.4205607476635514, 'test/recall_macro': 0.4110318444995864, 'eval/precision_macro': 0.36644736842105263, 'eval/precision_weighted': 0.3668546365914787, 'eval/f1_macro': 0.3417941405237231, 'eval/recall_weighted': 0.35714285714285715, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 99, 'dt_min_samples_leaf': 28}",wise-shape-994,DecisionTree,"['BoW', 'preprocessed']"
344,"{'eval/recall_weighted': 0.5238095238095238, 'test/recall_macro': 0.5593437469299539, 'test/accuracy': 0.5607476635514018, 'test/f1_macro': 0.5624101961867919, 'eval/precision_macro': 0.5270833333333333, 'test/precision_macro': 0.5691041716903786, 'test/precision_weighted': 0.5710113605376255, 'eval/accuracy': 0.5238095238095238, 'eval/f1_weighted': 0.5202094891535886, 'eval/precision_micro': 0.5238095238095238, 'test/precision_micro': 0.5607476635514018, 'test/recall_weighted': 0.5607476635514018, 'split': 10, 'eval/precision_weighted': 0.5234126984126984, 'eval/loss': 4.280803359634719, 'eval/f1_micro': 0.5238095238095238, '_runtime': 3.857525110244751, 'test/f1_weighted': 0.564080411535174, 'eval/recall_macro': 0.5272727272727273, 'eval/recall_micro': 0.5238095238095238, '_step': 20, 'eval/f1_macro': 0.5236526758265889, 'test/recall_micro': 0.5607476635514018, '_wandb': {'runtime': 2}, '_timestamp': 1704571028.811687, 'test/f1_micro': 0.5607476635514018, 'test/loss': 3.4943258440327867}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 92, 'dt_min_samples_leaf': 6}",laced-waterfall-993,DecisionTree,"['TfIdf', 'preprocessed']"
345,"{'eval/f1_macro': 0.21332565284178184, 'eval/accuracy': 0.21428571428571427, '_runtime': 3.5371789932250977, '_timestamp': 1704571023.49731, 'test/f1_micro': 0.3364485981308411, 'test/f1_weighted': 0.3352614049512239, 'eval/precision_weighted': 0.2683673469387755, '_wandb': {'runtime': 2}, 'test/f1_macro': 0.3263319598452489, 'eval/f1_weighted': 0.21436343354546117, 'test/recall_macro': 0.3261476426799007, 'test/recall_micro': 0.3364485981308411, 'test/precision_weighted': 0.3430278279536113, 'split': 10, 'eval/precision_macro': 0.2642857142857143, 'eval/recall_weighted': 0.21428571428571427, 'test/precision_micro': 0.3364485981308411, 'test/recall_weighted': 0.3364485981308411, 'eval/f1_micro': 0.21428571428571427, 'test/accuracy': 0.3364485981308411, 'eval/recall_macro': 0.2159090909090909, 'eval/precision_micro': 0.21428571428571427, 'test/precision_macro': 0.3355602240896358, '_step': 20, 'eval/loss': 1.5078524196618428, 'test/loss': 1.4133249629871143, 'eval/recall_micro': 0.21428571428571427}","{'dt_criterion': 'gini', 'dt_max_depth': 17, 'trial.number': 98, 'dt_min_samples_leaf': 31}",light-grass-992,DecisionTree,"['BoW', 'preprocessed']"
346,"{'test/loss': 2.8086864944341365, 'eval/f1_weighted': 0.42912322823866383, 'test/precision_weighted': 0.5508455718736093, 'eval/accuracy': 0.42857142857142855, 'test/f1_micro': 0.5233644859813084, 'eval/recall_micro': 0.42857142857142855, 'eval/recall_weighted': 0.42857142857142855, 'test/precision_macro': 0.5476190476190476, 'eval/loss': 3.5291818093081977, 'test/f1_macro': 0.52121363969876, 'test/recall_weighted': 0.5233644859813084, 'test/f1_weighted': 0.5228372037596222, '_step': 20, 'eval/f1_micro': 0.42857142857142855, 'eval/recall_macro': 0.43181818181818177, 'eval/precision_micro': 0.42857142857142855, '_wandb': {'runtime': 2}, 'test/accuracy': 0.5233644859813084, 'eval/precision_weighted': 0.4627739984882842, 'split': 10, '_runtime': 3.767650365829468, 'eval/f1_macro': 0.43005307386112335, 'test/recall_macro': 0.5233750859612928, 'test/recall_micro': 0.5233644859813084, 'test/precision_micro': 0.5233644859813084, '_timestamp': 1704571018.4924183, 'eval/precision_macro': 0.46230158730158727}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 91, 'dt_min_samples_leaf': 7}",gentle-planet-991,DecisionTree,"['TfIdf', 'preprocessed']"
347,"{'eval/recall_macro': 0.31136363636363634, 'test/recall_weighted': 0.3177570093457944, 'test/loss': 1.5091066440889702, 'test/recall_micro': 0.3177570093457944, 'test/f1_micro': 0.3177570093457944, '_wandb': {'runtime': 2}, 'test/accuracy': 0.3177570093457944, 'test/f1_macro': 0.32249742199624276, 'split': 10, 'eval/f1_macro': 0.3163919413919414, 'eval/f1_weighted': 0.31595150880865164, 'eval/precision_macro': 0.4097426470588236, 'test/precision_micro': 0.3177570093457944, '_timestamp': 1704571013.3587685, 'eval/recall_weighted': 0.30952380952380953, 'test/precision_macro': 0.3502314814814815, 'eval/precision_weighted': 0.41228991596638653, 'eval/precision_micro': 0.30952380952380953, 'test/recall_macro': 0.3186259305210918, 'eval/recall_micro': 0.30952380952380953, '_runtime': 3.584524393081665, 'eval/loss': 1.3979745349856256, 'eval/accuracy': 0.30952380952380953, 'eval/f1_micro': 0.30952380952380953, 'test/f1_weighted': 0.32519078229711273, 'test/precision_weighted': 0.3556767047421253, '_step': 20}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 97, 'dt_min_samples_leaf': 24}",dashing-hill-990,DecisionTree,"['BoW', 'preprocessed']"
348,"{'eval/f1_macro': 0.4436802232854864, 'eval/precision_micro': 0.4523809523809524, 'test/recall_weighted': 0.514018691588785, '_wandb': {'runtime': 2}, 'test/accuracy': 0.514018691588785, 'test/recall_macro': 0.5105712741919639, 'test/precision_micro': 0.514018691588785, 'eval/recall_weighted': 0.4523809523809524, '_step': 20, 'test/f1_micro': 0.514018691588785, 'eval/recall_macro': 0.45681818181818185, 'eval/precision_macro': 0.4434974747474747, '_runtime': 3.90256929397583, 'eval/loss': 1.9355635816859025, 'test/precision_macro': 0.5118518518518519, 'eval/f1_micro': 0.4523809523809524, 'eval/f1_weighted': 0.4408939014202172, 'split': 10, 'eval/recall_micro': 0.4523809523809524, 'test/precision_weighted': 0.5150709588092766, 'test/loss': 2.6418217712697425, '_timestamp': 1704571008.3602602, 'test/f1_weighted': 0.5142600899335281, 'eval/precision_weighted': 0.4421296296296296, 'eval/accuracy': 0.4523809523809524, 'test/f1_macro': 0.5109313424024009, 'test/recall_micro': 0.514018691588785}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 90, 'dt_min_samples_leaf': 11}",devout-frog-989,DecisionTree,"['TfIdf', 'preprocessed']"
349,"{'eval/f1_micro': 0.2619047619047619, 'eval/recall_micro': 0.2619047619047619, 'eval/precision_micro': 0.2619047619047619, 'test/precision_weighted': 0.38040350096424863, 'test/f1_weighted': 0.3784026578720579, 'eval/recall_weighted': 0.2619047619047619, 'eval/precision_macro': 0.24479166666666663, 'split': 10, '_wandb': {'runtime': 2}, '_runtime': 3.5336596965789795, 'test/recall_micro': 0.40186915887850466, 'test/recall_weighted': 0.40186915887850466, '_timestamp': 1704571003.0703146, 'eval/f1_macro': 0.24465598972177915, 'test/f1_macro': 0.3684119420006517, 'test/precision_micro': 0.40186915887850466, 'eval/accuracy': 0.2619047619047619, 'eval/f1_weighted': 0.24683657797692884, 'eval/precision_weighted': 0.24652777777777776, 'eval/loss': 1.4971431044040262, 'test/loss': 1.3810715903995736, 'test/f1_micro': 0.40186915887850466, 'eval/recall_macro': 0.2590909090909091, 'test/precision_macro': 0.3742063492063492, '_step': 20, 'test/accuracy': 0.40186915887850466, 'test/recall_macro': 0.39025020678246486}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 96, 'dt_min_samples_leaf': 37}",woven-sea-988,DecisionTree,"['BoW', 'preprocessed']"
350,"{'eval/loss': 5.196437236002528, 'eval/recall_macro': 0.45, 'test/precision_micro': 0.5046728971962616, 'eval/accuracy': 0.4523809523809524, 'test/accuracy': 0.5046728971962616, 'test/f1_micro': 0.5046728971962616, 'eval/recall_micro': 0.4523809523809524, 'test/recall_macro': 0.5044267609784852, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_macro': 0.5404674369747899, 'test/recall_weighted': 0.5046728971962616, 'test/loss': 4.470527299068619, '_timestamp': 1704570998.1639192, 'test/recall_micro': 0.5046728971962616, 'eval/f1_micro': 0.4523809523809524, 'test/f1_weighted': 0.5151353015382247, 'eval/precision_macro': 0.46050420168067224, 'test/f1_macro': 0.5110723236663086, 'eval/f1_weighted': 0.442354719665644, 'eval/precision_micro': 0.4523809523809524, 'eval/precision_weighted': 0.45692276910764307, '_step': 20, 'split': 10, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.4430438842203548, '_runtime': 3.9014933109283447, 'test/precision_weighted': 0.5489957197832404}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 89, 'dt_min_samples_leaf': 8}",bumbling-butterfly-987,DecisionTree,"['TfIdf', 'preprocessed']"
351,"{'_wandb': {'runtime': 2}, 'eval/loss': 1.5811322581331777, 'test/loss': 1.4395680746054185, 'test/precision_micro': 0.3364485981308411, '_step': 20, 'split': 10, 'eval/recall_weighted': 0.2619047619047619, 'eval/accuracy': 0.2619047619047619, 'test/precision_macro': 0.33611072847792695, 'test/precision_weighted': 0.3452090710319073, 'eval/recall_micro': 0.2619047619047619, 'eval/precision_weighted': 0.27154195011337867, 'eval/recall_macro': 0.26136363636363635, 'test/recall_micro': 0.3364485981308411, 'eval/precision_macro': 0.26904761904761904, 'eval/f1_micro': 0.2619047619047619, 'test/f1_macro': 0.3297986147101256, 'test/f1_weighted': 0.3384898202669416, 'test/recall_macro': 0.3284997932175352, 'test/recall_weighted': 0.3364485981308411, '_runtime': 3.5777273178100586, '_timestamp': 1704570992.8845804, 'eval/f1_macro': 0.2545833333333333, 'test/f1_micro': 0.3364485981308411, 'eval/precision_micro': 0.2619047619047619, 'test/accuracy': 0.3364485981308411, 'eval/f1_weighted': 0.25611111111111107}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 95, 'dt_min_samples_leaf': 22}",curious-bee-986,DecisionTree,"['BoW', 'preprocessed']"
352,"{'test/f1_macro': 0.4054347826086957, 'test/precision_micro': 0.4672897196261682, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.42857142857142855, 'test/recall_weighted': 0.4672897196261682, 'test/loss': 3.3947626445144556, 'test/recall_micro': 0.4672897196261682, 'test/f1_weighted': 0.40963023161316536, 'eval/precision_micro': 0.42857142857142855, 'test/accuracy': 0.4672897196261682, 'test/f1_micro': 0.4672897196261683, 'eval/f1_weighted': 0.36904761904761896, 'eval/f1_micro': 0.42857142857142855, 'eval/loss': 6.088487633250527, 'eval/f1_macro': 0.37499999999999994, 'eval/precision_weighted': 0.4027272727272727, '_timestamp': 1704570988.95432, 'test/precision_macro': 0.42533496201855175, 'test/recall_macro': 0.4723371647509579, 'eval/recall_weighted': 0.42857142857142855, '_runtime': 5.020153999328613, 'eval/recall_macro': 0.42954545454545456, 'eval/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.4138636363636363, 'test/precision_weighted': 0.4360876022402508, '_step': 20, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 88, 'dt_min_samples_leaf': 5}",wild-oath-985,DecisionTree,"['TfIdf', 'preprocessed']"
353,"{'eval/precision_macro': 0.36644736842105263, 'test/recall_weighted': 0.4205607476635514, 'test/recall_macro': 0.4110318444995864, 'eval/precision_micro': 0.35714285714285715, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.3417941405237231, 'eval/recall_macro': 0.35909090909090907, 'eval/accuracy': 0.35714285714285715, 'test/f1_micro': 0.4205607476635514, '_step': 20, 'split': 10, 'test/loss': 1.3877434012967198, 'eval/loss': 1.443315568366891, '_timestamp': 1704570982.718263, 'test/f1_weighted': 0.3958241246058959, 'test/precision_macro': 0.3914695945945946, 'test/precision_weighted': 0.39918540035362465, 'eval/f1_micro': 0.35714285714285715, 'test/accuracy': 0.4205607476635514, 'test/f1_macro': 0.386001585955656, 'eval/f1_weighted': 0.3418686288792589, 'test/precision_micro': 0.4205607476635514, 'eval/precision_weighted': 0.3668546365914787, '_runtime': 3.664959669113159, 'eval/recall_micro': 0.35714285714285715, 'test/recall_micro': 0.4205607476635514, 'eval/recall_weighted': 0.35714285714285715}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 94, 'dt_min_samples_leaf': 31}",revived-snow-984,DecisionTree,"['BoW', 'preprocessed']"
354,"{'eval/recall_macro': 0.45227272727272727, 'eval/recall_micro': 0.4523809523809524, 'test/recall_macro': 0.43895127222713426, 'eval/recall_weighted': 0.4523809523809524, 'eval/loss': 4.388590859344707, 'test/loss': 2.780938760283441, 'eval/precision_macro': 0.4164562289562289, 'test/precision_micro': 0.4299065420560747, 'eval/f1_weighted': 0.3759398496240601, '_timestamp': 1704570977.7787206, 'eval/f1_macro': 0.381578947368421, 'test/f1_micro': 0.4299065420560747, 'eval/precision_weighted': 0.40544332210998874, 'test/accuracy': 0.4299065420560747, 'test/f1_weighted': 0.37588443047215664, 'eval/precision_micro': 0.4523809523809524, 'test/precision_macro': 0.49738583013230897, '_wandb': {'runtime': 2}, 'eval/f1_micro': 0.4523809523809524, 'test/f1_macro': 0.3748944405348346, 'test/recall_micro': 0.4299065420560747, '_runtime': 4.198171615600586, 'eval/accuracy': 0.4523809523809524, 'test/recall_weighted': 0.4299065420560747, 'test/precision_weighted': 0.5061946302567599, '_step': 20, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 87, 'dt_min_samples_leaf': 6}",hardy-terrain-983,DecisionTree,"['TfIdf', 'preprocessed']"
355,"{'_timestamp': 1704570971.475844, 'eval/precision_micro': 0.3333333333333333, 'test/recall_weighted': 0.38317757009345793, 'split': 10, 'eval/recall_macro': 0.3340909090909091, 'eval/precision_macro': 0.34852941176470587, 'eval/recall_weighted': 0.3333333333333333, 'test/precision_weighted': 0.373785046728972, '_runtime': 3.6579339504241943, 'eval/f1_macro': 0.3259259259259259, 'test/accuracy': 0.38317757009345793, 'eval/f1_weighted': 0.326278659611993, 'test/loss': 1.4073623847905286, 'eval/accuracy': 0.3333333333333333, 'test/f1_macro': 0.3675263928481099, 'eval/recall_micro': 0.3333333333333333, 'test/precision_macro': 0.364375, 'eval/precision_weighted': 0.34859943977591035, '_wandb': {'runtime': 2}, 'test/recall_macro': 0.37417287014061207, '_step': 20, 'test/recall_micro': 0.38317757009345793, 'eval/f1_micro': 0.3333333333333333, 'test/f1_micro': 0.383177570093458, 'test/f1_weighted': 0.3768049054767262, 'test/precision_micro': 0.38317757009345793, 'eval/loss': 1.5105946539436068}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 93, 'dt_min_samples_leaf': 26}",pleasant-river-982,DecisionTree,"['BoW', 'preprocessed']"
356,"{'_runtime': 3.927211046218872, 'eval/f1_macro': 0.4430438842203548, 'test/f1_macro': 0.5110723236663086, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_micro': 0.5046728971962616, 'test/accuracy': 0.5046728971962616, 'split': 10, 'test/loss': 4.473023212949452, 'eval/accuracy': 0.4523809523809524, 'test/f1_weighted': 0.5151353015382247, 'test/precision_macro': 0.5404674369747899, 'test/precision_weighted': 0.5489957197832404, '_wandb': {'runtime': 2}, 'eval/f1_micro': 0.4523809523809524, 'eval/recall_macro': 0.45, 'test/recall_micro': 0.5046728971962616, 'eval/precision_weighted': 0.45692276910764307, '_step': 20, 'eval/loss': 4.384586206477246, '_timestamp': 1704570967.263274, 'test/recall_macro': 0.5044267609784852, 'eval/precision_micro': 0.4523809523809524, 'test/f1_micro': 0.5046728971962616, 'eval/precision_macro': 0.46050420168067224, 'eval/f1_weighted': 0.442354719665644, 'eval/recall_micro': 0.4523809523809524, 'test/recall_weighted': 0.5046728971962616}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 86, 'dt_min_samples_leaf': 8}",dainty-pyramid-981,DecisionTree,"['TfIdf', 'preprocessed']"
357,"{'_wandb': {'runtime': 2256}, 'eval/accuracy': 0.6666666666666666, 'eval/f1_micro': 0.6666666666666666, 'eval/f1_weighted': 0.6395883889618224, 'test/recall_micro': 0.6728971962616822, 'eval/precision_micro': 0.6666666666666666, 'eval/recall_weighted': 0.6666666666666666, 'test/precision_macro': 0.6775412087912088, '_step': 20, 'split': 10, '_runtime': 2258.3798172473907, 'eval/loss': 12.014551129705715, 'eval/f1_macro': 0.6354079643553328, 'test/f1_weighted': 0.6579798259440681, 'test/recall_weighted': 0.6728971962616822, 'eval/recall_micro': 0.6666666666666666, 'test/precision_weighted': 0.6779723391872926, 'test/recall_macro': 0.6676282051282051, 'eval/precision_weighted': 0.6911139455782314, 'test/loss': 11.78998008055234, '_timestamp': 1704573219.9384973, 'test/accuracy': 0.6728971962616822, 'eval/recall_macro': 0.6613636363636364, 'test/f1_macro': 0.6545715878324575, 'test/f1_micro': 0.6728971962616822, 'eval/precision_macro': 0.6897321428571428, 'test/precision_micro': 0.6728971962616822}","{'n_neighbours': 1, 'trial.number': 0}",graceful-firefly-980,KNeighbours,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
358,"{'_wandb': {'runtime': 2}, 'test/f1_micro': 0.4205607476635514, 'eval/loss': 1.443315568366891, 'test/accuracy': 0.4205607476635514, 'test/f1_macro': 0.386001585955656, 'eval/recall_weighted': 0.35714285714285715, 'eval/recall_micro': 0.35714285714285715, 'test/recall_micro': 0.4205607476635514, 'eval/precision_weighted': 0.3668546365914787, 'split': 10, '_timestamp': 1704570961.14776, 'eval/f1_macro': 0.3417941405237231, 'eval/f1_weighted': 0.3418686288792589, 'test/loss': 1.3877434012967198, 'eval/precision_macro': 0.36644736842105263, 'eval/precision_micro': 0.35714285714285715, 'test/recall_weighted': 0.4205607476635514, '_step': 20, '_runtime': 3.5208568572998047, 'test/f1_weighted': 0.3958241246058959, 'eval/recall_macro': 0.35909090909090907, 'eval/f1_micro': 0.35714285714285715, 'test/precision_weighted': 0.39918540035362465, 'eval/accuracy': 0.35714285714285715, 'test/recall_macro': 0.4110318444995864, 'test/precision_macro': 0.3914695945945946, 'test/precision_micro': 0.4205607476635514}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 92, 'dt_min_samples_leaf': 29}",apricot-blaze-979,DecisionTree,"['BoW', 'preprocessed']"
359,"{'_step': 20, 'eval/loss': 1.2121741543342732, 'eval/f1_macro': 0.4285619138959932, 'test/accuracy': 0.3644859813084112, 'test/precision_macro': 0.4389110889110889, 'test/f1_micro': 0.36448598130841114, 'eval/recall_weighted': 0.4523809523809524, 'split': 10, 'eval/accuracy': 0.4523809523809524, 'eval/recall_micro': 0.4523809523809524, 'test/recall_macro': 0.369259750466647, 'eval/precision_macro': 0.5833333333333333, 'eval/f1_weighted': 0.4298286343522916, '_runtime': 3.7508859634399414, 'eval/precision_micro': 0.4523809523809524, 'test/precision_weighted': 0.4449793197456749, 'test/loss': 1.85854471421384, 'test/f1_macro': 0.35540996971814587, 'test/recall_micro': 0.3644859813084112, 'test/recall_weighted': 0.3644859813084112, '_wandb': {'runtime': 2}, 'eval/f1_micro': 0.4523809523809524, 'eval/recall_macro': 0.44545454545454544, 'test/precision_micro': 0.3644859813084112, 'eval/precision_weighted': 0.5736961451247166, '_timestamp': 1704570957.879962, 'test/f1_weighted': 0.3547733650302275}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 85, 'dt_min_samples_leaf': 9}",prime-donkey-978,DecisionTree,"['TfIdf', 'preprocessed']"
360,"{'test/recall_weighted': 0.40186915887850466, 'eval/precision_weighted': 0.24652777777777776, 'eval/f1_weighted': 0.24683657797692884, 'test/f1_weighted': 0.3784026578720579, 'eval/accuracy': 0.2619047619047619, 'test/precision_weighted': 0.38040350096424863, '_step': 20, 'split': 10, 'test/accuracy': 0.40186915887850466, '_timestamp': 1704570953.2062843, 'eval/f1_micro': 0.2619047619047619, 'eval/f1_macro': 0.24465598972177915, 'eval/recall_macro': 0.2590909090909091, 'eval/recall_weighted': 0.2619047619047619, 'test/f1_macro': 0.3684119420006517, 'test/recall_micro': 0.40186915887850466, 'eval/precision_micro': 0.2619047619047619, 'test/precision_macro': 0.3742063492063492, 'test/precision_micro': 0.40186915887850466, 'test/recall_macro': 0.39025020678246486, 'eval/precision_macro': 0.24479166666666663, '_wandb': {'runtime': 2}, 'eval/recall_micro': 0.2619047619047619, 'test/loss': 1.3810715903995736, 'test/f1_micro': 0.40186915887850466, '_runtime': 4.030283451080322, 'eval/loss': 1.4971431044040262}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 91, 'dt_min_samples_leaf': 33}",decent-dream-977,DecisionTree,"['BoW', 'preprocessed']"
361,"{'_timestamp': 1704570949.3058038, 'eval/recall_macro': 0.35, 'test/precision_weighted': 0.20836999838168063, '_runtime': 4.501534700393677, 'eval/precision_macro': 0.2774714052287582, 'test/recall_weighted': 0.2803738317757009, '_step': 20, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.2803738317757009, 'test/precision_micro': 0.2803738317757009, 'eval/f1_macro': 0.30499860763018655, 'eval/loss': 1.3061459338929, 'test/loss': 1.3991031125067863, 'eval/accuracy': 0.35714285714285715, 'eval/recall_weighted': 0.35714285714285715, 'test/recall_macro': 0.2865242165242165, 'test/recall_micro': 0.2803738317757009, 'eval/precision_micro': 0.35714285714285715, 'eval/precision_weighted': 0.2801023187052599, 'split': 10, 'eval/f1_weighted': 0.30949728819403005, 'test/f1_weighted': 0.2382000906609569, 'eval/recall_micro': 0.35714285714285715, 'eval/f1_micro': 0.35714285714285715, 'test/f1_macro': 0.243266253869969, 'test/precision_macro': 0.212696158008658, 'test/accuracy': 0.2803738317757009}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 84, 'dt_min_samples_leaf': 100}",solar-durian-976,DecisionTree,"['TfIdf', 'preprocessed']"
362,"{'test/recall_macro': 0.3334625723738627, 'test/precision_weighted': 0.36431855664950774, '_wandb': {'runtime': 2}, 'test/loss': 1.3774077476942146, 'test/f1_micro': 0.34579439252336447, 'eval/recall_micro': 0.3333333333333333, 'eval/f1_micro': 0.3333333333333333, 'test/recall_micro': 0.34579439252336447, '_timestamp': 1704570942.5255651, 'eval/f1_macro': 0.3342674868990658, 'test/precision_macro': 0.35715240641711227, 'eval/precision_weighted': 0.37776221599751014, 'test/precision_micro': 0.34579439252336447, '_runtime': 3.5554232597351074, 'eval/loss': 1.391304034795851, 'test/accuracy': 0.34579439252336447, 'eval/recall_weighted': 0.3333333333333333, 'test/recall_weighted': 0.34579439252336447, '_step': 20, 'test/f1_macro': 0.3275896252007228, 'eval/f1_weighted': 0.3315019149605616, 'eval/precision_macro': 0.37826797385620914, 'split': 10, 'eval/accuracy': 0.3333333333333333, 'eval/precision_micro': 0.3333333333333333, 'test/f1_weighted': 0.3375866697924407, 'eval/recall_macro': 0.3363636363636364}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 90, 'dt_min_samples_leaf': 41}",major-firebrand-975,DecisionTree,"['BoW', 'preprocessed']"
363,"{'_runtime': 3.851537942886353, 'test/f1_macro': 0.5098370927318295, 'eval/f1_weighted': 0.40155430593289954, 'eval/f1_macro': 0.4037372843874392, '_wandb': {'runtime': 2}, 'eval/loss': 3.552942159806166, 'eval/accuracy': 0.4047619047619048, 'eval/recall_macro': 0.40909090909090906, 'eval/precision_weighted': 0.430035903250189, '_step': 20, 'test/loss': 2.5131720943720373, 'eval/f1_micro': 0.4047619047619048, 'test/f1_weighted': 0.5114210760546225, 'test/recall_macro': 0.5149135474997544, 'test/recall_micro': 0.514018691588785, 'eval/recall_weighted': 0.4047619047619048, 'test/accuracy': 0.514018691588785, 'eval/recall_micro': 0.4047619047619048, 'eval/precision_macro': 0.43105158730158727, 'eval/precision_micro': 0.4047619047619048, 'test/f1_micro': 0.514018691588785, 'split': 10, '_timestamp': 1704570938.373635, 'test/precision_macro': 0.5347085385878488, 'test/precision_micro': 0.514018691588785, 'test/recall_weighted': 0.514018691588785, 'test/precision_weighted': 0.5384305510796004}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 83, 'dt_min_samples_leaf': 7}",dry-bird-974,DecisionTree,"['TfIdf', 'preprocessed']"
364,"{'_step': 20, 'split': 10, 'eval/precision_micro': 0.35714285714285715, 'eval/f1_macro': 0.3417941405237231, 'test/recall_micro': 0.4205607476635514, 'test/precision_macro': 0.3914695945945946, '_runtime': 3.6525745391845703, 'eval/recall_micro': 0.35714285714285715, 'test/precision_micro': 0.4205607476635514, 'eval/precision_weighted': 0.3668546365914787, '_timestamp': 1704570931.3140404, 'eval/recall_macro': 0.35909090909090907, 'test/recall_weighted': 0.4205607476635514, 'eval/loss': 1.443315568366891, 'eval/accuracy': 0.35714285714285715, 'test/recall_macro': 0.4110318444995864, 'eval/precision_macro': 0.36644736842105263, 'test/loss': 1.3877434012967198, 'eval/f1_micro': 0.35714285714285715, 'test/f1_macro': 0.386001585955656, 'eval/f1_weighted': 0.3418686288792589, '_wandb': {'runtime': 2}, 'test/accuracy': 0.4205607476635514, 'test/f1_micro': 0.4205607476635514, 'test/f1_weighted': 0.3958241246058959, 'eval/recall_weighted': 0.35714285714285715, 'test/precision_weighted': 0.39918540035362465}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 89, 'dt_min_samples_leaf': 31}",apricot-darkness-973,DecisionTree,"['BoW', 'preprocessed']"
365,"{'eval/f1_micro': 0.6428571428571429, 'test/f1_micro': 0.7476635514018691, 'test/f1_weighted': 0.7460881156334369, 'test/precision_macro': 0.7537037037037038, 'test/precision_weighted': 0.7491173416407061, '_timestamp': 1704570931.7566223, 'eval/recall_macro': 0.6431818181818182, 'eval/recall_micro': 0.6428571428571429, 'eval/precision_macro': 0.65625, '_wandb': {'runtime': 4}, 'eval/loss': 1.0877478509059406, 'eval/accuracy': 0.6428571428571429, '_step': 20, 'test/recall_macro': 0.7518241167434715, 'eval/precision_micro': 0.6428571428571429, 'test/recall_weighted': 0.7476635514018691, 'test/f1_macro': 0.750246118283893, 'test/precision_micro': 0.7476635514018691, '_runtime': 4.769140243530273, 'test/loss': 1.0233193406300236, 'test/accuracy': 0.7476635514018691, 'eval/precision_weighted': 0.6577380952380952, 'eval/recall_weighted': 0.6428571428571429, 'split': 10, 'eval/f1_macro': 0.6397311212814645, 'eval/f1_weighted': 0.6404326032472486, 'test/recall_micro': 0.7476635514018691}",{'trial.number': 0},celestial-puddle-972,LogisticRegression,"['TfIdf', 'preprocessed']"
366,"{'eval/f1_micro': 0.4523809523809524, 'eval/f1_macro': 0.4547619047619048, 'test/recall_micro': 0.45794392523364486, 'test/loss': 4.935375711398629, 'eval/f1_weighted': 0.44982993197278903, 'eval/recall_macro': 0.45681818181818185, 'split': 10, '_wandb': {'runtime': 2}, '_runtime': 5.113342046737671, 'eval/accuracy': 0.4523809523809524, 'test/f1_macro': 0.45133415435139573, 'test/f1_weighted': 0.4503567975691727, 'eval/loss': 5.96269960509039, 'test/recall_macro': 0.46291138618724825, 'eval/precision_micro': 0.4523809523809524, 'test/precision_micro': 0.45794392523364486, 'test/precision_weighted': 0.5062022090059473, '_step': 20, 'eval/recall_micro': 0.4523809523809524, 'eval/precision_macro': 0.49615384615384617, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_macro': 0.49924242424242427, 'test/f1_micro': 0.45794392523364486, 'eval/precision_weighted': 0.4888278388278388, '_timestamp': 1704570928.2551022, 'test/accuracy': 0.45794392523364486, 'test/recall_weighted': 0.45794392523364486}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 82, 'dt_min_samples_leaf': 6}",leafy-morning-971,DecisionTree,"['TfIdf', 'preprocessed']"
367,"{'test/loss': 1.3810715903995736, 'eval/f1_micro': 0.2619047619047619, 'test/accuracy': 0.40186915887850466, 'eval/precision_weighted': 0.24652777777777776, '_wandb': {'runtime': 2}, 'eval/recall_macro': 0.2590909090909091, 'test/recall_micro': 0.40186915887850466, 'test/recall_weighted': 0.40186915887850466, 'test/precision_weighted': 0.38040350096424863, 'eval/loss': 1.4971431044040262, 'eval/accuracy': 0.2619047619047619, 'eval/f1_macro': 0.24465598972177915, 'eval/f1_weighted': 0.24683657797692884, 'test/precision_micro': 0.40186915887850466, '_step': 20, 'test/f1_macro': 0.3684119420006517, 'eval/precision_micro': 0.2619047619047619, '_runtime': 3.6876626014709473, 'test/f1_micro': 0.40186915887850466, 'eval/precision_macro': 0.24479166666666663, 'eval/recall_weighted': 0.2619047619047619, 'split': 10, '_timestamp': 1704570921.1043663, 'eval/recall_micro': 0.2619047619047619, 'test/recall_macro': 0.39025020678246486, 'test/precision_macro': 0.3742063492063492, 'test/f1_weighted': 0.3784026578720579}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 88, 'dt_min_samples_leaf': 35}",flowing-smoke-970,DecisionTree,"['BoW', 'preprocessed']"
368,"{'eval/recall_weighted': 0.5238095238095238, '_step': 20, 'split': 10, 'test/f1_macro': 0.5637342462421367, 'test/f1_micro': 0.5607476635514018, 'test/precision_macro': 0.5738717998955067, 'test/recall_weighted': 0.5607476635514018, 'test/loss': 3.178004079436703, 'eval/accuracy': 0.5238095238095238, 'eval/f1_macro': 0.5236526758265889, 'eval/f1_weighted': 0.5202094891535886, 'eval/recall_macro': 0.5272727272727273, 'eval/f1_micro': 0.5238095238095238, 'test/f1_weighted': 0.5649633695344952, 'eval/recall_micro': 0.5238095238095238, 'eval/precision_macro': 0.5270833333333333, 'eval/precision_weighted': 0.5234126984126984, 'test/recall_macro': 0.560338441890166, 'test/recall_micro': 0.5607476635514018, '_wandb': {'runtime': 2}, 'eval/loss': 4.280803359634719, 'test/accuracy': 0.5607476635514018, 'test/precision_micro': 0.5607476635514018, '_runtime': 3.497694969177246, '_timestamp': 1704570915.368878, 'eval/precision_micro': 0.5238095238095238, 'test/precision_weighted': 0.5760047705543998}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 81, 'dt_min_samples_leaf': 6}",icy-darkness-969,DecisionTree,"['TfIdf', 'preprocessed']"
369,"{'_wandb': {'runtime': 2}, 'test/loss': 1.3877434012967198, 'eval/recall_weighted': 0.35714285714285715, 'eval/precision_weighted': 0.3668546365914787, 'eval/recall_micro': 0.35714285714285715, 'test/precision_macro': 0.3914695945945946, 'test/precision_micro': 0.4205607476635514, 'test/f1_micro': 0.4205607476635514, 'eval/f1_weighted': 0.3418686288792589, 'eval/recall_macro': 0.35909090909090907, 'eval/precision_macro': 0.36644736842105263, 'eval/precision_micro': 0.35714285714285715, '_runtime': 3.744046449661255, 'eval/loss': 1.443315568366891, 'eval/f1_macro': 0.3417941405237231, 'test/accuracy': 0.4205607476635514, 'test/f1_weighted': 0.3958241246058959, 'test/recall_macro': 0.4110318444995864, 'split': 10, 'eval/accuracy': 0.35714285714285715, 'test/f1_macro': 0.386001585955656, 'test/recall_micro': 0.4205607476635514, 'test/precision_weighted': 0.39918540035362465, 'test/recall_weighted': 0.4205607476635514, '_step': 20, '_timestamp': 1704570910.9542904, 'eval/f1_micro': 0.35714285714285715}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 87, 'dt_min_samples_leaf': 27}",curious-sound-968,DecisionTree,"['BoW', 'preprocessed']"
370,"{'eval/loss': 2.6358429828777092, 'test/recall_micro': 0.5046728971962616, 'eval/precision_weighted': 0.532312925170068, 'test/f1_weighted': 0.5039230029884235, 'eval/recall_macro': 0.5045454545454545, 'eval/precision_micro': 0.5, '_runtime': 3.575453042984009, 'eval/f1_macro': 0.4713562753036437, 'test/f1_macro': 0.49550719550719546, 'test/f1_micro': 0.5046728971962616, 'eval/f1_weighted': 0.46447850395218826, '_wandb': {'runtime': 2}, 'eval/f1_micro': 0.5, '_step': 20, 'eval/precision_macro': 0.5369047619047619, 'test/loss': 3.256355001939101, 'test/accuracy': 0.5046728971962616, 'eval/recall_micro': 0.5, 'eval/recall_weighted': 0.5, 'split': 10, 'test/precision_macro': 0.5488607859531773, 'test/recall_macro': 0.4969127615679339, '_timestamp': 1704570905.164354, 'eval/accuracy': 0.5, 'test/precision_micro': 0.5046728971962616, 'test/recall_weighted': 0.5046728971962616, 'test/precision_weighted': 0.5553832088269309}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 80, 'dt_min_samples_leaf': 5}",peach-rain-967,DecisionTree,"['TfIdf', 'preprocessed']"
371,"{'eval/recall_micro': 0.2619047619047619, 'eval/precision_micro': 0.2619047619047619, 'eval/recall_weighted': 0.2619047619047619, 'test/recall_weighted': 0.40186915887850466, 'eval/recall_macro': 0.2590909090909091, 'test/accuracy': 0.40186915887850466, 'test/recall_micro': 0.40186915887850466, 'eval/precision_macro': 0.24479166666666663, '_wandb': {'runtime': 2}, 'test/precision_macro': 0.3742063492063492, 'eval/loss': 1.4971431044040262, 'eval/accuracy': 0.2619047619047619, 'test/precision_micro': 0.40186915887850466, '_step': 20, 'eval/f1_weighted': 0.24683657797692884, 'test/f1_weighted': 0.3784026578720579, 'test/f1_micro': 0.40186915887850466, 'eval/f1_macro': 0.24465598972177915, 'test/precision_weighted': 0.38040350096424863, 'split': 10, 'test/loss': 1.3810715903995736, '_timestamp': 1704570902.4684527, 'eval/f1_micro': 0.2619047619047619, '_runtime': 3.4820806980133057, 'test/recall_macro': 0.39025020678246486, 'eval/precision_weighted': 0.24652777777777776, 'test/f1_macro': 0.3684119420006517}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 86, 'dt_min_samples_leaf': 38}",bright-bush-966,DecisionTree,"['BoW', 'preprocessed']"
372,"{'test/precision_macro': 0.4249521312021312, 'test/precision_micro': 0.4205607476635514, 'eval/loss': 2.1415035604944843, 'test/loss': 1.502117946409655, 'test/recall_weighted': 0.4205607476635514, 'test/precision_weighted': 0.4264905655092571, 'eval/f1_micro': 0.35714285714285715, 'test/f1_micro': 0.4205607476635514, 'test/recall_macro': 0.4221210335003438, 'eval/precision_weighted': 0.33582766439909295, 'eval/accuracy': 0.35714285714285715, 'eval/recall_macro': 0.36136363636363633, 'eval/recall_weighted': 0.35714285714285715, 'test/f1_weighted': 0.41929631665750416, '_runtime': 4.524284601211548, 'eval/f1_macro': 0.3399621212121212, 'test/f1_macro': 0.41911764705882354, 'eval/f1_weighted': 0.3375721500721501, 'eval/precision_micro': 0.35714285714285715, '_step': 20, 'split': 10, 'test/accuracy': 0.4205607476635514, 'eval/precision_macro': 0.33625541125541125, '_timestamp': 1704570894.632871, '_wandb': {'runtime': 2}, 'eval/recall_micro': 0.35714285714285715, 'test/recall_micro': 0.4205607476635514}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 79, 'dt_min_samples_leaf': 17}",super-energy-965,DecisionTree,"['TfIdf', 'preprocessed']"
373,"{'test/precision_weighted': 0.3556767047421253, '_wandb': {'runtime': 2}, 'test/loss': 1.5091066440889702, 'split': 10, 'test/f1_weighted': 0.32519078229711273, 'test/precision_micro': 0.3177570093457944, '_timestamp': 1704570892.333916, 'eval/f1_micro': 0.30952380952380953, 'test/f1_macro': 0.32249742199624276, 'test/recall_macro': 0.3186259305210918, 'test/precision_macro': 0.3502314814814815, 'eval/accuracy': 0.30952380952380953, 'test/f1_micro': 0.3177570093457944, 'test/recall_micro': 0.3177570093457944, 'test/recall_weighted': 0.3177570093457944, '_step': 20, 'eval/f1_macro': 0.3163919413919414, 'eval/f1_weighted': 0.31595150880865164, 'eval/recall_weighted': 0.30952380952380953, 'eval/precision_weighted': 0.41228991596638653, 'eval/precision_macro': 0.4097426470588236, 'eval/precision_micro': 0.30952380952380953, '_runtime': 3.626317024230957, 'eval/loss': 1.3979745349856256, 'test/accuracy': 0.3177570093457944, 'eval/recall_macro': 0.31136363636363634, 'eval/recall_micro': 0.30952380952380953}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 85, 'dt_min_samples_leaf': 24}",solar-wildflower-964,DecisionTree,"['BoW', 'preprocessed']"
374,"{'eval/precision_weighted': 0.24652777777777776, 'test/f1_micro': 0.40186915887850466, 'test/recall_macro': 0.39025020678246486, 'test/recall_micro': 0.40186915887850466, 'eval/recall_weighted': 0.2619047619047619, 'test/precision_macro': 0.3742063492063492, 'test/precision_micro': 0.40186915887850466, 'test/precision_weighted': 0.38040350096424863, 'eval/accuracy': 0.2619047619047619, 'test/f1_weighted': 0.3784026578720579, 'eval/loss': 1.4971431044040262, '_runtime': 3.0553536415100098, 'eval/f1_weighted': 0.24683657797692884, 'eval/recall_macro': 0.2590909090909091, '_timestamp': 1704570884.536615, 'eval/f1_macro': 0.24465598972177915, 'test/accuracy': 0.40186915887850466, 'eval/recall_micro': 0.2619047619047619, 'split': 10, 'test/f1_macro': 0.3684119420006517, '_step': 20, 'test/loss': 1.3810715903995736, 'eval/f1_micro': 0.2619047619047619, 'eval/precision_macro': 0.24479166666666663, 'eval/precision_micro': 0.2619047619047619, 'test/recall_weighted': 0.40186915887850466, '_wandb': {'runtime': 1}}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 84, 'dt_min_samples_leaf': 33}",earthy-vortex-963,DecisionTree,"['BoW', 'preprocessed']"
375,"{'test/loss': 3.615923432745155, 'test/f1_macro': 0.4852530905814105, 'test/recall_weighted': 0.4766355140186916, 'test/precision_weighted': 0.565472263365855, '_runtime': 3.9536287784576416, 'eval/loss': 5.212326893956695, 'eval/f1_macro': 0.3806299557440531, 'eval/precision_macro': 0.4097222222222222, 'eval/recall_weighted': 0.380952380952381, 'test/precision_macro': 0.5607955430886707, 'eval/precision_weighted': 0.4034391534391534, '_wandb': {'runtime': 2}, 'test/accuracy': 0.4766355140186916, 'eval/precision_micro': 0.380952380952381, 'test/precision_micro': 0.4766355140186916, 'eval/recall_macro': 0.3863636363636363, 'eval/recall_micro': 0.380952380952381, '_step': 20, '_timestamp': 1704570882.7336357, 'eval/accuracy': 0.380952380952381, 'test/f1_weighted': 0.4894658613880232, 'test/recall_micro': 0.4766355140186916, 'test/recall_macro': 0.473837803320562, 'split': 10, 'eval/f1_micro': 0.380952380952381, 'test/f1_micro': 0.4766355140186916, 'eval/f1_weighted': 0.3746751051517786}","{'dt_criterion': 'gini', 'dt_max_depth': 17, 'trial.number': 78, 'dt_min_samples_leaf': 6}",pleasant-gorge-962,DecisionTree,"['TfIdf', 'preprocessed']"
376,"{'split': 10, 'eval/recall_micro': 0.35714285714285715, 'eval/precision_micro': 0.35714285714285715, 'test/precision_micro': 0.4205607476635514, '_runtime': 3.3506321907043457, 'eval/loss': 1.443315568366891, 'eval/accuracy': 0.35714285714285715, 'test/accuracy': 0.4205607476635514, 'test/f1_macro': 0.386001585955656, 'eval/recall_macro': 0.35909090909090907, 'eval/f1_weighted': 0.3418686288792589, 'test/f1_weighted': 0.3958241246058959, 'test/recall_micro': 0.4205607476635514, 'test/precision_macro': 0.3914695945945946, 'eval/precision_weighted': 0.3668546365914787, 'test/f1_micro': 0.4205607476635514, 'test/precision_weighted': 0.39918540035362465, '_wandb': {'runtime': 2}, '_timestamp': 1704570874.651642, 'eval/f1_macro': 0.3417941405237231, 'test/recall_macro': 0.4110318444995864, 'test/loss': 1.3877434012967198, 'eval/precision_macro': 0.36644736842105263, 'test/recall_weighted': 0.4205607476635514, '_step': 20, 'eval/f1_micro': 0.35714285714285715, 'eval/recall_weighted': 0.35714285714285715}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 83, 'dt_min_samples_leaf': 29}",happy-valley-961,DecisionTree,"['BoW', 'preprocessed']"
377,"{'test/loss': 4.8070600492156474, 'eval/recall_micro': 0.4523809523809524, 'test/recall_weighted': 0.5046728971962616, 'eval/precision_weighted': 0.45242541461028857, 'eval/accuracy': 0.4523809523809524, 'eval/f1_macro': 0.44076735957540913, 'eval/f1_micro': 0.4523809523809524, 'eval/recall_weighted': 0.4523809523809524, 'test/f1_macro': 0.5093012704174229, 'test/precision_macro': 0.531351461038961, 'test/precision_micro': 0.5046728971962616, 'test/recall_macro': 0.503432066018273, 'test/recall_micro': 0.5046728971962616, 'test/f1_micro': 0.5046728971962616, 'eval/recall_macro': 0.45, '_step': 20, '_timestamp': 1704570874.1564653, 'test/accuracy': 0.5046728971962616, 'test/precision_weighted': 0.539370676052919, 'eval/loss': 5.161694351909004, 'test/f1_weighted': 0.5137953649835191, 'eval/precision_macro': 0.4549486461251167, 'eval/precision_micro': 0.4523809523809524, 'split': 10, '_wandb': {'runtime': 2}, '_runtime': 3.870941400527954, 'eval/f1_weighted': 0.4405267370105937}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 77, 'dt_min_samples_leaf': 8}",genial-plant-959,DecisionTree,"['TfIdf', 'preprocessed']"
378,"{'_step': 0, 'split': 1, '_runtime': 1.8535497188568115, '_timestamp': 1704570871.897889}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 0, 'dt_min_samples_leaf': 25}",northern-thunder-960,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
379,"{'_step': 20, 'test/loss': 1.4073623847905286, 'test/accuracy': 0.38317757009345793, 'test/precision_micro': 0.38317757009345793, 'test/f1_macro': 0.3675263928481099, 'test/f1_micro': 0.383177570093458, 'test/recall_micro': 0.38317757009345793, 'test/precision_macro': 0.364375, 'eval/recall_micro': 0.3333333333333333, 'test/recall_weighted': 0.38317757009345793, '_wandb': {'runtime': 2}, 'test/f1_weighted': 0.3768049054767262, '_runtime': 3.475959062576294, 'eval/accuracy': 0.3333333333333333, 'eval/recall_weighted': 0.3333333333333333, 'eval/loss': 1.5105946539436068, '_timestamp': 1704570866.578943, 'eval/recall_macro': 0.3340909090909091, 'split': 10, 'eval/f1_macro': 0.3259259259259259, 'eval/precision_micro': 0.3333333333333333, 'eval/precision_weighted': 0.34859943977591035, 'eval/f1_micro': 0.3333333333333333, 'eval/f1_weighted': 0.326278659611993, 'test/recall_macro': 0.37417287014061207, 'eval/precision_macro': 0.34852941176470587, 'test/precision_weighted': 0.373785046728972}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 82, 'dt_min_samples_leaf': 26}",efficient-universe-958,DecisionTree,"['BoW', 'preprocessed']"
380,"{'test/f1_micro': 0.35514018691588783, 'eval/f1_weighted': 0.25939114648792067, 'test/precision_micro': 0.35514018691588783, 'eval/precision_weighted': 0.22936507936507936, '_runtime': 3.3466362953186035, 'eval/loss': 1.3025318387784075, 'test/recall_micro': 0.35514018691588783, 'test/recall_macro': 0.35169859514687096, 'eval/recall_weighted': 0.30952380952380953, 'test/precision_macro': 0.2752279981760146, '_step': 20, 'eval/accuracy': 0.30952380952380953, 'test/f1_weighted': 0.31085363489736095, 'eval/f1_micro': 0.30952380952380953, 'eval/precision_micro': 0.30952380952380953, '_wandb': {'runtime': 1}, 'test/f1_macro': 0.305805942827256, 'test/recall_weighted': 0.35514018691588783, 'eval/recall_macro': 0.3113636363636364, 'eval/recall_micro': 0.30952380952380953, 'eval/precision_macro': 0.23333333333333336, '_timestamp': 1704570864.3344944, 'eval/f1_macro': 0.26268328445747796, 'test/precision_weighted': 0.2811183417074719, 'split': 10, 'test/loss': 1.3321876798378665, 'test/accuracy': 0.35514018691588783}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 76, 'dt_min_samples_leaf': 56}",fragrant-pyramid-957,DecisionTree,"['TfIdf', 'preprocessed']"
381,"{'split': 10, '_wandb': {'runtime': 2}, 'eval/f1_weighted': 0.3418686288792589, '_runtime': 3.704458236694336, 'test/recall_micro': 0.4205607476635514, 'test/loss': 1.3877434012967198, 'eval/f1_macro': 0.3417941405237231, 'test/recall_weighted': 0.4205607476635514, 'eval/precision_weighted': 0.3668546365914787, '_step': 20, 'test/f1_macro': 0.386001585955656, 'test/precision_macro': 0.3914695945945946, 'test/f1_weighted': 0.3958241246058959, 'eval/recall_micro': 0.35714285714285715, 'test/precision_micro': 0.4205607476635514, 'test/precision_weighted': 0.39918540035362465, 'eval/loss': 1.443315568366891, '_timestamp': 1704570856.557439, 'eval/precision_macro': 0.36644736842105263, 'eval/recall_weighted': 0.35714285714285715, 'eval/f1_micro': 0.35714285714285715, 'test/f1_micro': 0.4205607476635514, 'eval/precision_micro': 0.35714285714285715, 'eval/accuracy': 0.35714285714285715, 'test/accuracy': 0.4205607476635514, 'eval/recall_macro': 0.35909090909090907, 'test/recall_macro': 0.4110318444995864}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 81, 'dt_min_samples_leaf': 30}",glowing-bush-956,DecisionTree,"['BoW', 'preprocessed']"
382,"{'eval/precision_micro': 0.30952380952380953, '_runtime': 3.2663772106170654, 'test/loss': 1.3000630277496037, 'eval/f1_macro': 0.30952380952380953, 'eval/f1_micro': 0.30952380952380953, 'test/f1_macro': 0.3712475929867234, 'test/recall_macro': 0.3777576382748796, 'test/accuracy': 0.38317757009345793, 'eval/recall_macro': 0.3159090909090909, 'test/precision_micro': 0.38317757009345793, 'eval/loss': 1.487251856516432, 'test/f1_micro': 0.383177570093458, 'split': 10, '_timestamp': 1704570855.026153, 'test/f1_weighted': 0.3750818597628837, 'eval/recall_micro': 0.30952380952380953, '_step': 20, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.30952380952380953, 'eval/precision_macro': 0.30454545454545456, 'test/precision_weighted': 0.3720999980650529, 'test/recall_micro': 0.38317757009345793, 'test/precision_macro': 0.3696946169772257, 'test/recall_weighted': 0.38317757009345793, 'eval/precision_weighted': 0.2995670995670996, 'eval/f1_weighted': 0.30385487528344673, 'eval/recall_weighted': 0.30952380952380953}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 75, 'dt_min_samples_leaf': 26}",polished-forest-955,DecisionTree,"['TfIdf', 'preprocessed']"
383,"{'eval/accuracy': 0.16666666666666666, 'eval/recall_micro': 0.16666666666666666, 'eval/precision_micro': 0.16666666666666666, 'test/precision_macro': 0.3351948051948052, '_wandb': {'runtime': 2}, '_runtime': 3.437321186065674, 'eval/loss': 1.503538124733836, 'split': 10, 'test/f1_macro': 0.3343973953217651, 'test/f1_weighted': 0.3431007067227911, 'test/recall_macro': 0.33576302729528534, 'eval/precision_macro': 0.16488095238095238, 'eval/recall_weighted': 0.16666666666666666, 'test/precision_micro': 0.34579439252336447, 'eval/f1_micro': 0.16666666666666666, 'test/f1_micro': 0.34579439252336447, 'test/recall_weighted': 0.34579439252336447, 'eval/precision_weighted': 0.1653628117913832, '_step': 20, 'test/accuracy': 0.34579439252336447, 'test/recall_micro': 0.34579439252336447, '_timestamp': 1704570848.0960712, 'test/loss': 1.4036204161034715, 'eval/f1_macro': 0.1619435817805383, 'eval/f1_weighted': 0.16271073646850043, 'eval/recall_macro': 0.1659090909090909, 'test/precision_weighted': 0.3426726544483554}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 80, 'dt_min_samples_leaf': 36}",noble-yogurt-954,DecisionTree,"['BoW', 'preprocessed']"
384,"{'test/f1_weighted': 0.537236059048935, 'eval/f1_weighted': 0.4988278777752462, 'test/f1_micro': 0.5327102803738317, 'eval/precision_macro': 0.5163690476190477, 'eval/f1_macro': 0.5032429558745348, 'eval/loss': 4.260166061350067, '_step': 20, 'test/precision_weighted': 0.5541284729710192, 'test/precision_macro': 0.5508123757670037, 'eval/recall_weighted': 0.5, 'test/precision_micro': 0.5327102803738317, 'eval/f1_micro': 0.5, 'test/loss': 3.234043880558631, 'test/recall_macro': 0.530338441890166, 'test/recall_weighted': 0.5327102803738317, 'split': 10, 'test/accuracy': 0.5327102803738317, 'eval/recall_macro': 0.5045454545454545, 'eval/recall_micro': 0.5, 'test/recall_micro': 0.5327102803738317, 'eval/precision_micro': 0.5, 'eval/accuracy': 0.5, '_runtime': 3.6774821281433105, '_timestamp': 1704570845.181365, 'test/f1_macro': 0.5342864875613097, 'eval/precision_weighted': 0.51218820861678, '_wandb': {'runtime': 2}}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 74, 'dt_min_samples_leaf': 6}",dutiful-aardvark-953,DecisionTree,"['TfIdf', 'preprocessed']"
385,"{'_step': 20, 'split': 10, 'eval/f1_macro': 0.29508847549909256, 'test/accuracy': 0.3925233644859813, 'eval/recall_weighted': 0.30952380952380953, 'test/precision_macro': 0.3644689987431923, 'eval/recall_micro': 0.30952380952380953, 'test/recall_macro': 0.3806348221670802, 'test/recall_weighted': 0.3925233644859813, 'eval/accuracy': 0.30952380952380953, 'test/precision_micro': 0.3925233644859813, 'eval/precision_weighted': 0.31331801726538566, 'eval/f1_micro': 0.30952380952380953, 'test/f1_macro': 0.35942019436109535, 'test/loss': 1.3874414581781045, 'eval/precision_micro': 0.30952380952380953, 'test/precision_weighted': 0.3709391603271616, '_wandb': {'runtime': 2}, '_runtime': 3.5724501609802246, 'test/f1_micro': 0.3925233644859813, 'eval/loss': 1.4902192291909484, '_timestamp': 1704570838.009452, 'eval/f1_weighted': 0.2979539365655518, 'eval/recall_macro': 0.30909090909090914, 'eval/precision_macro': 0.3088450292397661, 'test/f1_weighted': 0.36966301530650786, 'test/recall_micro': 0.3925233644859813}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 79, 'dt_min_samples_leaf': 32}",true-meadow-952,DecisionTree,"['BoW', 'preprocessed']"
386,"{'_timestamp': 1704570834.804478, 'eval/f1_weighted': 0.40155430593289954, 'test/recall_micro': 0.5327102803738317, '_step': 20, '_wandb': {'runtime': 2}, '_runtime': 3.511612892150879, 'test/precision_micro': 0.5327102803738317, 'test/f1_micro': 0.5327102803738317, 'test/precision_macro': 0.5502472527472527, 'test/recall_weighted': 0.5327102803738317, 'test/loss': 2.5288674018155337, 'eval/accuracy': 0.4047619047619048, 'eval/f1_macro': 0.4037372843874392, 'test/f1_macro': 0.5244510633200649, 'test/accuracy': 0.5327102803738317, 'test/recall_macro': 0.5349135474997544, 'eval/precision_weighted': 0.430035903250189, 'split': 10, 'eval/recall_macro': 0.40909090909090906, 'eval/recall_micro': 0.4047619047619048, 'test/precision_weighted': 0.5535199068843929, 'eval/precision_micro': 0.4047619047619048, 'eval/recall_weighted': 0.4047619047619048, 'eval/loss': 3.532016582380121, 'eval/f1_micro': 0.4047619047619048, 'test/f1_weighted': 0.5253721938849322, 'eval/precision_macro': 0.43105158730158727}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 73, 'dt_min_samples_leaf': 7}",morning-firefly-951,DecisionTree,"['TfIdf', 'preprocessed']"
387,"{'eval/f1_macro': 0.3417941405237231, 'test/f1_micro': 0.4205607476635514, 'eval/recall_micro': 0.35714285714285715, 'eval/accuracy': 0.35714285714285715, 'eval/precision_weighted': 0.3668546365914787, 'test/f1_macro': 0.386001585955656, 'eval/f1_weighted': 0.3418686288792589, 'eval/recall_macro': 0.35909090909090907, 'test/recall_weighted': 0.4205607476635514, 'test/accuracy': 0.4205607476635514, '_timestamp': 1704570830.3461685, 'test/recall_macro': 0.4110318444995864, 'eval/recall_weighted': 0.35714285714285715, 'test/loss': 1.3877434012967198, 'test/precision_weighted': 0.39918540035362465, 'test/f1_weighted': 0.3958241246058959, 'split': 10, '_runtime': 4.5589635372161865, 'eval/f1_micro': 0.35714285714285715, 'eval/precision_macro': 0.36644736842105263, 'test/precision_macro': 0.3914695945945946, '_step': 20, 'eval/loss': 1.443315568366891, 'test/recall_micro': 0.4205607476635514, 'eval/precision_micro': 0.35714285714285715, 'test/precision_micro': 0.4205607476635514, '_wandb': {'runtime': 1}}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 78, 'dt_min_samples_leaf': 28}",amber-dust-950,DecisionTree,"['BoW', 'preprocessed']"
388,"{'test/f1_macro': 0.46660208534513314, 'test/accuracy': 0.4766355140186916, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.4523809523809524, 'test/recall_weighted': 0.4766355140186916, '_step': 20, 'test/f1_micro': 0.4766355140186916, 'test/recall_macro': 0.4804352097455546, 'eval/recall_weighted': 0.4523809523809524, 'eval/precision_weighted': 0.48117913832199544, 'eval/f1_macro': 0.4442735042735043, 'test/loss': 5.135805316876665, 'eval/f1_micro': 0.4523809523809524, 'eval/f1_weighted': 0.43939763939763943, 'eval/recall_micro': 0.4523809523809524, 'split': 10, 'test/f1_weighted': 0.4664298411972359, 'test/recall_micro': 0.4766355140186916, 'eval/precision_micro': 0.4523809523809524, 'test/precision_macro': 0.4993506493506493, 'eval/loss': 6.66824748921872, '_timestamp': 1704570824.661765, 'eval/recall_macro': 0.45681818181818185, 'eval/precision_macro': 0.48809523809523814, 'test/precision_micro': 0.4766355140186916, 'test/precision_weighted': 0.5055860027822645, '_runtime': 3.594107151031494}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 72, 'dt_min_samples_leaf': 6}",noble-salad-949,DecisionTree,"['TfIdf', 'preprocessed']"
389,"{'eval/loss': 1.4485018228432194, 'eval/f1_micro': 0.2857142857142857, '_step': 20, '_runtime': 3.64985990524292, 'test/accuracy': 0.2897196261682243, 'eval/recall_micro': 0.2857142857142857, 'test/recall_macro': 0.2889784946236559, 'test/recall_micro': 0.2897196261682243, 'eval/accuracy': 0.2857142857142857, 'eval/f1_macro': 0.28305860805860805, 'test/f1_macro': 0.2902063321106761, 'eval/f1_weighted': 0.28103087388801673, 'test/f1_weighted': 0.2943149892500526, 'eval/precision_weighted': 0.34681372549019607, 'test/recall_weighted': 0.2897196261682243, 'test/precision_weighted': 0.3154855599880339, 'split': 10, 'test/f1_micro': 0.2897196261682243, '_wandb': {'runtime': 2}, 'test/loss': 1.5121729768379368, '_timestamp': 1704570819.169479, 'eval/precision_micro': 0.2857142857142857, 'eval/recall_weighted': 0.2857142857142857, 'test/precision_macro': 0.30849882688117986, 'eval/recall_macro': 0.28863636363636364, 'eval/precision_macro': 0.3472426470588236, 'test/precision_micro': 0.2897196261682243}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 77, 'dt_min_samples_leaf': 23}",easy-gorge-948,DecisionTree,"['BoW', 'preprocessed']"
390,"{'_step': 20, 'split': 10, 'eval/accuracy': 0.42857142857142855, 'eval/precision_micro': 0.42857142857142855, 'eval/recall_weighted': 0.42857142857142855, 'test/loss': 2.8086864944341365, 'eval/recall_micro': 0.42857142857142855, 'eval/loss': 3.5291818093081977, 'eval/f1_weighted': 0.42912322823866383, 'test/f1_weighted': 0.5228372037596222, 'eval/precision_weighted': 0.4627739984882842, 'eval/f1_micro': 0.42857142857142855, 'test/recall_micro': 0.5233644859813084, 'test/precision_macro': 0.5476190476190476, 'test/precision_weighted': 0.5508455718736093, '_runtime': 3.8156120777130127, 'eval/f1_macro': 0.43005307386112335, 'test/recall_macro': 0.5233750859612928, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.5233644859813084, 'test/precision_micro': 0.5233644859813084, 'test/accuracy': 0.5233644859813084, 'test/f1_macro': 0.52121363969876, 'eval/recall_macro': 0.43181818181818177, 'eval/precision_macro': 0.46230158730158727, 'test/recall_weighted': 0.5233644859813084, '_timestamp': 1704570814.707142}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 71, 'dt_min_samples_leaf': 7}",divine-sun-947,DecisionTree,"['TfIdf', 'preprocessed']"
391,"{'_timestamp': 1704570808.8267646, 'test/recall_weighted': 0.34579439252336447, 'eval/f1_weighted': 0.20891255052745733, 'eval/recall_macro': 0.2113636363636363, 'test/recall_micro': 0.34579439252336447, 'eval/precision_macro': 0.2073135198135198, 'eval/precision_micro': 0.21428571428571427, 'eval/precision_weighted': 0.2088883338883339, 'eval/loss': 1.5029451888595386, 'test/loss': 1.4189368187198526, 'test/f1_macro': 0.3351544289044289, 'test/f1_weighted': 0.34410060344639787, 'test/recall_macro': 0.33576302729528534, 'split': 10, 'test/precision_macro': 0.3383116883116883, 'test/precision_micro': 0.34579439252336447, '_runtime': 3.4903886318206787, 'test/accuracy': 0.34579439252336447, 'eval/recall_weighted': 0.21428571428571427, 'test/precision_weighted': 0.3461827891734434, '_step': 20, 'test/f1_micro': 0.34579439252336447, 'eval/recall_micro': 0.21428571428571427, 'eval/accuracy': 0.21428571428571427, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.20658643892339543, 'eval/f1_micro': 0.21428571428571427}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 76, 'dt_min_samples_leaf': 39}",grateful-energy-946,DecisionTree,"['BoW', 'preprocessed']"
392,"{'eval/recall_weighted': 0.3333333333333333, '_step': 20, 'test/f1_micro': 0.48598130841121495, 'eval/recall_micro': 0.3333333333333333, 'test/precision_weighted': 0.4873668387687079, 'split': 10, '_timestamp': 1704570803.6610708, 'eval/precision_weighted': 0.34961863533292104, 'test/recall_micro': 0.48598130841121495, 'eval/precision_micro': 0.3333333333333333, 'test/precision_micro': 0.48598130841121495, '_wandb': {'runtime': 2}, 'eval/loss': 4.570330110401986, 'eval/accuracy': 0.3333333333333333, 'eval/f1_micro': 0.3333333333333333, 'test/f1_weighted': 0.4801854047711198, 'eval/recall_macro': 0.33636363636363636, 'eval/precision_macro': 0.34805194805194806, 'test/precision_macro': 0.4873543123543124, '_runtime': 4.03837776184082, 'test/accuracy': 0.48598130841121495, 'test/f1_macro': 0.48102485838420506, 'eval/f1_weighted': 0.33276643990929705, 'test/recall_weighted': 0.48598130841121495, 'eval/f1_macro': 0.3335714285714286, 'test/recall_macro': 0.4881348855486786, 'test/loss': 3.6768519826325528}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 70, 'dt_min_samples_leaf': 9}",helpful-wood-945,DecisionTree,"['TfIdf', 'preprocessed']"
393,"{'eval/loss': 1.443315568366891, 'test/recall_weighted': 0.4205607476635514, '_runtime': 3.600963592529297, 'test/f1_micro': 0.4205607476635514, 'eval/f1_macro': 0.3417941405237231, 'eval/f1_weighted': 0.3418686288792589, 'test/precision_micro': 0.4205607476635514, 'test/precision_weighted': 0.39918540035362465, '_wandb': {'runtime': 2}, 'test/f1_weighted': 0.3958241246058959, 'eval/recall_macro': 0.35909090909090907, 'eval/recall_weighted': 0.35714285714285715, 'test/precision_macro': 0.3914695945945946, '_step': 20, 'eval/accuracy': 0.35714285714285715, 'test/f1_macro': 0.386001585955656, 'eval/precision_micro': 0.35714285714285715, 'test/accuracy': 0.4205607476635514, 'eval/recall_micro': 0.35714285714285715, 'test/recall_macro': 0.4110318444995864, 'eval/precision_macro': 0.36644736842105263, 'eval/precision_weighted': 0.3668546365914787, 'split': 10, '_timestamp': 1704570797.4874935, 'test/recall_micro': 0.4205607476635514, 'test/loss': 1.3877434012967198, 'eval/f1_micro': 0.35714285714285715}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 75, 'dt_min_samples_leaf': 31}",dulcet-pond-944,DecisionTree,"['BoW', 'preprocessed']"
394,"{'eval/recall_micro': 0.4523809523809524, 'eval/precision_macro': 0.46050420168067224, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.4523809523809524, 'eval/f1_micro': 0.4523809523809524, 'test/f1_macro': 0.5110723236663086, 'eval/recall_macro': 0.45, 'test/recall_macro': 0.5044267609784852, 'test/precision_micro': 0.5046728971962616, '_step': 20, 'eval/loss': 5.193257917130515, 'eval/f1_macro': 0.4430438842203548, 'eval/recall_weighted': 0.4523809523809524, 'test/loss': 4.791693710520122, 'test/accuracy': 0.5046728971962616, 'eval/f1_weighted': 0.442354719665644, 'eval/precision_weighted': 0.45692276910764307, '_timestamp': 1704570791.9668367, 'test/recall_micro': 0.5046728971962616, 'test/recall_weighted': 0.5046728971962616, 'eval/precision_micro': 0.4523809523809524, 'test/f1_micro': 0.5046728971962616, 'test/precision_macro': 0.5404674369747899, 'split': 10, '_runtime': 4.904730796813965, 'test/f1_weighted': 0.5151353015382247, 'test/precision_weighted': 0.5489957197832404}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 69, 'dt_min_samples_leaf': 8}",exalted-vortex-943,DecisionTree,"['TfIdf', 'preprocessed']"
395,"{'split': 10, 'eval/f1_micro': 0.30952380952380953, 'test/precision_macro': 0.37876157407407407, 'eval/precision_weighted': 0.35234093637454983, 'eval/precision_macro': 0.3521008403361344, 'eval/recall_weighted': 0.30952380952380953, '_timestamp': 1704570789.143605, 'eval/f1_macro': 0.3074945533769063, 'eval/recall_macro': 0.31136363636363634, 'eval/recall_micro': 0.30952380952380953, 'test/precision_weighted': 0.38741779162339907, 'eval/loss': 1.4429451519006609, 'test/f1_micro': 0.36448598130841114, 'test/f1_weighted': 0.3713207652287989, 'test/recall_macro': 0.35734594706368905, 'test/loss': 1.4364741492452922, 'test/accuracy': 0.3644859813084112, 'test/f1_macro': 0.36319524505806594, 'test/recall_micro': 0.3644859813084112, 'eval/precision_micro': 0.30952380952380953, 'test/recall_weighted': 0.3644859813084112, '_step': 20, '_runtime': 3.5313360691070557, 'eval/accuracy': 0.30952380952380953, 'eval/f1_weighted': 0.30696960265587714, '_wandb': {'runtime': 2}, 'test/precision_micro': 0.3644859813084112}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 74, 'dt_min_samples_leaf': 25}",neat-shape-942,DecisionTree,"['BoW', 'preprocessed']"
396,"{'test/f1_macro': 0.41440820058430894, 'test/recall_micro': 0.45794392523364486, 'eval/accuracy': 0.47619047619047616, 'test/accuracy': 0.45794392523364486, 'eval/recall_micro': 0.47619047619047616, 'eval/precision_micro': 0.47619047619047616, '_runtime': 3.668434858322144, '_timestamp': 1704570780.2394838, 'test/f1_micro': 0.45794392523364486, 'eval/recall_macro': 0.4772727272727273, 'test/precision_micro': 0.45794392523364486, '_step': 20, 'test/recall_macro': 0.46259111897042926, 'test/recall_weighted': 0.45794392523364486, 'eval/precision_weighted': 0.434065934065934, 'eval/loss': 4.347833122373697, 'eval/f1_micro': 0.47619047619047616, 'eval/f1_weighted': 0.4114114114114114, 'eval/recall_weighted': 0.47619047619047616, 'test/precision_macro': 0.4932216905901116, 'test/precision_weighted': 0.4993068908464875, '_wandb': {'runtime': 2}, 'test/loss': 2.0966419859226644, 'test/f1_weighted': 0.4172826295138804, 'split': 10, 'eval/f1_macro': 0.4184684684684684, 'eval/precision_macro': 0.4461538461538461}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 68, 'dt_min_samples_leaf': 5}",light-resonance-941,DecisionTree,"['TfIdf', 'preprocessed']"
397,"{'split': 10, 'eval/loss': 1.443315568366891, 'test/recall_macro': 0.4110318444995864, 'eval/f1_micro': 0.35714285714285715, 'eval/f1_weighted': 0.3418686288792589, 'eval/precision_micro': 0.35714285714285715, 'test/recall_weighted': 0.4205607476635514, '_runtime': 3.639368057250977, 'eval/recall_macro': 0.35909090909090907, 'test/precision_macro': 0.3914695945945946, 'eval/precision_weighted': 0.3668546365914787, '_step': 20, '_timestamp': 1704570778.9916031, 'eval/accuracy': 0.35714285714285715, 'test/f1_macro': 0.386001585955656, 'eval/recall_weighted': 0.35714285714285715, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.4205607476635514, 'eval/precision_macro': 0.36644736842105263, 'test/f1_weighted': 0.3958241246058959, 'eval/recall_micro': 0.35714285714285715, 'test/recall_micro': 0.4205607476635514, 'test/precision_micro': 0.4205607476635514, 'test/precision_weighted': 0.39918540035362465, 'test/loss': 1.3877434012967198, 'eval/f1_macro': 0.3417941405237231, 'test/accuracy': 0.4205607476635514}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 73, 'dt_min_samples_leaf': 28}",rural-rain-940,DecisionTree,"['BoW', 'preprocessed']"
398,"{'_timestamp': 1704570772.177641, 'test/f1_macro': 0.5110879190385832, 'test/recall_macro': 0.5023067098929168, 'test/precision_micro': 0.5046728971962616, '_runtime': 4.101614952087402, 'eval/f1_macro': 0.44901069518716574, 'eval/f1_micro': 0.4523809523809524, 'test/accuracy': 0.5046728971962616, 'eval/recall_macro': 0.4545454545454546, 'eval/recall_micro': 0.4523809523809524, 'split': 10, 'test/f1_weighted': 0.5159117321936312, 'eval/precision_micro': 0.4523809523809524, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_weighted': 0.5408886792470701, '_step': 20, 'eval/accuracy': 0.4523809523809524, 'eval/precision_macro': 0.4583333333333333, 'test/recall_weighted': 0.5046728971962616, 'eval/loss': 5.927855125780588, 'eval/f1_weighted': 0.44620066208301495, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.5046728971962616, 'test/precision_macro': 0.5332041147258538, 'test/loss': 3.570773912905647, 'test/recall_micro': 0.5046728971962616, 'eval/precision_weighted': 0.4546485260770975}","{'dt_criterion': 'gini', 'dt_max_depth': 16, 'trial.number': 67, 'dt_min_samples_leaf': 7}",true-plasma-939,DecisionTree,"['TfIdf', 'preprocessed']"
399,"{'test/recall_macro': 0.39025020678246486, 'eval/recall_weighted': 0.2619047619047619, 'test/precision_macro': 0.3742063492063492, 'test/loss': 1.3810715903995736, 'test/f1_micro': 0.40186915887850466, 'test/f1_weighted': 0.3784026578720579, 'eval/recall_micro': 0.2619047619047619, 'split': 10, '_runtime': 3.6483263969421382, 'eval/precision_macro': 0.24479166666666663, '_wandb': {'runtime': 2}, '_timestamp': 1704570767.6369624, 'test/recall_micro': 0.40186915887850466, 'test/precision_weighted': 0.38040350096424863, 'eval/f1_micro': 0.2619047619047619, 'test/f1_macro': 0.3684119420006517, 'test/precision_micro': 0.40186915887850466, 'test/recall_weighted': 0.40186915887850466, 'eval/loss': 1.4971431044040262, 'test/accuracy': 0.40186915887850466, 'eval/precision_weighted': 0.24652777777777776, '_step': 20, 'eval/recall_macro': 0.2590909090909091, 'eval/accuracy': 0.2619047619047619, 'eval/f1_weighted': 0.24683657797692884, 'eval/precision_micro': 0.2619047619047619, 'eval/f1_macro': 0.24465598972177915}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 72, 'dt_min_samples_leaf': 33}",graceful-jazz-938,DecisionTree,"['BoW', 'preprocessed']"
400,"{'_timestamp': 1704570761.774943, 'eval/f1_macro': 0.4436802232854864, 'eval/precision_macro': 0.4434974747474747, '_runtime': 3.8920681476593018, 'eval/accuracy': 0.4523809523809524, 'test/recall_micro': 0.514018691588785, '_step': 20, 'eval/recall_macro': 0.45681818181818185, 'test/precision_weighted': 0.5150709588092766, 'test/f1_macro': 0.5109313424024009, 'eval/f1_weighted': 0.4408939014202172, 'test/precision_macro': 0.5118518518518519, '_wandb': {'runtime': 2}, 'eval/recall_micro': 0.4523809523809524, 'eval/precision_micro': 0.4523809523809524, 'eval/recall_weighted': 0.4523809523809524, 'eval/precision_weighted': 0.4421296296296296, 'eval/f1_micro': 0.4523809523809524, 'test/f1_micro': 0.514018691588785, 'test/f1_weighted': 0.5142600899335281, 'test/recall_macro': 0.5105712741919639, 'test/precision_micro': 0.514018691588785, 'test/loss': 2.6418217712697425, 'eval/loss': 1.9355635816859025, 'test/accuracy': 0.514018691588785, 'test/recall_weighted': 0.514018691588785, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 66, 'dt_min_samples_leaf': 11}",drawn-lake-937,DecisionTree,"['TfIdf', 'preprocessed']"
401,"{'eval/f1_micro': 0.35714285714285715, '_runtime': 3.611428737640381, 'test/f1_micro': 0.4205607476635514, 'test/recall_macro': 0.4110318444995864, 'eval/precision_macro': 0.36644736842105263, 'eval/accuracy': 0.35714285714285715, 'eval/f1_macro': 0.3417941405237231, 'eval/precision_micro': 0.35714285714285715, 'eval/recall_weighted': 0.35714285714285715, 'test/recall_weighted': 0.4205607476635514, '_step': 20, 'test/loss': 1.3877434012967198, 'eval/recall_macro': 0.35909090909090907, 'test/f1_macro': 0.386001585955656, 'test/precision_weighted': 0.39918540035362465, 'eval/loss': 1.443315568366891, '_timestamp': 1704570756.341369, 'eval/recall_micro': 0.35714285714285715, 'test/precision_micro': 0.4205607476635514, 'test/precision_macro': 0.3914695945945946, 'eval/precision_weighted': 0.3668546365914787, 'split': 10, '_wandb': {'runtime': 2}, 'test/accuracy': 0.4205607476635514, 'eval/f1_weighted': 0.3418686288792589, 'test/recall_micro': 0.4205607476635514, 'test/f1_weighted': 0.3958241246058959}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 71, 'dt_min_samples_leaf': 29}",sleek-energy-936,DecisionTree,"['BoW', 'preprocessed']"
402,"{'eval/recall_macro': 0.45227272727272727, 'eval/recall_micro': 0.4523809523809524, 'eval/precision_micro': 0.4523809523809524, 'test/loss': 3.7808430589301687, '_timestamp': 1704570751.466611, 'eval/f1_macro': 0.4132034632034632, '_wandb': {'runtime': 2}, 'eval/f1_weighted': 0.40968872397443823, 'test/recall_macro': 0.4449366342469791, 'test/precision_macro': 0.4816627816627817, 'eval/accuracy': 0.4523809523809524, 'test/f1_weighted': 0.4184790246644649, 'test/recall_micro': 0.4392523364485981, 'test/recall_weighted': 0.4392523364485981, 'eval/recall_weighted': 0.4523809523809524, 'split': 10, 'eval/f1_micro': 0.4523809523809524, 'eval/precision_macro': 0.4772727272727273, 'test/f1_micro': 0.4392523364485981, 'test/precision_micro': 0.4392523364485981, 'eval/precision_weighted': 0.4702380952380952, 'test/precision_weighted': 0.4895322745790035, '_step': 20, 'test/accuracy': 0.4392523364485981, 'test/f1_macro': 0.4174133249791145, '_runtime': 3.8952367305755615, 'eval/loss': 5.183806724410207}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 65, 'dt_min_samples_leaf': 6}",clear-snow-935,DecisionTree,"['TfIdf', 'preprocessed']"
403,"{'eval/loss': 1.435708486799936, 'eval/f1_weighted': 0.16904761904761903, '_step': 20, 'test/precision_macro': 0.23768366464995677, 'test/recall_weighted': 0.29906542056074764, '_wandb': {'runtime': 1984}, 'test/recall_micro': 0.29906542056074764, 'test/precision_weighted': 0.2116091406231068, 'eval/f1_macro': 0.17083333333333334, 'eval/precision_macro': 0.1907894736842105, 'test/f1_macro': 0.225, 'test/loss': 2.2560449876324524, 'test/f1_weighted': 0.2046728971962617, 'eval/precision_weighted': 0.19360902255639095, '_runtime': 1984.775378227234, 'eval/precision_micro': 0.2857142857142857, '_timestamp': 1704572732.0434082, 'test/accuracy': 0.29906542056074764, 'test/recall_macro': 0.3189799331103679, 'eval/recall_weighted': 0.2857142857142857, 'eval/f1_micro': 0.2857142857142857, 'eval/accuracy': 0.2857142857142857, 'test/f1_micro': 0.29906542056074764, 'eval/recall_macro': 0.29545454545454547, 'eval/recall_micro': 0.2857142857142857, 'test/precision_micro': 0.29906542056074764, 'split': 10}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 0, 'dt_min_samples_leaf': 10}",pleasant-snow-934,DecisionTree,"['pre-trained:openai-gpt', 'preprocessed']"
404,"{'_step': 20, 'test/loss': 1.3877434012967198, 'eval/accuracy': 0.35714285714285715, 'eval/recall_macro': 0.35909090909090907, 'test/recall_weighted': 0.4205607476635514, 'eval/loss': 1.443315568366891, 'test/f1_macro': 0.386001585955656, 'test/precision_micro': 0.4205607476635514, 'split': 10, '_runtime': 3.535557508468628, 'eval/f1_macro': 0.3417941405237231, 'test/precision_macro': 0.3914695945945946, 'test/precision_weighted': 0.39918540035362465, 'eval/f1_weighted': 0.3418686288792589, 'test/recall_macro': 0.4110318444995864, '_wandb': {'runtime': 2}, '_timestamp': 1704570743.5147276, 'test/f1_weighted': 0.3958241246058959, 'test/recall_micro': 0.4205607476635514, 'eval/recall_weighted': 0.35714285714285715, 'eval/precision_weighted': 0.3668546365914787, 'eval/f1_micro': 0.35714285714285715, 'test/accuracy': 0.4205607476635514, 'eval/precision_micro': 0.35714285714285715, 'test/f1_micro': 0.4205607476635514, 'eval/recall_micro': 0.35714285714285715, 'eval/precision_macro': 0.36644736842105263}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 70, 'dt_min_samples_leaf': 27}",dazzling-blaze-933,DecisionTree,"['BoW', 'preprocessed']"
405,"{'test/precision_macro': 0.4746503496503496, 'test/precision_weighted': 0.4759819619632704, '_runtime': 4.01978611946106, 'test/f1_weighted': 0.4674219753820141, 'eval/precision_macro': 0.3758297258297258, '_step': 20, '_wandb': {'runtime': 2}, 'test/f1_macro': 0.4677968583140997, 'eval/f1_weighted': 0.3589807852965748, 'eval/precision_weighted': 0.3767951625094482, 'split': 10, 'eval/loss': 3.740813906002195, 'test/f1_micro': 0.4672897196261683, 'eval/recall_micro': 0.35714285714285715, 'eval/f1_macro': 0.35950558213716105, 'test/accuracy': 0.4672897196261682, 'eval/recall_macro': 0.3590909090909091, 'test/precision_micro': 0.4672897196261682, 'test/loss': 2.7314821033474024, 'test/recall_macro': 0.4696163670301601, 'test/recall_micro': 0.4672897196261682, '_timestamp': 1704570742.002376, 'eval/precision_micro': 0.35714285714285715, 'test/recall_weighted': 0.4672897196261682, 'eval/accuracy': 0.35714285714285715, 'eval/f1_micro': 0.35714285714285715, 'eval/recall_weighted': 0.35714285714285715}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 64, 'dt_min_samples_leaf': 9}",unique-paper-932,DecisionTree,"['TfIdf', 'preprocessed']"
406,"{'eval/loss': 2.350498698399196, 'test/loss': 2.356644653533863, 'test/f1_macro': 0.31623818448500657, 'test/recall_macro': 0.3155241935483871, 'eval/precision_micro': 0.2619047619047619, '_timestamp': 1704570733.349954, 'test/f1_weighted': 0.3211230793600507, 'eval/recall_micro': 0.2619047619047619, 'eval/precision_macro': 0.325, '_wandb': {'runtime': 2}, 'test/accuracy': 0.3177570093457944, 'test/f1_micro': 0.3177570093457944, 'eval/precision_weighted': 0.3261904761904762, 'eval/f1_micro': 0.2619047619047619, 'test/recall_weighted': 0.3177570093457944, '_step': 20, 'eval/f1_weighted': 0.25025010831462446, 'test/recall_micro': 0.3177570093457944, 'test/precision_micro': 0.3177570093457944, '_runtime': 3.574272871017456, 'eval/f1_macro': 0.2496443341604632, 'eval/recall_macro': 0.2613636363636364, 'test/precision_macro': 0.3460851648351648, 'eval/accuracy': 0.2619047619047619, 'eval/recall_weighted': 0.2619047619047619, 'test/precision_weighted': 0.3522029372496662, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 69, 'dt_min_samples_leaf': 21}",floral-frog-931,DecisionTree,"['BoW', 'preprocessed']"
407,"{'test/f1_micro': 0.5046728971962616, 'eval/precision_weighted': 0.45692276910764307, '_step': 20, '_wandb': {'runtime': 2}, 'test/accuracy': 0.5046728971962616, 'test/f1_macro': 0.5110723236663086, 'test/recall_micro': 0.5046728971962616, 'split': 10, '_timestamp': 1704570731.7035005, 'test/f1_weighted': 0.5151353015382247, 'test/recall_macro': 0.5044267609784852, 'eval/recall_micro': 0.4523809523809524, 'eval/precision_micro': 0.4523809523809524, 'test/recall_weighted': 0.5046728971962616, 'test/loss': 4.786701882758459, 'eval/f1_micro': 0.4523809523809524, 'eval/recall_macro': 0.45, 'eval/precision_macro': 0.46050420168067224, 'test/precision_macro': 0.5404674369747899, 'test/precision_micro': 0.5046728971962616, 'test/precision_weighted': 0.5489957197832404, '_runtime': 3.9575932025909424, 'eval/loss': 5.196437236002528, 'eval/f1_macro': 0.4430438842203548, 'eval/f1_weighted': 0.442354719665644, 'eval/accuracy': 0.4523809523809524, 'eval/recall_weighted': 0.4523809523809524}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 63, 'dt_min_samples_leaf': 8}",revived-wood-930,DecisionTree,"['TfIdf', 'preprocessed']"
408,"{'eval/precision_micro': 0.21428571428571427, 'eval/recall_weighted': 0.21428571428571427, 'test/precision_macro': 0.2440331416361694, 'test/precision_micro': 0.32710280373831774, '_wandb': {'runtime': 2}, 'test/f1_weighted': 0.2693213598289872, 'test/recall_micro': 0.32710280373831774, 'eval/precision_macro': 0.16636762360446572, 'test/precision_weighted': 0.23112895403283149, 'split': 10, 'eval/loss': 1.4678844826358557, 'eval/f1_micro': 0.21428571428571427, 'eval/recall_macro': 0.2068181818181818, '_runtime': 3.634801626205444, 'test/accuracy': 0.32710280373831774, 'eval/recall_micro': 0.21428571428571427, 'eval/f1_weighted': 0.1889283249531697, 'test/recall_weighted': 0.32710280373831774, '_step': 20, 'test/f1_micro': 0.32710280373831774, '_timestamp': 1704570724.2130406, 'eval/accuracy': 0.21428571428571427, 'eval/precision_weighted': 0.1721253892306524, 'test/loss': 1.395613100671975, 'eval/f1_macro': 0.18250517598343685, 'test/f1_macro': 0.28465644949618524, 'test/recall_macro': 0.34615384615384615}","{'dt_criterion': 'gini', 'dt_max_depth': 12, 'trial.number': 68, 'dt_min_samples_leaf': 44}",solar-cosmos-929,DecisionTree,"['BoW', 'preprocessed']"
409,"{'_wandb': {'runtime': 1943}, '_timestamp': 1704572662.8526828, 'test/f1_weighted': 0.425788458685655, 'test/precision_micro': 0.45794392523364486, 'split': 10, 'test/f1_micro': 0.45794392523364486, '_step': 20, 'test/f1_macro': 0.42662698412698413, 'eval/recall_macro': 0.5181818181818182, 'eval/loss': 1.3011108859247251, 'test/recall_micro': 0.45794392523364486, 'eval/precision_micro': 0.5238095238095238, 'eval/f1_macro': 0.5191183085919928, 'test/precision_macro': 0.4417996453900709, 'eval/recall_weighted': 0.5238095238095238, 'eval/recall_micro': 0.5238095238095238, 'test/recall_macro': 0.46582532051282055, 'test/recall_weighted': 0.45794392523364486, 'eval/f1_micro': 0.5238095238095238, 'test/loss': 1.3229907434707142, 'test/accuracy': 0.45794392523364486, 'eval/f1_weighted': 0.5230919178287599, 'test/precision_weighted': 0.44646384304368, '_runtime': 1944.5886669158936, 'eval/precision_macro': 0.53125, 'eval/precision_weighted': 0.5337301587301587, 'eval/accuracy': 0.5238095238095238}","{'rf_max_depth': 2, 'trial.number': 0}",deep-durian-928,RandomForest,"['pre-trained:openai-gpt', 'preprocessed']"
410,"{'_step': 20, 'eval/f1_macro': 0.4037372843874392, 'test/recall_micro': 0.514018691588785, 'eval/precision_weighted': 0.430035903250189, 'eval/accuracy': 0.4047619047619048, 'test/f1_micro': 0.514018691588785, 'test/f1_macro': 0.5098370927318295, 'split': 10, '_runtime': 3.93450665473938, 'eval/loss': 2.723401901976163, 'test/loss': 2.520795895843646, 'eval/precision_macro': 0.43105158730158727, 'eval/precision_micro': 0.4047619047619048, 'test/precision_weighted': 0.5384305510796004, 'test/recall_weighted': 0.514018691588785, '_timestamp': 1704570721.4518447, 'eval/f1_micro': 0.4047619047619048, 'eval/recall_macro': 0.40909090909090906, 'test/recall_macro': 0.5149135474997544, 'test/precision_micro': 0.514018691588785, 'test/f1_weighted': 0.5114210760546225, 'eval/recall_micro': 0.4047619047619048, 'eval/recall_weighted': 0.4047619047619048, 'test/precision_macro': 0.5347085385878488, '_wandb': {'runtime': 2}, 'test/accuracy': 0.514018691588785, 'eval/f1_weighted': 0.40155430593289954}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 62, 'dt_min_samples_leaf': 7}",golden-mountain-927,DecisionTree,"['TfIdf', 'preprocessed']"
411,"{'eval/recall_weighted': 0.7142857142857143, 'test/recall_weighted': 0.7102803738317757, 'eval/precision_weighted': 0.713326356183499, 'test/precision_weighted': 0.6924741145405591, 'eval/loss': 10.298186682604902, 'test/precision_micro': 0.7102803738317757, 'eval/accuracy': 0.7142857142857143, 'test/loss': 10.442553785632072, 'eval/f1_weighted': 0.7032227032227032, 'test/recall_micro': 0.7102803738317757, '_wandb': {'runtime': 2071}, 'eval/precision_macro': 0.7157509157509158, 'eval/f1_micro': 0.7142857142857143, 'test/accuracy': 0.7102803738317757, 'test/f1_macro': 0.6966702777527009, 'test/precision_macro': 0.6981263904338153, '_runtime': 2071.805146217346, 'test/f1_micro': 0.7102803738317757, 'eval/recall_macro': 0.7204545454545455, 'eval/recall_micro': 0.7142857142857143, '_timestamp': 1704572789.288242, 'split': 10, 'eval/f1_macro': 0.7078282828282829, 'test/f1_weighted': 0.6840909442455628, 'eval/precision_micro': 0.7142857142857143, '_step': 20, 'test/recall_macro': 0.7286206896551723}","{'n_neighbours': 1, 'trial.number': 0}",avid-snowflake-926,KNeighbours,"['pre-trained:openai-gpt', 'preprocessed']"
412,"{'eval/loss': 1.4971431044040262, '_timestamp': 1704570713.972019, 'test/accuracy': 0.40186915887850466, 'test/f1_micro': 0.40186915887850466, 'eval/recall_weighted': 0.2619047619047619, 'test/precision_macro': 0.3742063492063492, 'split': 10, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.24465598972177915, 'eval/recall_micro': 0.2619047619047619, 'eval/precision_weighted': 0.24652777777777776, '_step': 20, '_runtime': 3.5787549018859863, 'eval/accuracy': 0.2619047619047619, 'eval/f1_weighted': 0.24683657797692884, 'test/precision_micro': 0.40186915887850466, 'test/recall_weighted': 0.40186915887850466, 'eval/f1_micro': 0.2619047619047619, 'test/f1_macro': 0.3684119420006517, 'test/f1_weighted': 0.3784026578720579, 'eval/precision_macro': 0.24479166666666663, 'test/loss': 1.3810715903995736, 'test/recall_micro': 0.40186915887850466, 'eval/recall_macro': 0.2590909090909091, 'eval/precision_micro': 0.2619047619047619, 'test/recall_macro': 0.39025020678246486, 'test/precision_weighted': 0.38040350096424863}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 67, 'dt_min_samples_leaf': 35}",snowy-jazz-925,DecisionTree,"['BoW', 'preprocessed']"
413,"{'eval/accuracy': 0.42857142857142855, 'eval/f1_micro': 0.42857142857142855, 'test/accuracy': 0.5233644859813084, 'eval/precision_micro': 0.42857142857142855, 'eval/precision_weighted': 0.4627739984882842, '_timestamp': 1704570711.0874224, 'test/f1_micro': 0.5233644859813084, 'eval/loss': 4.337853519961468, 'test/f1_macro': 0.52121363969876, 'eval/recall_macro': 0.43181818181818177, '_step': 20, 'eval/recall_weighted': 0.42857142857142855, '_wandb': {'runtime': 2}, 'test/recall_micro': 0.5233644859813084, 'split': 10, 'eval/f1_weighted': 0.42912322823866383, 'test/f1_weighted': 0.5228372037596222, 'eval/recall_micro': 0.42857142857142855, 'test/precision_micro': 0.5233644859813084, '_runtime': 3.865276336669922, 'test/loss': 2.4928973179817313, 'eval/f1_macro': 0.43005307386112335, 'eval/precision_macro': 0.46230158730158727, 'test/precision_weighted': 0.5508455718736093, 'test/recall_macro': 0.5233750859612928, 'test/precision_macro': 0.5476190476190476, 'test/recall_weighted': 0.5233644859813084}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 61, 'dt_min_samples_leaf': 7}",comic-dream-924,DecisionTree,"['TfIdf', 'preprocessed']"
414,"{'_step': 20, 'test/f1_weighted': 0.2943149892500526, 'eval/precision_micro': 0.2857142857142857, 'split': 10, 'eval/accuracy': 0.2857142857142857, 'test/f1_micro': 0.2897196261682243, 'eval/recall_macro': 0.28863636363636364, 'test/recall_micro': 0.2897196261682243, 'test/precision_micro': 0.2897196261682243, 'test/f1_macro': 0.2902063321106761, 'test/precision_macro': 0.30849882688117986, 'test/recall_weighted': 0.2897196261682243, '_timestamp': 1704570704.324838, 'test/accuracy': 0.2897196261682243, 'eval/f1_weighted': 0.28103087388801673, '_wandb': {'runtime': 1}, 'eval/recall_micro': 0.2857142857142857, 'eval/precision_macro': 0.3472426470588236, 'eval/recall_weighted': 0.2857142857142857, 'test/precision_weighted': 0.3154855599880339, 'eval/f1_macro': 0.28305860805860805, 'eval/precision_weighted': 0.34681372549019607, '_runtime': 3.1421890258789062, 'eval/loss': 1.4485018228432194, 'test/loss': 1.5121729768379368, 'eval/f1_micro': 0.2857142857142857, 'test/recall_macro': 0.2889784946236559}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 66, 'dt_min_samples_leaf': 23}",treasured-elevator-923,DecisionTree,"['BoW', 'preprocessed']"
415,"{'split': 10, 'eval/f1_macro': 0.381578947368421, 'eval/f1_weighted': 0.3759398496240601, 'test/recall_macro': 0.43895127222713426, 'test/precision_micro': 0.4299065420560747, '_wandb': {'runtime': 2}, 'eval/f1_micro': 0.4523809523809524, 'eval/precision_micro': 0.4523809523809524, '_step': 20, 'eval/loss': 4.388590859344707, 'test/f1_weighted': 0.37588443047215664, 'eval/precision_weighted': 0.40544332210998874, '_runtime': 4.2086403369903564, 'test/loss': 2.780938760283441, 'test/f1_micro': 0.4299065420560747, 'eval/recall_macro': 0.45227272727272727, 'test/recall_weighted': 0.4299065420560747, '_timestamp': 1704570702.1543005, 'test/accuracy': 0.4299065420560747, 'test/f1_macro': 0.3748944405348346, 'eval/recall_micro': 0.4523809523809524, 'test/recall_micro': 0.4299065420560747, 'eval/recall_weighted': 0.4523809523809524, 'eval/precision_macro': 0.4164562289562289, 'eval/accuracy': 0.4523809523809524, 'test/precision_macro': 0.49738583013230897, 'test/precision_weighted': 0.5061946302567599}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 60, 'dt_min_samples_leaf': 6}",hardy-snow-922,DecisionTree,"['TfIdf', 'preprocessed']"
416,"{'eval/f1_macro': 0.3417941405237231, 'test/f1_macro': 0.386001585955656, 'test/f1_weighted': 0.3958241246058959, 'eval/recall_micro': 0.35714285714285715, 'test/precision_macro': 0.3914695945945946, 'test/recall_weighted': 0.4205607476635514, 'eval/precision_macro': 0.36644736842105263, 'eval/recall_weighted': 0.35714285714285715, '_wandb': {'runtime': 1}, '_timestamp': 1704570695.1106248, 'eval/f1_micro': 0.35714285714285715, 'test/accuracy': 0.4205607476635514, 'eval/recall_macro': 0.35909090909090907, 'test/recall_micro': 0.4205607476635514, 'test/precision_micro': 0.4205607476635514, 'eval/f1_weighted': 0.3418686288792589, 'eval/precision_micro': 0.35714285714285715, 'eval/precision_weighted': 0.3668546365914787, 'test/precision_weighted': 0.39918540035362465, '_runtime': 3.1332926750183105, 'eval/loss': 1.443315568366891, 'test/loss': 1.3877434012967198, '_step': 20, 'eval/accuracy': 0.35714285714285715, 'test/recall_macro': 0.4110318444995864, 'split': 10, 'test/f1_micro': 0.4205607476635514}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 65, 'dt_min_samples_leaf': 30}",lucky-sea-921,DecisionTree,"['BoW', 'preprocessed']"
417,"{'split': 10, 'eval/recall_micro': 0.4523809523809524, '_timestamp': 1704570692.5964763, 'eval/accuracy': 0.4523809523809524, 'eval/f1_macro': 0.3982683982683982, 'eval/f1_micro': 0.4523809523809524, 'test/f1_micro': 0.45794392523364486, 'eval/recall_weighted': 0.4523809523809524, '_runtime': 3.8605144023895264, 'test/recall_micro': 0.45794392523364486, 'eval/precision_macro': 0.41875, 'test/precision_macro': 0.5333333333333332, 'test/precision_weighted': 0.5411214953271027, '_wandb': {'runtime': 2}, 'test/loss': 3.063966937902475, 'test/recall_weighted': 0.45794392523364486, 'eval/loss': 6.052857691757556, 'test/f1_macro': 0.4096270086982161, 'eval/f1_weighted': 0.3915481344052773, 'test/accuracy': 0.45794392523364486, '_step': 20, 'test/f1_weighted': 0.4133374943681358, 'eval/recall_macro': 0.4545454545454546, 'test/recall_macro': 0.46185037822968855, 'eval/precision_micro': 0.4523809523809524, 'test/precision_micro': 0.45794392523364486, 'eval/precision_weighted': 0.4077380952380952}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 59, 'dt_min_samples_leaf': 5}",giddy-resonance-920,DecisionTree,"['TfIdf', 'preprocessed']"
418,"{'_step': 20, 'test/f1_macro': 0.2451271813073055, 'test/f1_weighted': 0.2468246136325314, 'eval/precision_micro': 0.30952380952380953, 'eval/recall_weighted': 0.30952380952380953, 'test/precision_micro': 0.27102803738317754, 'test/recall_weighted': 0.27102803738317754, '_timestamp': 1704572753.6325145, 'test/f1_micro': 0.27102803738317754, 'eval/precision_weighted': 0.1830550401978973, 'test/recall_micro': 0.27102803738317754, 'test/precision_macro': 0.3450534759358289, 'split': 10, 'eval/loss': 7.745848052871273, 'test/accuracy': 0.27102803738317754, 'eval/f1_weighted': 0.22082679225536367, 'eval/recall_macro': 0.3068181818181818, 'test/loss': 7.93269554479009, 'eval/f1_macro': 0.2216117216117216, 'eval/f1_micro': 0.30952380952380953, 'eval/precision_macro': 0.18506493506493504, '_wandb': {'runtime': 2064}, 'test/precision_weighted': 0.34302064071167976, '_runtime': 2066.5753734111786, 'eval/accuracy': 0.30952380952380953, 'eval/recall_micro': 0.30952380952380953, 'test/recall_macro': 0.27193910256410253}","{'smoothing': 0.9970216404256736, 'trial.number': 0}",hardy-cosmos-919,Bernolli,"['pre-trained:openai-gpt', 'preprocessed']"
419,"{'_timestamp': 1704572765.369727, 'eval/recall_weighted': 0.16666666666666666, 'eval/recall_micro': 0.16666666666666666, 'test/precision_micro': 0.22429906542056072, 'test/accuracy': 0.22429906542056072, 'eval/f1_weighted': 0.1080246913580247, 'test/precision_macro': 0.11294862772695284, 'eval/accuracy': 0.16666666666666666, 'test/f1_micro': 0.22429906542056072, 'eval/precision_weighted': 0.0803921568627451, 'eval/f1_micro': 0.16666666666666666, 'test/f1_weighted': 0.1414252182430892, 'test/f1_macro': 0.15425181278839814, 'test/recall_macro': 0.245, 'eval/precision_macro': 0.07941176470588235, 'eval/precision_micro': 0.16666666666666666, 'test/precision_weighted': 0.10362585253244062, 'eval/loss': 1.3836106968514752, 'test/loss': 1.3865997210641388, 'eval/f1_macro': 0.10648148148148148, '_runtime': 2078.2446389198303, 'eval/recall_macro': 0.16363636363636364, 'test/recall_micro': 0.22429906542056072, 'test/recall_weighted': 0.22429906542056072, '_step': 20, 'split': 10, '_wandb': {'runtime': 2077}}",{'trial.number': 0},lemon-haze-918,LogisticRegression,"['pre-trained:openai-gpt', 'preprocessed']"
420,"{'eval/f1_micro': 0.30952380952380953, 'test/accuracy': 0.3644859813084112, 'eval/recall_macro': 0.31136363636363634, 'test/precision_weighted': 0.38741779162339907, 'split': 10, 'test/loss': 1.4364741492452922, 'eval/recall_weighted': 0.30952380952380953, 'eval/loss': 1.4429451519006609, '_timestamp': 1704570687.1938937, 'test/precision_micro': 0.3644859813084112, '_step': 20, 'eval/f1_macro': 0.3074945533769063, 'test/recall_weighted': 0.3644859813084112, 'eval/precision_weighted': 0.35234093637454983, '_runtime': 3.706942558288574, 'eval/precision_micro': 0.30952380952380953, 'test/recall_micro': 0.3644859813084112, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.30952380952380953, 'test/f1_macro': 0.36319524505806594, 'test/f1_weighted': 0.3713207652287989, 'test/precision_macro': 0.37876157407407407, 'eval/recall_micro': 0.30952380952380953, 'test/recall_macro': 0.35734594706368905, 'eval/precision_macro': 0.3521008403361344, 'test/f1_micro': 0.36448598130841114, 'eval/f1_weighted': 0.30696960265587714}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 64, 'dt_min_samples_leaf': 25}",dry-sunset-917,DecisionTree,"['BoW', 'preprocessed']"
421,"{'test/f1_weighted': 0.45311650101369727, 'test/recall_macro': 0.4489777974260733, '_step': 20, '_runtime': 4.057748317718506, 'eval/f1_micro': 0.4523809523809524, 'test/f1_macro': 0.4522156084656085, 'test/f1_micro': 0.4485981308411215, 'eval/recall_micro': 0.4523809523809524, 'test/precision_weighted': 0.46433780587825063, '_timestamp': 1704570682.5451944, 'eval/f1_macro': 0.45097571828121025, 'test/accuracy': 0.4485981308411215, 'eval/precision_micro': 0.4523809523809524, 'test/precision_micro': 0.4485981308411215, 'eval/accuracy': 0.4523809523809524, 'eval/recall_macro': 0.45227272727272727, 'test/loss': 3.0062582302563117, 'eval/recall_weighted': 0.4523809523809524, 'test/recall_weighted': 0.4485981308411215, 'eval/f1_weighted': 0.45194810698243193, 'eval/precision_macro': 0.4642857142857143, 'test/precision_macro': 0.4622012406495165, '_wandb': {'runtime': 2}, 'split': 10, 'eval/loss': 2.7303887451696744, 'test/recall_micro': 0.4485981308411215, 'eval/precision_weighted': 0.4659863945578231}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 58, 'dt_min_samples_leaf': 10}",gallant-surf-916,DecisionTree,"['TfIdf', 'preprocessed']"
422,"{'eval/precision_weighted': 0.3668546365914787, 'test/precision_weighted': 0.39918540035362465, 'split': 10, '_runtime': 3.2685065269470215, 'test/recall_weighted': 0.4205607476635514, 'test/precision_macro': 0.3914695945945946, 'test/precision_micro': 0.4205607476635514, 'test/accuracy': 0.4205607476635514, 'test/recall_micro': 0.4205607476635514, 'eval/recall_weighted': 0.35714285714285715, 'eval/loss': 1.443315568366891, 'eval/recall_micro': 0.35714285714285715, 'test/f1_weighted': 0.3958241246058959, 'eval/f1_micro': 0.35714285714285715, 'eval/recall_macro': 0.35909090909090907, '_step': 20, 'eval/f1_macro': 0.3417941405237231, 'test/f1_macro': 0.386001585955656, 'test/recall_macro': 0.4110318444995864, 'test/loss': 1.3877434012967198, 'test/f1_micro': 0.4205607476635514, 'eval/f1_weighted': 0.3418686288792589, 'eval/precision_macro': 0.36644736842105263, 'eval/precision_micro': 0.35714285714285715, '_wandb': {'runtime': 1}, '_timestamp': 1704570679.2684426, 'eval/accuracy': 0.35714285714285715}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 63, 'dt_min_samples_leaf': 27}",effortless-river-915,DecisionTree,"['BoW', 'preprocessed']"
423,"{'_step': 20, 'test/accuracy': 0.4392523364485981, 'eval/f1_weighted': 0.4126148705096074, 'eval/accuracy': 0.42857142857142855, 'eval/f1_macro': 0.41491228070175434, 'eval/recall_macro': 0.4272727272727273, 'eval/recall_micro': 0.42857142857142855, '_wandb': {'runtime': 2}, 'test/loss': 2.7389659380542244, 'eval/precision_micro': 0.42857142857142855, 'eval/recall_weighted': 0.42857142857142855, 'test/precision_macro': 0.5062408424908424, '_timestamp': 1704570672.2891133, 'test/f1_macro': 0.43745083649898314, 'test/recall_macro': 0.44398713036644066, 'split': 10, 'test/f1_micro': 0.4392523364485981, 'test/recall_micro': 0.4392523364485981, '_runtime': 4.029658317565918, 'eval/loss': 4.4301590036058895, 'eval/f1_micro': 0.42857142857142855, 'test/recall_weighted': 0.4392523364485981, 'test/f1_weighted': 0.439546712296492, 'eval/precision_macro': 0.4497076023391813, 'test/precision_micro': 0.4392523364485981, 'eval/precision_weighted': 0.443609022556391, 'test/precision_weighted': 0.517161856834754}","{'dt_criterion': 'gini', 'dt_max_depth': 14, 'trial.number': 57, 'dt_min_samples_leaf': 8}",rose-planet-914,DecisionTree,"['TfIdf', 'preprocessed']"
424,"{'eval/accuracy': 0.35714285714285715, 'test/precision_macro': 0.3914695945945946, 'eval/f1_macro': 0.3417941405237231, 'eval/f1_weighted': 0.3418686288792589, 'eval/precision_micro': 0.35714285714285715, 'test/recall_weighted': 0.4205607476635514, 'test/recall_micro': 0.4205607476635514, 'eval/recall_weighted': 0.35714285714285715, 'test/precision_micro': 0.4205607476635514, 'eval/precision_macro': 0.36644736842105263, '_step': 20, '_runtime': 3.586189985275269, 'test/loss': 1.3877434012967198, 'eval/f1_micro': 0.35714285714285715, 'test/f1_macro': 0.386001585955656, 'test/f1_micro': 0.4205607476635514, 'eval/recall_micro': 0.35714285714285715, '_wandb': {'runtime': 2}, 'eval/loss': 1.443315568366891, 'test/accuracy': 0.4205607476635514, '_timestamp': 1704570669.3946, 'test/f1_weighted': 0.3958241246058959, 'eval/recall_macro': 0.35909090909090907, 'eval/precision_weighted': 0.3668546365914787, 'test/precision_weighted': 0.39918540035362465, 'split': 10, 'test/recall_macro': 0.4110318444995864}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 62, 'dt_min_samples_leaf': 31}",sandy-jazz-913,DecisionTree,"['BoW', 'preprocessed']"
425,"{'_step': 20, 'eval/precision_macro': 0.49255952380952384, 'eval/precision_micro': 0.47619047619047616, 'eval/recall_weighted': 0.47619047619047616, 'test/precision_weighted': 0.4817050497037606, '_runtime': 3.839723825454712, 'eval/f1_micro': 0.47619047619047616, 'eval/recall_macro': 0.47954545454545455, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.4766355140186916, 'eval/f1_weighted': 0.46635756056808686, 'test/f1_weighted': 0.4784276006614634, 'test/precision_macro': 0.48043766578249336, 'test/precision_micro': 0.4766355140186916, 'eval/loss': 1.951623149357079, '_timestamp': 1704570661.869892, 'eval/f1_macro': 0.4697807017543859, 'test/accuracy': 0.4766355140186916, 'eval/precision_weighted': 0.4882369614512471, 'split': 10, 'test/loss': 3.6324341328123824, 'eval/accuracy': 0.47619047619047616, 'eval/recall_micro': 0.47619047619047616, 'test/recall_micro': 0.4766355140186916, 'test/f1_macro': 0.4780513234453301, 'test/recall_macro': 0.4771117005599764, 'test/recall_weighted': 0.4766355140186916}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 56, 'dt_min_samples_leaf': 12}",swift-aardvark-912,DecisionTree,"['TfIdf', 'preprocessed']"
426,"{'eval/f1_weighted': 0.189640768588137, 'test/recall_micro': 0.2336448598130841, '_timestamp': 1704572383.8666186, 'eval/recall_weighted': 0.2857142857142857, 'test/f1_macro': 0.16221182759772804, 'test/f1_micro': 0.23364485981308417, 'eval/recall_macro': 0.28181818181818186, 'test/recall_macro': 0.2554347826086957, 'eval/precision_weighted': 0.145628621819098, '_step': 20, 'test/loss': 1.3797161177713275, 'test/accuracy': 0.2336448598130841, 'eval/recall_micro': 0.2857142857142857, '_wandb': {'runtime': 1726}, 'eval/f1_macro': 0.18859649122807015, '_runtime': 1728.9467265605929, 'eval/loss': 1.3783111534752766, 'eval/f1_micro': 0.2857142857142857, 'test/f1_weighted': 0.1494577690623917, 'eval/precision_micro': 0.2857142857142857, 'test/precision_macro': 0.11999639379733142, 'eval/accuracy': 0.2857142857142857, 'test/precision_weighted': 0.11092949031212188, 'split': 10, 'eval/precision_macro': 0.1455026455026455, 'test/precision_micro': 0.2336448598130841, 'test/recall_weighted': 0.2336448598130841}",{'trial.number': 0},sleek-waterfall-910,LogisticRegression,"['pre-trained:bert-base-uncased', 'preprocessed']"
427,"{'test/f1_weighted': 0.3958241246058959, 'eval/precision_weighted': 0.3668546365914787, '_runtime': 5.353564023971558, 'eval/accuracy': 0.35714285714285715, 'test/f1_micro': 0.4205607476635514, 'test/loss': 1.3877434012967198, 'test/f1_macro': 0.386001585955656, 'test/recall_weighted': 0.4205607476635514, 'test/precision_weighted': 0.39918540035362465, '_step': 20, 'test/recall_macro': 0.4110318444995864, 'eval/recall_weighted': 0.35714285714285715, 'split': 10, 'test/accuracy': 0.4205607476635514, 'eval/precision_macro': 0.36644736842105263, 'eval/precision_micro': 0.35714285714285715, 'eval/f1_micro': 0.35714285714285715, 'eval/recall_macro': 0.35909090909090907, 'test/recall_micro': 0.4205607476635514, 'test/precision_micro': 0.4205607476635514, 'eval/loss': 1.443315568366891, '_timestamp': 1704570659.047242, 'test/precision_macro': 0.3914695945945946, 'eval/recall_micro': 0.35714285714285715, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.3417941405237231, 'eval/f1_weighted': 0.3418686288792589}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 61, 'dt_min_samples_leaf': 30}",earthy-dust-910,DecisionTree,"['BoW', 'preprocessed']"
428,"{'test/recall_micro': 0.40186915887850466, 'test/precision_weighted': 0.398910302303232, '_timestamp': 1704570649.6414657, 'test/recall_macro': 0.3986501620984379, 'eval/precision_micro': 0.47619047619047616, 'eval/precision_weighted': 0.469078144078144, '_step': 20, 'split': 10, '_wandb': {'runtime': 2}, 'eval/loss': 2.0444969923844325, 'test/f1_macro': 0.3964686761229314, 'test/recall_weighted': 0.40186915887850466, '_runtime': 3.4348437786102295, 'test/loss': 3.430305030209538, 'test/f1_micro': 0.40186915887850466, 'eval/recall_macro': 0.4818181818181818, 'eval/precision_macro': 0.47419871794871793, 'eval/recall_weighted': 0.47619047619047616, 'eval/accuracy': 0.47619047619047616, 'test/f1_weighted': 0.39825512030224697, 'test/precision_macro': 0.39842132505175987, 'eval/f1_macro': 0.4652709467287473, 'test/accuracy': 0.40186915887850466, 'eval/f1_weighted': 0.4597064392460811, 'eval/recall_micro': 0.47619047619047616, 'eval/f1_micro': 0.47619047619047616, 'test/precision_micro': 0.40186915887850466}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 55, 'dt_min_samples_leaf': 15}",astral-violet-909,DecisionTree,"['TfIdf', 'preprocessed']"
429,"{'split': 10, 'test/f1_macro': 0.3684119420006517, 'eval/recall_weighted': 0.2619047619047619, 'eval/recall_macro': 0.2590909090909091, 'test/accuracy': 0.40186915887850466, 'eval/recall_micro': 0.2619047619047619, 'eval/precision_weighted': 0.24652777777777776, '_wandb': {'runtime': 2}, '_runtime': 3.608259677886963, 'eval/loss': 1.4971431044040262, 'eval/f1_micro': 0.2619047619047619, 'test/recall_weighted': 0.40186915887850466, 'eval/accuracy': 0.2619047619047619, 'eval/f1_macro': 0.24465598972177915, 'eval/precision_macro': 0.24479166666666663, 'test/precision_macro': 0.3742063492063492, '_timestamp': 1704570649.0324116, 'test/f1_micro': 0.40186915887850466, 'test/recall_macro': 0.39025020678246486, 'test/precision_weighted': 0.38040350096424863, '_step': 20, 'eval/f1_weighted': 0.24683657797692884, 'test/f1_weighted': 0.3784026578720579, 'test/loss': 1.3810715903995736, 'test/recall_micro': 0.40186915887850466, 'eval/precision_micro': 0.2619047619047619, 'test/precision_micro': 0.40186915887850466}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 60, 'dt_min_samples_leaf': 35}",ruby-flower-908,DecisionTree,"['BoW', 'preprocessed']"
430,"{'eval/recall_micro': 0.42857142857142855, 'test/recall_micro': 0.48598130841121495, 'test/precision_micro': 0.48598130841121495, 'split': 10, '_runtime': 3.5456721782684326, 'eval/accuracy': 0.42857142857142855, 'eval/recall_macro': 0.4340909090909091, 'eval/loss': 3.5970289729947535, 'test/loss': 2.572760285408522, 'test/precision_weighted': 0.509929906542056, 'test/recall_macro': 0.48584192946261906, 'test/recall_weighted': 0.48598130841121495, 'eval/f1_macro': 0.4136990328365229, 'eval/recall_weighted': 0.42857142857142855, 'test/precision_macro': 0.5041307471264368, '_step': 20, '_timestamp': 1704570639.521187, 'test/f1_macro': 0.46533262889818994, 'eval/f1_weighted': 0.4107002521148389, 'test/f1_weighted': 0.4692738775879812, 'eval/precision_macro': 0.4641290726817043, 'eval/precision_weighted': 0.4638530850936866, '_wandb': {'runtime': 2}, 'eval/f1_micro': 0.42857142857142855, 'eval/precision_micro': 0.42857142857142855, 'test/accuracy': 0.48598130841121495, 'test/f1_micro': 0.48598130841121495}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 54, 'dt_min_samples_leaf': 7}",wise-field-907,DecisionTree,"['TfIdf', 'preprocessed']"
431,"{'_timestamp': 1704570638.9400835, 'test/recall_micro': 0.34579439252336447, '_runtime': 3.76559853553772, 'eval/f1_macro': 0.3342674868990658, 'test/f1_macro': 0.3275896252007228, 'eval/precision_micro': 0.3333333333333333, 'test/precision_micro': 0.34579439252336447, 'split': 10, 'test/loss': 1.3774077476942146, 'test/accuracy': 0.34579439252336447, 'test/f1_micro': 0.34579439252336447, 'test/f1_weighted': 0.3375866697924407, 'eval/precision_macro': 0.37826797385620914, 'test/precision_macro': 0.35715240641711227, 'eval/precision_weighted': 0.37776221599751014, '_step': 20, 'eval/recall_weighted': 0.3333333333333333, 'eval/f1_micro': 0.3333333333333333, 'eval/accuracy': 0.3333333333333333, 'eval/recall_macro': 0.3363636363636364, 'test/recall_weighted': 0.34579439252336447, 'eval/loss': 1.391304034795851, 'eval/f1_weighted': 0.3315019149605616, 'eval/recall_micro': 0.3333333333333333, 'test/recall_macro': 0.3334625723738627, 'test/precision_weighted': 0.36431855664950774, '_wandb': {'runtime': 2}}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 59, 'dt_min_samples_leaf': 41}",legendary-cloud-906,DecisionTree,"['BoW', 'preprocessed']"
432,"{'test/f1_micro': 0.48598130841121495, 'eval/f1_macro': 0.3335714285714286, 'test/recall_micro': 0.48598130841121495, 'eval/precision_micro': 0.3333333333333333, 'eval/precision_weighted': 0.34961863533292104, 'test/precision_weighted': 0.4873668387687079, 'split': 10, 'eval/recall_macro': 0.33636363636363636, 'test/recall_macro': 0.4881348855486786, 'test/loss': 3.992072971194464, 'eval/loss': 4.570330110401986, '_timestamp': 1704570629.688447, 'eval/accuracy': 0.3333333333333333, 'eval/f1_micro': 0.3333333333333333, 'test/precision_micro': 0.48598130841121495, '_wandb': {'runtime': 2}, 'eval/f1_weighted': 0.33276643990929705, 'test/f1_macro': 0.48102485838420506, 'eval/recall_weighted': 0.3333333333333333, 'test/recall_weighted': 0.48598130841121495, 'eval/precision_macro': 0.34805194805194806, 'eval/recall_micro': 0.3333333333333333, '_step': 20, 'test/accuracy': 0.48598130841121495, 'test/f1_weighted': 0.4801854047711198, 'test/precision_macro': 0.4873543123543124, '_runtime': 4.746929883956909}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 53, 'dt_min_samples_leaf': 9}",legendary-firebrand-905,DecisionTree,"['TfIdf', 'preprocessed']"
433,"{'_timestamp': 1704570627.6098435, 'test/accuracy': 0.3177570093457944, 'eval/recall_micro': 0.2619047619047619, 'eval/precision_weighted': 0.3261904761904762, 'test/precision_weighted': 0.3522029372496662, '_step': 20, 'test/recall_macro': 0.3155241935483871, 'eval/precision_macro': 0.325, 'test/precision_macro': 0.3460851648351648, '_runtime': 3.748072385787964, 'eval/f1_micro': 0.2619047619047619, 'eval/loss': 2.28502573443191, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.3177570093457944, 'eval/f1_weighted': 0.25025010831462446, 'eval/recall_weighted': 0.2619047619047619, 'eval/precision_micro': 0.2619047619047619, 'test/precision_micro': 0.3177570093457944, 'test/recall_weighted': 0.3177570093457944, 'eval/accuracy': 0.2619047619047619, 'test/f1_macro': 0.31623818448500657, 'test/f1_weighted': 0.3211230793600507, 'eval/recall_macro': 0.2613636363636364, 'split': 10, 'test/loss': 2.318632712144711, 'eval/f1_macro': 0.2496443341604632, 'test/recall_micro': 0.3177570093457944}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 58, 'dt_min_samples_leaf': 19}",wobbly-oath-904,DecisionTree,"['BoW', 'preprocessed']"
434,"{'_runtime': 1729.0188081264496, 'eval/loss': 1.3879160759598954, 'test/f1_micro': 0.21495327102803735, 'test/recall_macro': 0.25, 'test/precision_micro': 0.21495327102803735, 'test/loss': 1.4025061656215816, 'eval/accuracy': 0.2619047619047619, 'test/f1_weighted': 0.07606038820992093, 'eval/precision_micro': 0.2619047619047619, 'test/f1_macro': 0.08846153846153847, 'test/recall_micro': 0.21495327102803735, 'test/precision_macro': 0.053738317757009345, 'test/precision_weighted': 0.046204908725652895, 'split': 10, '_wandb': {'runtime': 1728}, 'eval/precision_macro': 0.06547619047619048, 'test/recall_weighted': 0.21495327102803735, 'eval/f1_macro': 0.10377358490566038, 'eval/f1_micro': 0.2619047619047619, 'eval/f1_weighted': 0.10871518418688232, 'eval/precision_weighted': 0.06859410430839002, '_timestamp': 1704572351.910365, 'test/accuracy': 0.21495327102803735, 'eval/recall_micro': 0.2619047619047619, 'eval/recall_weighted': 0.2619047619047619, '_step': 20, 'eval/recall_macro': 0.25}","{'smoothing': 0.8002540534450651, 'trial.number': 0}",elated-monkey-902,Bernolli,"['pre-trained:bert-base-uncased', 'preprocessed']"
435,"{'test/precision_macro': 0.7212475633528265, 'test/recall_micro': 0.6915887850467289, 'eval/precision_micro': 0.7619047619047619, 'test/precision_weighted': 0.7311581133519155, '_timestamp': 1704572397.7642603, 'eval/f1_macro': 0.7462606837606838, 'test/f1_micro': 0.6915887850467289, '_step': 20, 'test/loss': 11.11626693309221, 'test/f1_weighted': 0.667061970635204, 'test/recall_macro': 0.6937169312169311, 'eval/recall_weighted': 0.7619047619047619, 'eval/accuracy': 0.7619047619047619, 'test/f1_macro': 0.6625410558359368, 'eval/f1_weighted': 0.7417582417582418, 'test/precision_micro': 0.6915887850467289, 'test/recall_weighted': 0.6915887850467289, 'eval/precision_macro': 0.7793650793650794, 'split': 10, 'eval/f1_micro': 0.7619047619047619, 'test/accuracy': 0.6915887850467289, 'eval/loss': 8.581822235504083, 'eval/recall_micro': 0.7619047619047619, 'eval/precision_weighted': 0.7775510204081633, '_wandb': {'runtime': 1774}, '_runtime': 1774.800463438034, 'eval/recall_macro': 0.7672979797979798}","{'n_neighbours': 1, 'trial.number': 0}",laced-lion-903,KNeighbours,"['pre-trained:bert-base-uncased', 'preprocessed']"
436,"{'_wandb': {'runtime': 2}, 'test/f1_macro': 0.45133415435139573, 'eval/f1_weighted': 0.44982993197278903, 'test/recall_macro': 0.46291138618724825, 'eval/f1_micro': 0.4523809523809524, 'test/f1_micro': 0.45794392523364486, 'eval/recall_macro': 0.45681818181818185, 'test/precision_micro': 0.45794392523364486, 'eval/precision_weighted': 0.4888278388278388, 'test/loss': 4.904706053093356, '_timestamp': 1704570620.1024714, 'eval/precision_macro': 0.49615384615384617, 'test/accuracy': 0.45794392523364486, 'test/recall_weighted': 0.45794392523364486, '_runtime': 3.700506448745727, 'eval/accuracy': 0.4523809523809524, 'eval/recall_micro': 0.4523809523809524, 'test/precision_macro': 0.49924242424242427, '_step': 20, 'eval/f1_macro': 0.4547619047619048, 'test/recall_micro': 0.45794392523364486, 'eval/recall_weighted': 0.4523809523809524, 'split': 10, 'eval/loss': 5.930371234819657, 'test/f1_weighted': 0.4503567975691727, 'test/precision_weighted': 0.5062022090059473, 'eval/precision_micro': 0.4523809523809524}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 52, 'dt_min_samples_leaf': 6}",eternal-dew-901,DecisionTree,"['TfIdf', 'preprocessed']"
437,"{'_wandb': {'runtime': 2}, '_runtime': 3.7345709800720215, '_timestamp': 1704570616.077781, 'test/f1_weighted': 0.3958241246058959, 'eval/recall_micro': 0.35714285714285715, 'eval/precision_micro': 0.35714285714285715, 'eval/recall_weighted': 0.35714285714285715, '_step': 20, 'test/f1_macro': 0.386001585955656, 'test/precision_macro': 0.3914695945945946, 'eval/precision_weighted': 0.3668546365914787, 'split': 10, 'eval/accuracy': 0.35714285714285715, 'eval/recall_macro': 0.35909090909090907, 'test/f1_micro': 0.4205607476635514, 'test/recall_macro': 0.4110318444995864, 'test/precision_micro': 0.4205607476635514, 'test/recall_weighted': 0.4205607476635514, 'eval/loss': 1.443315568366891, 'test/loss': 1.3877434012967198, 'eval/f1_macro': 0.3417941405237231, 'eval/f1_micro': 0.35714285714285715, 'test/accuracy': 0.4205607476635514, 'eval/f1_weighted': 0.3418686288792589, 'eval/precision_macro': 0.36644736842105263, 'test/precision_weighted': 0.39918540035362465, 'test/recall_micro': 0.4205607476635514}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 57, 'dt_min_samples_leaf': 28}",charmed-star-900,DecisionTree,"['BoW', 'preprocessed']"
438,"{'test/recall_micro': 0.5233644859813084, 'test/precision_weighted': 0.5508455718736093, '_runtime': 3.567899465560913, 'eval/loss': 3.5291818093081977, 'eval/f1_macro': 0.43005307386112335, '_timestamp': 1704570609.7134326, 'test/f1_micro': 0.5233644859813084, 'eval/precision_macro': 0.46230158730158727, 'split': 10, 'test/f1_weighted': 0.5228372037596222, 'eval/recall_macro': 0.43181818181818177, '_step': 20, 'eval/accuracy': 0.42857142857142855, 'eval/f1_micro': 0.42857142857142855, 'test/accuracy': 0.5233644859813084, 'test/precision_macro': 0.5476190476190476, 'test/loss': 2.8086864944341365, 'test/recall_macro': 0.5233750859612928, 'eval/precision_micro': 0.42857142857142855, 'eval/recall_weighted': 0.42857142857142855, 'test/recall_weighted': 0.5233644859813084, '_wandb': {'runtime': 2}, 'eval/f1_weighted': 0.42912322823866383, 'eval/recall_micro': 0.42857142857142855, 'test/f1_macro': 0.52121363969876, 'test/precision_micro': 0.5233644859813084, 'eval/precision_weighted': 0.4627739984882842}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 51, 'dt_min_samples_leaf': 7}",dandy-donkey-899,DecisionTree,"['TfIdf', 'preprocessed']"
439,"{'test/recall_micro': 0.2897196261682243, 'test/precision_micro': 0.2897196261682243, '_step': 20, 'eval/accuracy': 0.23809523809523808, 'test/f1_macro': 0.28984319943622266, 'test/recall_macro': 0.2881772125723739, 'eval/precision_micro': 0.23809523809523808, 'eval/f1_micro': 0.23809523809523808, 'eval/recall_weighted': 0.23809523809523808, 'test/recall_weighted': 0.2897196261682243, '_wandb': {'runtime': 1}, '_runtime': 6.748276710510254, 'eval/f1_weighted': 0.23452380952380952, 'eval/precision_weighted': 0.3058608058608059, 'test/f1_weighted': 0.29403621083690634, 'eval/precision_macro': 0.30673076923076925, 'split': 10, 'eval/loss': 1.4559638998295668, 'test/loss': 1.531133113162552, 'eval/f1_macro': 0.2375, 'test/accuracy': 0.2897196261682243, 'test/f1_micro': 0.2897196261682243, 'eval/recall_macro': 0.24318181818181817, 'eval/recall_micro': 0.23809523809523808, 'test/precision_weighted': 0.3127176104086495, '_timestamp': 1704570605.2853308, 'test/precision_macro': 0.3059129901960784}","{'dt_criterion': 'gini', 'dt_max_depth': 13, 'trial.number': 56, 'dt_min_samples_leaf': 23}",young-pond-898,DecisionTree,"['BoW', 'preprocessed']"
440,"{'eval/f1_macro': 0.3446889140271493, 'eval/f1_micro': 0.380952380952381, 'eval/recall_micro': 0.380952380952381, 'eval/precision_weighted': 0.3390873015873016, 'split': 10, 'test/f1_macro': 0.3086739361570605, 'eval/recall_macro': 0.3931818181818182, 'test/precision_macro': 0.28440126050420167, '_step': 20, '_runtime': 3.5030126571655273, 'test/recall_micro': 0.3925233644859813, 'eval/recall_weighted': 0.380952380952381, 'eval/precision_macro': 0.34270833333333334, '_wandb': {'runtime': 2}, '_timestamp': 1704570599.4052126, 'test/f1_micro': 0.3925233644859813, 'eval/precision_micro': 0.380952380952381, 'test/precision_weighted': 0.29335192020733525, 'test/recall_weighted': 0.3925233644859813, 'eval/loss': 1.2512671874520924, 'test/loss': 1.2291218657846656, 'eval/f1_weighted': 0.33685358758888173, 'test/f1_weighted': 0.32126539694380063, 'test/recall_macro': 0.3746600844876707, 'eval/accuracy': 0.380952380952381, 'test/accuracy': 0.3925233644859813, 'test/precision_micro': 0.3925233644859813}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 50, 'dt_min_samples_leaf': 20}",chocolate-plant-897,DecisionTree,"['TfIdf', 'preprocessed']"
441,"{'_wandb': {'runtime': 1709}, 'eval/accuracy': 0.35714285714285715, 'eval/precision_macro': 0.2583333333333333, 'test/recall_macro': 0.36825028419856, 'eval/recall_weighted': 0.35714285714285715, 'test/precision_micro': 0.38317757009345793, 'test/recall_weighted': 0.38317757009345793, '_timestamp': 1704572305.2569785, 'eval/f1_macro': 0.3005952380952381, 'test/f1_macro': 0.31660514667872836, 'split': 10, 'eval/recall_micro': 0.35714285714285715, 'test/recall_micro': 0.38317757009345793, '_step': 20, 'test/accuracy': 0.38317757009345793, 'eval/f1_weighted': 0.2908163265306123, 'eval/loss': 1.1763696688230223, 'eval/recall_macro': 0.3704545454545455, 'test/precision_macro': 0.28174603174603174, 'test/precision_weighted': 0.29215249962913514, 'test/loss': 2.599004057283187, 'test/f1_micro': 0.383177570093458, 'eval/precision_micro': 0.35714285714285715, 'test/f1_weighted': 0.32884842191587577, '_runtime': 1710.1364665031433, 'eval/f1_micro': 0.35714285714285715, 'eval/precision_weighted': 0.2507936507936508}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 0, 'dt_min_samples_leaf': 61}",feasible-dew-896,DecisionTree,"['pre-trained:bert-base-uncased', 'preprocessed']"
442,"{'eval/recall_micro': 0.5952380952380952, '_timestamp': 1704572256.3380454, 'eval/recall_macro': 0.5954545454545455, 'test/f1_micro': 0.4485981308411215, 'eval/precision_weighted': 0.5742115027829313, '_step': 20, 'test/loss': 1.299416070938589, 'eval/f1_weighted': 0.5768707482993198, 'test/recall_micro': 0.4485981308411215, 'eval/precision_macro': 0.5743506493506493, 'eval/precision_micro': 0.5952380952380952, 'eval/loss': 1.2178864407059349, 'eval/f1_micro': 0.5952380952380952, 'test/recall_weighted': 0.4485981308411215, 'test/precision_weighted': 0.44657086115083133, 'eval/f1_macro': 0.5773809523809523, 'test/precision_macro': 0.44510803808622007, 'test/precision_micro': 0.4485981308411215, 'eval/recall_weighted': 0.5952380952380952, 'eval/accuracy': 0.5952380952380952, '_wandb': {'runtime': 1662}, '_runtime': 1663.038981437683, 'test/accuracy': 0.4485981308411215, 'test/f1_macro': 0.442485754985755, 'test/f1_weighted': 0.4351452458929094, 'test/recall_macro': 0.4649867606519321, 'split': 10}","{'rf_max_depth': 3, 'trial.number': 0}",visionary-lion-895,RandomForest,"['pre-trained:bert-base-uncased', 'preprocessed']"
443,"{'eval/recall_macro': 0.2590909090909091, 'eval/f1_weighted': 0.24683657797692884, 'eval/recall_weighted': 0.2619047619047619, 'eval/precision_weighted': 0.24652777777777776, 'eval/accuracy': 0.2619047619047619, 'eval/f1_macro': 0.24465598972177915, 'test/f1_weighted': 0.3784026578720579, 'test/recall_weighted': 0.40186915887850466, '_wandb': {'runtime': 1}, 'eval/loss': 1.4971431044040262, 'test/precision_micro': 0.40186915887850466, 'test/loss': 1.3810715903995736, 'test/f1_macro': 0.3684119420006517, 'test/precision_macro': 0.3742063492063492, 'eval/precision_micro': 0.2619047619047619, 'test/precision_weighted': 0.38040350096424863, 'test/recall_micro': 0.40186915887850466, '_step': 20, 'split': 10, '_runtime': 3.1593916416168213, 'eval/f1_micro': 0.2619047619047619, 'test/accuracy': 0.40186915887850466, 'test/f1_micro': 0.40186915887850466, 'test/recall_macro': 0.39025020678246486, 'eval/precision_macro': 0.24479166666666663, '_timestamp': 1704570594.2095895, 'eval/recall_micro': 0.2619047619047619}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 55, 'dt_min_samples_leaf': 37}",worldly-vortex-894,DecisionTree,"['BoW', 'preprocessed']"
444,"{'eval/recall_micro': 0.35714285714285715, 'eval/loss': 1.443315568366891, 'test/f1_weighted': 0.3958241246058959, 'eval/precision_weighted': 0.3668546365914787, 'test/precision_weighted': 0.39918540035362465, '_step': 20, 'test/recall_macro': 0.4110318444995864, 'eval/precision_micro': 0.35714285714285715, 'test/loss': 1.3877434012967198, 'eval/f1_weighted': 0.3418686288792589, 'eval/recall_weighted': 0.35714285714285715, 'test/precision_micro': 0.4205607476635514, 'split': 10, '_wandb': {'runtime': 2}, 'eval/f1_micro': 0.35714285714285715, 'eval/precision_macro': 0.36644736842105263, 'test/f1_macro': 0.386001585955656, 'eval/recall_macro': 0.35909090909090907, 'test/precision_macro': 0.3914695945945946, 'eval/f1_macro': 0.3417941405237231, 'test/accuracy': 0.4205607476635514, 'test/f1_micro': 0.4205607476635514, 'test/recall_micro': 0.4205607476635514, 'test/recall_weighted': 0.4205607476635514, '_runtime': 3.6663408279418945, '_timestamp': 1704570586.5333748, 'eval/accuracy': 0.35714285714285715}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 54, 'dt_min_samples_leaf': 30}",toasty-shadow-893,DecisionTree,"['BoW', 'preprocessed']"
445,"{'split': 10, 'eval/accuracy': 0.42857142857142855, 'eval/recall_macro': 0.4272727272727273, '_timestamp': 1704570589.4284878, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.45794392523364486, 'test/recall_macro': 0.4575984870812457, 'eval/recall_weighted': 0.42857142857142855, 'test/f1_weighted': 0.46254119472548416, 'test/recall_micro': 0.45794392523364486, 'eval/precision_macro': 0.438034188034188, 'test/precision_micro': 0.45794392523364486, 'test/recall_weighted': 0.45794392523364486, 'test/loss': 2.9880721540969164, 'eval/recall_micro': 0.42857142857142855, 'eval/precision_weighted': 0.4396621896621897, 'test/precision_weighted': 0.4730974632843792, 'eval/loss': 2.776719939194801, 'eval/f1_macro': 0.4285024154589372, 'test/accuracy': 0.45794392523364486, 'test/f1_macro': 0.4612223365016314, 'eval/f1_weighted': 0.43004370830457783, '_runtime': 6.720172882080078, '_step': 20, 'eval/f1_micro': 0.42857142857142855, 'eval/precision_micro': 0.42857142857142855, 'test/precision_macro': 0.4708333333333333}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 49, 'dt_min_samples_leaf': 10}",logical-snowflake-892,DecisionTree,"['TfIdf', 'preprocessed']"
446,"{'test/loss': 1.4073623847905286, 'eval/precision_weighted': 0.34859943977591035, '_timestamp': 1704570577.7062786, 'test/f1_micro': 0.383177570093458, 'eval/precision_macro': 0.34852941176470587, 'eval/loss': 1.5105946539436068, 'eval/f1_micro': 0.3333333333333333, 'test/recall_macro': 0.37417287014061207, 'test/precision_micro': 0.38317757009345793, 'test/f1_macro': 0.3675263928481099, 'eval/f1_weighted': 0.326278659611993, 'eval/recall_micro': 0.3333333333333333, 'test/recall_micro': 0.38317757009345793, 'eval/precision_micro': 0.3333333333333333, 'test/recall_weighted': 0.38317757009345793, 'eval/recall_weighted': 0.3333333333333333, 'test/precision_weighted': 0.373785046728972, 'split': 10, 'eval/accuracy': 0.3333333333333333, 'eval/f1_macro': 0.3259259259259259, 'test/accuracy': 0.38317757009345793, '_wandb': {'runtime': 1}, '_runtime': 6.513836622238159, 'test/f1_weighted': 0.3768049054767262, '_step': 20, 'eval/recall_macro': 0.3340909090909091, 'test/precision_macro': 0.364375}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 53, 'dt_min_samples_leaf': 26}",faithful-forest-891,DecisionTree,"['BoW', 'preprocessed']"
447,"{'test/precision_weighted': 0.4666050460442984, '_runtime': 4.083293914794922, 'test/accuracy': 0.45794392523364486, 'eval/f1_weighted': 0.3827425707124955, 'eval/recall_weighted': 0.4523809523809524, 'test/recall_weighted': 0.45794392523364486, 'test/recall_macro': 0.46509578544061303, 'test/precision_micro': 0.45794392523364486, 'eval/precision_weighted': 0.4184303350970017, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.4523809523809524, 'eval/f1_macro': 0.38872180451127814, 'eval/precision_macro': 0.4300925925925926, 'eval/loss': 4.372341811604633, 'test/loss': 2.383717729567481, 'test/f1_macro': 0.39900895925380464, 'test/recall_micro': 0.45794392523364486, 'eval/precision_micro': 0.4523809523809524, '_step': 20, 'eval/recall_micro': 0.4523809523809524, 'test/precision_macro': 0.45421245421245426, '_timestamp': 1704570577.5225549, 'split': 10, 'test/f1_weighted': 0.4023893255153492, 'eval/recall_macro': 0.45227272727272727, 'eval/f1_micro': 0.4523809523809524, 'test/f1_micro': 0.45794392523364486}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 48, 'dt_min_samples_leaf': 5}",twilight-moon-890,DecisionTree,"['TfIdf', 'preprocessed']"
448,"{'eval/precision_weighted': 0.25396825396825395, 'eval/recall_weighted': 0.3333333333333333, 'test/recall_macro': 0.3706896551724138, 'eval/recall_macro': 0.33181818181818185, 'test/accuracy': 0.40186915887850466, '_runtime': 2238.8540110588074, 'eval/precision_micro': 0.3333333333333333, 'test/precision_macro': 0.3265534332688588, 'test/precision_micro': 0.40186915887850466, 'test/precision_weighted': 0.354020544478389, 'eval/precision_macro': 0.25757575757575757, 'eval/accuracy': 0.3333333333333333, 'eval/f1_macro': 0.2678787878787879, 'test/recall_weighted': 0.40186915887850466, 'eval/loss': 1.379403938891467, 'test/recall_micro': 0.40186915887850466, 'eval/f1_micro': 0.3333333333333333, 'test/f1_micro': 0.40186915887850466, 'test/f1_weighted': 0.35501350996233383, 'eval/recall_micro': 0.3333333333333333, 'split': 10, '_wandb': {'runtime': 2235}, 'test/loss': 1.3330307417626697, '_timestamp': 1704572800.3942862, 'test/f1_macro': 0.32746935832732516, 'eval/f1_weighted': 0.2666666666666667, '_step': 20}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 0, 'dt_min_samples_leaf': 10}",decent-resonance-888,DecisionTree,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
449,"{'_runtime': 3.111989736557007, 'test/f1_macro': 0.3684119420006517, '_step': 20, '_wandb': {'runtime': 1}, 'test/precision_macro': 0.3742063492063492, 'split': 10, 'test/loss': 1.3810715903995736, '_timestamp': 1704570567.0546618, 'test/f1_micro': 0.40186915887850466, 'test/precision_micro': 0.40186915887850466, 'eval/loss': 1.4971431044040262, 'eval/f1_micro': 0.2619047619047619, 'test/accuracy': 0.40186915887850466, 'eval/f1_weighted': 0.24683657797692884, 'test/f1_weighted': 0.3784026578720579, 'eval/precision_weighted': 0.24652777777777776, 'eval/accuracy': 0.2619047619047619, 'eval/f1_macro': 0.24465598972177915, 'test/recall_macro': 0.39025020678246486, 'eval/precision_macro': 0.24479166666666663, 'eval/recall_weighted': 0.2619047619047619, 'eval/recall_micro': 0.2619047619047619, 'eval/precision_micro': 0.2619047619047619, 'eval/recall_macro': 0.2590909090909091, 'test/recall_micro': 0.40186915887850466, 'test/recall_weighted': 0.40186915887850466, 'test/precision_weighted': 0.38040350096424863}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 52, 'dt_min_samples_leaf': 34}",worthy-cosmos-889,DecisionTree,"['BoW', 'preprocessed']"
450,"{'split': 10, 'eval/f1_macro': 0.4430438842203548, 'eval/f1_weighted': 0.442354719665644, 'eval/recall_macro': 0.45, 'eval/precision_micro': 0.4523809523809524, 'eval/precision_weighted': 0.45692276910764307, '_runtime': 4.084367036819458, 'test/recall_micro': 0.5046728971962616, 'test/loss': 4.470527299068619, 'eval/accuracy': 0.4523809523809524, '_step': 20, '_timestamp': 1704570567.298517, 'eval/precision_macro': 0.46050420168067224, 'eval/f1_micro': 0.4523809523809524, 'test/f1_micro': 0.5046728971962616, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_macro': 0.5404674369747899, 'test/precision_weighted': 0.5489957197832404, 'test/recall_macro': 0.5044267609784852, 'test/recall_weighted': 0.5046728971962616, '_wandb': {'runtime': 2}, 'eval/loss': 5.196437236002528, 'test/accuracy': 0.5046728971962616, 'test/f1_macro': 0.5110723236663086, 'test/f1_weighted': 0.5151353015382247, 'eval/recall_micro': 0.4523809523809524, 'test/precision_micro': 0.5046728971962616}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 47, 'dt_min_samples_leaf': 8}",splendid-butterfly-887,DecisionTree,"['TfIdf', 'preprocessed']"
451,"{'test/precision_macro': 0.3914695945945946, '_runtime': 3.506525993347168, '_timestamp': 1704570559.272011, 'eval/f1_weighted': 0.3418686288792589, 'test/recall_micro': 0.4205607476635514, 'test/f1_macro': 0.386001585955656, 'eval/recall_weighted': 0.35714285714285715, 'eval/precision_micro': 0.35714285714285715, 'test/recall_weighted': 0.4205607476635514, '_wandb': {'runtime': 2}, 'eval/loss': 1.443315568366891, 'test/accuracy': 0.4205607476635514, 'test/recall_macro': 0.4110318444995864, 'split': 10, 'eval/f1_micro': 0.35714285714285715, 'test/f1_micro': 0.4205607476635514, 'eval/accuracy': 0.35714285714285715, 'eval/recall_micro': 0.35714285714285715, 'test/precision_micro': 0.4205607476635514, 'test/precision_weighted': 0.39918540035362465, '_step': 20, 'eval/f1_macro': 0.3417941405237231, 'eval/precision_weighted': 0.3668546365914787, 'test/loss': 1.3877434012967198, 'test/f1_weighted': 0.3958241246058959, 'eval/recall_macro': 0.35909090909090907, 'eval/precision_macro': 0.36644736842105263}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 51, 'dt_min_samples_leaf': 29}",fiery-pine-886,DecisionTree,"['BoW', 'preprocessed']"
452,"{'test/recall_weighted': 0.4766355140186916, '_step': 20, 'eval/f1_micro': 0.380952380952381, 'test/f1_weighted': 0.4894658613880232, 'eval/precision_macro': 0.4097222222222222, 'split': 10, 'eval/recall_micro': 0.380952380952381, 'test/precision_micro': 0.4766355140186916, 'eval/precision_weighted': 0.4034391534391534, 'test/recall_micro': 0.4766355140186916, 'test/precision_weighted': 0.565472263365855, '_wandb': {'runtime': 2}, '_runtime': 4.043045520782471, 'test/accuracy': 0.4766355140186916, 'test/f1_macro': 0.4852530905814105, '_timestamp': 1704570557.0866234, 'eval/f1_weighted': 0.3746751051517786, 'eval/recall_macro': 0.3863636363636363, 'eval/loss': 5.212326893956695, 'test/f1_micro': 0.4766355140186916, 'test/precision_macro': 0.5607955430886707, 'test/loss': 3.615923432745155, 'test/recall_macro': 0.473837803320562, 'eval/accuracy': 0.380952380952381, 'eval/f1_macro': 0.3806299557440531, 'eval/precision_micro': 0.380952380952381, 'eval/recall_weighted': 0.380952380952381}","{'dt_criterion': 'gini', 'dt_max_depth': 17, 'trial.number': 46, 'dt_min_samples_leaf': 6}",silvery-wind-885,DecisionTree,"['TfIdf', 'preprocessed']"
453,"{'eval/accuracy': 0.2619047619047619, 'eval/f1_macro': 0.2545833333333333, 'test/recall_macro': 0.3284997932175352, '_step': 20, 'split': 10, '_runtime': 3.2005441188812256, 'eval/loss': 1.5811322581331777, 'test/f1_macro': 0.3297986147101256, 'eval/f1_weighted': 0.25611111111111107, 'test/precision_micro': 0.3364485981308411, '_wandb': {'runtime': 1}, 'eval/recall_weighted': 0.2619047619047619, '_timestamp': 1704570549.6998222, 'test/recall_weighted': 0.3364485981308411, 'test/precision_macro': 0.33611072847792695, 'test/precision_weighted': 0.3452090710319073, 'test/accuracy': 0.3364485981308411, 'eval/recall_macro': 0.26136363636363635, 'eval/recall_micro': 0.2619047619047619, 'test/recall_micro': 0.3364485981308411, 'eval/precision_weighted': 0.27154195011337867, 'test/loss': 1.4395680746054185, 'eval/f1_micro': 0.2619047619047619, 'test/f1_micro': 0.3364485981308411, 'eval/precision_micro': 0.2619047619047619, 'test/f1_weighted': 0.3384898202669416, 'eval/precision_macro': 0.26904761904761904}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 50, 'dt_min_samples_leaf': 22}",colorful-fire-884,DecisionTree,"['BoW', 'preprocessed']"
454,"{'_timestamp': 1704570546.7336478, 'eval/recall_micro': 0.47619047619047616, 'eval/precision_micro': 0.47619047619047616, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.47619047619047616, 'test/precision_macro': 0.5341443167305236, 'test/f1_macro': 0.5309837247267879, 'eval/recall_weighted': 0.47619047619047616, 'eval/loss': 6.718681163924393, 'test/f1_weighted': 0.5346592074397108, 'eval/recall_macro': 0.4818181818181818, 'test/recall_weighted': 0.5327102803738317, '_step': 20, '_runtime': 3.93048882484436, 'test/f1_micro': 0.5327102803738317, 'test/precision_micro': 0.5327102803738317, 'split': 10, 'test/accuracy': 0.5327102803738317, 'test/precision_weighted': 0.5390394003413662, 'test/recall_macro': 0.5301129776991846, 'eval/f1_micro': 0.47619047619047616, 'eval/f1_weighted': 0.4692714989053662, 'test/recall_micro': 0.5327102803738317, 'eval/precision_macro': 0.4722222222222222, 'eval/precision_weighted': 0.4675925925925926, 'test/loss': 3.500800744729166, 'eval/f1_macro': 0.4743655086332432}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 45, 'dt_min_samples_leaf': 6}",ruby-bird-883,DecisionTree,"['TfIdf', 'preprocessed']"
455,"{'eval/accuracy': 0.35714285714285715, 'eval/f1_weighted': 0.3418686288792589, 'eval/recall_macro': 0.35909090909090907, 'test/recall_micro': 0.4205607476635514, 'test/loss': 1.3877434012967198, 'test/accuracy': 0.4205607476635514, 'test/f1_weighted': 0.3958241246058959, 'test/precision_micro': 0.4205607476635514, 'test/precision_weighted': 0.39918540035362465, '_runtime': 3.6820931434631343, '_timestamp': 1704570541.9763331, 'eval/f1_micro': 0.35714285714285715, 'eval/loss': 1.443315568366891, 'test/recall_macro': 0.4110318444995864, 'test/precision_macro': 0.3914695945945946, 'test/f1_micro': 0.4205607476635514, 'eval/recall_micro': 0.35714285714285715, 'test/recall_weighted': 0.4205607476635514, '_step': 20, 'eval/precision_macro': 0.36644736842105263, 'eval/recall_weighted': 0.35714285714285715, 'split': 10, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.3417941405237231, 'test/f1_macro': 0.386001585955656, 'eval/precision_weighted': 0.3668546365914787, 'eval/precision_micro': 0.35714285714285715}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 49, 'dt_min_samples_leaf': 29}",classic-sun-882,DecisionTree,"['BoW', 'preprocessed']"
456,"{'test/precision_macro': 0.4213823928485913, 'test/precision_micro': 0.45794392523364486, 'eval/loss': 6.0788337021050936, '_timestamp': 1704570536.7073152, 'test/f1_macro': 0.3982919254658385, 'eval/precision_macro': 0.415, 'eval/precision_micro': 0.42857142857142855, 'split': 10, '_wandb': {'runtime': 2}, 'test/f1_weighted': 0.4024206187960759, 'test/recall_macro': 0.4630779054916986, 'eval/precision_weighted': 0.40380952380952384, '_step': 20, '_runtime': 4.115600109100342, 'test/recall_weighted': 0.45794392523364486, 'eval/accuracy': 0.42857142857142855, 'eval/f1_weighted': 0.376984126984127, 'eval/recall_weighted': 0.42857142857142855, 'eval/f1_macro': 0.3833333333333333, 'test/f1_micro': 0.45794392523364486, 'test/accuracy': 0.45794392523364486, 'test/recall_micro': 0.45794392523364486, 'test/loss': 3.401240655547727, 'eval/f1_micro': 0.42857142857142855, 'eval/recall_macro': 0.42954545454545456, 'eval/recall_micro': 0.42857142857142855, 'test/precision_weighted': 0.4320980931715056}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 44, 'dt_min_samples_leaf': 5}",feasible-dew-881,DecisionTree,"['TfIdf', 'preprocessed']"
457,"{'test/f1_weighted': 0.363180181447828, 'test/f1_micro': 0.37383177570093457, 'eval/recall_macro': 0.3090909090909091, 'eval/precision_micro': 0.30952380952380953, '_step': 20, 'split': 10, 'eval/loss': 1.406877894694618, 'eval/precision_weighted': 0.35865457294028724, 'test/loss': 1.364829808990211, 'eval/f1_micro': 0.30952380952380953, 'test/precision_weighted': 0.3885576490579239, '_wandb': {'runtime': 1}, '_timestamp': 1704570533.9353185, 'eval/precision_macro': 0.35813492063492064, 'test/recall_weighted': 0.37383177570093457, 'eval/f1_macro': 0.30561038011695907, 'test/recall_macro': 0.3639112903225806, 'test/accuracy': 0.37383177570093457, 'test/f1_macro': 0.3552476711777343, 'eval/recall_micro': 0.30952380952380953, 'eval/recall_weighted': 0.30952380952380953, 'test/precision_micro': 0.37383177570093457, '_runtime': 3.0784385204315186, 'eval/accuracy': 0.30952380952380953, 'eval/f1_weighted': 0.3048471874129769, 'test/recall_micro': 0.37383177570093457, 'test/precision_macro': 0.38322192513368986}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 48, 'dt_min_samples_leaf': 40}",peachy-microwave-880,DecisionTree,"['BoW', 'preprocessed']"
458,"{'test/precision_micro': 0.4299065420560747, 'test/recall_weighted': 0.4299065420560747, 'test/precision_weighted': 0.5163676373203053, 'test/recall_macro': 0.4452477499352499, 'eval/recall_weighted': 0.3333333333333333, '_step': 20, 'test/loss': 1.324601970759042, 'test/f1_micro': 0.4299065420560747, 'eval/precision_micro': 0.3333333333333333, '_wandb': {'runtime': 2195}, 'eval/loss': 1.3345770887198465, 'eval/recall_micro': 0.3333333333333333, 'test/recall_micro': 0.4299065420560747, '_runtime': 2196.0362572669983, '_timestamp': 1704572726.8930862, 'eval/recall_macro': 0.33181818181818185, 'eval/f1_micro': 0.3333333333333333, 'test/f1_macro': 0.43093305402810506, 'eval/precision_weighted': 0.3817460317460317, 'test/f1_weighted': 0.4309275070784787, 'test/precision_macro': 0.4970912599944858, 'split': 10, 'test/accuracy': 0.4299065420560747, 'eval/f1_weighted': 0.34320793021981477, 'eval/precision_macro': 0.3833333333333333, 'eval/accuracy': 0.3333333333333333, 'eval/f1_macro': 0.343390398038106}","{'rf_max_depth': 2, 'trial.number': 0}",rich-glade-879,RandomForest,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
459,"{'split': 10, 'test/loss': 1.4133249629871143, 'eval/f1_macro': 0.21332565284178184, 'test/recall_micro': 0.3364485981308411, 'eval/accuracy': 0.21428571428571427, 'eval/recall_macro': 0.2159090909090909, 'eval/precision_micro': 0.21428571428571427, 'eval/precision_weighted': 0.2683673469387755, 'test/recall_weighted': 0.3364485981308411, '_step': 20, '_wandb': {'runtime': 1}, 'eval/loss': 1.5078524196618428, 'test/f1_micro': 0.3364485981308411, 'eval/f1_weighted': 0.21436343354546117, 'test/recall_macro': 0.3261476426799007, '_timestamp': 1704570526.713364, 'test/precision_macro': 0.3355602240896358, 'eval/recall_micro': 0.21428571428571427, 'eval/recall_weighted': 0.21428571428571427, '_runtime': 3.0695719718933105, 'eval/f1_micro': 0.21428571428571427, 'test/accuracy': 0.3364485981308411, 'test/f1_weighted': 0.3352614049512239, 'test/precision_micro': 0.3364485981308411, 'test/f1_macro': 0.3263319598452489, 'eval/precision_macro': 0.2642857142857143, 'test/precision_weighted': 0.3430278279536113}","{'dt_criterion': 'gini', 'dt_max_depth': 9, 'trial.number': 47, 'dt_min_samples_leaf': 32}",twilight-disco-878,DecisionTree,"['BoW', 'preprocessed']"
460,"{'eval/precision_micro': 0.4047619047619048, '_wandb': {'runtime': 2}, 'test/loss': 2.520795895843646, 'eval/accuracy': 0.4047619047619048, 'test/f1_micro': 0.514018691588785, 'test/precision_micro': 0.514018691588785, 'test/recall_weighted': 0.514018691588785, '_runtime': 4.134561777114868, 'test/f1_weighted': 0.5114210760546225, 'test/precision_macro': 0.5347085385878488, 'eval/f1_weighted': 0.40155430593289954, 'eval/precision_macro': 0.43105158730158727, 'eval/loss': 2.723401901976163, 'test/accuracy': 0.514018691588785, 'test/f1_macro': 0.5098370927318295, 'test/recall_macro': 0.5149135474997544, 'test/precision_weighted': 0.5384305510796004, '_step': 20, 'eval/f1_macro': 0.4037372843874392, 'eval/recall_macro': 0.40909090909090906, 'split': 10, 'eval/precision_weighted': 0.430035903250189, '_timestamp': 1704570526.5130568, 'eval/recall_micro': 0.4047619047619048, 'test/recall_micro': 0.514018691588785, 'eval/recall_weighted': 0.4047619047619048, 'eval/f1_micro': 0.4047619047619048}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 43, 'dt_min_samples_leaf': 7}",logical-dew-877,DecisionTree,"['TfIdf', 'preprocessed']"
461,"{'split': 10, 'eval/loss': 1.4089976425026407, 'eval/f1_micro': 0.2857142857142857, 'eval/f1_weighted': 0.281089380196523, 'eval/recall_micro': 0.2857142857142857, 'test/recall_micro': 0.38317757009345793, 'eval/accuracy': 0.2857142857142857, 'test/accuracy': 0.38317757009345793, 'test/f1_weighted': 0.374004845187714, 'test/precision_weighted': 0.39244316119173656, '_wandb': {'runtime': 1}, '_timestamp': 1704570519.5095768, 'test/f1_micro': 0.383177570093458, 'eval/recall_weighted': 0.2857142857142857, 'test/recall_weighted': 0.38317757009345793, 'eval/precision_micro': 0.2857142857142857, 'test/precision_macro': 0.3862917795844625, 'eval/precision_weighted': 0.32756991685563114, '_runtime': 3.098418712615967, 'eval/f1_macro': 0.2773313492063492, 'eval/precision_macro': 0.32688492063492064, 'test/precision_micro': 0.38317757009345793, '_step': 20, 'test/loss': 1.3533616937600823, 'test/f1_macro': 0.37209844918082374, 'eval/recall_macro': 0.27954545454545454, 'test/recall_macro': 0.38683829611248965}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 46, 'dt_min_samples_leaf': 46}",super-forest-876,DecisionTree,"['BoW', 'preprocessed']"
462,"{'eval/loss': 2.732897328875813, 'eval/precision_micro': 0.4523809523809524, 'test/precision_weighted': 0.46433780587825063, '_step': 20, 'eval/precision_macro': 0.4642857142857143, 'eval/precision_weighted': 0.4659863945578231, 'test/recall_macro': 0.4489777974260733, 'test/recall_micro': 0.4485981308411215, 'split': 10, 'test/f1_micro': 0.4485981308411215, 'eval/f1_weighted': 0.45194810698243193, 'test/precision_micro': 0.4485981308411215, '_wandb': {'runtime': 2}, 'eval/f1_micro': 0.4523809523809524, 'test/f1_macro': 0.4522156084656085, 'test/f1_weighted': 0.45311650101369727, 'test/recall_weighted': 0.4485981308411215, 'eval/accuracy': 0.4523809523809524, 'eval/f1_macro': 0.45097571828121025, 'test/accuracy': 0.4485981308411215, '_runtime': 3.9145255088806152, 'test/precision_macro': 0.4622012406495165, 'eval/recall_micro': 0.4523809523809524, 'eval/recall_weighted': 0.4523809523809524, 'test/loss': 3.3166719285538253, '_timestamp': 1704570516.0705514, 'eval/recall_macro': 0.45227272727272727}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 42, 'dt_min_samples_leaf': 10}",crisp-eon-875,DecisionTree,"['TfIdf', 'preprocessed']"
463,"{'test/recall_macro': 0.29934346567411085, '_step': 20, 'split': 10, '_wandb': {'runtime': 2}, '_timestamp': 1704570511.7618155, 'eval/accuracy': 0.23809523809523808, 'eval/f1_macro': 0.22574074074074071, 'eval/f1_micro': 0.23809523809523808, 'eval/f1_weighted': 0.22776014109347448, 'eval/recall_macro': 0.2340909090909091, 'test/recall_weighted': 0.29906542056074764, 'eval/recall_micro': 0.23809523809523808, 'eval/precision_micro': 0.23809523809523808, 'test/precision_macro': 0.3180884009009009, 'test/recall_micro': 0.29906542056074764, 'eval/precision_weighted': 0.288265306122449, 'test/precision_weighted': 0.3261092868569504, 'test/accuracy': 0.29906542056074764, 'test/f1_weighted': 0.3017388207052858, 'eval/precision_macro': 0.29107142857142854, 'test/precision_micro': 0.29906542056074764, '_runtime': 3.6016924381256104, 'eval/loss': 1.4736907298517885, 'test/f1_macro': 0.2982821916645446, 'eval/recall_weighted': 0.23809523809523808, 'test/loss': 1.440378413990885, 'test/f1_micro': 0.29906542056074764}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 45, 'dt_min_samples_leaf': 25}",wobbly-thunder-874,DecisionTree,"['BoW', 'preprocessed']"
464,"{'_runtime': 3.2761542797088623, '_timestamp': 1704570504.2267222, 'test/recall_micro': 0.514018691588785, 'eval/precision_micro': 0.4047619047619048, 'test/precision_macro': 0.5347085385878488, 'test/loss': 2.5160534154903043, 'test/accuracy': 0.514018691588785, 'eval/recall_macro': 0.40909090909090906, 'eval/recall_micro': 0.4047619047619048, 'test/recall_weighted': 0.514018691588785, 'eval/precision_weighted': 0.430035903250189, 'test/f1_macro': 0.5098370927318295, 'eval/f1_weighted': 0.40155430593289954, '_step': 20, 'split': 10, 'eval/f1_macro': 0.4037372843874392, 'eval/recall_weighted': 0.4047619047619048, 'test/f1_micro': 0.514018691588785, 'test/precision_weighted': 0.5384305510796004, 'eval/precision_macro': 0.43105158730158727, 'test/precision_micro': 0.514018691588785, '_wandb': {'runtime': 1}, 'eval/loss': 3.552942159806166, 'eval/accuracy': 0.4047619047619048, 'eval/f1_micro': 0.4047619047619048, 'test/f1_weighted': 0.5114210760546225, 'test/recall_macro': 0.5149135474997544}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 41, 'dt_min_samples_leaf': 7}",wild-brook-873,DecisionTree,"['TfIdf', 'preprocessed']"
465,"{'split': 10, 'eval/precision_weighted': 0.25314625850340133, '_wandb': {'runtime': 2210}, 'eval/f1_macro': 0.2548872180451128, 'test/f1_macro': 0.34462382513981205, 'eval/f1_weighted': 0.2543262919202769, 'test/accuracy': 0.35514018691588783, 'eval/precision_macro': 0.2526785714285714, 'test/loss': 14.019627778083214, 'eval/recall_macro': 0.26363636363636367, 'eval/recall_micro': 0.2619047619047619, 'eval/accuracy': 0.2619047619047619, 'test/precision_micro': 0.35514018691588783, '_timestamp': 1704572711.9048092, 'test/f1_weighted': 0.34786061677919405, 'test/precision_macro': 0.356359649122807, 'test/precision_weighted': 0.3614936874897524, 'test/recall_macro': 0.35410544727636184, 'test/recall_micro': 0.35514018691588783, 'eval/recall_weighted': 0.2619047619047619, '_step': 20, '_runtime': 2210.6079092025757, 'eval/loss': 16.08893674232243, 'eval/f1_micro': 0.2619047619047619, 'test/f1_micro': 0.35514018691588783, 'eval/precision_micro': 0.2619047619047619, 'test/recall_weighted': 0.35514018691588783}","{'smoothing': 0.7151921972924918, 'trial.number': 0}",vague-terrain-872,Bernolli,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
466,"{'test/loss': 1.3810715903995736, '_wandb': {'runtime': 2}, '_runtime': 3.5817856788635254, 'eval/loss': 1.4971431044040262, 'eval/recall_macro': 0.2590909090909091, 'test/recall_micro': 0.40186915887850466, 'eval/precision_macro': 0.24479166666666663, 'eval/precision_micro': 0.2619047619047619, 'split': 10, 'eval/f1_weighted': 0.24683657797692884, 'test/f1_weighted': 0.3784026578720579, 'test/recall_weighted': 0.40186915887850466, '_step': 20, 'eval/accuracy': 0.2619047619047619, 'eval/f1_macro': 0.24465598972177915, 'test/f1_micro': 0.40186915887850466, 'test/precision_macro': 0.3742063492063492, 'test/precision_micro': 0.40186915887850466, 'test/precision_weighted': 0.38040350096424863, 'eval/f1_micro': 0.2619047619047619, 'test/accuracy': 0.40186915887850466, 'eval/recall_weighted': 0.2619047619047619, 'eval/precision_weighted': 0.24652777777777776, 'test/recall_macro': 0.39025020678246486, '_timestamp': 1704570501.1545486, 'test/f1_macro': 0.3684119420006517, 'eval/recall_micro': 0.2619047619047619}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 44, 'dt_min_samples_leaf': 36}",balmy-lake-871,DecisionTree,"['BoW', 'preprocessed']"
467,"{'eval/loss': 1.5418833787231634, 'test/f1_macro': 0.3922210868216488, 'eval/recall_micro': 0.2857142857142857, 'eval/precision_macro': 0.2901785714285714, 'test/precision_micro': 0.40186915887850466, 'eval/precision_weighted': 0.2900510204081633, 'test/precision_macro': 0.3937825785651873, 'eval/f1_macro': 0.2848997493734336, 'test/f1_micro': 0.40186915887850466, 'eval/f1_weighted': 0.28338703902613677, 'test/recall_micro': 0.40186915887850466, 'eval/precision_micro': 0.2857142857142857, '_runtime': 3.788673639297486, 'test/accuracy': 0.40186915887850466, 'test/precision_weighted': 0.3959289518005487, '_step': 20, '_wandb': {'runtime': 2}, 'test/loss': 1.3808435789523876, '_timestamp': 1704570496.3762755, 'eval/accuracy': 0.2857142857142857, 'test/recall_weighted': 0.40186915887850466, 'split': 10, 'eval/f1_micro': 0.2857142857142857, 'test/f1_weighted': 0.39593490971348455, 'eval/recall_macro': 0.28863636363636364, 'test/recall_macro': 0.396349837901562, 'eval/recall_weighted': 0.2857142857142857}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 40, 'dt_min_samples_leaf': 32}",lilac-sponge-870,DecisionTree,"['TfIdf', 'preprocessed']"
468,"{'split': 10, 'eval/accuracy': 0.2857142857142857, 'eval/precision_macro': 0.3333333333333333, '_step': 20, 'eval/loss': 2.220772308979414, 'test/accuracy': 0.308411214953271, 'test/recall_micro': 0.308411214953271, 'test/precision_weighted': 0.3425547789209141, 'eval/f1_micro': 0.2857142857142857, 'eval/recall_micro': 0.2857142857142857, 'eval/f1_macro': 0.26190239867659215, 'eval/precision_micro': 0.2857142857142857, 'test/recall_weighted': 0.308411214953271, 'eval/precision_weighted': 0.3344671201814059, 'test/f1_macro': 0.3077846588439809, '_wandb': {'runtime': 2}, 'eval/f1_weighted': 0.2614943479459608, 'eval/recall_macro': 0.28863636363636364, 'test/precision_macro': 0.33603850193923723, '_runtime': 3.5875697135925293, 'test/f1_weighted': 0.31349068060615665, 'eval/recall_weighted': 0.2857142857142857, 'test/precision_micro': 0.308411214953271, 'test/loss': 2.3463964475212307, '_timestamp': 1704570492.9686136, 'test/f1_micro': 0.308411214953271, 'test/recall_macro': 0.30430624483043844}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 43, 'dt_min_samples_leaf': 20}",icy-butterfly-869,DecisionTree,"['BoW', 'preprocessed']"
469,"{'_runtime': 3.76861023902893, 'eval/recall_micro': 0.4523809523809524, 'test/recall_micro': 0.40186915887850466, 'test/recall_weighted': 0.40186915887850466, 'test/loss': 3.392212680806379, 'test/f1_micro': 0.40186915887850466, 'test/f1_weighted': 0.40037383177570096, 'test/accuracy': 0.40186915887850466, 'test/f1_macro': 0.3988888888888889, 'split': 10, 'eval/f1_macro': 0.4478610475464022, 'eval/recall_weighted': 0.4523809523809524, '_wandb': {'runtime': 2}, 'eval/f1_weighted': 0.4414674972455292, 'eval/precision_macro': 0.4495192307692307, 'eval/precision_micro': 0.4523809523809524, '_step': 20, 'eval/loss': 2.0502600585226136, 'eval/accuracy': 0.4523809523809524, 'test/precision_weighted': 0.4039460020768432, 'eval/precision_weighted': 0.44322344322344315, 'eval/f1_micro': 0.4523809523809524, 'eval/recall_macro': 0.45909090909090905, 'test/precision_macro': 0.4041666666666667, 'test/precision_micro': 0.40186915887850466, '_timestamp': 1704570486.1688192, 'test/recall_macro': 0.3986501620984379}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 39, 'dt_min_samples_leaf': 13}",faithful-sky-868,DecisionTree,"['TfIdf', 'preprocessed']"
470,"{'eval/recall_macro': 0.35909090909090907, '_runtime': 4.193308591842651, 'eval/accuracy': 0.35714285714285715, 'test/accuracy': 0.4205607476635514, 'test/f1_micro': 0.4205607476635514, 'test/recall_macro': 0.4110318444995864, 'split': 10, '_wandb': {'runtime': 1}, 'test/loss': 1.3877434012967198, '_timestamp': 1704570484.1857216, 'eval/f1_micro': 0.35714285714285715, 'test/recall_micro': 0.4205607476635514, '_step': 20, 'eval/loss': 1.443315568366891, 'eval/recall_micro': 0.35714285714285715, 'eval/f1_macro': 0.3417941405237231, 'test/precision_macro': 0.3914695945945946, 'test/precision_weighted': 0.39918540035362465, 'eval/f1_weighted': 0.3418686288792589, 'eval/precision_micro': 0.35714285714285715, 'eval/recall_weighted': 0.35714285714285715, 'test/f1_weighted': 0.3958241246058959, 'test/precision_micro': 0.4205607476635514, 'test/recall_weighted': 0.4205607476635514, 'test/f1_macro': 0.386001585955656, 'eval/precision_macro': 0.36644736842105263, 'eval/precision_weighted': 0.3668546365914787}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 42, 'dt_min_samples_leaf': 27}",elated-glitter-867,DecisionTree,"['BoW', 'preprocessed']"
471,"{'eval/recall_micro': 0.5, 'eval/loss': 2.6358429828777092, 'eval/accuracy': 0.5, 'eval/f1_weighted': 0.46447850395218826, 'test/precision_macro': 0.5488607859531773, 'test/precision_micro': 0.5046728971962616, '_timestamp': 1704570476.4723475, 'eval/recall_macro': 0.5045454545454545, '_step': 20, 'test/recall_macro': 0.4969127615679339, 'eval/precision_weighted': 0.532312925170068, 'test/recall_micro': 0.5046728971962616, 'eval/recall_weighted': 0.5, 'test/recall_weighted': 0.5046728971962616, 'test/precision_weighted': 0.5553832088269309, 'split': 10, '_runtime': 4.302684545516968, 'test/loss': 3.256355001939101, 'eval/f1_micro': 0.5, 'test/accuracy': 0.5046728971962616, 'test/f1_macro': 0.49550719550719546, 'test/f1_micro': 0.5046728971962616, 'test/f1_weighted': 0.5039230029884235, 'eval/precision_macro': 0.5369047619047619, 'eval/precision_micro': 0.5, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.4713562753036437}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 38, 'dt_min_samples_leaf': 5}",golden-snow-865,DecisionTree,"['TfIdf', 'preprocessed']"
472,"{'test/precision_macro': 0.3861062717770035, 'test/precision_micro': 0.411214953271028, 'eval/precision_micro': 0.2857142857142857, 'eval/recall_weighted': 0.2857142857142857, '_step': 20, '_wandb': {'runtime': 1}, 'eval/loss': 1.4452132447654031, 'eval/f1_micro': 0.2857142857142857, 'test/f1_micro': 0.411214953271028, 'eval/precision_macro': 0.29852941176470593, 'test/recall_weighted': 0.411214953271028, '_timestamp': 1704570475.7635095, 'test/accuracy': 0.411214953271028, 'test/f1_macro': 0.3772522292907049, 'split': 10, '_runtime': 6.4741106033325195, 'eval/accuracy': 0.2857142857142857, 'eval/f1_weighted': 0.2771023880046436, 'test/f1_weighted': 0.3873200770063171, 'eval/precision_weighted': 0.2972689075630252, 'eval/recall_micro': 0.2857142857142857, 'test/recall_micro': 0.411214953271028, 'test/precision_weighted': 0.39397245107297535, 'eval/recall_macro': 0.28409090909090906, 'test/recall_macro': 0.4014164598842018, 'test/loss': 1.3869957336331695, 'eval/f1_macro': 0.27676577808156755}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 41, 'dt_min_samples_leaf': 30}",efficient-flower-866,DecisionTree,"['BoW', 'preprocessed']"
473,"{'test/f1_micro': 0.37383177570093457, 'eval/recall_micro': 0.4047619047619048, '_step': 20, '_wandb': {'runtime': 1}, '_runtime': 3.214031219482422, 'eval/f1_macro': 0.40262515262515264, 'test/f1_macro': 0.3661954915003696, 'test/precision_micro': 0.37383177570093457, 'test/recall_weighted': 0.37383177570093457, 'test/precision_weighted': 0.5830242792859616, 'split': 10, 'test/accuracy': 0.37383177570093457, 'test/recall_micro': 0.37383177570093457, 'eval/recall_weighted': 0.4047619047619048, 'eval/precision_macro': 0.4479166666666667, 'test/loss': 1.914472418230628, 'eval/f1_micro': 0.4047619047619048, 'eval/recall_macro': 0.4022727272727273, 'eval/precision_weighted': 0.4424603174603175, 'eval/precision_micro': 0.4047619047619048, 'eval/loss': 3.6522601803502233, '_timestamp': 1704570466.199108, 'eval/accuracy': 0.4047619047619048, 'test/f1_weighted': 0.362778457011418, 'eval/f1_weighted': 0.4017675446246874, 'test/recall_macro': 0.3824314765694076, 'test/precision_macro': 0.5683862433862434}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 37, 'dt_min_samples_leaf': 8}",vital-water-864,DecisionTree,"['TfIdf', 'preprocessed']"
474,"{'eval/loss': 1.4989571577826235, 'test/loss': 1.3881037124640934, 'test/accuracy': 0.35514018691588783, 'test/f1_micro': 0.35514018691588783, 'test/f1_weighted': 0.32604057969907485, 'test/recall_weighted': 0.35514018691588783, 'split': 10, '_timestamp': 1704570465.1342676, 'eval/f1_micro': 0.21428571428571427, 'eval/precision_macro': 0.16636762360446572, 'eval/recall_weighted': 0.21428571428571427, 'test/precision_micro': 0.35514018691588783, '_wandb': {'runtime': 1}, 'test/recall_micro': 0.35514018691588783, 'test/precision_weighted': 0.39566117390420424, '_runtime': 3.087540626525879, 'eval/f1_macro': 0.18250517598343685, 'eval/precision_weighted': 0.1721253892306524, 'eval/accuracy': 0.21428571428571427, 'test/f1_macro': 0.3352155429124215, '_step': 20, 'eval/recall_macro': 0.2068181818181818, 'eval/f1_weighted': 0.1889283249531697, 'test/recall_macro': 0.3703473945409429, 'eval/precision_micro': 0.21428571428571427, 'test/precision_macro': 0.3892730216961394, 'eval/recall_micro': 0.21428571428571427}","{'dt_criterion': 'gini', 'dt_max_depth': 11, 'trial.number': 40, 'dt_min_samples_leaf': 40}",happy-fire-863,DecisionTree,"['BoW', 'preprocessed']"
475,"{'test/recall_micro': 0.40186915887850466, 'eval/recall_weighted': 0.2619047619047619, 'eval/precision_macro': 0.24479166666666663, 'test/precision_micro': 0.40186915887850466, '_runtime': 2.9915385246276855, '_timestamp': 1704570457.8285966, 'eval/accuracy': 0.2619047619047619, 'eval/f1_macro': 0.24465598972177915, 'eval/f1_micro': 0.2619047619047619, 'eval/recall_micro': 0.2619047619047619, '_step': 20, 'test/f1_macro': 0.3684119420006517, 'eval/precision_weighted': 0.24652777777777776, 'eval/loss': 1.4971431044040262, 'test/f1_micro': 0.40186915887850466, 'test/recall_weighted': 0.40186915887850466, 'test/precision_weighted': 0.38040350096424863, 'split': 10, 'eval/recall_macro': 0.2590909090909091, 'test/recall_macro': 0.39025020678246486, 'eval/precision_micro': 0.2619047619047619, 'test/precision_macro': 0.3742063492063492, 'test/loss': 1.3810715903995736, 'eval/f1_weighted': 0.24683657797692884, '_wandb': {'runtime': 1}, 'test/accuracy': 0.40186915887850466, 'test/f1_weighted': 0.3784026578720579}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 39, 'dt_min_samples_leaf': 33}",dandy-voice-862,DecisionTree,"['BoW', 'preprocessed']"
476,"{'_step': 20, 'test/f1_macro': 0.4134774851407814, 'test/recall_macro': 0.47259111897042927, 'eval/recall_weighted': 0.42857142857142855, 'test/loss': 3.0157211385215303, 'eval/f1_micro': 0.42857142857142855, 'test/f1_micro': 0.4672897196261683, 'eval/recall_macro': 0.42954545454545456, 'eval/f1_macro': 0.3644787644787645, 'eval/loss': 4.397954999636069, 'eval/accuracy': 0.42857142857142855, 'test/recall_micro': 0.4672897196261682, 'eval/precision_macro': 0.3729020979020979, 'test/precision_macro': 0.5250767884567306, 'test/recall_weighted': 0.4672897196261682, '_runtime': 4.046913146972656, 'eval/f1_weighted': 0.3587056444199301, 'eval/precision_micro': 0.42857142857142855, 'test/precision_micro': 0.4672897196261682, '_wandb': {'runtime': 2}, '_timestamp': 1704570457.7884402, 'test/accuracy': 0.4672897196261682, 'eval/precision_weighted': 0.3633866133866133, 'split': 10, 'test/f1_weighted': 0.4160505210182502, 'eval/recall_micro': 0.42857142857142855, 'test/precision_weighted': 0.5306644796726718}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 36, 'dt_min_samples_leaf': 6}",lunar-music-861,DecisionTree,"['TfIdf', 'preprocessed']"
477,"{'test/precision_micro': 0.38317757009345793, 'eval/accuracy': 0.42857142857142855, 'test/f1_micro': 0.383177570093458, 'eval/f1_weighted': 0.4326379674676888, 'eval/recall_micro': 0.42857142857142855, 'test/f1_macro': 0.3812602291325695, 'eval/recall_weighted': 0.42857142857142855, 'test/precision_weighted': 0.4324689068405328, 'eval/loss': 2.8656436041604243, 'eval/f1_micro': 0.42857142857142855, 'eval/precision_micro': 0.42857142857142855, 'eval/precision_weighted': 0.4559131344845631, 'test/loss': 2.5473584778894725, 'test/accuracy': 0.38317757009345793, 'test/f1_weighted': 0.381911069642229, 'test/recall_macro': 0.38451173985656745, 'test/precision_macro': 0.42998150917405575, '_step': 20, '_wandb': {'runtime': 2}, '_runtime': 3.7527105808258057, 'eval/recall_macro': 0.4272727272727273, 'test/recall_weighted': 0.38317757009345793, 'split': 10, 'eval/f1_macro': 0.43124355005159953, 'test/recall_micro': 0.38317757009345793, 'eval/precision_macro': 0.45467032967032966, '_timestamp': 1704570447.2123916}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 35, 'dt_min_samples_leaf': 9}",dark-silence-859,DecisionTree,"['TfIdf', 'preprocessed']"
478,"{'_step': 20, 'eval/accuracy': 0.30952380952380953, 'eval/precision_macro': 0.4097426470588236, 'test/precision_micro': 0.3177570093457944, '_runtime': 3.8989531993865967, 'eval/f1_micro': 0.30952380952380953, 'test/f1_macro': 0.32249742199624276, 'test/loss': 1.5091066440889702, 'eval/f1_macro': 0.3163919413919414, 'eval/recall_micro': 0.30952380952380953, 'test/recall_macro': 0.3186259305210918, 'test/precision_weighted': 0.3556767047421253, 'split': 10, 'test/f1_weighted': 0.32519078229711273, 'eval/precision_micro': 0.30952380952380953, 'eval/loss': 1.3979745349856256, 'test/f1_micro': 0.3177570093457944, 'test/precision_macro': 0.3502314814814815, 'eval/precision_weighted': 0.41228991596638653, '_timestamp': 1704570447.3650763, 'eval/recall_macro': 0.31136363636363634, 'eval/recall_weighted': 0.30952380952380953, 'test/recall_micro': 0.3177570093457944, 'test/recall_weighted': 0.3177570093457944, '_wandb': {'runtime': 2}, 'test/accuracy': 0.3177570093457944, 'eval/f1_weighted': 0.31595150880865164}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 38, 'dt_min_samples_leaf': 24}",resilient-water-859,DecisionTree,"['BoW', 'preprocessed']"
479,"{'eval/accuracy': 0.30952380952380953, 'test/recall_weighted': 0.27102803738317754, 'test/precision_weighted': 0.35480640854472634, 'test/loss': 1.3851343702402503, 'eval/f1_macro': 0.29166666666666663, 'test/accuracy': 0.27102803738317754, 'test/recall_macro': 0.31444998905269306, '_step': 20, 'test/f1_weighted': 0.24406568990297023, 'eval/precision_micro': 0.30952380952380953, 'test/precision_macro': 0.33035714285714285, 'test/f1_macro': 0.25671461057478373, 'test/f1_micro': 0.27102803738317754, 'eval/recall_weighted': 0.30952380952380953, 'eval/loss': 1.3497616343292054, '_timestamp': 1704572705.4649303, 'eval/precision_macro': 0.3596230158730158, 'test/precision_micro': 0.27102803738317754, 'eval/precision_weighted': 0.3557256235827665, 'eval/f1_weighted': 0.2936507936507936, 'eval/recall_micro': 0.30952380952380953, 'split': 10, '_wandb': {'runtime': 2263}, '_runtime': 2264.287305355072, 'eval/f1_micro': 0.30952380952380953, 'eval/recall_macro': 0.3041666666666667, 'test/recall_micro': 0.27102803738317754}",{'trial.number': 0},sandy-dawn-858,LogisticRegression,"['pre-trained:microsoft/codebert-base', 'preprocessed']"
480,"{'eval/f1_macro': 0.2773313492063492, 'test/f1_micro': 0.383177570093458, 'test/recall_weighted': 0.38317757009345793, 'eval/precision_macro': 0.32688492063492064, 'eval/precision_micro': 0.2857142857142857, '_wandb': {'runtime': 2}, '_timestamp': 1704570438.4726157, 'test/recall_micro': 0.38317757009345793, 'eval/loss': 1.4089976425026407, 'eval/f1_micro': 0.2857142857142857, 'test/accuracy': 0.38317757009345793, 'test/precision_macro': 0.3862917795844625, 'test/precision_micro': 0.38317757009345793, 'eval/precision_weighted': 0.32756991685563114, 'split': 10, 'test/f1_macro': 0.37209844918082374, 'eval/recall_micro': 0.2857142857142857, 'test/recall_macro': 0.38683829611248965, 'eval/recall_weighted': 0.2857142857142857, 'test/loss': 1.3533616937600823, 'eval/recall_macro': 0.27954545454545454, '_runtime': 3.4360854625701904, 'eval/f1_weighted': 0.281089380196523, 'test/precision_weighted': 0.39244316119173656, '_step': 20, 'eval/accuracy': 0.2857142857142857, 'test/f1_weighted': 0.374004845187714}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 37, 'dt_min_samples_leaf': 51}",cosmic-star-857,DecisionTree,"['BoW', 'preprocessed']"
481,"{'_wandb': {'runtime': 2}, 'eval/accuracy': 0.42857142857142855, 'eval/precision_macro': 0.46230158730158727, 'test/loss': 2.8086864944341365, 'test/f1_macro': 0.52121363969876, 'test/recall_macro': 0.5233750859612928, 'test/recall_micro': 0.5233644859813084, 'test/precision_macro': 0.5476190476190476, 'split': 10, 'eval/loss': 3.5291818093081977, 'test/f1_weighted': 0.5228372037596222, 'eval/recall_macro': 0.43181818181818177, 'eval/recall_weighted': 0.42857142857142855, 'test/precision_weighted': 0.5508455718736093, '_runtime': 3.899954319000244, 'test/f1_micro': 0.5233644859813084, 'eval/f1_weighted': 0.42912322823866383, 'test/recall_weighted': 0.5233644859813084, '_timestamp': 1704570437.1328604, 'eval/precision_micro': 0.42857142857142855, 'eval/f1_macro': 0.43005307386112335, 'eval/f1_micro': 0.42857142857142855, 'test/accuracy': 0.5233644859813084, 'eval/recall_micro': 0.42857142857142855, 'test/precision_micro': 0.5233644859813084, '_step': 20, 'eval/precision_weighted': 0.4627739984882842}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 34, 'dt_min_samples_leaf': 7}",usual-star-856,DecisionTree,"['TfIdf', 'preprocessed']"
482,"{'split': 10, 'eval/accuracy': 0.2619047619047619, 'test/f1_macro': 0.2390721487756528, 'test/f1_micro': 0.27102803738317754, 'eval/recall_weighted': 0.2619047619047619, 'test/recall_weighted': 0.27102803738317754, 'eval/precision_weighted': 0.20192743764172336, '_step': 20, 'eval/f1_macro': 0.21809104873621, 'eval/recall_micro': 0.2619047619047619, 'test/recall_macro': 0.28365384615384615, 'test/recall_micro': 0.27102803738317754, 'test/precision_weighted': 0.20584411089083987, 'test/f1_weighted': 0.2277916593859864, 'eval/precision_micro': 0.2619047619047619, 'eval/loss': 1.473443500286949, 'eval/f1_micro': 0.2619047619047619, 'test/accuracy': 0.27102803738317754, 'test/precision_micro': 0.27102803738317754, '_runtime': 3.66502046585083, 'test/loss': 1.4385008505235477, '_timestamp': 1704570431.4639184, 'eval/f1_weighted': 0.22079584521980836, 'test/precision_macro': 0.21639730639730637, '_wandb': {'runtime': 2}, 'eval/recall_macro': 0.26136363636363635, 'eval/precision_macro': 0.19816017316017315}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 36, 'dt_min_samples_leaf': 60}",misty-wave-855,DecisionTree,"['BoW', 'preprocessed']"
483,"{'eval/loss': 3.6003336985016183, '_timestamp': 1704570427.884485, 'test/f1_macro': 0.3617675941080196, 'split': 10, '_runtime': 3.864310979843139, 'eval/f1_macro': 0.3637218045112782, 'test/accuracy': 0.4205607476635514, 'eval/f1_micro': 0.42857142857142855, 'eval/precision_micro': 0.42857142857142855, 'test/recall_weighted': 0.4205607476635514, 'test/precision_weighted': 0.37850877733039456, 'test/f1_micro': 0.4205607476635514, 'eval/f1_weighted': 0.3583064804869316, 'test/precision_macro': 0.3706082564778217, 'eval/precision_weighted': 0.40115854771027176, 'test/precision_micro': 0.4205607476635514, '_wandb': {'runtime': 2}, 'test/loss': 2.4656510779554894, 'eval/recall_macro': 0.4272727272727273, 'test/recall_micro': 0.4205607476635514, 'test/f1_weighted': 0.364475580096976, 'eval/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.41259578544061304, 'test/recall_macro': 0.4258365261813538, 'eval/recall_weighted': 0.42857142857142855, '_step': 20, 'eval/accuracy': 0.42857142857142855}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 33, 'dt_min_samples_leaf': 6}",stilted-smoke-854,DecisionTree,"['TfIdf', 'preprocessed']"
484,"{'test/recall_macro': 0.39025020678246486, '_step': 20, 'eval/accuracy': 0.2619047619047619, 'eval/precision_weighted': 0.24652777777777776, 'test/precision_weighted': 0.38040350096424863, '_timestamp': 1704570423.274856, 'test/precision_macro': 0.3742063492063492, 'eval/precision_macro': 0.24479166666666663, 'test/precision_micro': 0.40186915887850466, '_wandb': {'runtime': 2}, 'eval/f1_micro': 0.2619047619047619, 'eval/precision_micro': 0.2619047619047619, 'test/recall_weighted': 0.40186915887850466, 'eval/loss': 1.4971431044040262, 'test/f1_micro': 0.40186915887850466, 'test/loss': 1.3810715903995736, 'eval/f1_macro': 0.24465598972177915, 'test/accuracy': 0.40186915887850466, 'test/f1_weighted': 0.3784026578720579, 'eval/recall_micro': 0.2619047619047619, 'test/recall_micro': 0.40186915887850466, 'split': 10, '_runtime': 3.671402931213379, 'eval/recall_weighted': 0.2619047619047619, 'eval/recall_macro': 0.2590909090909091, 'test/f1_macro': 0.3684119420006517, 'eval/f1_weighted': 0.24683657797692884}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 35, 'dt_min_samples_leaf': 37}",prime-smoke-853,DecisionTree,"['BoW', 'preprocessed']"
485,"{'eval/f1_micro': 0.42857142857142855, 'eval/recall_macro': 0.4318181818181818, 'test/precision_macro': 0.5436347517730497, 'eval/loss': 5.219313604130664, 'test/recall_macro': 0.4887788584340308, 'eval/precision_micro': 0.42857142857142855, 'eval/recall_weighted': 0.42857142857142855, 'test/loss': 3.6570768932306903, 'test/accuracy': 0.4953271028037383, 'test/f1_micro': 0.4953271028037383, 'eval/f1_weighted': 0.4303352920115414, 'test/f1_weighted': 0.5052914052327045, 'eval/precision_macro': 0.4624183006535948, '_step': 20, 'split': 10, 'eval/accuracy': 0.42857142857142855, 'eval/recall_micro': 0.42857142857142855, 'test/precision_micro': 0.4953271028037383, 'test/precision_weighted': 0.551414462782528, 'test/recall_weighted': 0.4953271028037383, 'eval/precision_weighted': 0.45930594460006224, '_runtime': 3.9964096546173096, 'test/recall_micro': 0.4953271028037383, '_wandb': {'runtime': 2}, '_timestamp': 1704570417.7934966, 'eval/f1_macro': 0.4340999557717824, 'test/f1_macro': 0.4976142092252556}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 32, 'dt_min_samples_leaf': 5}",lively-vortex-852,DecisionTree,"['TfIdf', 'preprocessed']"
486,"{'test/f1_micro': 0.4205607476635514, 'test/f1_weighted': 0.3958241246058959, 'test/precision_micro': 0.4205607476635514, 'split': 10, 'test/f1_macro': 0.386001585955656, 'eval/recall_micro': 0.35714285714285715, 'eval/precision_micro': 0.35714285714285715, '_timestamp': 1704570414.145963, 'eval/f1_macro': 0.3417941405237231, '_wandb': {'runtime': 1}, 'test/precision_macro': 0.3914695945945946, 'test/loss': 1.3877434012967198, 'eval/precision_macro': 0.36644736842105263, 'eval/precision_weighted': 0.3668546365914787, 'test/precision_weighted': 0.39918540035362465, '_runtime': 2.8957018852233887, 'eval/loss': 1.443315568366891, 'test/recall_micro': 0.4205607476635514, 'test/recall_weighted': 0.4205607476635514, '_step': 20, 'test/accuracy': 0.4205607476635514, 'test/recall_macro': 0.4110318444995864, 'eval/accuracy': 0.35714285714285715, 'eval/recall_macro': 0.35909090909090907, 'eval/recall_weighted': 0.35714285714285715, 'eval/f1_micro': 0.35714285714285715, 'eval/f1_weighted': 0.3418686288792589}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 34, 'dt_min_samples_leaf': 31}",floral-aardvark-851,DecisionTree,"['BoW', 'preprocessed']"
487,"{'_wandb': {'runtime': 1}, 'test/loss': 1.390899456307103, 'eval/precision_weighted': 0.32261904761904764, 'eval/loss': 1.4987498079010395, 'test/accuracy': 0.35514018691588783, 'test/precision_weighted': 0.3620552894054818, '_step': 20, 'test/f1_micro': 0.35514018691588783, 'eval/f1_weighted': 0.2611379377083961, 'eval/precision_micro': 0.2857142857142857, 'eval/f1_macro': 0.25925425734424035, 'test/f1_macro': 0.3279990026313555, 'eval/recall_macro': 0.28181818181818186, 'eval/precision_macro': 0.325, 'test/recall_weighted': 0.35514018691588783, '_runtime': 2.9090187549591064, 'test/recall_micro': 0.35514018691588783, 'test/f1_weighted': 0.33295889865433564, 'split': 10, 'eval/f1_micro': 0.2857142857142857, 'eval/recall_weighted': 0.2857142857142857, 'test/precision_micro': 0.35514018691588783, '_timestamp': 1704570407.7046866, 'eval/accuracy': 0.2857142857142857, 'eval/recall_micro': 0.2857142857142857, 'test/recall_macro': 0.35302936311000827, 'test/precision_macro': 0.35567226890756304}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 33, 'dt_min_samples_leaf': 27}",avid-valley-850,DecisionTree,"['BoW', 'preprocessed']"
488,"{'_step': 20, 'test/f1_macro': 0.4701550611483896, 'eval/precision_micro': 0.4047619047619048, 'split': 10, 'eval/f1_weighted': 0.3947579031612645, 'test/precision_micro': 0.48598130841121495, '_timestamp': 1704570407.447857, 'test/recall_macro': 0.48683662442283127, 'test/loss': 2.5742382300120368, 'test/precision_macro': 0.5050465838509316, '_runtime': 3.933038711547851, 'eval/accuracy': 0.4047619047619048, 'eval/recall_macro': 0.40909090909090906, 'test/recall_micro': 0.48598130841121495, 'eval/precision_weighted': 0.4217687074829932, '_wandb': {'runtime': 2}, 'eval/loss': 3.5307197618378305, 'eval/f1_macro': 0.3972498090145149, 'eval/recall_weighted': 0.4047619047619048, 'test/f1_micro': 0.48598130841121495, 'eval/recall_micro': 0.4047619047619048, 'eval/precision_macro': 0.4231601731601731, 'eval/f1_micro': 0.4047619047619048, 'test/accuracy': 0.48598130841121495, 'test/f1_weighted': 0.473145600488111, 'test/recall_weighted': 0.48598130841121495, 'test/precision_weighted': 0.5102794063582361}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 31, 'dt_min_samples_leaf': 7}",elated-plant-849,DecisionTree,"['TfIdf', 'preprocessed']"
489,"{'_runtime': 3.1528897285461426, 'test/f1_micro': 0.35514018691588783, 'eval/precision_macro': 0.2612637362637362, 'eval/precision_micro': 0.23809523809523808, 'test/loss': 1.435726481581742, 'eval/f1_micro': 0.23809523809523808, 'eval/recall_macro': 0.23636363636363633, 'eval/recall_micro': 0.23809523809523808, 'test/recall_macro': 0.3477305624483044, 'test/precision_macro': 0.35561342592592593, 'test/precision_micro': 0.35514018691588783, '_step': 20, 'eval/loss': 1.4448428282991728, 'test/f1_weighted': 0.35652459331747977, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.23809523809523808, 'test/recall_micro': 0.35514018691588783, 'eval/recall_weighted': 0.23809523809523808, 'test/recall_weighted': 0.35514018691588783, 'eval/precision_weighted': 0.25941915227629514, '_timestamp': 1704570398.7249236, 'test/accuracy': 0.35514018691588783, 'test/f1_macro': 0.3479722604954587, 'eval/f1_weighted': 0.23944444444444443, 'test/precision_weighted': 0.36491865697473175, 'split': 10, 'eval/f1_macro': 0.23916666666666664}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 32, 'dt_min_samples_leaf': 25}",eager-wind-848,DecisionTree,"['BoW', 'preprocessed']"
490,"{'eval/accuracy': 0.4047619047619048, 'eval/recall_macro': 0.4022727272727272, 'test/recall_macro': 0.414635032910895, 'test/precision_macro': 0.5137586082619834, 'eval/precision_weighted': 0.4607898715041572, 'test/accuracy': 0.411214953271028, 'eval/f1_weighted': 0.4114665356397432, 'test/f1_weighted': 0.4105950798483906, 'test/precision_micro': 0.411214953271028, 'test/recall_weighted': 0.411214953271028, 'eval/precision_micro': 0.4047619047619048, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.4125496075491666, 'eval/precision_macro': 0.4664682539682539, 'eval/recall_weighted': 0.4047619047619048, 'eval/f1_micro': 0.4047619047619048, 'test/f1_macro': 0.4101078953123861, 'test/f1_micro': 0.411214953271028, 'test/precision_weighted': 0.5210888251470809, '_step': 20, 'split': 10, '_runtime': 4.02781343460083, 'test/loss': 2.7186703037397546, '_timestamp': 1704570398.2963014, 'eval/recall_micro': 0.4047619047619048, 'eval/loss': 2.8039273173781645, 'test/recall_micro': 0.411214953271028}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 30, 'dt_min_samples_leaf': 8}",vibrant-sun-847,DecisionTree,"['TfIdf', 'preprocessed']"
491,"{'eval/loss': 0.8549692314635858, 'eval/precision_macro': 0.6982142857142857, 'eval/recall_weighted': 0.6904761904761905, 'test/precision_macro': 0.6244883040935673, 'split': 10, 'test/loss': 1.0281668441037275, '_timestamp': 1704570394.3135808, 'eval/f1_weighted': 0.6873182957393483, 'test/recall_macro': 0.607032967032967, 'eval/f1_macro': 0.6878947368421053, 'eval/recall_macro': 0.6909090909090909, 'test/recall_micro': 0.6074766355140186, '_runtime': 3.483132839202881, 'eval/accuracy': 0.6904761904761905, 'eval/f1_micro': 0.6904761904761905, 'test/f1_micro': 0.6074766355140186, 'test/f1_weighted': 0.6090612784806788, 'test/precision_weighted': 0.6241842925069683, '_wandb': {'runtime': 2}, 'test/accuracy': 0.6074766355140186, 'eval/recall_micro': 0.6904761904761905, 'test/precision_micro': 0.6074766355140186, 'eval/precision_weighted': 0.6981292517006803, '_step': 20, 'test/f1_macro': 0.6087091241077851, 'eval/precision_micro': 0.6904761904761905, 'test/recall_weighted': 0.6074766355140186}","{'rf_max_depth': 25, 'trial.number': 29}",ethereal-puddle-846,RandomForest,"['TfIdf', 'preprocessed']"
492,"{'test/accuracy': 0.35514018691588783, 'test/f1_macro': 0.3279990026313555, 'test/f1_micro': 0.35514018691588783, 'eval/precision_macro': 0.325, 'test/precision_micro': 0.35514018691588783, 'test/recall_weighted': 0.35514018691588783, '_runtime': 3.570647954940796, 'eval/precision_micro': 0.2857142857142857, 'test/precision_macro': 0.35567226890756304, 'test/precision_weighted': 0.3620552894054818, 'split': 10, 'eval/accuracy': 0.2857142857142857, 'eval/f1_micro': 0.2857142857142857, 'test/f1_weighted': 0.33295889865433564, 'test/recall_macro': 0.35302936311000827, '_step': 20, 'eval/f1_weighted': 0.2611379377083961, 'eval/f1_macro': 0.25925425734424035, 'test/recall_micro': 0.35514018691588783, 'eval/recall_micro': 0.2857142857142857, 'eval/precision_weighted': 0.32261904761904764, 'eval/loss': 1.4740611463180189, '_timestamp': 1704570390.9159698, 'eval/recall_macro': 0.28181818181818186, 'eval/recall_weighted': 0.2857142857142857, '_wandb': {'runtime': 2}, 'test/loss': 1.391647666042313}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 31, 'dt_min_samples_leaf': 29}",vague-shape-845,DecisionTree,"['BoW', 'preprocessed']"
493,"{'test/f1_micro': 0.48598130841121495, 'eval/f1_weighted': 0.3563893393614756, 'eval/recall_weighted': 0.35714285714285715, 'eval/f1_macro': 0.3599931200550396, 'test/f1_macro': 0.4921707728667133, 'eval/precision_micro': 0.35714285714285715, 'test/precision_weighted': 0.5549446399913689, '_wandb': {'runtime': 2}, 'test/precision_micro': 0.48598130841121495, 'test/loss': 4.249311032589994, '_timestamp': 1704570386.952151, 'test/recall_micro': 0.48598130841121495, 'eval/precision_macro': 0.3887061403508772, 'test/precision_macro': 0.5522005772005771, '_step': 20, 'split': 10, 'test/accuracy': 0.48598130841121495, 'eval/recall_micro': 0.35714285714285715, 'test/recall_macro': 0.4824584929757344, '_runtime': 4.075134992599487, 'test/f1_weighted': 0.4962602991577277, 'eval/accuracy': 0.35714285714285715, 'eval/recall_macro': 0.35909090909090907, 'test/recall_weighted': 0.48598130841121495, 'eval/loss': 4.437677806422663, 'eval/f1_micro': 0.35714285714285715, 'eval/precision_weighted': 0.3843984962406015}","{'dt_criterion': 'gini', 'dt_max_depth': 17, 'trial.number': 29, 'dt_min_samples_leaf': 6}",apricot-wildflower-843,DecisionTree,"['TfIdf', 'preprocessed']"
494,"{'eval/f1_micro': 0.6428571428571429, 'eval/recall_micro': 0.6428571428571429, 'eval/precision_weighted': 0.6785714285714286, 'split': 10, '_runtime': 3.198359966278076, 'test/f1_micro': 0.5420560747663551, 'eval/recall_weighted': 0.6428571428571429, 'eval/loss': 1.1377697154366249, 'test/loss': 1.1495548055299492, 'test/recall_micro': 0.5420560747663551, 'eval/precision_macro': 0.6840909090909091, 'test/accuracy': 0.5420560747663551, 'test/f1_weighted': 0.5410124354978808, 'test/recall_macro': 0.5424725274725275, 'test/precision_micro': 0.5420560747663551, 'eval/accuracy': 0.6428571428571429, 'eval/f1_macro': 0.6549732620320856, '_step': 20, 'eval/f1_weighted': 0.6522689075630252, 'test/precision_weighted': 0.5502851378049293, 'eval/recall_macro': 0.6431818181818182, 'test/precision_macro': 0.5516116941529234, 'test/f1_macro': 0.5417234826055818, 'eval/precision_micro': 0.6428571428571429, 'test/recall_weighted': 0.5420560747663551, '_wandb': {'runtime': 1}, '_timestamp': 1704570386.582134}","{'rf_max_depth': 15, 'trial.number': 28}",morning-aardvark-844,RandomForest,"['TfIdf', 'preprocessed']"
495,"{'test/recall_macro': 0.3155241935483871, 'eval/precision_macro': 0.325, 'eval/precision_micro': 0.2619047619047619, 'test/loss': 2.356644653533863, 'test/f1_weighted': 0.3211230793600507, 'eval/recall_macro': 0.2613636363636364, 'eval/f1_micro': 0.2619047619047619, 'test/accuracy': 0.3177570093457944, 'eval/f1_weighted': 0.25025010831462446, 'test/precision_micro': 0.3177570093457944, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.2496443341604632, 'test/precision_macro': 0.3460851648351648, 'test/recall_weighted': 0.3177570093457944, 'eval/precision_weighted': 0.3261904761904762, 'test/precision_weighted': 0.3522029372496662, 'eval/recall_weighted': 0.2619047619047619, '_runtime': 3.7453055381774902, 'test/f1_micro': 0.3177570093457944, 'test/recall_micro': 0.3177570093457944, 'eval/accuracy': 0.2619047619047619, 'test/f1_macro': 0.31623818448500657, 'split': 10, 'eval/loss': 2.350498698399196, '_timestamp': 1704570382.5929425, '_step': 20, 'eval/recall_micro': 0.2619047619047619}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 30, 'dt_min_samples_leaf': 21}",iconic-bee-842,DecisionTree,"['BoW', 'preprocessed']"
496,"{'eval/f1_macro': 0.817844611528822, 'test/recall_micro': 0.6074766355140186, 'eval/precision_macro': 0.85, 'eval/precision_micro': 0.8095238095238095, 'eval/recall_weighted': 0.8095238095238095, '_timestamp': 1704570376.6056292, 'test/f1_weighted': 0.6107872147188937, 'split': 10, 'test/f1_macro': 0.6119290192566055, 'eval/recall_macro': 0.8136363636363637, 'eval/precision_weighted': 0.8523809523809524, 'test/accuracy': 0.6074766355140186, 'eval/f1_micro': 0.8095238095238095, 'test/recall_macro': 0.6071153846153846, 'test/precision_weighted': 0.6222987374979505, '_runtime': 3.4330852031707764, 'test/loss': 0.9900598296706874, 'eval/recall_micro': 0.8095238095238095, 'test/precision_macro': 0.6254072681704261, 'test/precision_micro': 0.6074766355140186, 'eval/loss': 0.7979670171382665, 'eval/f1_weighted': 0.8170903449098939, 'test/recall_weighted': 0.6074766355140186, '_step': 20, 'test/f1_micro': 0.6074766355140186, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.8095238095238095}","{'rf_max_depth': 23, 'trial.number': 27}",pious-rain-841,RandomForest,"['TfIdf', 'preprocessed']"
497,"{'test/f1_macro': 0.5244510633200649, 'eval/precision_weighted': 0.430035903250189, 'test/precision_weighted': 0.5535199068843929, 'eval/precision_macro': 0.43105158730158727, '_step': 20, 'eval/accuracy': 0.4047619047619048, 'test/recall_macro': 0.5349135474997544, 'eval/f1_macro': 0.4037372843874392, 'test/precision_macro': 0.5502472527472527, 'test/recall_weighted': 0.5327102803738317, 'eval/f1_weighted': 0.40155430593289954, 'eval/recall_micro': 0.4047619047619048, 'eval/recall_weighted': 0.4047619047619048, '_runtime': 3.893621444702149, 'test/loss': 2.5288674018155337, 'eval/f1_micro': 0.4047619047619048, 'eval/recall_macro': 0.40909090909090906, 'test/recall_micro': 0.5327102803738317, 'split': 10, 'test/accuracy': 0.5327102803738317, 'test/f1_weighted': 0.5253721938849322, 'test/precision_micro': 0.5327102803738317, '_wandb': {'runtime': 2}, '_timestamp': 1704570376.5381644, 'eval/precision_micro': 0.4047619047619048, 'eval/loss': 3.532016582380121, 'test/f1_micro': 0.5327102803738317}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 28, 'dt_min_samples_leaf': 7}",genial-lake-840,DecisionTree,"['TfIdf', 'preprocessed']"
498,"{'test/f1_weighted': 0.27881920179233843, 'test/recall_micro': 0.27102803738317754, 'eval/precision_macro': 0.32291666666666663, 'test/precision_micro': 0.27102803738317754, 'eval/precision_micro': 0.30952380952380953, 'test/precision_macro': 0.28603383458646614, '_runtime': 3.196174144744873, 'test/loss': 2.076568453718568, '_timestamp': 1704570374.5108285, 'test/accuracy': 0.27102803738317754, 'test/f1_micro': 0.27102803738317754, 'eval/recall_micro': 0.30952380952380953, 'test/precision_weighted': 0.2937017778090085, 'eval/loss': 3.115826860244788, 'eval/f1_macro': 0.30643053340421755, 'eval/f1_micro': 0.30952380952380953, 'eval/f1_weighted': 0.30641207395593356, 'eval/recall_macro': 0.3090909090909091, 'split': 10, 'test/f1_macro': 0.2721945275285256, 'eval/recall_weighted': 0.30952380952380953, 'test/recall_weighted': 0.27102803738317754, 'eval/precision_weighted': 0.3224206349206349, '_step': 20, 'eval/accuracy': 0.30952380952380953, 'test/recall_macro': 0.26579301075268813, '_wandb': {'runtime': 1}}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 29, 'dt_min_samples_leaf': 15}",expert-water-839,DecisionTree,"['BoW', 'preprocessed']"
499,"{'_wandb': {'runtime': 2}, 'test/f1_weighted': 0.374004845187714, 'eval/recall_macro': 0.27954545454545454, 'eval/precision_macro': 0.32688492063492064, 'test/recall_weighted': 0.38317757009345793, '_step': 20, '_runtime': 4.746665954589844, 'eval/f1_micro': 0.2857142857142857, 'test/precision_macro': 0.3862917795844625, 'test/precision_weighted': 0.39244316119173656, 'eval/f1_weighted': 0.281089380196523, 'eval/recall_micro': 0.2857142857142857, 'test/recall_micro': 0.38317757009345793, 'eval/accuracy': 0.2857142857142857, 'eval/precision_micro': 0.2857142857142857, 'eval/precision_weighted': 0.32756991685563114, 'test/loss': 1.3533616937600823, '_timestamp': 1704570367.621791, 'test/f1_macro': 0.37209844918082374, 'test/f1_micro': 0.383177570093458, 'split': 10, 'eval/loss': 1.4089976425026407, 'test/recall_macro': 0.38683829611248965, 'eval/recall_weighted': 0.2857142857142857, 'test/precision_micro': 0.38317757009345793, 'eval/f1_macro': 0.2773313492063492, 'test/accuracy': 0.38317757009345793}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 28, 'dt_min_samples_leaf': 44}",flowing-sun-838,DecisionTree,"['BoW', 'preprocessed']"
500,"{'_runtime': 3.257110357284546, 'eval/f1_micro': 0.6428571428571429, 'eval/recall_weighted': 0.6428571428571429, 'test/recall_weighted': 0.6915887850467289, 'split': 10, 'eval/precision_macro': 0.6981792717086834, 'eval/loss': 0.9626410280078456, '_timestamp': 1704570366.1298974, 'test/precision_micro': 0.6915887850467289, 'eval/precision_weighted': 0.69781245831666, 'test/loss': 1.253380807638036, 'test/f1_macro': 0.690902063588089, 'eval/f1_weighted': 0.6516662025433956, 'eval/recall_macro': 0.65, 'eval/precision_micro': 0.6428571428571429, 'eval/f1_macro': 0.6553606237816764, 'eval/recall_micro': 0.6428571428571429, 'test/recall_macro': 0.6895329670329671, 'test/precision_macro': 0.6977627257799672, 'test/f1_micro': 0.6915887850467289, '_wandb': {'runtime': 1}, '_step': 20, 'test/accuracy': 0.6915887850467289, 'test/f1_weighted': 0.6914807339184428, 'test/recall_micro': 0.6915887850467289, 'test/precision_weighted': 0.6965900894679496, 'eval/accuracy': 0.6428571428571429}","{'rf_max_depth': 23, 'trial.number': 26}",amber-moon-837,RandomForest,"['TfIdf', 'preprocessed']"
501,"{'split': 10, '_runtime': 3.902644395828247, 'eval/f1_micro': 0.42857142857142855, 'eval/precision_macro': 0.4497076023391813, 'eval/recall_micro': 0.42857142857142855, 'test/precision_micro': 0.4392523364485981, '_timestamp': 1704570366.3121805, 'test/f1_micro': 0.4392523364485981, 'eval/recall_macro': 0.4272727272727273, 'test/recall_micro': 0.4392523364485981, 'eval/recall_weighted': 0.42857142857142855, 'test/precision_macro': 0.49226481288981294, 'test/precision_weighted': 0.502486884799969, 'eval/f1_weighted': 0.4126148705096074, 'test/f1_weighted': 0.4414772393272828, 'test/accuracy': 0.4392523364485981, 'test/f1_macro': 0.4391916416648672, 'test/recall_macro': 0.44176490814421854, 'eval/precision_micro': 0.42857142857142855, 'test/recall_weighted': 0.4392523364485981, '_wandb': {'runtime': 2}, 'test/loss': 2.704050508581488, 'eval/loss': 5.186384431596233, 'eval/accuracy': 0.42857142857142855, '_step': 20, 'eval/precision_weighted': 0.443609022556391, 'eval/f1_macro': 0.41491228070175434}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 27, 'dt_min_samples_leaf': 8}",sweet-tree-836,DecisionTree,"['TfIdf', 'preprocessed']"
502,"{'test/precision_macro': 0.4869297369297369, '_step': 20, '_wandb': {'runtime': 2}, 'test/f1_macro': 0.4521939427111841, 'eval/f1_weighted': 0.421485260770975, 'test/recall_micro': 0.45794392523364486, 'split': 10, 'test/precision_micro': 0.45794392523364486, 'eval/loss': 5.988857040534869, 'eval/f1_micro': 0.42857142857142855, 'eval/recall_micro': 0.42857142857142855, 'eval/precision_weighted': 0.4697802197802198, 'test/accuracy': 0.45794392523364486, 'eval/recall_weighted': 0.42857142857142855, '_runtime': 4.000269174575806, 'eval/accuracy': 0.42857142857142855, 'eval/precision_micro': 0.42857142857142855, 'test/recall_weighted': 0.45794392523364486, 'test/f1_weighted': 0.4519935478040537, 'eval/recall_macro': 0.4318181818181818, 'test/recall_macro': 0.4619166912270361, 'eval/precision_macro': 0.4768356643356643, 'test/precision_weighted': 0.4932544091422596, 'test/loss': 5.251697475994713, '_timestamp': 1704570356.1584733, 'eval/f1_macro': 0.4253246753246753, 'test/f1_micro': 0.45794392523364486}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 26, 'dt_min_samples_leaf': 6}",comfy-smoke-833,DecisionTree,"['TfIdf', 'preprocessed']"
503,"{'_step': 20, 'eval/loss': 1.4971431044040262, 'test/accuracy': 0.40186915887850466, '_runtime': 3.386357307434082, 'test/recall_macro': 0.39025020678246486, 'test/f1_micro': 0.40186915887850466, 'eval/precision_micro': 0.2619047619047619, 'test/precision_micro': 0.40186915887850466, 'test/precision_weighted': 0.38040350096424863, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.24465598972177915, 'test/recall_micro': 0.40186915887850466, 'test/f1_weighted': 0.3784026578720579, 'eval/recall_weighted': 0.2619047619047619, 'eval/precision_weighted': 0.24652777777777776, '_timestamp': 1704570355.9593043, 'eval/f1_micro': 0.2619047619047619, 'eval/recall_macro': 0.2590909090909091, 'eval/recall_micro': 0.2619047619047619, 'test/precision_macro': 0.3742063492063492, 'test/recall_weighted': 0.40186915887850466, 'split': 10, 'test/loss': 1.3810715903995736, 'eval/accuracy': 0.2619047619047619, 'test/f1_macro': 0.3684119420006517, 'eval/f1_weighted': 0.24683657797692884, 'eval/precision_macro': 0.24479166666666663}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 27, 'dt_min_samples_leaf': 33}",magic-donkey-834,DecisionTree,"['BoW', 'preprocessed']"
504,"{'_wandb': {'runtime': 1}, 'test/loss': 0.8435378571539447, 'test/f1_weighted': 0.6560857490411007, '_step': 20, 'test/accuracy': 0.6542056074766355, 'eval/accuracy': 0.6904761904761905, 'eval/recall_macro': 0.6931818181818182, 'test/recall_macro': 0.65, 'test/precision_micro': 0.6542056074766355, '_runtime': 3.3335540294647217, 'test/precision_macro': 0.6698495370370371, 'eval/f1_macro': 0.7001537110232763, 'test/f1_macro': 0.6542440221311021, 'test/f1_micro': 0.6542056074766355, 'eval/recall_weighted': 0.6904761904761905, 'test/recall_weighted': 0.6542056074766355, 'split': 10, 'eval/recall_micro': 0.6904761904761905, 'test/recall_micro': 0.6542056074766355, 'eval/f1_micro': 0.6904761904761905, 'eval/precision_micro': 0.6904761904761905, 'eval/f1_weighted': 0.6964573268921095, '_timestamp': 1704570355.996138, 'eval/precision_macro': 0.7140151515151515, 'eval/precision_weighted': 0.709054834054834, 'test/precision_weighted': 0.6687867774316373, 'eval/loss': 0.9066256186374924}","{'rf_max_depth': 32, 'trial.number': 25}",vague-armadillo-835,RandomForest,"['TfIdf', 'preprocessed']"
505,"{'eval/loss': 1.5811322581331777, 'test/recall_weighted': 0.3364485981308411, 'eval/recall_weighted': 0.2619047619047619, 'split': 10, 'eval/f1_micro': 0.2619047619047619, 'test/recall_micro': 0.3364485981308411, 'eval/precision_micro': 0.2619047619047619, 'test/precision_micro': 0.3364485981308411, 'test/f1_micro': 0.3364485981308411, 'eval/f1_weighted': 0.25611111111111107, 'test/f1_macro': 0.3297986147101256, 'test/recall_macro': 0.3284997932175352, 'test/precision_weighted': 0.3452090710319073, '_runtime': 3.730185031890869, 'eval/f1_macro': 0.2545833333333333, 'test/loss': 1.4395680746054185, 'eval/recall_micro': 0.2619047619047619, 'eval/accuracy': 0.2619047619047619, 'test/f1_weighted': 0.3384898202669416, 'eval/recall_macro': 0.26136363636363635, '_step': 20, '_wandb': {'runtime': 2}, 'eval/precision_weighted': 0.27154195011337867, '_timestamp': 1704570348.119859, 'test/accuracy': 0.3364485981308411, 'eval/precision_macro': 0.26904761904761904, 'test/precision_macro': 0.33611072847792695}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 26, 'dt_min_samples_leaf': 22}",toasty-snowflake-832,DecisionTree,"['BoW', 'preprocessed']"
506,"{'_wandb': {'runtime': 2}, 'eval/f1_micro': 0.7142857142857143, 'eval/loss': 0.8926093084089649, 'eval/recall_macro': 0.7113636363636364, 'eval/precision_macro': 0.7309343434343435, 'test/accuracy': 0.6448598130841121, 'eval/recall_micro': 0.7142857142857143, 'eval/precision_micro': 0.7142857142857143, 'eval/accuracy': 0.7142857142857143, 'test/f1_micro': 0.6448598130841121, 'test/recall_micro': 0.6448598130841121, 'test/precision_weighted': 0.6575295502988567, '_step': 20, 'test/recall_weighted': 0.6448598130841121, 'eval/precision_weighted': 0.7346560846560847, 'test/precision_macro': 0.6612838915470494, '_timestamp': 1704570346.1617656, 'eval/f1_weighted': 0.7225585609044256, 'eval/recall_weighted': 0.7142857142857143, 'eval/f1_macro': 0.7191843244474824, 'test/f1_macro': 0.6451037009438649, 'test/f1_weighted': 0.6447332989772089, 'test/recall_macro': 0.6421428571428571, 'test/precision_micro': 0.6448598130841121, 'split': 10, '_runtime': 3.722322463989258, 'test/loss': 0.9886900826770612}","{'rf_max_depth': 22, 'trial.number': 24}",electric-butterfly-831,RandomForest,"['TfIdf', 'preprocessed']"
507,"{'_wandb': {'runtime': 2}, '_runtime': 3.5131754875183105, 'test/precision_weighted': 0.5535199068843929, '_timestamp': 1704570344.4249544, 'test/accuracy': 0.5327102803738317, 'test/recall_micro': 0.5327102803738317, 'eval/loss': 2.7233448717268507, 'eval/accuracy': 0.4047619047619048, 'eval/f1_weighted': 0.40155430593289954, 'test/precision_micro': 0.5327102803738317, '_step': 20, 'test/f1_micro': 0.5327102803738317, 'eval/precision_macro': 0.43105158730158727, 'test/precision_macro': 0.5502472527472527, 'eval/f1_micro': 0.4047619047619048, 'eval/recall_micro': 0.4047619047619048, 'eval/precision_micro': 0.4047619047619048, 'eval/recall_weighted': 0.4047619047619048, 'test/recall_weighted': 0.5327102803738317, 'eval/precision_weighted': 0.430035903250189, 'eval/f1_macro': 0.4037372843874392, 'eval/recall_macro': 0.40909090909090906, 'test/recall_macro': 0.5349135474997544, 'test/f1_weighted': 0.5253721938849322, 'split': 10, 'test/loss': 2.525986080697267, 'test/f1_macro': 0.5244510633200649}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 25, 'dt_min_samples_leaf': 7}",sunny-wind-830,DecisionTree,"['TfIdf', 'preprocessed']"
508,"{'_runtime': 3.5132715702056885, 'eval/f1_weighted': 0.22502376631233256, 'test/recall_macro': 0.281870347394541, 'eval/loss': 3.0775303733276167, 'test/accuracy': 0.2897196261682243, 'test/precision_weighted': 0.29287236783547654, '_wandb': {'runtime': 2}, 'test/f1_macro': 0.2780008072528565, 'eval/recall_macro': 0.23636363636363633, 'eval/recall_micro': 0.23809523809523808, '_step': 20, '_timestamp': 1704570337.7093797, 'test/f1_weighted': 0.2860993495549954, 'eval/precision_micro': 0.23809523809523808, 'test/precision_micro': 0.2897196261682243, 'test/loss': 2.13722600269256, 'eval/f1_micro': 0.23809523809523808, 'test/recall_weighted': 0.2897196261682243, 'test/precision_macro': 0.28483709273182956, 'split': 10, 'eval/accuracy': 0.23809523809523808, 'eval/f1_macro': 0.22502268602540837, 'test/f1_micro': 0.2897196261682243, 'test/recall_micro': 0.2897196261682243, 'eval/precision_macro': 0.23402777777777775, 'eval/recall_weighted': 0.23809523809523808, 'eval/precision_weighted': 0.23247354497354497}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 25, 'dt_min_samples_leaf': 17}",robust-salad-828,DecisionTree,"['BoW', 'preprocessed']"
509,"{'_wandb': {'runtime': 2}, 'eval/recall_weighted': 0.7142857142857143, 'eval/precision_weighted': 0.7419217687074829, '_step': 20, '_timestamp': 1704570337.6391497, 'eval/f1_weighted': 0.7205513784461153, 'test/f1_macro': 0.6980087143392284, 'test/recall_macro': 0.7031318681318681, 'test/precision_weighted': 0.6950486170112338, 'split': 10, 'test/f1_weighted': 0.6959465811410673, 'test/recall_micro': 0.7009345794392523, 'test/recall_weighted': 0.7009345794392523, '_runtime': 3.4203407764434814, 'eval/loss': 0.7651212823882629, 'eval/accuracy': 0.7142857142857143, 'test/precision_macro': 0.6970959595959596, 'eval/recall_micro': 0.7142857142857143, 'test/precision_micro': 0.7009345794392523, 'eval/f1_macro': 0.7206937799043062, 'eval/precision_macro': 0.7406655844155845, 'test/loss': 1.1635522156715743, 'eval/f1_micro': 0.7142857142857143, 'test/accuracy': 0.7009345794392523, 'test/f1_micro': 0.7009345794392523, 'eval/recall_macro': 0.7159090909090909, 'eval/precision_micro': 0.7142857142857143}","{'rf_max_depth': 32, 'trial.number': 23}",apricot-disco-829,RandomForest,"['TfIdf', 'preprocessed']"
510,"{'eval/precision_macro': 0.5650252525252525, 'test/precision_macro': 0.7271664103986019, 'eval/loss': 1.142681864885907, 'eval/precision_weighted': 0.567881192881193, 'eval/f1_macro': 0.5485213032581454, 'test/recall_micro': 0.7102803738317757, '_runtime': 3.196768045425415, 'eval/recall_micro': 0.5476190476190477, 'test/recall_weighted': 0.7102803738317757, 'test/loss': 0.8717435381225543, 'test/f1_weighted': 0.7117051527690036, 'eval/recall_macro': 0.5454545454545454, 'test/f1_micro': 0.7102803738317757, 'eval/accuracy': 0.5476190476190477, 'test/accuracy': 0.7102803738317757, 'test/recall_macro': 0.7136964886964887, 'eval/recall_weighted': 0.5476190476190477, '_timestamp': 1704570335.2490652, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.5476190476190477, 'test/f1_macro': 0.7082779588195671, 'test/precision_weighted': 0.7390916457317604, 'split': 10, 'eval/f1_weighted': 0.5507721685165294, 'eval/precision_micro': 0.5476190476190477, 'test/precision_micro': 0.7102803738317757, '_step': 20}","{'rf_max_depth': 25, 'trial.number': 29}",smart-water-827,RandomForest,"['BoW', 'preprocessed']"
511,"{'eval/f1_macro': 0.4037372843874392, 'test/f1_weighted': 0.5253721938849322, 'eval/recall_macro': 0.40909090909090906, 'test/recall_micro': 0.5327102803738317, 'eval/precision_micro': 0.4047619047619048, 'test/precision_macro': 0.5502472527472527, 'split': 10, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.4047619047619048, 'eval/precision_macro': 0.43105158730158727, 'eval/recall_weighted': 0.4047619047619048, 'test/precision_micro': 0.5327102803738317, 'test/recall_weighted': 0.5327102803738317, 'test/loss': 2.5288674018155337, 'eval/recall_micro': 0.4047619047619048, 'eval/precision_weighted': 0.430035903250189, '_step': 20, '_timestamp': 1704570333.635486, 'test/precision_weighted': 0.5535199068843929, 'eval/loss': 3.532016582380121, 'eval/f1_micro': 0.4047619047619048, 'test/accuracy': 0.5327102803738317, 'test/f1_macro': 0.5244510633200649, 'eval/f1_weighted': 0.40155430593289954, 'test/recall_macro': 0.5349135474997544, '_runtime': 3.956295967102051, 'test/f1_micro': 0.5327102803738317}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 24, 'dt_min_samples_leaf': 7}",comic-cosmos-826,DecisionTree,"['TfIdf', 'preprocessed']"
512,"{'_wandb': {'runtime': 1}, 'eval/loss': 0.7811120350132705, 'test/accuracy': 0.6448598130841121, 'test/recall_micro': 0.6448598130841121, 'test/precision_weighted': 0.6518743946176602, '_timestamp': 1704570330.0378084, 'eval/precision_micro': 0.8095238095238095, 'test/precision_macro': 0.6538953081232493, 'test/recall_weighted': 0.6448598130841121, '_runtime': 3.054054498672486, 'test/loss': 0.887732854737864, 'eval/f1_weighted': 0.8128079861489473, 'eval/recall_micro': 0.8095238095238095, 'test/f1_macro': 0.6419822346891071, 'eval/recall_macro': 0.8136363636363636, 'split': 10, 'eval/f1_macro': 0.8144387236206458, 'eval/f1_micro': 0.8095238095238095, 'eval/precision_weighted': 0.8494897959183674, '_step': 20, 'test/f1_weighted': 0.642725004696928, 'eval/precision_macro': 0.8482142857142857, 'test/precision_micro': 0.6448598130841121, 'eval/accuracy': 0.8095238095238095, 'test/f1_micro': 0.6448598130841121, 'test/recall_macro': 0.6414560439560439, 'eval/recall_weighted': 0.8095238095238095}","{'rf_max_depth': 31, 'trial.number': 22}",denim-firefly-825,RandomForest,"['TfIdf', 'preprocessed']"
513,"{'_step': 20, 'eval/recall_macro': 0.44545454545454544, 'test/f1_macro': 0.5264382676147382, 'test/f1_micro': 0.5233644859813084, 'eval/f1_weighted': 0.4528852789722354, 'test/recall_micro': 0.5233644859813084, 'eval/precision_weighted': 0.5952380952380952, '_wandb': {'runtime': 2}, 'test/f1_weighted': 0.5292041187431119, 'test/recall_weighted': 0.5233644859813084, 'eval/accuracy': 0.4523809523809524, 'eval/f1_micro': 0.4523809523809524, 'eval/precision_micro': 0.4523809523809524, 'split': 10, 'eval/loss': 1.298982024196145, 'test/loss': 1.227283103035862, 'eval/recall_micro': 0.4523809523809524, 'eval/precision_macro': 0.6045454545454545, 'test/precision_weighted': 0.5677810381577534, '_timestamp': 1704570326.30618, 'eval/f1_macro': 0.45188000405391704, 'test/accuracy': 0.5233644859813084, '_runtime': 3.464102983474731, 'test/recall_macro': 0.5273689273689273, 'test/precision_macro': 0.5570823610751015, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_micro': 0.5233644859813084}","{'rf_max_depth': 10, 'trial.number': 28}",celestial-blaze-823,RandomForest,"['BoW', 'preprocessed']"
514,"{'_runtime': 3.4737253189086914, 'eval/accuracy': 0.35714285714285715, 'test/accuracy': 0.4205607476635514, 'eval/precision_micro': 0.35714285714285715, 'eval/recall_weighted': 0.35714285714285715, 'eval/f1_weighted': 0.3418686288792589, 'test/f1_weighted': 0.3958241246058959, '_step': 20, 'split': 10, 'eval/recall_macro': 0.35909090909090907, '_wandb': {'runtime': 2}, 'test/loss': 1.3877434012967198, 'test/recall_weighted': 0.4205607476635514, 'eval/precision_weighted': 0.3668546365914787, 'eval/f1_micro': 0.35714285714285715, 'test/recall_macro': 0.4110318444995864, 'test/precision_weighted': 0.39918540035362465, '_timestamp': 1704570326.3507333, 'eval/precision_macro': 0.36644736842105263, 'eval/loss': 1.443315568366891, 'eval/f1_macro': 0.3417941405237231, 'test/f1_micro': 0.4205607476635514, 'test/precision_micro': 0.4205607476635514, 'test/f1_macro': 0.386001585955656, 'eval/recall_micro': 0.35714285714285715, 'test/recall_micro': 0.4205607476635514, 'test/precision_macro': 0.3914695945945946}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 24, 'dt_min_samples_leaf': 28}",desert-planet-824,DecisionTree,"['BoW', 'preprocessed']"
515,"{'test/recall_micro': 0.5327102803738317, '_wandb': {'runtime': 2}, '_timestamp': 1704570321.7503066, 'eval/recall_macro': 0.40909090909090906, 'eval/precision_micro': 0.4047619047619048, '_step': 20, 'test/loss': 2.5288674018155337, 'eval/f1_micro': 0.4047619047619048, 'eval/f1_weighted': 0.40155430593289954, 'eval/recall_weighted': 0.4047619047619048, 'eval/loss': 2.7233448717268507, 'test/precision_macro': 0.5502472527472527, 'test/recall_weighted': 0.5327102803738317, 'test/precision_weighted': 0.5535199068843929, 'split': 10, '_runtime': 3.4162755012512207, 'test/accuracy': 0.5327102803738317, 'test/f1_macro': 0.5244510633200649, 'eval/accuracy': 0.4047619047619048, 'eval/f1_macro': 0.4037372843874392, 'eval/precision_macro': 0.43105158730158727, 'test/f1_micro': 0.5327102803738317, 'test/f1_weighted': 0.5253721938849322, 'eval/recall_micro': 0.4047619047619048, 'test/recall_macro': 0.5349135474997544, 'test/precision_micro': 0.5327102803738317, 'eval/precision_weighted': 0.430035903250189}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 23, 'dt_min_samples_leaf': 7}",floral-moon-822,DecisionTree,"['TfIdf', 'preprocessed']"
516,"{'_step': 20, 'test/loss': 0.9627381768164432, 'eval/recall_macro': 0.7340909090909091, 'test/recall_micro': 0.6635514018691588, 'eval/recall_weighted': 0.7380952380952381, '_runtime': 3.807112693786621, 'eval/loss': 0.8461811516101927, 'eval/f1_micro': 0.7380952380952381, 'test/f1_micro': 0.6635514018691588, 'eval/f1_weighted': 0.7379651815742042, 'eval/recall_micro': 0.7380952380952381, 'eval/precision_micro': 0.7380952380952381, 'test/precision_micro': 0.6635514018691588, 'eval/precision_weighted': 0.7544973544973546, 'test/precision_weighted': 0.6642309219939608, 'split': 10, '_timestamp': 1704570321.4039726, 'eval/accuracy': 0.7380952380952381, 'test/f1_macro': 0.6612154556487574, 'test/recall_macro': 0.6613736263736264, 'test/precision_macro': 0.6649065540194572, 'test/recall_weighted': 0.6635514018691588, '_wandb': {'runtime': 2}, 'eval/precision_macro': 0.7555555555555555, 'eval/f1_macro': 0.736585052374526, 'test/f1_weighted': 0.662028962983398, 'test/accuracy': 0.6635514018691588}","{'rf_max_depth': 26, 'trial.number': 21}",trim-sunset-821,RandomForest,"['TfIdf', 'preprocessed']"
517,"{'eval/f1_weighted': 0.5064247921390779, 'test/recall_weighted': 0.616822429906542, '_step': 20, 'test/f1_macro': 0.619357074540102, 'test/f1_weighted': 0.6284048626873916, 'eval/recall_micro': 0.5, 'eval/precision_macro': 0.5418067226890756, 'test/precision_micro': 0.616822429906542, '_runtime': 3.068826198577881, 'eval/f1_macro': 0.5071428571428571, 'test/recall_macro': 0.613413900913901, 'split': 10, 'test/loss': 1.0587266816652956, 'eval/accuracy': 0.5, 'test/f1_micro': 0.616822429906542, 'eval/recall_macro': 0.5, 'eval/loss': 1.250072055535854, '_timestamp': 1704570317.5298162, 'test/precision_weighted': 0.6593658181630551, 'test/accuracy': 0.616822429906542, 'test/recall_micro': 0.616822429906542, 'eval/f1_micro': 0.5, 'eval/precision_weighted': 0.5414165666266507, '_wandb': {'runtime': 1}, 'eval/recall_weighted': 0.5, 'eval/precision_micro': 0.5, 'test/precision_macro': 0.644100947361817}","{'rf_max_depth': 21, 'trial.number': 27}",peach-haze-820,RandomForest,"['BoW', 'preprocessed']"
518,"{'test/f1_weighted': 0.32551113523415365, 'eval/precision_macro': 0.4083333333333333, 'eval/precision_micro': 0.3333333333333333, 'test/accuracy': 0.3364485981308411, 'eval/f1_macro': 0.28058943089430893, 'test/recall_macro': 0.3450165425971877, 'test/recall_micro': 0.3364485981308411, 'test/loss': 1.3916557008061043, 'eval/accuracy': 0.3333333333333333, 'test/f1_macro': 0.3246665735957932, 'eval/f1_weighted': 0.2840301974448316, 'test/recall_weighted': 0.3364485981308411, 'split': 10, 'eval/recall_macro': 0.32500000000000007, 'test/precision_weighted': 0.4075960930363291, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.3364485981308411, 'eval/recall_micro': 0.3333333333333333, 'test/precision_macro': 0.40146439817492446, 'test/precision_micro': 0.3364485981308411, 'eval/precision_weighted': 0.40793650793650793, 'eval/loss': 1.4196703882284845, '_timestamp': 1704570317.1910112, 'eval/f1_micro': 0.3333333333333333, '_step': 20, '_runtime': 4.86891508102417, 'eval/recall_weighted': 0.3333333333333333}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 23, 'dt_min_samples_leaf': 20}",sparkling-dawn-819,DecisionTree,"['BoW', 'preprocessed']"
519,"{'eval/loss': 1.9355635816859025, 'test/recall_macro': 0.5105712741919639, 'split': 10, 'test/loss': 2.6418217712697425, 'eval/accuracy': 0.4523809523809524, 'test/accuracy': 0.514018691588785, 'eval/f1_micro': 0.4523809523809524, 'eval/recall_micro': 0.4523809523809524, '_runtime': 3.333038806915283, 'test/f1_micro': 0.514018691588785, 'eval/recall_macro': 0.45681818181818185, 'eval/recall_weighted': 0.4523809523809524, 'test/recall_weighted': 0.514018691588785, 'eval/precision_weighted': 0.4421296296296296, '_step': 20, 'eval/f1_macro': 0.4436802232854864, 'eval/f1_weighted': 0.4408939014202172, 'test/recall_micro': 0.514018691588785, 'eval/precision_micro': 0.4523809523809524, '_wandb': {'runtime': 2}, 'test/f1_macro': 0.5109313424024009, 'test/precision_micro': 0.514018691588785, '_timestamp': 1704570313.494532, 'test/precision_macro': 0.5118518518518519, 'test/precision_weighted': 0.5150709588092766, 'test/f1_weighted': 0.5142600899335281, 'eval/precision_macro': 0.4434974747474747}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 22, 'dt_min_samples_leaf': 11}",dulcet-galaxy-818,DecisionTree,"['TfIdf', 'preprocessed']"
520,"{'_runtime': 3.2696070671081543, 'test/loss': 1.2990841529348294, 'eval/f1_macro': 0.5501385336743392, 'test/recall_micro': 0.4672897196261682, 'eval/precision_macro': 0.5734126984126984, 'test/precision_weighted': 0.49743415463041635, 'test/accuracy': 0.4672897196261682, 'test/f1_micro': 0.4672897196261683, 'eval/recall_weighted': 0.5476190476190477, 'test/precision_macro': 0.5002272727272727, '_wandb': {'runtime': 1}, 'eval/loss': 1.2725924788161649, 'test/f1_weighted': 0.4712973501546944, '_timestamp': 1704570313.242417, 'eval/accuracy': 0.5476190476190477, 'test/precision_micro': 0.4672897196261682, 'eval/precision_weighted': 0.5752078609221466, 'eval/f1_micro': 0.5476190476190477, 'eval/f1_weighted': 0.5524093695449194, 'eval/recall_micro': 0.5476190476190477, 'test/recall_macro': 0.46546703296703296, 'eval/precision_micro': 0.5476190476190477, 'split': 10, 'test/f1_macro': 0.4718481989708404, 'eval/recall_macro': 0.5454545454545454, 'test/recall_weighted': 0.4672897196261682, '_step': 20}","{'rf_max_depth': 6, 'trial.number': 20}",fragrant-bird-817,RandomForest,"['TfIdf', 'preprocessed']"
521,"{'eval/precision_micro': 0.4047619047619048, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.4047619047619048, 'test/precision_micro': 0.6261682242990654, 'split': 10, 'test/recall_macro': 0.6226070226070226, 'test/loss': 1.0475495711902851, '_step': 20, 'test/f1_macro': 0.6296456636369231, 'test/f1_micro': 0.6261682242990654, 'eval/recall_weighted': 0.4047619047619048, 'test/precision_macro': 0.6747990383893021, 'test/recall_weighted': 0.6261682242990654, '_runtime': 3.0234391689300537, 'eval/loss': 1.195486153623886, 'eval/precision_macro': 0.4561051693404634, 'eval/precision_weighted': 0.450046685340803, 'test/accuracy': 0.6261682242990654, 'test/recall_micro': 0.6261682242990654, 'test/f1_weighted': 0.641299095909108, 'eval/recall_macro': 0.40454545454545454, 'eval/recall_micro': 0.4047619047619048, '_timestamp': 1704570309.2463422, 'eval/accuracy': 0.4047619047619048, 'test/precision_weighted': 0.6974219200338136, 'eval/f1_macro': 0.4163059163059163, 'eval/f1_weighted': 0.4136432350718065}","{'rf_max_depth': 15, 'trial.number': 26}",dulcet-tree-816,RandomForest,"['BoW', 'preprocessed']"
522,"{'eval/f1_weighted': 0.2771023880046436, 'test/f1_weighted': 0.3873200770063171, 'test/recall_weighted': 0.411214953271028, 'eval/precision_macro': 0.29852941176470593, 'test/precision_weighted': 0.39397245107297535, '_step': 20, '_runtime': 3.299048662185669, 'eval/recall_weighted': 0.2857142857142857, 'split': 10, 'eval/loss': 1.4452132447654031, 'test/recall_macro': 0.4014164598842018, 'test/recall_micro': 0.411214953271028, 'eval/precision_weighted': 0.2972689075630252, '_wandb': {'runtime': 1}, 'test/precision_micro': 0.411214953271028, 'test/loss': 1.3869957336331695, 'eval/accuracy': 0.2857142857142857, 'test/f1_macro': 0.3772522292907049, 'eval/recall_macro': 0.28409090909090906, 'eval/recall_micro': 0.2857142857142857, 'eval/f1_macro': 0.27676577808156755, 'test/accuracy': 0.411214953271028, 'test/precision_macro': 0.3861062717770035, '_timestamp': 1704570304.3240206, 'eval/f1_micro': 0.2857142857142857, 'test/f1_micro': 0.411214953271028, 'eval/precision_micro': 0.2857142857142857}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 22, 'dt_min_samples_leaf': 27}",hardy-bee-815,DecisionTree,"['BoW', 'preprocessed']"
523,"{'split': 10, '_timestamp': 1704570304.1842952, 'test/recall_macro': 0.4086501620984379, 'eval/precision_micro': 0.5, '_step': 20, 'eval/loss': 2.041905632376983, 'test/accuracy': 0.411214953271028, '_wandb': {'runtime': 2}, 'eval/precision_macro': 0.5002403846153846, 'eval/recall_weighted': 0.5, 'eval/recall_micro': 0.5, 'test/precision_macro': 0.4083333333333333, 'eval/precision_weighted': 0.4963598901098901, '_runtime': 4.189020156860352, 'eval/accuracy': 0.5, 'eval/recall_macro': 0.5045454545454545, 'test/precision_micro': 0.411214953271028, 'test/recall_weighted': 0.411214953271028, 'test/recall_micro': 0.411214953271028, 'test/loss': 3.3954772291975512, 'eval/f1_macro': 0.4831924315619968, 'eval/f1_micro': 0.5, 'test/f1_weighted': 0.40735224605892745, 'test/f1_macro': 0.4061470965197673, 'test/f1_micro': 0.411214953271028, 'eval/f1_weighted': 0.4784813281190092, 'test/precision_weighted': 0.4083073727933541}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 21, 'dt_min_samples_leaf': 14}",crimson-frog-813,DecisionTree,"['TfIdf', 'preprocessed']"
524,"{'test/f1_macro': 0.5630173521949015, 'eval/recall_macro': 0.6704545454545454, 'test/precision_weighted': 0.5733999374713875, '_runtime': 3.274115800857544, 'test/recall_micro': 0.5700934579439252, 'eval/precision_macro': 0.7013888888888888, 'test/precision_macro': 0.5737193847072879, 'eval/loss': 0.8149231020924119, 'eval/accuracy': 0.6666666666666666, 'test/accuracy': 0.5700934579439252, 'test/f1_micro': 0.5700934579439252, '_step': 20, '_wandb': {'runtime': 1}, 'eval/f1_weighted': 0.6738512949039265, 'split': 10, 'eval/f1_macro': 0.6750877192982456, 'eval/precision_weighted': 0.7025132275132275, '_timestamp': 1704570304.0348818, 'test/recall_macro': 0.567967032967033, 'eval/recall_weighted': 0.6666666666666666, 'test/precision_micro': 0.5700934579439252, 'eval/f1_micro': 0.6666666666666666, 'test/f1_weighted': 0.5640621190890867, 'eval/recall_micro': 0.6666666666666666, 'eval/precision_micro': 0.6666666666666666, 'test/loss': 1.0764959135799748, 'test/recall_weighted': 0.5700934579439252}","{'rf_max_depth': 23, 'trial.number': 19}",sleek-yogurt-814,RandomForest,"['TfIdf', 'preprocessed']"
525,"{'test/precision_micro': 0.6448598130841121, 'test/loss': 0.9967494721261048, 'eval/recall_macro': 0.6181818181818182, 'eval/recall_micro': 0.6190476190476191, 'test/recall_macro': 0.6375, 'eval/recall_weighted': 0.6190476190476191, 'test/precision_weighted': 0.6839562194870521, 'test/f1_micro': 0.6448598130841121, 'test/accuracy': 0.6448598130841121, 'test/precision_macro': 0.6666711287213536, '_wandb': {'runtime': 2}, 'test/recall_weighted': 0.6448598130841121, '_timestamp': 1704570302.1040704, 'test/f1_weighted': 0.6529397556800252, 'test/recall_micro': 0.6448598130841121, 'eval/precision_macro': 0.6678571428571429, 'eval/accuracy': 0.6190476190476191, 'eval/precision_weighted': 0.6649659863945578, 'eval/f1_macro': 0.6205318909172864, 'eval/f1_micro': 0.6190476190476191, 'test/f1_macro': 0.6415940388605923, 'eval/f1_weighted': 0.6189885916052245, 'eval/precision_micro': 0.6190476190476191, '_step': 20, '_runtime': 4.069476366043091, 'eval/loss': 1.046847292530242, 'split': 10}","{'rf_max_depth': 23, 'trial.number': 25}",good-dew-812,RandomForest,"['BoW', 'preprocessed']"
526,"{'test/precision_macro': 0.3861062717770035, 'test/recall_weighted': 0.411214953271028, 'eval/recall_micro': 0.2857142857142857, 'test/precision_weighted': 0.39397245107297535, 'split': 10, '_wandb': {'runtime': 1}, 'test/f1_macro': 0.3772522292907049, 'eval/precision_weighted': 0.2972689075630252, '_step': 20, 'eval/f1_macro': 0.27676577808156755, 'eval/precision_macro': 0.29852941176470593, 'eval/recall_weighted': 0.2857142857142857, 'test/f1_micro': 0.411214953271028, 'eval/precision_micro': 0.2857142857142857, 'eval/loss': 1.4452132447654031, 'test/loss': 1.3869957336331695, '_timestamp': 1704570296.7167845, 'eval/f1_micro': 0.2857142857142857, '_runtime': 2.9608373641967773, 'test/recall_micro': 0.411214953271028, 'test/f1_weighted': 0.3873200770063171, 'test/recall_macro': 0.4014164598842018, 'test/precision_micro': 0.411214953271028, 'eval/accuracy': 0.2857142857142857, 'test/accuracy': 0.411214953271028, 'eval/f1_weighted': 0.2771023880046436, 'eval/recall_macro': 0.28409090909090906}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 21, 'dt_min_samples_leaf': 28}",expert-haze-811,DecisionTree,"['BoW', 'preprocessed']"
527,"{'test/recall_weighted': 0.616822429906542, 'split': 10, 'test/precision_weighted': 0.6256777549667731, 'eval/f1_macro': 0.6889506374632233, 'eval/f1_micro': 0.6904761904761905, 'test/accuracy': 0.616822429906542, 'eval/recall_macro': 0.6931818181818181, 'test/recall_macro': 0.618489010989011, 'eval/precision_micro': 0.6904761904761905, '_runtime': 3.762629985809326, 'test/loss': 1.0258621675978208, 'eval/precision_macro': 0.6950757575757576, '_wandb': {'runtime': 2}, 'eval/recall_micro': 0.6904761904761905, '_step': 20, 'eval/f1_weighted': 0.6877442052335808, 'test/f1_weighted': 0.6105816387876679, 'eval/recall_weighted': 0.6904761904761905, 'eval/precision_weighted': 0.6957070707070707, '_timestamp': 1704570296.270331, 'eval/accuracy': 0.6904761904761905, 'test/f1_macro': 0.6109798305287026, 'test/precision_macro': 0.62444093434205, 'eval/loss': 0.9496462393874248, 'test/f1_micro': 0.616822429906542, 'test/recall_micro': 0.616822429906542, 'test/precision_micro': 0.616822429906542}","{'rf_max_depth': 18, 'trial.number': 18}",trim-bird-810,RandomForest,"['TfIdf', 'preprocessed']"
528,"{'eval/precision_macro': 0.5909090909090909, 'test/precision_weighted': 0.7343003231361622, 'eval/recall_micro': 0.5, 'test/precision_macro': 0.7220173395445135, 'eval/f1_macro': 0.507725279106858, 'test/f1_macro': 0.659964962319977, 'test/f1_micro': 0.6542056074766355, 'eval/f1_weighted': 0.5051169590643274, 'eval/recall_macro': 0.4977272727272727, 'test/recall_micro': 0.6542056074766355, 'split': 10, '_runtime': 3.428208112716675, 'test/precision_micro': 0.6542056074766355, 'test/f1_weighted': 0.663711908069409, '_timestamp': 1704570293.256515, 'eval/accuracy': 0.5, 'eval/f1_micro': 0.5, 'eval/recall_weighted': 0.5, '_step': 20, 'test/loss': 1.0884449605359592, '_wandb': {'runtime': 2}, 'test/recall_macro': 0.6546717171717171, 'eval/precision_micro': 0.5, 'test/recall_weighted': 0.6542056074766355, 'eval/precision_weighted': 0.5833333333333334, 'eval/loss': 1.2084393522014223, 'test/accuracy': 0.6542056074766355}","{'rf_max_depth': 17, 'trial.number': 24}",laced-universe-809,RandomForest,"['BoW', 'preprocessed']"
529,"{'test/f1_macro': 0.4522156084656085, 'eval/recall_macro': 0.45227272727272727, 'test/recall_macro': 0.4489777974260733, '_runtime': 5.001293420791626, '_timestamp': 1704570293.4802644, 'test/precision_micro': 0.4485981308411215, 'eval/precision_micro': 0.4523809523809524, 'eval/precision_weighted': 0.4659863945578231, 'test/f1_weighted': 0.45311650101369727, 'test/recall_micro': 0.4485981308411215, 'test/f1_micro': 0.4485981308411215, 'test/recall_weighted': 0.4485981308411215, 'split': 10, 'eval/f1_micro': 0.4523809523809524, 'test/precision_weighted': 0.46433780587825063, '_step': 20, 'eval/accuracy': 0.4523809523809524, 'eval/precision_macro': 0.4642857142857143, 'eval/f1_macro': 0.45097571828121025, 'eval/recall_micro': 0.4523809523809524, 'test/precision_macro': 0.4622012406495165, 'eval/loss': 2.7303887451696744, 'eval/recall_weighted': 0.4523809523809524, 'test/accuracy': 0.4485981308411215, 'eval/f1_weighted': 0.45194810698243193, '_wandb': {'runtime': 2}, 'test/loss': 3.320610639419539}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 20, 'dt_min_samples_leaf': 10}",efficient-plant-808,DecisionTree,"['TfIdf', 'preprocessed']"
530,"{'eval/precision_micro': 0.2857142857142857, 'eval/recall_weighted': 0.2857142857142857, 'split': 10, 'eval/loss': 1.4452132447654031, 'test/loss': 1.3869957336331695, 'test/f1_micro': 0.411214953271028, 'test/recall_micro': 0.411214953271028, '_wandb': {'runtime': 1}, 'eval/recall_micro': 0.2857142857142857, '_timestamp': 1704570289.5001354, 'test/f1_macro': 0.3772522292907049, 'test/precision_macro': 0.3861062717770035, 'test/precision_weighted': 0.39397245107297535, 'eval/f1_weighted': 0.2771023880046436, '_runtime': 2.974642515182495, 'eval/f1_macro': 0.27676577808156755, 'test/precision_micro': 0.411214953271028, '_step': 20, 'eval/recall_macro': 0.28409090909090906, 'eval/precision_weighted': 0.2972689075630252, 'test/recall_weighted': 0.411214953271028, 'eval/accuracy': 0.2857142857142857, 'test/accuracy': 0.411214953271028, 'test/f1_weighted': 0.3873200770063171, 'test/recall_macro': 0.4014164598842018, 'eval/precision_macro': 0.29852941176470593, 'eval/f1_micro': 0.2857142857142857}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 20, 'dt_min_samples_leaf': 29}",dry-vortex-807,DecisionTree,"['BoW', 'preprocessed']"
531,"{'eval/loss': 0.7975623700214727, 'eval/precision_micro': 0.8333333333333334, 'test/recall_weighted': 0.6728971962616822, 'eval/recall_weighted': 0.8333333333333334, 'test/precision_micro': 0.6728971962616822, '_timestamp': 1704570286.1631265, 'test/accuracy': 0.6728971962616822, 'test/f1_weighted': 0.6774798627439358, 'test/recall_micro': 0.6728971962616822, '_runtime': 3.8466405868530273, 'test/f1_micro': 0.6728971962616822, 'eval/f1_weighted': 0.8403258145363408, 'eval/recall_macro': 0.8340909090909091, 'test/recall_macro': 0.6692307692307692, 'eval/precision_weighted': 0.8588435374149659, 'test/precision_weighted': 0.6930524223869373, 'split': 10, 'test/loss': 0.8836954423757132, 'eval/f1_micro': 0.8333333333333334, '_step': 20, 'test/f1_macro': 0.6756631933957515, 'eval/recall_micro': 0.8333333333333334, 'eval/accuracy': 0.8333333333333334, 'eval/precision_macro': 0.8607142857142858, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.841842105263158, 'test/precision_macro': 0.6936704638752053}","{'rf_max_depth': 31, 'trial.number': 17}",earthy-feather-806,RandomForest,"['TfIdf', 'preprocessed']"
532,"{'_wandb': {'runtime': 2}, 'eval/precision_macro': 0.6650210084033613, 'test/precision_weighted': 0.7644406683659019, 'eval/precision_weighted': 0.6621648659463786, '_timestamp': 1704570281.806679, 'eval/f1_macro': 0.6154761904761904, 'test/f1_micro': 0.7476635514018691, 'eval/precision_micro': 0.5952380952380952, 'eval/f1_micro': 0.5952380952380952, 'eval/recall_micro': 0.5952380952380952, 'test/recall_macro': 0.7509078884078885, 'test/recall_micro': 0.7476635514018691, 'test/loss': 0.932720432810214, 'test/f1_macro': 0.7443607329438712, 'test/precision_micro': 0.7476635514018691, '_step': 20, 'eval/loss': 1.1493298551341191, 'test/accuracy': 0.7476635514018691, 'eval/recall_weighted': 0.5952380952380952, 'test/f1_weighted': 0.7472919516299761, 'eval/recall_macro': 0.5977272727272727, 'test/precision_macro': 0.7546969696969696, 'test/recall_weighted': 0.7476635514018691, 'split': 10, '_runtime': 3.4405629634857178, 'eval/accuracy': 0.5952380952380952, 'eval/f1_weighted': 0.6122448979591836}","{'rf_max_depth': 25, 'trial.number': 23}",flowing-blaze-805,RandomForest,"['BoW', 'preprocessed']"
533,"{'_wandb': {'runtime': 2}, 'eval/loss': 2.0762947683250936, 'eval/accuracy': 0.47619047619047616, 'eval/f1_micro': 0.47619047619047616, 'test/accuracy': 0.40186915887850466, 'test/precision_weighted': 0.398910302303232, 'test/loss': 3.441118744563969, 'eval/recall_macro': 0.4818181818181818, 'eval/recall_micro': 0.47619047619047616, 'test/recall_micro': 0.40186915887850466, 'eval/precision_weighted': 0.469078144078144, 'split': 10, 'test/f1_weighted': 0.39825512030224697, 'test/recall_macro': 0.3986501620984379, 'test/precision_micro': 0.40186915887850466, 'test/recall_weighted': 0.40186915887850466, 'eval/f1_macro': 0.4652709467287473, 'eval/precision_macro': 0.47419871794871793, 'eval/f1_weighted': 0.4597064392460811, 'eval/precision_micro': 0.47619047619047616, '_timestamp': 1704570282.1452212, 'test/precision_macro': 0.39842132505175987, '_runtime': 3.90705132484436, 'eval/recall_weighted': 0.47619047619047616, '_step': 20, 'test/f1_macro': 0.3964686761229314, 'test/f1_micro': 0.40186915887850466}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 19, 'dt_min_samples_leaf': 16}",peachy-shape-803,DecisionTree,"['TfIdf', 'preprocessed']"
534,"{'eval/f1_micro': 0.23809523809523808, 'test/precision_micro': 0.3364485981308411, 'eval/precision_weighted': 0.23378684807256236, '_runtime': 3.5358333587646484, 'eval/accuracy': 0.23809523809523808, 'eval/f1_macro': 0.22048611111111108, 'test/f1_weighted': 0.28549856080118935, 'eval/precision_macro': 0.23452380952380952, 'eval/recall_weighted': 0.23809523809523808, '_step': 20, 'test/loss': 1.3852474631845575, 'split': 10, 'test/recall_micro': 0.3364485981308411, 'test/recall_weighted': 0.3364485981308411, 'test/precision_weighted': 0.26703644606539517, '_wandb': {'runtime': 2}, 'eval/loss': 1.4185242093039472, '_timestamp': 1704570281.8787963, 'test/f1_micro': 0.3364485981308411, 'eval/recall_micro': 0.23809523809523808, 'eval/precision_micro': 0.23809523809523808, 'test/accuracy': 0.3364485981308411, 'test/recall_macro': 0.33100703060380476, 'test/precision_macro': 0.26314363143631436, 'test/f1_macro': 0.2805100227115631, 'eval/f1_weighted': 0.22040343915343913, 'eval/recall_macro': 0.2363636363636364}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 19, 'dt_min_samples_leaf': 43}",noble-donkey-804,DecisionTree,"['BoW', 'preprocessed']"
535,"{'_runtime': 3.65989089012146, 'test/loss': 1.2308226355936678, 'eval/recall_weighted': 0.5952380952380952, 'test/precision_micro': 0.4299065420560747, '_step': 20, '_timestamp': 1704570277.7903528, 'eval/f1_micro': 0.5952380952380952, 'test/recall_macro': 0.4307417582417582, 'test/precision_macro': 0.4630122599723326, 'test/precision_weighted': 0.46598943570465184, 'eval/f1_weighted': 0.5779054916985951, 'eval/precision_weighted': 0.6011904761904762, '_wandb': {'runtime': 2}, 'eval/loss': 1.0808828392172447, 'test/f1_weighted': 0.4401175183202785, 'test/recall_weighted': 0.4299065420560747, 'test/accuracy': 0.4299065420560747, 'test/f1_micro': 0.4299065420560747, 'eval/recall_macro': 0.5886363636363636, 'eval/recall_micro': 0.5952380952380952, 'eval/precision_micro': 0.5952380952380952, 'test/f1_macro': 0.4392879591907369, 'eval/precision_macro': 0.602840909090909, 'split': 10, 'eval/f1_macro': 0.5753744339951236, 'eval/accuracy': 0.5952380952380952, 'test/recall_micro': 0.4299065420560747}","{'rf_max_depth': 13, 'trial.number': 16}",cerulean-bird-802,RandomForest,"['TfIdf', 'preprocessed']"
536,"{'test/loss': 0.9068666569063528, 'test/accuracy': 0.6635514018691588, 'eval/precision_micro': 0.6428571428571429, 'test/recall_weighted': 0.6635514018691588, 'eval/recall_micro': 0.6428571428571429, 'test/recall_micro': 0.6635514018691588, 'eval/recall_weighted': 0.6428571428571429, 'test/precision_micro': 0.6635514018691588, '_runtime': 3.7667531967163086, 'eval/loss': 1.0202769866864276, 'eval/accuracy': 0.6428571428571429, 'eval/f1_macro': 0.6510319917440659, 'test/f1_macro': 0.6641227875029547, 'eval/recall_macro': 0.640909090909091, 'split': 10, '_timestamp': 1704570271.9137151, 'eval/precision_macro': 0.7077067669172932, 'eval/precision_weighted': 0.703141783029001, 'test/precision_weighted': 0.6835843835694453, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.6635514018691588, 'test/f1_weighted': 0.6687253680602563, 'test/precision_macro': 0.6745553634473086, '_step': 20, 'eval/f1_micro': 0.6428571428571429, 'eval/f1_weighted': 0.6493537765983586, 'test/recall_macro': 0.662584175084175}","{'rf_max_depth': 24, 'trial.number': 22}",worldly-yogurt-800,RandomForest,"['BoW', 'preprocessed']"
537,"{'test/recall_weighted': 0.4485981308411215, 'split': 10, '_wandb': {'runtime': 2}, 'test/f1_macro': 0.4528236873626678, 'eval/recall_micro': 0.380952380952381, 'eval/f1_macro': 0.3726675285498815, 'eval/f1_micro': 0.380952380952381, 'test/f1_micro': 0.4485981308411215, 'eval/precision_macro': 0.3763347763347763, 'test/precision_macro': 0.4819717987306157, '_step': 20, 'eval/accuracy': 0.380952380952381, 'eval/loss': 2.910284211326787, '_timestamp': 1704570271.6921482, 'test/recall_micro': 0.4485981308411215, 'eval/precision_micro': 0.380952380952381, 'test/precision_micro': 0.4485981308411215, 'eval/f1_weighted': 0.3706723715127076, 'test/f1_weighted': 0.45700139842554616, 'test/loss': 1.7628040056655074, 'test/recall_macro': 0.4474963159445918, 'eval/recall_weighted': 0.380952380952381, 'test/accuracy': 0.4485981308411215, 'eval/recall_macro': 0.38181818181818183, 'test/precision_weighted': 0.4908761246538057, '_runtime': 3.6330602169036865, 'eval/precision_weighted': 0.37322888751460176}","{'dt_criterion': 'gini', 'dt_max_depth': 16, 'trial.number': 18, 'dt_min_samples_leaf': 9}",rural-feather-799,DecisionTree,"['TfIdf', 'preprocessed']"
538,"{'eval/accuracy': 0.30952380952380953, 'eval/recall_micro': 0.30952380952380953, 'test/recall_weighted': 0.3177570093457944, '_step': 20, 'split': 10, 'eval/f1_micro': 0.30952380952380953, 'test/precision_micro': 0.3177570093457944, 'eval/loss': 1.3979745349856256, 'test/accuracy': 0.3177570093457944, 'test/recall_macro': 0.3186259305210918, 'test/precision_macro': 0.3502314814814815, 'eval/f1_macro': 0.3163919413919414, 'eval/f1_weighted': 0.31595150880865164, 'test/recall_micro': 0.3177570093457944, '_wandb': {'runtime': 2}, 'test/loss': 1.5091066440889702, 'test/f1_macro': 0.32249742199624276, 'test/f1_weighted': 0.32519078229711273, 'eval/precision_weighted': 0.41228991596638653, 'test/f1_micro': 0.3177570093457944, 'eval/recall_macro': 0.31136363636363634, 'eval/precision_macro': 0.4097426470588236, 'eval/recall_weighted': 0.30952380952380953, 'test/precision_weighted': 0.3556767047421253, '_runtime': 3.6324477195739746, '_timestamp': 1704570271.7608566, 'eval/precision_micro': 0.30952380952380953}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 18, 'dt_min_samples_leaf': 24}",quiet-armadillo-800,DecisionTree,"['BoW', 'preprocessed']"
539,"{'eval/precision_macro': 0.6793300653594772, 'test/precision_micro': 0.5700934579439252, '_timestamp': 1704570269.2647383, 'eval/accuracy': 0.6190476190476191, 'test/f1_macro': 0.5669218310948738, 'test/precision_weighted': 0.5723408989764129, 'eval/loss': 1.004413994986182, 'test/recall_macro': 0.5668131868131868, 'test/recall_micro': 0.5700934579439252, '_step': 20, 'eval/f1_macro': 0.6347465886939572, 'eval/recall_weighted': 0.6190476190476191, 'test/recall_weighted': 0.5700934579439252, 'eval/f1_micro': 0.6190476190476191, 'test/f1_weighted': 0.5689918855344608, 'eval/recall_micro': 0.6190476190476191, 'test/accuracy': 0.5700934579439252, 'test/loss': 1.058727940235284, 'eval/precision_micro': 0.6190476190476191, 'test/precision_macro': 0.5715029761904762, 'eval/precision_weighted': 0.6780656707127295, 'split': 10, '_wandb': {'runtime': 1}, 'eval/recall_macro': 0.625, '_runtime': 5.6131932735443115, 'test/f1_micro': 0.5700934579439252, 'eval/f1_weighted': 0.6314629165506359}","{'rf_max_depth': 20, 'trial.number': 15}",blooming-sky-798,RandomForest,"['TfIdf', 'preprocessed']"
540,"{'test/precision_macro': 0.30787918476871967, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.31399521531100477, 'test/recall_micro': 0.3644859813084112, 'eval/recall_weighted': 0.3333333333333333, 'test/f1_micro': 0.36448598130841114, 'eval/recall_macro': 0.34545454545454546, 'eval/precision_macro': 0.29464285714285715, 'eval/precision_weighted': 0.2865646258503401, '_timestamp': 1704570258.2344494, 'eval/accuracy': 0.3333333333333333, 'test/accuracy': 0.3644859813084112, 'test/f1_macro': 0.3168840404284936, 'eval/recall_micro': 0.3333333333333333, '_step': 20, 'eval/loss': 1.288259638509316, 'eval/f1_micro': 0.3333333333333333, '_runtime': 3.328179359436035, 'test/loss': 1.2288804337458967, 'test/f1_weighted': 0.32592998374964155, 'eval/f1_weighted': 0.30405559352927775, 'test/recall_weighted': 0.3644859813084112, 'test/recall_macro': 0.35216671578740544, 'eval/precision_micro': 0.3333333333333333, 'split': 10, 'test/precision_micro': 0.3644859813084112, 'test/precision_weighted': 0.31408777594932774}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 17, 'dt_min_samples_leaf': 18}",vibrant-eon-797,DecisionTree,"['TfIdf', 'preprocessed']"
541,"{'eval/recall_macro': 0.5931818181818181, 'eval/precision_micro': 0.5952380952380952, 'eval/recall_weighted': 0.5952380952380952, 'split': 10, '_timestamp': 1704570257.823518, 'eval/precision_weighted': 0.6391865079365079, 'eval/f1_macro': 0.6025462962962963, 'eval/f1_weighted': 0.6020723104056438, 'test/precision_weighted': 0.5870613970839559, 'test/loss': 1.0309303609632636, 'eval/accuracy': 0.5952380952380952, 'eval/f1_micro': 0.5952380952380952, 'test/recall_micro': 0.5887850467289719, 'eval/precision_macro': 0.6427083333333333, '_step': 20, '_runtime': 3.418285131454468, 'test/precision_micro': 0.5887850467289719, 'test/recall_weighted': 0.5887850467289719, '_wandb': {'runtime': 2}, 'test/f1_macro': 0.5804980235545683, 'test/recall_macro': 0.5895021645021645, 'test/f1_micro': 0.5887850467289719, 'test/f1_weighted': 0.5845116705438277, 'eval/loss': 1.1827909103037544, 'test/precision_macro': 0.5792842215256008, 'test/accuracy': 0.5887850467289719, 'eval/recall_micro': 0.5952380952380952}","{'rf_max_depth': 24, 'trial.number': 21}",peach-voice-796,RandomForest,"['BoW', 'preprocessed']"
542,"{'_step': 20, '_timestamp': 1704570258.0227044, 'eval/recall_weighted': 0.7619047619047619, 'test/precision_macro': 0.6778060649028391, 'eval/precision_weighted': 0.8127917833800188, 'test/loss': 0.8576735926749861, 'test/f1_micro': 0.6728971962616822, 'eval/recall_micro': 0.7619047619047619, '_wandb': {'runtime': 2}, '_runtime': 4.0102293491363525, 'test/recall_macro': 0.6727472527472528, 'test/precision_micro': 0.6728971962616822, 'eval/precision_micro': 0.7619047619047619, 'eval/f1_micro': 0.7619047619047619, 'test/accuracy': 0.6728971962616822, 'test/f1_macro': 0.6732278391012994, 'eval/loss': 0.7099178149453981, 'eval/f1_macro': 0.7677527151211361, 'eval/recall_macro': 0.7613636363636364, 'eval/precision_macro': 0.8137254901960784, 'split': 10, 'eval/f1_weighted': 0.7667183832597366, 'test/recall_weighted': 0.6728971962616822, 'eval/accuracy': 0.7619047619047619, 'test/f1_weighted': 0.6732553528714741, 'test/recall_micro': 0.6728971962616822, 'test/precision_weighted': 0.6775637687606334}","{'rf_max_depth': 31, 'trial.number': 14}",major-firebrand-794,RandomForest,"['TfIdf', 'preprocessed']"
543,"{'test/precision_macro': 0.3742063492063492, 'test/recall_weighted': 0.40186915887850466, 'test/loss': 1.3810715903995736, 'eval/accuracy': 0.2619047619047619, 'test/f1_macro': 0.3684119420006517, 'test/recall_macro': 0.39025020678246486, '_runtime': 3.4763214588165283, '_timestamp': 1704570257.5016725, 'test/precision_micro': 0.40186915887850466, 'split': 10, 'test/f1_micro': 0.40186915887850466, 'eval/recall_macro': 0.2590909090909091, 'eval/precision_macro': 0.24479166666666663, 'eval/precision_weighted': 0.24652777777777776, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.24465598972177915, 'eval/loss': 1.4971431044040262, 'test/precision_weighted': 0.38040350096424863, 'test/recall_micro': 0.40186915887850466, 'eval/precision_micro': 0.2619047619047619, 'eval/f1_weighted': 0.24683657797692884, 'eval/recall_micro': 0.2619047619047619, 'test/accuracy': 0.40186915887850466, 'test/f1_weighted': 0.3784026578720579, 'eval/recall_weighted': 0.2619047619047619, '_step': 20, 'eval/f1_micro': 0.2619047619047619}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 17, 'dt_min_samples_leaf': 38}",ethereal-spaceship-795,DecisionTree,"['BoW', 'preprocessed']"
544,"{'eval/accuracy': 0.5714285714285714, 'eval/f1_micro': 0.5714285714285714, 'eval/f1_weighted': 0.5792033848061012, 'test/precision_micro': 0.6728971962616822, '_step': 20, '_timestamp': 1704570249.8384771, 'test/f1_micro': 0.6728971962616822, 'test/f1_weighted': 0.6796367578309734, 'test/recall_macro': 0.6758116883116883, 'test/recall_weighted': 0.6728971962616822, 'eval/recall_micro': 0.5714285714285714, 'eval/loss': 1.178130483712419, 'eval/recall_weighted': 0.5714285714285714, 'eval/precision_weighted': 0.6467120181405894, 'test/precision_weighted': 0.7267156499152101, 'test/loss': 1.04141629791106, 'test/f1_macro': 0.6744649653709366, 'test/precision_macro': 0.7107570806100217, 'test/accuracy': 0.6728971962616822, 'eval/recall_macro': 0.5681818181818182, 'test/recall_micro': 0.6728971962616822, 'eval/precision_macro': 0.6476190476190475, 'split': 10, '_wandb': {'runtime': 2}, '_runtime': 3.909932136535645, 'eval/f1_macro': 0.5785936615732881, 'eval/precision_micro': 0.5714285714285714}","{'rf_max_depth': 17, 'trial.number': 20}",silver-eon-793,RandomForest,"['BoW', 'preprocessed']"
545,"{'_runtime': 4.173846244812012, 'eval/f1_macro': 0.6283242829295461, 'test/f1_macro': 0.7817142132019954, 'test/recall_macro': 0.7776984523611211, 'eval/precision_micro': 0.6666666666666666, '_timestamp': 1704570249.6385772, 'eval/accuracy': 0.6666666666666666, 'test/recall_weighted': 0.7850467289719626, 'test/loss': 7.747701195791538, 'test/f1_micro': 0.7850467289719625, 'test/f1_weighted': 0.7836301132825586, 'test/recall_micro': 0.7850467289719626, 'eval/precision_weighted': 0.6811630635160048, '_step': 20, 'eval/recall_micro': 0.6666666666666666, 'test/precision_macro': 0.8014095279720279, 'test/accuracy': 0.7850467289719626, 'eval/precision_macro': 0.681246857717446, '_wandb': {'runtime': 2}, 'eval/recall_weighted': 0.6666666666666666, 'test/precision_weighted': 0.796420577086465, 'split': 10, 'eval/loss': 12.01455112970572, 'eval/f1_micro': 0.6666666666666666, 'eval/f1_weighted': 0.6230639429260982, 'eval/recall_macro': 0.675, 'test/precision_micro': 0.7850467289719626}","{'n_neighbours': 1, 'trial.number': 9}",earthy-microwave-792,KNeighbours,"['TfIdf', 'preprocessed']"
546,"{'eval/loss': 1.4971431044040262, 'test/recall_micro': 0.40186915887850466, 'eval/recall_weighted': 0.2619047619047619, '_runtime': 4.039720058441162, 'eval/recall_micro': 0.2619047619047619, 'test/precision_weighted': 0.38040350096424863, 'split': 10, '_wandb': {'runtime': 2}, 'test/loss': 1.3810715903995736, 'test/precision_macro': 0.3742063492063492, 'test/f1_macro': 0.3684119420006517, 'test/f1_weighted': 0.3784026578720579, 'test/recall_macro': 0.39025020678246486, 'test/precision_micro': 0.40186915887850466, '_step': 20, 'eval/f1_micro': 0.2619047619047619, 'test/f1_micro': 0.40186915887850466, 'eval/f1_macro': 0.24465598972177915, 'test/accuracy': 0.40186915887850466, 'eval/precision_weighted': 0.24652777777777776, '_timestamp': 1704570249.473717, 'eval/recall_macro': 0.2590909090909091, 'eval/precision_macro': 0.24479166666666663, 'test/recall_weighted': 0.40186915887850466, 'eval/accuracy': 0.2619047619047619, 'eval/f1_weighted': 0.24683657797692884, 'eval/precision_micro': 0.2619047619047619}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 16, 'dt_min_samples_leaf': 33}",decent-darkness-790,DecisionTree,"['BoW', 'preprocessed']"
547,"{'eval/f1_weighted': 0.46635756056808686, 'eval/recall_micro': 0.47619047619047616, 'eval/loss': 1.951623149357079, 'test/recall_micro': 0.4766355140186916, 'eval/recall_weighted': 0.47619047619047616, 'test/precision_micro': 0.4766355140186916, 'split': 10, 'test/precision_macro': 0.48043766578249336, 'eval/f1_micro': 0.47619047619047616, 'test/loss': 3.6324341328123824, '_timestamp': 1704570249.7834277, 'test/accuracy': 0.4766355140186916, 'test/f1_weighted': 0.4784276006614634, '_step': 20, 'test/f1_macro': 0.4780513234453301, 'eval/f1_macro': 0.4697807017543859, 'eval/accuracy': 0.47619047619047616, 'eval/precision_micro': 0.47619047619047616, 'eval/precision_weighted': 0.4882369614512471, '_runtime': 4.349552392959595, 'test/recall_macro': 0.4771117005599764, 'eval/precision_macro': 0.49255952380952384, 'test/precision_weighted': 0.4817050497037606, '_wandb': {'runtime': 3}, 'eval/recall_macro': 0.47954545454545455, 'test/recall_weighted': 0.4766355140186916, 'test/f1_micro': 0.4766355140186916}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 16, 'dt_min_samples_leaf': 12}",glamorous-blaze-789,DecisionTree,"['TfIdf', 'preprocessed']"
548,"{'_step': 20, 'split': 10, 'test/accuracy': 0.38317757009345793, 'test/precision_macro': 0.41341540404040406, 'test/precision_micro': 0.38317757009345793, 'eval/precision_weighted': 0.572463768115942, 'eval/f1_micro': 0.4047619047619048, 'test/recall_micro': 0.38317757009345793, 'eval/recall_macro': 0.40454545454545454, 'eval/recall_micro': 0.4047619047619048, '_wandb': {'runtime': 2}, '_runtime': 4.307971954345703, 'test/f1_macro': 0.3717468458261763, 'test/f1_micro': 0.383177570093458, 'eval/f1_weighted': 0.38001443001443, 'eval/precision_micro': 0.4047619047619048, 'test/precision_weighted': 0.4120952515812328, 'eval/loss': 1.2702015140097902, '_timestamp': 1704570249.726137, 'test/recall_macro': 0.3794505494505495, 'eval/precision_macro': 0.5760869565217391, 'test/recall_weighted': 0.38317757009345793, 'eval/accuracy': 0.4047619047619048, 'eval/f1_macro': 0.3765151515151515, 'test/loss': 1.3178959967382669, 'test/f1_weighted': 0.3724551494962396, 'eval/recall_weighted': 0.4047619047619048}","{'rf_max_depth': 6, 'trial.number': 13}",rural-brook-790,RandomForest,"['TfIdf', 'preprocessed']"
549,"{'_step': 20, 'eval/loss': 1.443315568366891, 'eval/f1_micro': 0.35714285714285715, 'test/f1_macro': 0.386001585955656, 'test/accuracy': 0.4205607476635514, 'eval/f1_weighted': 0.3418686288792589, 'test/recall_weighted': 0.4205607476635514, '_runtime': 3.1430327892303467, 'test/f1_weighted': 0.3958241246058959, '_timestamp': 1704570241.0814295, 'eval/recall_macro': 0.35909090909090907, 'eval/recall_weighted': 0.35714285714285715, 'test/precision_weighted': 0.39918540035362465, 'split': 10, 'eval/accuracy': 0.35714285714285715, 'eval/precision_micro': 0.35714285714285715, 'test/precision_macro': 0.3914695945945946, '_wandb': {'runtime': 1}, 'eval/recall_micro': 0.35714285714285715, 'test/loss': 1.3877434012967198, 'test/recall_micro': 0.4205607476635514, 'eval/precision_weighted': 0.3668546365914787, 'eval/f1_macro': 0.3417941405237231, 'test/f1_micro': 0.4205607476635514, 'test/recall_macro': 0.4110318444995864, 'eval/precision_macro': 0.36644736842105263, 'test/precision_micro': 0.4205607476635514}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 15, 'dt_min_samples_leaf': 31}",astral-lion-788,DecisionTree,"['BoW', 'preprocessed']"
550,"{'eval/recall_macro': 0.5204545454545454, 'test/precision_macro': 0.6502272727272727, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.5343828320802004, 'split': 10, 'eval/f1_weighted': 0.5358783864422962, 'eval/precision_weighted': 0.5892644936762584, 'test/f1_micro': 0.6261682242990654, 'eval/f1_micro': 0.5238095238095238, 'test/f1_macro': 0.6262262870894242, 'test/recall_macro': 0.627555315055315, 'test/precision_micro': 0.6261682242990654, '_runtime': 3.568159580230713, 'test/recall_weighted': 0.6261682242990654, 'test/f1_weighted': 0.627989483020447, 'eval/precision_micro': 0.5238095238095238, 'eval/recall_weighted': 0.5238095238095238, 'eval/accuracy': 0.5238095238095238, 'test/loss': 1.1633363052700598, 'test/accuracy': 0.6261682242990654, 'eval/recall_micro': 0.5238095238095238, 'eval/precision_macro': 0.5896836007130125, 'eval/loss': 1.2094268152128158, '_timestamp': 1704570241.2733035, 'test/recall_micro': 0.6261682242990654, 'test/precision_weighted': 0.656822429906542, '_step': 20}","{'rf_max_depth': 12, 'trial.number': 19}",exalted-dragon-787,RandomForest,"['BoW', 'preprocessed']"
551,"{'test/precision_macro': 0.33127185314685315, 'test/precision_micro': 0.34579439252336447, '_step': 20, 'eval/f1_micro': 0.35714285714285715, 'eval/recall_macro': 0.3568181818181818, 'test/recall_macro': 0.3447601596027383, 'eval/recall_weighted': 0.35714285714285715, 'test/f1_macro': 0.3236752973054343, 'eval/recall_micro': 0.35714285714285715, 'eval/precision_macro': 0.38055555555555554, 'eval/precision_micro': 0.35714285714285715, '_wandb': {'runtime': 2}, '_timestamp': 1704570238.8051035, 'test/accuracy': 0.34579439252336447, 'test/f1_weighted': 0.3228576868443723, 'test/precision_weighted': 0.3294912641875259, 'test/recall_weighted': 0.34579439252336447, 'split': 10, '_runtime': 4.313314437866211, 'test/loss': 2.7736212525090855, 'eval/f1_macro': 0.3511904761904762, 'eval/f1_weighted': 0.3530612244897959, 'test/recall_micro': 0.34579439252336447, 'eval/loss': 3.773740321823307, 'eval/accuracy': 0.35714285714285715, 'test/f1_micro': 0.34579439252336447, 'eval/precision_weighted': 0.3825396825396825}","{'n_neighbours': 10, 'trial.number': 8}",peachy-darkness-786,KNeighbours,"['TfIdf', 'preprocessed']"
552,"{'test/recall_macro': 0.3986501620984379, '_runtime': 5.810935020446777, 'test/loss': 3.392212680806379, 'test/f1_weighted': 0.40037383177570096, 'test/f1_micro': 0.40186915887850466, 'eval/recall_macro': 0.45909090909090905, 'eval/precision_macro': 0.4495192307692307, 'eval/f1_macro': 0.4478610475464022, 'eval/f1_micro': 0.4523809523809524, 'split': 10, '_timestamp': 1704570238.755769, 'eval/accuracy': 0.4523809523809524, 'test/accuracy': 0.40186915887850466, 'test/recall_micro': 0.40186915887850466, 'test/precision_macro': 0.4041666666666667, 'test/precision_weighted': 0.4039460020768432, '_step': 20, '_wandb': {'runtime': 2}, 'eval/f1_weighted': 0.4414674972455292, 'test/recall_weighted': 0.40186915887850466, 'eval/loss': 2.0502600585226136, 'test/f1_macro': 0.3988888888888889, 'eval/recall_weighted': 0.4523809523809524, 'eval/precision_micro': 0.4523809523809524, 'eval/precision_weighted': 0.44322344322344315, 'eval/recall_micro': 0.4523809523809524, 'test/precision_micro': 0.40186915887850466}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 15, 'dt_min_samples_leaf': 13}",elated-leaf-784,DecisionTree,"['TfIdf', 'preprocessed']"
553,"{'eval/precision_macro': 0.6175213675213675, 'test/precision_micro': 0.514018691588785, 'eval/accuracy': 0.6190476190476191, 'eval/f1_macro': 0.6132564200355962, 'eval/recall_macro': 0.615909090909091, 'test/recall_weighted': 0.514018691588785, 'test/loss': 1.1710321069324048, 'test/f1_weighted': 0.5115527073794573, 'test/recall_micro': 0.514018691588785, 'test/precision_weighted': 0.5215979415721601, 'eval/f1_weighted': 0.6143332364728245, 'test/recall_macro': 0.5131593406593407, 'eval/recall_weighted': 0.6190476190476191, 'eval/f1_micro': 0.6190476190476191, 'eval/precision_micro': 0.6190476190476191, 'test/precision_macro': 0.5223344280240831, 'eval/precision_weighted': 0.6165038665038665, 'split': 10, '_runtime': 5.5742411613464355, 'test/accuracy': 0.514018691588785, '_wandb': {'runtime': 2}, 'test/f1_macro': 0.5112020532849038, 'eval/recall_micro': 0.6190476190476191, '_step': 20, '_timestamp': 1704570238.944241, 'test/f1_micro': 0.514018691588785, 'eval/loss': 1.0935245673470693}","{'rf_max_depth': 12, 'trial.number': 12}",royal-terrain-785,RandomForest,"['TfIdf', 'preprocessed']"
554,"{'test/precision_micro': 0.7383177570093458, 'test/recall_weighted': 0.7383177570093458, 'split': 10, '_runtime': 3.2480437755584717, 'eval/loss': 1.033389478722666, 'test/recall_macro': 0.7453403078403078, 'eval/precision_micro': 0.6190476190476191, '_timestamp': 1704570229.4713595, 'eval/f1_micro': 0.6190476190476191, 'eval/precision_weighted': 0.6477324263038549, 'test/accuracy': 0.7383177570093458, 'test/f1_macro': 0.737831019434793, 'test/f1_weighted': 0.7415626863519651, 'eval/recall_micro': 0.6190476190476191, 'test/precision_weighted': 0.7652603173610895, '_step': 20, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.6190476190476191, 'test/recall_micro': 0.7383177570093458, 'eval/precision_macro': 0.655952380952381, 'test/precision_macro': 0.7524845444410662, 'test/loss': 0.9883782269379956, 'eval/f1_macro': 0.6301335918982978, 'test/f1_micro': 0.7383177570093457, 'eval/recall_macro': 0.6227272727272727, 'eval/recall_weighted': 0.6190476190476191, 'eval/f1_weighted': 0.6242856116805697}","{'rf_max_depth': 22, 'trial.number': 18}",major-grass-782,RandomForest,"['BoW', 'preprocessed']"
555,"{'_step': 20, 'eval/accuracy': 0.23809523809523808, 'eval/f1_macro': 0.2348776223776224, 'test/recall_macro': 0.3438275434243176, 'split': 10, 'eval/f1_micro': 0.23809523809523808, 'test/f1_weighted': 0.3499873923850005, 'test/precision_micro': 0.35514018691588783, '_wandb': {'runtime': 1}, 'test/loss': 2.3815510158729207, 'eval/recall_micro': 0.23809523809523808, '_runtime': 3.245885848999023, 'test/f1_micro': 0.35514018691588783, 'test/recall_micro': 0.35514018691588783, 'eval/precision_micro': 0.23809523809523808, 'eval/precision_weighted': 0.2619047619047619, 'eval/loss': 3.136358975594356, 'eval/f1_weighted': 0.23697136197136195, 'eval/precision_macro': 0.25833333333333336, 'test/recall_weighted': 0.35514018691588783, 'test/precision_weighted': 0.35521806853582555, 'test/accuracy': 0.35514018691588783, 'test/f1_macro': 0.34158531753178917, 'eval/recall_weighted': 0.23809523809523808, '_timestamp': 1704570229.94902, 'eval/recall_macro': 0.2363636363636364, 'test/precision_macro': 0.34930555555555554}","{'dt_criterion': 'gini', 'dt_max_depth': 13, 'trial.number': 14, 'dt_min_samples_leaf': 17}",vague-music-783,DecisionTree,"['BoW', 'preprocessed']"
556,"{'eval/recall_macro': 0.675, 'test/recall_weighted': 0.7850467289719626, 'eval/precision_weighted': 0.6811630635160048, '_wandb': {'runtime': 1}, '_timestamp': 1704570229.3446095, 'test/recall_macro': 0.7776984523611211, 'test/recall_micro': 0.7850467289719626, 'test/precision_micro': 0.7850467289719626, '_step': 20, 'eval/f1_macro': 0.6283242829295461, 'eval/precision_macro': 0.681246857717446, 'test/precision_weighted': 0.796420577086465, 'test/f1_micro': 0.7850467289719625, '_runtime': 3.1437528133392334, 'eval/loss': 12.01455112970572, 'eval/f1_micro': 0.6666666666666666, 'test/accuracy': 0.7850467289719626, 'split': 10, 'eval/accuracy': 0.6666666666666666, 'eval/f1_weighted': 0.6230639429260982, 'test/loss': 7.747701195791538, 'test/f1_macro': 0.7817142132019954, 'eval/precision_micro': 0.6666666666666666, 'test/f1_weighted': 0.7836301132825586, 'eval/recall_micro': 0.6666666666666666, 'eval/recall_weighted': 0.6666666666666666, 'test/precision_macro': 0.8014095279720279}","{'n_neighbours': 1, 'trial.number': 7}",treasured-puddle-781,KNeighbours,"['TfIdf', 'preprocessed']"
557,"{'eval/recall_macro': 0.7386363636363636, 'test/accuracy': 0.6542056074766355, 'eval/f1_weighted': 0.7448450672134884, 'test/loss': 0.9051064262671964, '_timestamp': 1704570227.4355898, 'eval/f1_micro': 0.7380952380952381, '_runtime': 3.3186557292938232, 'test/f1_macro': 0.6538180152774823, 'eval/recall_micro': 0.7380952380952381, 'test/recall_micro': 0.6542056074766355, 'eval/recall_weighted': 0.7380952380952381, 'test/recall_macro': 0.6493131868131868, 'test/precision_micro': 0.6542056074766355, 'eval/precision_weighted': 0.7676282051282051, 'eval/loss': 0.8896623423804025, 'eval/f1_macro': 0.7449162679425837, 'test/f1_weighted': 0.6556542300797137, 'test/f1_micro': 0.6542056074766355, 'test/precision_macro': 0.6734903381642512, '_step': 20, 'split': 10, 'eval/accuracy': 0.7380952380952381, 'eval/precision_macro': 0.7668269230769231, 'test/precision_weighted': 0.6718452300329586, '_wandb': {'runtime': 1}, 'eval/precision_micro': 0.7380952380952381, 'test/recall_weighted': 0.6542056074766355}","{'rf_max_depth': 31, 'trial.number': 11}",fearless-oath-780,RandomForest,"['TfIdf', 'preprocessed']"
558,"{'eval/f1_micro': 0.4523809523809524, 'test/accuracy': 0.514018691588785, '_timestamp': 1704570226.5898466, 'eval/precision_macro': 0.4434974747474747, 'eval/recall_weighted': 0.4523809523809524, 'eval/precision_weighted': 0.4421296296296296, 'eval/loss': 1.9355635816859025, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.4436802232854864, 'eval/recall_macro': 0.45681818181818185, '_step': 20, 'eval/recall_micro': 0.4523809523809524, 'test/recall_macro': 0.5105712741919639, 'test/precision_micro': 0.514018691588785, 'test/loss': 2.6418217712697425, 'eval/f1_weighted': 0.4408939014202172, 'test/f1_weighted': 0.5142600899335281, 'eval/precision_micro': 0.4523809523809524, 'test/recall_weighted': 0.514018691588785, 'test/precision_weighted': 0.5150709588092766, 'split': 10, 'test/f1_macro': 0.5109313424024009, 'test/f1_micro': 0.514018691588785, 'test/recall_micro': 0.514018691588785, '_runtime': 3.841360569000244, 'test/precision_macro': 0.5118518518518519, 'eval/accuracy': 0.4523809523809524}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 14, 'dt_min_samples_leaf': 11}",northern-galaxy-779,DecisionTree,"['TfIdf', 'preprocessed']"
559,"{'test/recall_micro': 0.5700934579439252, 'test/precision_weighted': 0.6023963575365444, 'test/f1_weighted': 0.5700644630427386, 'eval/f1_macro': 0.4351604278074866, 'test/accuracy': 0.5700934579439252, 'eval/recall_macro': 0.42954545454545456, 'test/precision_macro': 0.5923076923076922, 'test/precision_micro': 0.5700934579439252, 'split': 10, '_wandb': {'runtime': 1}, '_timestamp': 1704570221.9344392, 'eval/f1_weighted': 0.430672268907563, 'test/recall_macro': 0.5792929292929293, 'test/recall_weighted': 0.5700934579439252, 'eval/f1_micro': 0.42857142857142855, 'test/f1_macro': 0.5677557164624152, '_step': 20, 'eval/loss': 1.226441547018411, 'test/loss': 1.161238770671105, '_runtime': 3.191927194595337, 'eval/precision_weighted': 0.46158463385354137, 'eval/precision_micro': 0.42857142857142855, 'eval/recall_weighted': 0.42857142857142855, 'test/f1_micro': 0.5700934579439252, 'eval/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.4698242933537051, 'eval/accuracy': 0.42857142857142855}","{'rf_max_depth': 13, 'trial.number': 17}",spring-flower-778,RandomForest,"['BoW', 'preprocessed']"
560,"{'eval/loss': 1.3762386064477865, 'test/f1_micro': 0.2803738317757009, 'eval/f1_weighted': 0.290311986863711, 'test/recall_weighted': 0.2803738317757009, 'eval/accuracy': 0.3333333333333333, 'eval/recall_micro': 0.3333333333333333, 'test/precision_micro': 0.2803738317757009, 'test/f1_macro': 0.2428075396825397, '_wandb': {'runtime': 1}, '_runtime': 3.232330560684204, 'test/precision_weighted': 0.1966153068956807, '_timestamp': 1704570221.7603536, 'eval/recall_macro': 0.3295454545454546, 'test/recall_macro': 0.296474358974359, 'test/recall_micro': 0.2803738317757009, 'test/precision_macro': 0.20709459459459464, 'split': 10, 'eval/f1_micro': 0.3333333333333333, 'test/f1_weighted': 0.23015873015873017, 'eval/recall_weighted': 0.3333333333333333, 'eval/precision_weighted': 0.26851851851851855, 'test/loss': 1.3473974875158932, 'eval/f1_macro': 0.28620689655172415, 'test/accuracy': 0.2803738317757009, 'eval/precision_macro': 0.2638888888888889, '_step': 20, 'eval/precision_micro': 0.3333333333333333}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 13, 'dt_min_samples_leaf': 99}",noble-meadow-777,DecisionTree,"['BoW', 'preprocessed']"
561,"{'eval/f1_weighted': 0.5197210197210196, '_timestamp': 1704570219.9598155, 'eval/accuracy': 0.5238095238095238, 'test/f1_macro': 0.519228314865599, 'eval/recall_micro': 0.5238095238095238, 'eval/recall_weighted': 0.5238095238095238, 'eval/precision_weighted': 0.5389266817838246, 'split': 10, 'test/accuracy': 0.5233644859813084, 'test/recall_weighted': 0.5233644859813084, 'test/precision_weighted': 0.5581961133363004, '_runtime': 3.05221176147461, 'eval/f1_macro': 0.5220959595959596, 'eval/f1_micro': 0.5238095238095238, 'test/f1_weighted': 0.5232368895764441, 'eval/recall_macro': 0.5295454545454545, 'test/recall_micro': 0.5233644859813084, '_wandb': {'runtime': 1}, 'eval/loss': 1.1578200911185348, 'test/recall_macro': 0.5158241758241758, 'test/loss': 1.2347666547404268, 'test/f1_micro': 0.5233644859813084, 'eval/precision_micro': 0.5238095238095238, 'test/precision_macro': 0.558531746031746, 'test/precision_micro': 0.5233644859813084, '_step': 20, 'eval/precision_macro': 0.5376984126984128}","{'rf_max_depth': 9, 'trial.number': 10}",smooth-serenity-776,RandomForest,"['TfIdf', 'preprocessed']"
562,"{'_runtime': 3.2962515354156494, 'test/recall_macro': 0.3447601596027383, 'eval/recall_weighted': 0.35714285714285715, 'eval/precision_weighted': 0.3825396825396825, 'split': 10, 'eval/f1_macro': 0.3511904761904762, 'eval/precision_macro': 0.38055555555555554, 'eval/precision_micro': 0.35714285714285715, 'test/loss': 2.7736212525090855, 'test/f1_macro': 0.3236752973054343, 'test/f1_weighted': 0.3228576868443723, 'eval/recall_micro': 0.35714285714285715, 'eval/f1_micro': 0.35714285714285715, 'test/precision_weighted': 0.3294912641875259, '_timestamp': 1704570219.3126686, 'test/accuracy': 0.34579439252336447, 'test/recall_micro': 0.34579439252336447, 'test/precision_macro': 0.33127185314685315, 'test/precision_micro': 0.34579439252336447, 'test/recall_weighted': 0.34579439252336447, '_wandb': {'runtime': 1}, 'eval/loss': 3.773740321823307, 'eval/accuracy': 0.35714285714285715, 'eval/f1_weighted': 0.3530612244897959, '_step': 20, 'test/f1_micro': 0.34579439252336447, 'eval/recall_macro': 0.3568181818181818}","{'n_neighbours': 10, 'trial.number': 6}",neat-dragon-775,KNeighbours,"['TfIdf', 'preprocessed']"
563,"{'eval/f1_macro': 0.3335714285714286, 'test/f1_weighted': 0.4306013547036666, 'eval/precision_micro': 0.3333333333333333, 'test/precision_macro': 0.4353250915750916, 'test/recall_weighted': 0.4392523364485981, '_step': 20, '_wandb': {'runtime': 1}, 'test/f1_macro': 0.4292036910457963, 'test/loss': 3.655931464295336, 'eval/f1_micro': 0.3333333333333333, 'test/recall_macro': 0.4392887317025248, 'eval/precision_weighted': 0.34961863533292104, 'test/recall_micro': 0.4392523364485981, '_runtime': 3.223848342895508, 'eval/loss': 3.7149011532339697, 'eval/recall_weighted': 0.3333333333333333, 'eval/accuracy': 0.3333333333333333, 'test/f1_micro': 0.4392523364485981, 'eval/f1_weighted': 0.33276643990929705, 'eval/recall_micro': 0.3333333333333333, 'eval/recall_macro': 0.33636363636363636, 'eval/precision_macro': 0.34805194805194806, 'test/precision_micro': 0.4392523364485981, 'split': 10, '_timestamp': 1704570215.5784714, 'test/accuracy': 0.4392523364485981, 'test/precision_weighted': 0.4375731744890624}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 13, 'dt_min_samples_leaf': 9}",floral-lake-774,DecisionTree,"['TfIdf', 'preprocessed']"
564,"{'eval/accuracy': 0.5476190476190477, 'test/accuracy': 0.719626168224299, 'test/f1_macro': 0.7268771036345781, 'test/f1_weighted': 0.7250964447513929, 'eval/precision_weighted': 0.6060553009082421, 'test/precision_weighted': 0.7423549279314634, '_runtime': 3.106407403945923, 'eval/f1_macro': 0.5616384711779449, 'eval/precision_macro': 0.6119095365418895, 'eval/precision_micro': 0.5476190476190477, 'split': 10, 'test/f1_micro': 0.7196261682242989, 'eval/recall_weighted': 0.5476190476190477, '_wandb': {'runtime': 1}, 'test/recall_macro': 0.7229437229437229, 'test/precision_micro': 0.719626168224299, '_step': 20, 'eval/loss': 1.1164006912623967, 'test/recall_micro': 0.719626168224299, 'test/precision_macro': 0.7417803703190422, '_timestamp': 1704570214.6188664, 'eval/f1_micro': 0.5476190476190477, 'eval/recall_macro': 0.55, 'test/loss': 0.9925743822488124, 'eval/f1_weighted': 0.5576291920276882, 'eval/recall_micro': 0.5476190476190477, 'test/recall_weighted': 0.719626168224299}","{'rf_max_depth': 21, 'trial.number': 16}",golden-darkness-773,RandomForest,"['BoW', 'preprocessed']"
565,"{'test/loss': 1.4133249629871143, 'test/accuracy': 0.3364485981308411, 'test/f1_macro': 0.3263319598452489, 'test/precision_macro': 0.3355602240896358, 'eval/accuracy': 0.21428571428571427, 'eval/recall_macro': 0.2159090909090909, 'eval/recall_micro': 0.21428571428571427, '_timestamp': 1704570212.135917, 'eval/precision_micro': 0.21428571428571427, '_step': 20, 'test/f1_weighted': 0.3352614049512239, 'eval/precision_macro': 0.2642857142857143, 'eval/recall_weighted': 0.21428571428571427, 'eval/precision_weighted': 0.2683673469387755, 'split': 10, 'test/recall_macro': 0.3261476426799007, 'eval/f1_macro': 0.21332565284178184, 'eval/f1_micro': 0.21428571428571427, 'test/precision_micro': 0.3364485981308411, 'test/recall_weighted': 0.3364485981308411, '_wandb': {'runtime': 2}, 'eval/loss': 1.5078524196618428, '_runtime': 3.841284036636353, 'test/f1_micro': 0.3364485981308411, 'eval/f1_weighted': 0.21436343354546117, 'test/recall_micro': 0.3364485981308411, 'test/precision_weighted': 0.3430278279536113}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 12, 'dt_min_samples_leaf': 31}",balmy-music-770,DecisionTree,"['BoW', 'preprocessed']"
566,"{'_wandb': {'runtime': 1}, 'eval/recall_micro': 0.6666666666666666, 'test/precision_macro': 0.8014095279720279, '_step': 20, '_timestamp': 1704570211.788103, 'eval/precision_micro': 0.6666666666666666, 'test/recall_macro': 0.7776984523611211, 'eval/f1_macro': 0.6283242829295461, 'test/accuracy': 0.7850467289719626, 'eval/precision_weighted': 0.6811630635160048, 'test/precision_weighted': 0.796420577086465, 'split': 10, '_runtime': 3.0369322299957275, 'eval/f1_micro': 0.6666666666666666, 'eval/recall_macro': 0.675, 'eval/precision_macro': 0.681246857717446, 'test/f1_micro': 0.7850467289719625, 'test/precision_micro': 0.7850467289719626, 'eval/accuracy': 0.6666666666666666, 'test/recall_micro': 0.7850467289719626, 'test/recall_weighted': 0.7850467289719626, 'eval/recall_weighted': 0.6666666666666666, 'eval/loss': 12.01455112970572, 'test/loss': 7.747701195791538, 'test/f1_macro': 0.7817142132019954, 'eval/f1_weighted': 0.6230639429260982, 'test/f1_weighted': 0.7836301132825586}","{'n_neighbours': 1, 'trial.number': 5}",earnest-sponge-772,KNeighbours,"['TfIdf', 'preprocessed']"
567,"{'eval/f1_micro': 0.35714285714285715, 'eval/recall_macro': 0.36590909090909096, 'eval/precision_weighted': 0.30599647266313934, 'test/accuracy': 0.35514018691588783, 'eval/f1_weighted': 0.297007722007722, 'test/recall_macro': 0.35030219780219773, 'test/loss': 1.360922664054511, '_step': 20, 'split': 10, 'eval/loss': 1.3469040559218928, 'test/f1_macro': 0.33383847320525784, 'test/recall_micro': 0.35514018691588783, 'eval/precision_macro': 0.3101851851851852, 'test/precision_micro': 0.35514018691588783, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.35714285714285715, 'test/f1_micro': 0.35514018691588783, 'eval/recall_micro': 0.35714285714285715, 'eval/precision_micro': 0.35714285714285715, 'test/precision_macro': 0.39507662835249047, '_runtime': 3.4813358783721924, '_timestamp': 1704570212.202216, 'test/f1_weighted': 0.3370084953176531, 'eval/recall_weighted': 0.35714285714285715, 'test/recall_weighted': 0.35514018691588783, 'eval/f1_macro': 0.3018581081081081, 'test/precision_weighted': 0.3972141655029183}","{'rf_max_depth': 2, 'trial.number': 9}",faithful-violet-771,RandomForest,"['TfIdf', 'preprocessed']"
568,"{'eval/f1_weighted': 0.4408939014202172, 'test/recall_macro': 0.5101866588073485, 'test/recall_micro': 0.514018691588785, '_timestamp': 1704570203.617664, '_runtime': 3.465378999710083, 'test/loss': 2.6520854010604658, 'eval/f1_macro': 0.4436802232854864, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_macro': 0.5130134932533733, '_step': 20, 'eval/precision_weighted': 0.4421296296296296, 'eval/precision_micro': 0.4523809523809524, 'split': 10, 'eval/f1_micro': 0.4523809523809524, 'test/accuracy': 0.514018691588785, 'eval/recall_macro': 0.45681818181818185, 'test/recall_weighted': 0.514018691588785, 'eval/accuracy': 0.4523809523809524, 'test/precision_micro': 0.514018691588785, 'eval/loss': 1.9182187985684136, 'eval/precision_macro': 0.4434974747474747, 'test/f1_macro': 0.5108319999209829, 'test/f1_micro': 0.514018691588785, 'test/f1_weighted': 0.5143660249671655, 'eval/recall_micro': 0.4523809523809524, 'test/precision_weighted': 0.516216284381174, '_wandb': {'runtime': 2}}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 12, 'dt_min_samples_leaf': 11}",eager-totem-769,DecisionTree,"['TfIdf', 'preprocessed']"
569,"{'eval/f1_weighted': 0.5729782790309105, 'test/precision_macro': 0.655281432748538, 'test/precision_weighted': 0.6744589276930644, 'eval/loss': 1.1514832818126954, 'test/loss': 1.0803420225857492, 'eval/recall_weighted': 0.5714285714285714, 'test/f1_macro': 0.6017101284958428, 'test/precision_micro': 0.5887850467289719, '_wandb': {'runtime': 2}, 'test/accuracy': 0.5887850467289719, 'test/recall_macro': 0.5911014911014911, 'eval/precision_macro': 0.6028693528693528, 'test/recall_micro': 0.5887850467289719, 'split': 10, 'eval/f1_macro': 0.5750438596491227, 'eval/f1_micro': 0.5714285714285714, 'eval/recall_micro': 0.5714285714285714, '_timestamp': 1704570202.778486, 'test/f1_weighted': 0.6095676068973799, 'eval/recall_macro': 0.5704545454545453, 'eval/precision_micro': 0.5714285714285714, '_step': 20, '_runtime': 3.469775915145874, 'test/recall_weighted': 0.5887850467289719, 'eval/precision_weighted': 0.5971858829001686, 'eval/accuracy': 0.5714285714285714, 'test/f1_micro': 0.5887850467289719}","{'rf_max_depth': 18, 'trial.number': 15}",ruby-microwave-768,RandomForest,"['BoW', 'preprocessed']"
570,"{'test/loss': 7.747701195791538, 'eval/accuracy': 0.6666666666666666, 'test/f1_macro': 0.7817142132019954, '_runtime': 3.5730574131011963, 'eval/recall_macro': 0.675, 'eval/recall_micro': 0.6666666666666666, 'eval/f1_macro': 0.6283242829295461, 'test/f1_micro': 0.7850467289719625, 'test/recall_micro': 0.7850467289719626, 'eval/precision_weighted': 0.6811630635160048, '_step': 20, 'eval/precision_macro': 0.681246857717446, 'eval/precision_micro': 0.6666666666666666, 'eval/recall_weighted': 0.6666666666666666, 'test/precision_weighted': 0.796420577086465, 'test/accuracy': 0.7850467289719626, 'eval/f1_weighted': 0.6230639429260982, 'test/recall_weighted': 0.7850467289719626, 'eval/f1_micro': 0.6666666666666666, 'test/precision_macro': 0.8014095279720279, 'test/precision_micro': 0.7850467289719626, 'split': 10, 'eval/loss': 12.01455112970572, 'test/f1_weighted': 0.7836301132825586, 'test/recall_macro': 0.7776984523611211, '_wandb': {'runtime': 2}, '_timestamp': 1704570201.6575515}","{'n_neighbours': 1, 'trial.number': 4}",lilac-fire-766,KNeighbours,"['TfIdf', 'preprocessed']"
571,"{'eval/recall_macro': 0.43863636363636366, 'eval/precision_weighted': 0.4565826330532213, '_runtime': 3.28513240814209, 'test/f1_micro': 0.3364485981308411, 'test/f1_weighted': 0.278062081365711, 'eval/f1_weighted': 0.3865341008198151, 'eval/recall_micro': 0.4523809523809524, '_timestamp': 1704570201.9744897, 'eval/accuracy': 0.4523809523809524, 'eval/f1_macro': 0.37945387945387943, 'eval/precision_macro': 0.4585561497326204, 'eval/precision_micro': 0.4523809523809524, 'test/loss': 1.3596759091062176, 'test/accuracy': 0.3364485981308411, 'test/f1_macro': 0.2836680761099366, 'test/precision_macro': 0.2809139784946237, 'test/precision_micro': 0.3364485981308411, 'split': 10, 'test/recall_macro': 0.34557692307692306, '_wandb': {'runtime': 1}, 'eval/loss': 1.3133556661952683, 'eval/f1_micro': 0.4523809523809524, 'test/recall_micro': 0.3364485981308411, 'eval/recall_weighted': 0.4523809523809524, 'test/precision_weighted': 0.27833383579539744, '_step': 20, 'test/recall_weighted': 0.3364485981308411}","{'rf_max_depth': 2, 'trial.number': 8}",neat-totem-767,RandomForest,"['TfIdf', 'preprocessed']"
572,"{'eval/precision_macro': 0.3991228070175439, 'eval/precision_weighted': 0.4101921470342523, 'eval/precision_micro': 0.2857142857142857, 'eval/recall_weighted': 0.2857142857142857, '_step': 20, 'eval/f1_macro': 0.18216902145473576, 'eval/recall_micro': 0.2857142857142857, 'test/recall_micro': 0.2897196261682243, 'test/precision_weighted': 0.40284300636142306, 'test/accuracy': 0.2897196261682243, 'eval/f1_weighted': 0.18718073309910044, 'test/recall_weighted': 0.2897196261682243, '_wandb': {'runtime': 1}, '_runtime': 3.1496663093566895, 'split': 10, '_timestamp': 1704570200.2101653, 'eval/recall_macro': 0.27499999999999997, 'test/precision_macro': 0.40525210084033614, 'eval/loss': 2.1861967380002474, 'eval/accuracy': 0.2857142857142857, 'test/f1_macro': 0.24753919547809053, 'test/f1_micro': 0.2897196261682243, 'test/f1_weighted': 0.2386583847202491, 'test/recall_macro': 0.3110008271298594, 'test/precision_micro': 0.2897196261682243, 'test/loss': 2.5557702797376582, 'eval/f1_micro': 0.2857142857142857}","{'dt_criterion': 'gini', 'dt_max_depth': 8, 'trial.number': 11, 'dt_min_samples_leaf': 5}",gallant-lion-765,DecisionTree,"['BoW', 'preprocessed']"
573,"{'eval/f1_macro': 0.59222334682861, 'eval/recall_micro': 0.6190476190476191, 'eval/precision_macro': 0.6008547008547008, 'split': 10, 'eval/precision_micro': 0.6190476190476191, 'test/precision_weighted': 0.6306175335694368, 'test/accuracy': 0.616822429906542, '_step': 20, 'eval/loss': 2.341115973856962, 'eval/accuracy': 0.6190476190476191, 'eval/f1_micro': 0.6190476190476191, 'test/recall_macro': 0.6324890010351967, 'eval/recall_weighted': 0.6190476190476191, '_wandb': {'runtime': 2}, 'test/loss': 2.464789941524463, 'test/f1_macro': 0.5950098422680675, 'test/precision_macro': 0.6224021574631331, 'test/recall_weighted': 0.616822429906542, 'test/f1_weighted': 0.5916030962946291, 'eval/recall_macro': 0.6113636363636363, 'test/recall_micro': 0.616822429906542, 'test/precision_micro': 0.616822429906542, 'test/f1_micro': 0.616822429906542, 'eval/f1_weighted': 0.5965313925840241, '_runtime': 3.4216833114624023, '_timestamp': 1704570198.0311732, 'eval/precision_weighted': 0.6014245014245014}","{'smoothing': 0.2791947237878828, 'trial.number': 4}",blooming-shadow-764,Bernolli,"['TfIdf', 'preprocessed']"
574,"{'eval/precision_micro': 0.42857142857142855, 'eval/recall_weighted': 0.42857142857142855, 'eval/loss': 2.8114815380088944, 'test/accuracy': 0.38317757009345793, 'test/f1_weighted': 0.38334975282015776, 'eval/recall_macro': 0.42272727272727273, 'eval/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.4928571428571428, 'test/precision_weighted': 0.5116663549148242, 'test/loss': 1.794065303395474, 'test/recall_micro': 0.38317757009345793, 'test/precision_macro': 0.5000843983602604, 'test/precision_micro': 0.38317757009345793, '_runtime': 3.5105059146881104, 'eval/f1_micro': 0.42857142857142855, 'test/f1_macro': 0.381576448243115, 'test/f1_micro': 0.383177570093458, 'eval/precision_weighted': 0.48684807256235824, '_step': 20, '_wandb': {'runtime': 2}, 'test/recall_macro': 0.3865011297769918, 'test/recall_weighted': 0.38317757009345793, 'split': 10, 'eval/f1_weighted': 0.41157885098154057, '_timestamp': 1704570194.4740138, 'eval/accuracy': 0.42857142857142855, 'eval/f1_macro': 0.4105589155502529}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 11, 'dt_min_samples_leaf': 7}",driven-silence-762,DecisionTree,"['TfIdf', 'preprocessed']"
575,"{'eval/recall_weighted': 0.7142857142857143, 'eval/precision_weighted': 0.7899159663865545, 'test/loss': 1.099699163106146, 'test/f1_weighted': 0.5841376432027245, 'eval/f1_macro': 0.7345238095238095, 'test/accuracy': 0.5794392523364486, 'eval/f1_micro': 0.7142857142857143, 'test/f1_micro': 0.5794392523364486, 'eval/recall_micro': 0.7142857142857143, 'eval/loss': 0.9591039911078832, 'eval/accuracy': 0.7142857142857143, '_wandb': {'runtime': 1}, 'eval/precision_macro': 0.7926470588235294, 'test/precision_micro': 0.5794392523364486, '_runtime': 3.0810234546661377, 'test/f1_macro': 0.5847646153000055, 'eval/f1_weighted': 0.7316704459561602, 'test/recall_macro': 0.5785714285714286, 'test/recall_micro': 0.5794392523364486, 'eval/precision_micro': 0.7142857142857143, 'test/precision_macro': 0.5985178463399878, '_step': 20, '_timestamp': 1704570194.3103375, 'test/recall_weighted': 0.5794392523364486, 'test/precision_weighted': 0.595972205731861, 'split': 10, 'eval/recall_macro': 0.7159090909090909}","{'rf_max_depth': 17, 'trial.number': 7}",vocal-fire-763,RandomForest,"['TfIdf', 'preprocessed']"
576,"{'test/f1_weighted': 0.7483010046608969, 'eval/recall_macro': 0.6454545454545455, 'test/recall_macro': 0.7436688311688311, 'eval/precision_micro': 0.6428571428571429, '_step': 20, '_runtime': 3.4791507720947266, 'eval/f1_micro': 0.6428571428571429, 'test/f1_macro': 0.7421674370826913, 'test/precision_weighted': 0.7540711598634552, 'split': 10, 'eval/loss': 1.091924093419932, 'eval/accuracy': 0.6428571428571429, 'test/recall_weighted': 0.7476635514018691, 'eval/precision_weighted': 0.6923280423280423, 'eval/f1_macro': 0.6393829401088928, 'test/f1_micro': 0.7476635514018691, 'eval/recall_weighted': 0.6428571428571429, 'test/precision_micro': 0.7476635514018691, 'test/loss': 1.0092212549040946, 'test/accuracy': 0.7476635514018691, 'eval/precision_macro': 0.6944444444444444, '_wandb': {'runtime': 2}, '_timestamp': 1704570192.5742998, 'eval/recall_micro': 0.6428571428571429, 'test/recall_micro': 0.7476635514018691, 'eval/f1_weighted': 0.6356192204649554, 'test/precision_macro': 0.7453706672009617}","{'rf_max_depth': 19, 'trial.number': 14}",hearty-dragon-760,RandomForest,"['BoW', 'preprocessed']"
577,"{'eval/loss': 12.01455112970572, 'test/accuracy': 0.7850467289719626, 'eval/precision_micro': 0.6666666666666666, '_runtime': 3.0492000579833984, '_timestamp': 1704570192.632285, 'eval/f1_micro': 0.6666666666666666, 'test/f1_micro': 0.7850467289719625, 'eval/f1_weighted': 0.6230639429260982, 'test/f1_weighted': 0.7836301132825586, 'eval/recall_weighted': 0.6666666666666666, 'eval/accuracy': 0.6666666666666666, 'test/loss': 7.747701195791538, 'eval/recall_macro': 0.675, 'test/recall_macro': 0.7776984523611211, 'test/recall_micro': 0.7850467289719626, 'split': 10, '_wandb': {'runtime': 1}, 'test/precision_macro': 0.8014095279720279, 'eval/precision_weighted': 0.6811630635160048, 'test/precision_weighted': 0.796420577086465, '_step': 20, 'eval/f1_macro': 0.6283242829295461, 'test/precision_micro': 0.7850467289719626, 'test/recall_weighted': 0.7850467289719626, 'test/f1_macro': 0.7817142132019954, 'eval/recall_micro': 0.6666666666666666, 'eval/precision_macro': 0.681246857717446}","{'n_neighbours': 1, 'trial.number': 3}",desert-field-761,KNeighbours,"['TfIdf', 'preprocessed']"
578,"{'_timestamp': 1704570191.5952263, 'eval/f1_micro': 0.35714285714285715, 'test/f1_micro': 0.37383177570093457, 'eval/recall_macro': 0.34545454545454546, 'eval/recall_micro': 0.35714285714285715, 'eval/precision_micro': 0.35714285714285715, 'test/recall_micro': 0.37383177570093457, 'test/precision_macro': 0.29794973544973546, 'eval/f1_weighted': 0.2906462585034014, 'eval/precision_weighted': 0.3167305236270753, '_wandb': {'runtime': 2}, 'test/accuracy': 0.37383177570093457, 'test/f1_macro': 0.31593053173241853, 'eval/f1_macro': 0.2839285714285715, 'test/f1_weighted': 0.3190522755326141, 'eval/recall_weighted': 0.35714285714285715, 'test/precision_micro': 0.37383177570093457, 'test/recall_weighted': 0.37383177570093457, '_runtime': 3.6956005096435542, 'eval/accuracy': 0.35714285714285715, 'test/recall_macro': 0.38042803970223327, 'test/loss': 1.3300920066772022, 'eval/precision_macro': 0.3136973180076628, 'test/precision_weighted': 0.3069524798496761, '_step': 20, 'split': 10, 'eval/loss': 1.343599234419078}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 10, 'dt_min_samples_leaf': 71}",winter-rain-758,DecisionTree,"['BoW', 'preprocessed']"
579,"{'_timestamp': 1704570191.3375216, '_wandb': {'runtime': 1}, 'split': 10, '_runtime': 3.19905161857605, 'test/recall_macro': 0.6116556677018634, 'test/recall_weighted': 0.5981308411214953, 'eval/precision_weighted': 0.5295810631945086, '_step': 20, 'eval/loss': 2.2526196723674947, 'eval/f1_macro': 0.5024159663865546, 'test/f1_macro': 0.5767540042564027, 'test/recall_micro': 0.5981308411214953, 'test/loss': 2.376098446974136, 'eval/f1_micro': 0.5238095238095238, 'test/f1_micro': 0.5981308411214953, 'test/precision_macro': 0.6292005420054201, 'eval/precision_micro': 0.5238095238095238, 'eval/accuracy': 0.5238095238095238, 'eval/recall_macro': 0.5159090909090909, 'eval/precision_macro': 0.5308338720103426, 'eval/recall_weighted': 0.5238095238095238, 'test/precision_weighted': 0.6416710989539801, 'test/accuracy': 0.5981308411214953, 'eval/f1_weighted': 0.5059857276243831, 'test/f1_weighted': 0.5761085591408764, 'eval/recall_micro': 0.5238095238095238, 'test/precision_micro': 0.5981308411214953}","{'smoothing': 0.3854753334074996, 'trial.number': 3}",divine-planet-759,Bernolli,"['TfIdf', 'preprocessed']"
580,"{'eval/precision_macro': 0.48903508771929827, 'eval/recall_weighted': 0.3333333333333333, 'split': 10, 'eval/recall_micro': 0.3333333333333333, 'eval/accuracy': 0.3333333333333333, 'test/recall_macro': 0.31218685529030354, 'eval/precision_weighted': 0.4726399331662489, '_wandb': {'runtime': 2}, 'test/f1_macro': 0.22863624578688105, 'eval/recall_macro': 0.325, 'test/precision_micro': 0.308411214953271, 'eval/f1_micro': 0.3333333333333333, 'test/accuracy': 0.308411214953271, 'eval/precision_micro': 0.3333333333333333, '_timestamp': 1704570187.4288237, 'test/recall_weighted': 0.308411214953271, 'test/recall_micro': 0.308411214953271, 'eval/f1_weighted': 0.23414000965021373, 'test/f1_weighted': 0.22985711135718773, 'test/precision_weighted': 0.344392523364486, 'test/f1_micro': 0.308411214953271, '_runtime': 3.680551528930664, 'eval/loss': 1.3303399605003787, 'test/loss': 1.3247989552617547, 'eval/f1_macro': 0.23462252033680603, 'test/precision_macro': 0.3375, '_step': 20}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 10, 'dt_min_samples_leaf': 5}",drawn-wood-757,DecisionTree,"['TfIdf', 'preprocessed']"
581,"{'test/f1_macro': 0.6560242031302168, 'test/recall_macro': 0.6548901098901099, 'eval/f1_macro': 0.7006102212051868, 'eval/f1_micro': 0.6904761904761905, 'test/f1_micro': 0.6542056074766355, 'split': 10, 'eval/f1_weighted': 0.6978107795368338, 'test/precision_macro': 0.6672673944413074, 'test/precision_micro': 0.6542056074766355, 'test/recall_weighted': 0.6542056074766355, 'eval/recall_micro': 0.6904761904761905, '_step': 20, 'eval/loss': 0.8222512588867383, 'eval/recall_macro': 0.6931818181818181, 'test/f1_weighted': 0.6559789148249174, 'test/recall_micro': 0.6542056074766355, '_wandb': {'runtime': 1}, 'test/loss': 0.9360106544685954, 'eval/accuracy': 0.6904761904761905, 'eval/precision_weighted': 0.7084415584415584, '_runtime': 3.2230026721954346, 'eval/precision_micro': 0.6904761904761905, 'eval/recall_weighted': 0.6904761904761905, 'test/precision_weighted': 0.6677040914749163, '_timestamp': 1704570185.2392807, 'test/accuracy': 0.6542056074766355, 'eval/precision_macro': 0.7113636363636364}","{'rf_max_depth': 27, 'trial.number': 6}",swift-grass-756,RandomForest,"['TfIdf', 'preprocessed']"
582,"{'test/precision_macro': 0.4606153301648296, 'test/loss': 4.785564740612375, 'eval/f1_macro': 0.3508525149190111, 'eval/recall_macro': 0.3545454545454546, 'eval/precision_macro': 0.352518315018315, 'eval/precision_weighted': 0.35297837083551376, '_timestamp': 1704570183.618596, 'eval/f1_micro': 0.35714285714285715, 'test/recall_micro': 0.4672897196261682, 'split': 10, 'test/recall_macro': 0.46835857864718433, 'test/precision_micro': 0.4672897196261682, 'test/f1_micro': 0.4672897196261683, 'test/f1_macro': 0.4619119426354934, 'test/f1_weighted': 0.4621684231811354, 'test/recall_weighted': 0.4672897196261682, 'test/precision_weighted': 0.4624474659373249, 'eval/accuracy': 0.35714285714285715, 'eval/f1_weighted': 0.35243372711403403, 'eval/recall_weighted': 0.35714285714285715, '_step': 20, 'eval/loss': 5.224807842969406, 'eval/recall_micro': 0.35714285714285715, 'eval/precision_micro': 0.35714285714285715, '_wandb': {'runtime': 1}, '_runtime': 3.250331163406372, 'test/accuracy': 0.4672897196261682}","{'n_neighbours': 5, 'trial.number': 2}",silver-oath-755,KNeighbours,"['TfIdf', 'preprocessed']"
583,"{'_runtime': 3.4354360103607178, '_timestamp': 1704570183.083304, 'eval/recall_micro': 0.5476190476190477, 'eval/precision_weighted': 0.5490362811791384, 'test/precision_micro': 0.6074766355140186, '_wandb': {'runtime': 2}, 'test/loss': 2.3198596279248105, 'test/f1_micro': 0.6074766355140186, 'test/recall_micro': 0.6074766355140186, 'test/precision_macro': 0.6461871461871462, '_step': 20, 'eval/f1_macro': 0.52107181703266, 'eval/f1_micro': 0.5476190476190477, 'test/f1_macro': 0.5880959559965646, 'eval/f1_weighted': 0.5255299521107792, 'eval/recall_macro': 0.5386363636363637, 'eval/accuracy': 0.5476190476190477, 'eval/loss': 2.1998186125372547, 'test/accuracy': 0.6074766355140186, 'test/precision_weighted': 0.6587252311551377, 'test/recall_weighted': 0.6074766355140186, 'test/f1_weighted': 0.5869393876825016, 'test/recall_macro': 0.62207233436853, 'eval/precision_macro': 0.549404761904762, 'eval/precision_micro': 0.5476190476190477, 'eval/recall_weighted': 0.5476190476190477, 'split': 10}","{'smoothing': 0.5630778658164328, 'trial.number': 2}",chocolate-capybara-754,Bernolli,"['TfIdf', 'preprocessed']"
584,"{'test/accuracy': 0.616822429906542, 'eval/recall_macro': 0.5954545454545455, '_runtime': 4.148462772369385, 'test/loss': 1.0941636665382026, 'eval/f1_micro': 0.5952380952380952, 'eval/f1_macro': 0.6126283846872081, 'test/f1_macro': 0.6241728701406121, 'eval/precision_micro': 0.5952380952380952, '_wandb': {'runtime': 2}, 'test/precision_macro': 0.6606150793650793, 'test/recall_weighted': 0.616822429906542, 'eval/f1_weighted': 0.6089658085456404, 'test/recall_macro': 0.6236832611832612, 'eval/precision_weighted': 0.651890756302521, 'split': 10, 'test/f1_micro': 0.616822429906542, 'test/f1_weighted': 0.6267711787760024, 'eval/recall_weighted': 0.5952380952380952, '_step': 20, 'eval/recall_micro': 0.5952380952380952, 'eval/precision_macro': 0.6591911764705882, 'test/recall_micro': 0.616822429906542, 'test/precision_micro': 0.616822429906542, 'test/precision_weighted': 0.6741878059635068, 'eval/loss': 1.1571790131443067, '_timestamp': 1704570183.5264578, 'eval/accuracy': 0.5952380952380952}","{'rf_max_depth': 19, 'trial.number': 13}",sage-deluge-753,RandomForest,"['BoW', 'preprocessed']"
585,"{'_timestamp': 1704570182.8266978, 'test/precision_macro': 0.17976190476190476, 'test/recall_weighted': 0.22429906542056072, 'eval/accuracy': 0.2619047619047619, 'eval/f1_weighted': 0.10871518418688232, 'test/recall_micro': 0.22429906542056072, 'eval/precision_micro': 0.2619047619047619, '_wandb': {'runtime': 2}, '_runtime': 4.617835760116577, 'eval/loss': 1.3884210984949714, 'test/loss': 1.706655400104888, 'test/accuracy': 0.22429906542056072, 'test/precision_micro': 0.22429906542056072, '_step': 20, 'eval/precision_macro': 0.06547619047619048, 'eval/f1_macro': 0.10377358490566038, 'eval/f1_micro': 0.2619047619047619, 'test/f1_weighted': 0.09754137769786544, 'eval/recall_weighted': 0.2619047619047619, 'eval/precision_weighted': 0.06859410430839002, 'split': 10, 'test/f1_micro': 0.22429906542056072, 'eval/recall_micro': 0.2619047619047619, 'test/recall_macro': 0.2476478494623656, 'test/f1_macro': 0.10429880197322058, 'eval/recall_macro': 0.25, 'test/precision_weighted': 0.19399198931909212}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 9, 'dt_min_samples_leaf': 9}",eager-sun-752,DecisionTree,"['BoW', 'preprocessed']"
586,"{'eval/loss': 2.320822336183609, 'test/loss': 2.0248419771995505, 'eval/recall_micro': 0.380952380952381, '_runtime': 5.340548515319824, 'test/f1_micro': 0.37383177570093457, 'test/recall_weighted': 0.37383177570093457, 'test/precision_weighted': 0.3704232454867359, '_wandb': {'runtime': 2}, '_timestamp': 1704570179.2380705, 'test/accuracy': 0.37383177570093457, 'test/recall_macro': 0.37087238432066016, 'test/precision_micro': 0.37383177570093457, 'eval/precision_weighted': 0.3939909297052153, 'eval/accuracy': 0.380952380952381, 'eval/f1_macro': 0.38444547779586136, 'eval/precision_micro': 0.380952380952381, '_step': 20, 'split': 10, 'eval/f1_weighted': 0.3828899148592243, 'test/f1_weighted': 0.37156517681797285, 'eval/recall_macro': 0.38181818181818183, 'test/precision_macro': 0.3690314440993789, 'eval/f1_micro': 0.380952380952381, 'test/recall_micro': 0.37383177570093457, 'eval/precision_macro': 0.3966450216450216, 'eval/recall_weighted': 0.380952380952381, 'test/f1_macro': 0.3693982861400894}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 9, 'dt_min_samples_leaf': 25}",decent-elevator-751,DecisionTree,"['TfIdf', 'preprocessed']"
587,"{'test/loss': 1.076381053175031, 'test/accuracy': 0.5514018691588785, 'test/precision_macro': 0.5921626984126984, 'test/precision_micro': 0.5514018691588785, 'eval/f1_weighted': 0.6992664742664743, 'eval/recall_micro': 0.6904761904761905, 'eval/recall_weighted': 0.6904761904761905, 'test/precision_weighted': 0.5921079958463136, '_step': 20, '_wandb': {'runtime': 2}, 'eval/loss': 0.951508161739168, 'test/f1_micro': 0.5514018691588785, 'test/f1_weighted': 0.5647670690052781, 'eval/recall_macro': 0.6931818181818182, 'test/recall_micro': 0.5514018691588785, 'eval/precision_macro': 0.7248931623931624, 'eval/precision_micro': 0.6904761904761905, '_runtime': 3.707119226455689, 'eval/precision_weighted': 0.7217134717134718, 'eval/accuracy': 0.6904761904761905, 'test/f1_macro': 0.5634033279382116, 'test/recall_macro': 0.5489560439560439, 'split': 10, '_timestamp': 1704570176.1456013, 'eval/f1_macro': 0.7021464646464647, 'eval/f1_micro': 0.6904761904761905, 'test/recall_weighted': 0.5514018691588785}","{'rf_max_depth': 17, 'trial.number': 5}",sage-durian-750,RandomForest,"['TfIdf', 'preprocessed']"
588,"{'eval/accuracy': 0.3333333333333333, 'test/precision_micro': 0.4953271028037383, 'eval/loss': 7.534656321644307, '_timestamp': 1704570174.180405, 'test/recall_macro': 0.498385231987181, 'test/precision_macro': 0.4902224898580122, 'eval/f1_weighted': 0.3218364968364968, 'eval/recall_micro': 0.3333333333333333, 'eval/precision_micro': 0.3333333333333333, 'eval/f1_macro': 0.318312937062937, 'test/f1_macro': 0.4853216490293247, 'test/f1_weighted': 0.4854616669742625, 'eval/precision_macro': 0.3194444444444444, 'test/loss': 4.915368693214542, 'test/f1_micro': 0.4953271028037383, '_wandb': {'runtime': 1}, 'test/recall_weighted': 0.4953271028037383, '_runtime': 2.9921939373016357, 'eval/recall_weighted': 0.3333333333333333, '_step': 20, 'split': 10, 'eval/recall_macro': 0.3295454545454546, 'test/recall_micro': 0.4953271028037383, 'eval/precision_weighted': 0.3227513227513227, 'test/precision_weighted': 0.4942542558434912, 'eval/f1_micro': 0.3333333333333333, 'test/accuracy': 0.4953271028037383}","{'n_neighbours': 3, 'trial.number': 1}",graceful-resonance-749,KNeighbours,"['TfIdf', 'preprocessed']"
589,"{'eval/f1_weighted': 0.6209755157123579, 'eval/recall_macro': 0.6227272727272727, 'test/precision_micro': 0.719626168224299, 'test/loss': 0.8755271378608172, 'test/f1_weighted': 0.7276636219129108, 'eval/precision_micro': 0.6190476190476191, 'eval/precision_weighted': 0.6377645502645503, '_step': 20, 'eval/loss': 1.0653249987290143, 'test/f1_micro': 0.7196261682242989, 'eval/recall_micro': 0.6190476190476191, 'test/precision_weighted': 0.7420111881552943, '_wandb': {'runtime': 1}, '_runtime': 4.23990273475647, 'eval/f1_macro': 0.6254048582995951, 'test/recall_macro': 0.7102272727272727, 'eval/precision_macro': 0.6423611111111112, 'eval/accuracy': 0.6190476190476191, 'test/recall_micro': 0.719626168224299, 'test/recall_weighted': 0.719626168224299, 'split': 10, 'eval/f1_micro': 0.6190476190476191, 'test/accuracy': 0.719626168224299, 'test/f1_macro': 0.714691608670641, 'test/precision_macro': 0.7253927718040621, '_timestamp': 1704570173.3559368, 'eval/recall_weighted': 0.6190476190476191}","{'rf_max_depth': 30, 'trial.number': 12}",quiet-darkness-748,RandomForest,"['BoW', 'preprocessed']"
590,"{'eval/loss': 2.1986667770348736, 'test/loss': 2.322729361934792, '_timestamp': 1704570172.9685965, 'eval/f1_weighted': 0.5255299521107792, 'test/precision_macro': 0.6205033643892339, 'split': 10, 'test/recall_macro': 0.5897062629399585, 'test/recall_micro': 0.5700934579439252, 'test/accuracy': 0.5700934579439252, 'eval/recall_micro': 0.5476190476190477, 'eval/precision_weighted': 0.5490362811791384, 'test/recall_weighted': 0.5700934579439252, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.5476190476190477, 'test/f1_macro': 0.5512997623291741, 'test/f1_micro': 0.5700934579439252, 'test/precision_micro': 0.5700934579439252, 'eval/f1_macro': 0.52107181703266, 'eval/precision_macro': 0.549404761904762, 'test/f1_weighted': 0.5469827466528951, 'eval/f1_micro': 0.5476190476190477, 'eval/recall_weighted': 0.5476190476190477, '_step': 20, '_runtime': 3.755795478820801, 'eval/recall_macro': 0.5386363636363637, 'eval/precision_micro': 0.5476190476190477, 'test/precision_weighted': 0.6322487954954432}","{'smoothing': 0.6877396115449599, 'trial.number': 1}",dandy-voice-747,Bernolli,"['TfIdf', 'preprocessed']"
591,"{'_wandb': {'runtime': 2}, 'eval/accuracy': 0.30952380952380953, 'eval/recall_weighted': 0.30952380952380953, '_runtime': 3.612483024597168, 'eval/loss': 1.3372645706536197, 'test/f1_weighted': 0.2321692080668962, 'eval/precision_macro': 0.56875, 'eval/precision_weighted': 0.5720238095238095, 'test/f1_macro': 0.23848684210526316, 'test/f1_micro': 0.29906542056074764, 'test/precision_macro': 0.3334686147186147, 'test/recall_weighted': 0.29906542056074764, 'eval/f1_micro': 0.30952380952380953, 'eval/f1_macro': 0.19496434937611412, '_step': 20, 'test/recall_micro': 0.29906542056074764, 'eval/precision_micro': 0.30952380952380953, 'eval/f1_weighted': 0.1999193616840676, 'eval/recall_macro': 0.29772727272727273, 'test/recall_macro': 0.3198666253101737, 'test/precision_micro': 0.29906542056074764, 'split': 10, 'test/loss': 1.6195752697154555, '_timestamp': 1704570171.111057, 'test/accuracy': 0.29906542056074764, 'eval/recall_micro': 0.30952380952380953, 'test/precision_weighted': 0.3396852368814985}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 8, 'dt_min_samples_leaf': 11}",glowing-hill-746,DecisionTree,"['BoW', 'preprocessed']"
592,"{'eval/precision_micro': 0.5, 'eval/recall_weighted': 0.5, 'eval/loss': 1.2957737468420505, 'eval/precision_macro': 0.6723214285714286, 'test/recall_weighted': 0.37383177570093457, 'test/precision_weighted': 0.3290419774064634, 'eval/accuracy': 0.5, 'eval/precision_weighted': 0.6635204081632653, 'test/precision_micro': 0.37383177570093457, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.5, 'eval/recall_micro': 0.5, 'split': 10, 'eval/f1_macro': 0.46394194041252856, 'test/accuracy': 0.37383177570093457, 'test/f1_macro': 0.33670531787285085, 'test/f1_micro': 0.37383177570093457, 'eval/f1_weighted': 0.4676998071956054, 'test/f1_weighted': 0.33128580343563513, '_step': 20, 'test/loss': 1.3471303224953288, '_timestamp': 1704570168.9852731, 'eval/recall_macro': 0.4909090909090909, 'test/recall_macro': 0.37884615384615383, 'test/recall_micro': 0.37383177570093457, '_runtime': 3.0229830741882324, 'test/precision_macro': 0.33638468013468015}","{'rf_max_depth': 3, 'trial.number': 4}",valiant-night-745,RandomForest,"['TfIdf', 'preprocessed']"
593,"{'eval/loss': 1.3061459338929, 'eval/accuracy': 0.35714285714285715, 'eval/recall_macro': 0.35, 'test/precision_micro': 0.2803738317757009, 'eval/f1_micro': 0.35714285714285715, 'test/f1_micro': 0.2803738317757009, '_step': 20, 'test/f1_weighted': 0.2382000906609569, 'test/recall_weighted': 0.2803738317757009, 'eval/precision_micro': 0.35714285714285715, 'eval/recall_weighted': 0.35714285714285715, 'test/precision_weighted': 0.20836999838168063, 'eval/precision_weighted': 0.2801023187052599, '_wandb': {'runtime': 2}, '_runtime': 3.479193210601806, 'eval/f1_macro': 0.30499860763018655, 'eval/f1_weighted': 0.30949728819403005, 'eval/recall_micro': 0.35714285714285715, 'test/recall_micro': 0.2803738317757009, '_timestamp': 1704570169.1795971, 'test/f1_macro': 0.243266253869969, 'test/recall_macro': 0.2865242165242165, 'test/precision_macro': 0.212696158008658, 'split': 10, 'test/accuracy': 0.2803738317757009, 'eval/precision_macro': 0.2774714052287582, 'test/loss': 1.3991031125067863}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 8, 'dt_min_samples_leaf': 84}",absurd-donkey-744,DecisionTree,"['TfIdf', 'preprocessed']"
594,"{'eval/loss': 12.01455112970572, 'test/loss': 7.747701195791538, 'test/f1_macro': 0.7817142132019954, 'test/recall_micro': 0.7850467289719626, 'eval/precision_macro': 0.681246857717446, '_step': 20, '_timestamp': 1704570164.332224, 'test/f1_micro': 0.7850467289719625, 'test/precision_micro': 0.7850467289719626, 'eval/precision_weighted': 0.6811630635160048, 'eval/accuracy': 0.6666666666666666, 'eval/f1_macro': 0.6283242829295461, 'eval/f1_weighted': 0.6230639429260982, 'eval/recall_macro': 0.675, 'eval/recall_micro': 0.6666666666666666, 'eval/recall_weighted': 0.6666666666666666, 'split': 10, 'test/recall_weighted': 0.7850467289719626, 'test/precision_weighted': 0.796420577086465, '_wandb': {'runtime': 2}, 'eval/f1_micro': 0.6666666666666666, 'eval/precision_micro': 0.6666666666666666, '_runtime': 2.5252749919891357, 'test/accuracy': 0.7850467289719626, 'test/f1_weighted': 0.7836301132825586, 'test/precision_macro': 0.8014095279720279, 'test/recall_macro': 0.7776984523611211}","{'n_neighbours': 1, 'trial.number': 0}",electric-forest-743,KNeighbours,"['TfIdf', 'preprocessed']"
595,"{'eval/recall_weighted': 0.2619047619047619, '_step': 20, '_wandb': {'runtime': 1}, 'test/accuracy': 0.40186915887850466, 'test/f1_macro': 0.3684119420006517, 'eval/precision_macro': 0.24479166666666663, '_runtime': 4.179861068725586, 'eval/recall_micro': 0.2619047619047619, 'test/recall_micro': 0.40186915887850466, 'test/precision_weighted': 0.38040350096424863, '_timestamp': 1704570163.368699, 'test/f1_micro': 0.40186915887850466, 'eval/f1_weighted': 0.24683657797692884, 'eval/precision_weighted': 0.24652777777777776, 'eval/loss': 1.4971431044040262, 'test/loss': 1.3810715903995736, 'test/recall_macro': 0.39025020678246486, 'test/precision_micro': 0.40186915887850466, 'test/recall_weighted': 0.40186915887850466, 'split': 10, 'eval/f1_micro': 0.2619047619047619, 'test/f1_weighted': 0.3784026578720579, 'eval/recall_macro': 0.2590909090909091, 'test/precision_macro': 0.3742063492063492, 'eval/accuracy': 0.2619047619047619, 'eval/f1_macro': 0.24465598972177915, 'eval/precision_micro': 0.2619047619047619}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 7, 'dt_min_samples_leaf': 37}",fresh-wood-742,DecisionTree,"['BoW', 'preprocessed']"
596,"{'eval/precision_macro': 0.32916666666666666, 'eval/recall_weighted': 0.2857142857142857, 'eval/precision_micro': 0.2857142857142857, 'test/recall_weighted': 0.3364485981308411, '_step': 20, 'eval/loss': 1.367246594841915, '_timestamp': 1704570162.3957126, 'eval/recall_micro': 0.2857142857142857, 'test/recall_micro': 0.3364485981308411, 'eval/accuracy': 0.2857142857142857, 'eval/recall_macro': 0.2818181818181818, 'test/recall_macro': 0.3425621377345516, 'test/precision_macro': 0.3538847117794486, 'test/precision_weighted': 0.35258707516454685, '_runtime': 3.210683584213257, 'eval/f1_micro': 0.2857142857142857, 'test/f1_micro': 0.3364485981308411, 'test/loss': 1.3421890045176337, 'test/f1_macro': 0.33334188326493386, 'eval/precision_weighted': 0.32857142857142857, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.2903096903096903, 'test/accuracy': 0.3364485981308411, 'eval/f1_weighted': 0.29244564958850666, 'split': 10, 'test/f1_weighted': 0.32957615778326116, 'test/precision_micro': 0.3364485981308411}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 7, 'dt_min_samples_leaf': 61}",hopeful-cherry-740,DecisionTree,"['TfIdf', 'preprocessed']"
597,"{'test/loss': 4.1679477796015005, 'eval/recall_micro': 0.6666666666666666, 'test/recall_macro': 0.6871765010351967, 'test/precision_micro': 0.6822429906542056, 'eval/loss': 4.578881934058465, 'test/accuracy': 0.6822429906542056, 'test/f1_macro': 0.6792933926461637, 'eval/precision_macro': 0.6569541569541569, 'eval/precision_micro': 0.6666666666666666, 'test/precision_macro': 0.677856071964018, '_step': 20, 'split': 10, 'eval/recall_macro': 0.6613636363636364, 'eval/accuracy': 0.6666666666666666, '_timestamp': 1704570163.423087, 'eval/f1_macro': 0.6568979266347688, 'eval/f1_micro': 0.6666666666666666, 'test/f1_weighted': 0.6790024588853864, 'test/recall_weighted': 0.6822429906542056, '_wandb': {'runtime': 2}, 'eval/precision_weighted': 0.6591371591371592, 'test/f1_micro': 0.6822429906542056, 'eval/f1_weighted': 0.660609857978279, 'test/recall_micro': 0.6822429906542056, 'eval/recall_weighted': 0.6666666666666666, '_runtime': 2.717031955718994, 'test/precision_weighted': 0.6820098362033937}","{'smoothing': 0.005052273652484618, 'trial.number': 0}",wandering-shadow-741,Bernolli,"['TfIdf', 'preprocessed']"
598,"{'_step': 20, '_runtime': 4.011447429656982, 'eval/f1_macro': 0.6201612903225806, 'test/f1_micro': 0.7102803738317757, 'eval/loss': 0.9964283678822654, 'test/loss': 0.8252804967376353, 'eval/accuracy': 0.6190476190476191, 'eval/recall_micro': 0.6190476190476191, 'eval/precision_micro': 0.6190476190476191, 'test/precision_micro': 0.7102803738317757, 'test/f1_macro': 0.7151175213675214, 'test/recall_weighted': 0.7102803738317757, '_timestamp': 1704570162.7770877, 'eval/recall_macro': 0.6204545454545454, 'test/recall_macro': 0.7130892255892256, 'test/recall_micro': 0.7102803738317757, 'eval/precision_macro': 0.7250000000000001, 'test/precision_macro': 0.7328088578088578, 'split': 10, 'eval/f1_micro': 0.6190476190476191, 'test/accuracy': 0.7102803738317757, 'test/precision_weighted': 0.7434154630416313, '_wandb': {'runtime': 2}, 'test/f1_weighted': 0.7186157041297229, 'eval/recall_weighted': 0.6190476190476191, 'eval/f1_weighted': 0.617153097798259, 'eval/precision_weighted': 0.725}","{'rf_max_depth': 32, 'trial.number': 11}",dry-leaf-739,RandomForest,"['BoW', 'preprocessed']"
599,"{'_step': 20, 'split': 10, 'test/precision_macro': 0.7522727272727273, 'test/recall_weighted': 0.7383177570093458, 'eval/loss': 0.8055654558077489, 'eval/accuracy': 0.7619047619047619, 'test/accuracy': 0.7383177570093458, 'eval/recall_weighted': 0.7619047619047619, 'eval/f1_macro': 0.7657211209842789, 'test/f1_macro': 0.7398756359525155, 'eval/f1_weighted': 0.7666243530905186, 'eval/precision_micro': 0.7619047619047619, 'test/loss': 0.9284712011174956, 'test/f1_weighted': 0.740056740436278, 'test/recall_macro': 0.7356318681318681, '_wandb': {'runtime': 2}, 'eval/recall_macro': 0.7636363636363637, 'test/precision_weighted': 0.7497309544038516, 'test/precision_micro': 0.7383177570093458, 'eval/precision_weighted': 0.786075036075036, '_runtime': 3.66832423210144, 'eval/f1_micro': 0.7619047619047619, 'test/f1_micro': 0.7383177570093457, 'eval/recall_micro': 0.7619047619047619, '_timestamp': 1704570159.308982, 'test/recall_micro': 0.7383177570093458, 'eval/precision_macro': 0.7821969696969697}","{'rf_max_depth': 30, 'trial.number': 3}",stilted-dragon-738,RandomForest,"['TfIdf', 'preprocessed']"
600,"{'eval/f1_micro': 0.21428571428571427, 'eval/accuracy': 0.21428571428571427, 'eval/f1_macro': 0.2089655172413793, 'test/f1_macro': 0.29462090548521097, 'eval/precision_micro': 0.21428571428571427, 'test/precision_micro': 0.29906542056074764, 'eval/precision_weighted': 0.26611170784103116, '_step': 20, 'eval/recall_weighted': 0.21428571428571427, 'test/f1_micro': 0.29906542056074764, 'test/recall_micro': 0.29906542056074764, 'test/recall_macro': 0.2915374276261373, 'eval/f1_weighted': 0.20917350848385333, 'test/f1_weighted': 0.3018174362607094, 'eval/recall_micro': 0.21428571428571427, 'test/recall_weighted': 0.29906542056074764, '_wandb': {'runtime': 1}, '_timestamp': 1704570154.0216596, 'test/accuracy': 0.29906542056074764, 'eval/recall_macro': 0.2159090909090909, 'eval/precision_macro': 0.2633458646616541, 'test/precision_macro': 0.3194729121453259, 'test/precision_weighted': 0.3257014228654576, '_runtime': 3.0583295822143555, 'eval/loss': 3.9368921984217686, 'test/loss': 3.019431726487222, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 6, 'dt_min_samples_leaf': 18}",rose-moon-737,DecisionTree,"['BoW', 'preprocessed']"
601,"{'eval/f1_weighted': 0.3512738428704815, 'test/precision_macro': 0.5783435314685315, '_runtime': 4.4838502407073975, 'test/loss': 1.8092896820582305, 'eval/precision_macro': 0.4190668202764977, 'test/recall_weighted': 0.4205607476635514, '_wandb': {'runtime': 1}, 'eval/recall_macro': 0.425, 'eval/recall_micro': 0.42857142857142855, 'test/recall_macro': 0.4290534433637882, 'test/recall_micro': 0.4205607476635514, 'eval/recall_weighted': 0.42857142857142855, 'test/accuracy': 0.4205607476635514, '_timestamp': 1704570153.2536252, 'test/f1_weighted': 0.3773045026393286, 'test/precision_weighted': 0.5886175740147703, '_step': 20, 'eval/accuracy': 0.42857142857142855, 'eval/f1_micro': 0.42857142857142855, 'test/f1_macro': 0.374768973970261, 'eval/precision_micro': 0.42857142857142855, 'eval/precision_weighted': 0.4075597981127934, 'eval/loss': 3.6470086411779583, 'eval/f1_macro': 0.35574229691876746, 'test/f1_micro': 0.4205607476635514, 'test/precision_micro': 0.4205607476635514, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 6, 'dt_min_samples_leaf': 5}",toasty-glade-736,DecisionTree,"['TfIdf', 'preprocessed']"
602,"{'_step': 20, 'eval/loss': 1.0507963875679234, 'eval/accuracy': 0.5714285714285714, 'eval/recall_macro': 0.5704545454545454, 'test/loss': 0.931901342506082, 'test/precision_micro': 0.6635514018691588, 'test/recall_weighted': 0.6635514018691588, 'eval/precision_weighted': 0.6452440625372956, 'eval/f1_micro': 0.5714285714285714, 'eval/precision_micro': 0.5714285714285714, 'test/precision_weighted': 0.7324391381121532, 'split': 10, 'test/f1_micro': 0.6635514018691588, 'eval/f1_weighted': 0.5874883286647992, 'test/recall_macro': 0.6681277056277057, 'test/recall_micro': 0.6635514018691588, 'test/f1_macro': 0.6698791963529173, 'test/f1_weighted': 0.6759176011289949, 'eval/precision_macro': 0.6516290726817042, '_timestamp': 1704570152.402459, 'eval/recall_micro': 0.5714285714285714, 'eval/f1_macro': 0.5901960784313725, 'test/accuracy': 0.6635514018691588, '_wandb': {'runtime': 2}, '_runtime': 3.8068015575408936, 'eval/recall_weighted': 0.5714285714285714, 'test/precision_macro': 0.7141254257663795}","{'rf_max_depth': 28, 'trial.number': 10}",warm-valley-735,RandomForest,"['BoW', 'preprocessed']"
603,"{'_runtime': 3.2647042274475098, 'test/accuracy': 0.616822429906542, 'eval/f1_weighted': 0.7037037037037037, '_step': 20, 'test/precision_macro': 0.6365740740740741, 'test/precision_micro': 0.616822429906542, 'split': 10, 'test/loss': 0.969766040197726, 'eval/recall_micro': 0.6904761904761905, 'eval/recall_weighted': 0.6904761904761905, 'test/f1_macro': 0.6199750830564784, 'test/recall_weighted': 0.616822429906542, 'eval/loss': 0.8913993877294185, '_timestamp': 1704570149.691075, 'eval/f1_macro': 0.7055555555555555, 'eval/f1_micro': 0.6904761904761905, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.6904761904761905, 'eval/recall_macro': 0.6977272727272726, 'eval/precision_macro': 0.7910714285714286, 'test/precision_weighted': 0.6320526133610245, 'test/f1_weighted': 0.6180675008538516, 'test/recall_macro': 0.6167307692307692, 'test/recall_micro': 0.616822429906542, 'eval/precision_weighted': 0.79421768707483, 'test/f1_micro': 0.616822429906542, 'eval/precision_micro': 0.6904761904761905}","{'rf_max_depth': 23, 'trial.number': 2}",drawn-morning-734,RandomForest,"['TfIdf', 'preprocessed']"
604,"{'eval/precision_weighted': 0.3321718931475029, '_wandb': {'runtime': 2}, 'eval/loss': 1.363891090696966, 'test/accuracy': 0.29906542056074764, 'eval/precision_macro': 0.3170731707317073, 'eval/recall_weighted': 0.2857142857142857, 'test/recall_micro': 0.29906542056074764, 'test/f1_weighted': 0.20805657696951352, 'eval/precision_micro': 0.2857142857142857, '_runtime': 3.713436365127563, '_timestamp': 1704570147.4464853, 'eval/accuracy': 0.2857142857142857, 'eval/recall_micro': 0.2857142857142857, '_step': 20, 'split': 10, 'test/loss': 1.6199753369802656, 'test/f1_macro': 0.2187052713368503, 'test/f1_micro': 0.29906542056074764, 'eval/f1_weighted': 0.15445665445665446, 'test/precision_macro': 0.353494623655914, 'test/recall_weighted': 0.29906542056074764, 'eval/f1_macro': 0.14743589743589744, 'eval/f1_micro': 0.2857142857142857, 'eval/recall_macro': 0.2727272727272727, 'test/recall_macro': 0.3245709263854425, 'test/precision_micro': 0.29906542056074764, 'test/precision_weighted': 0.3623253944327203}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 5, 'dt_min_samples_leaf': 7}",daily-thunder-733,DecisionTree,"['BoW', 'preprocessed']"
605,"{'_timestamp': 1704570145.3192935, 'test/precision_macro': 0.3377380952380952, '_runtime': 2.9976656436920166, 'eval/accuracy': 0.2619047619047619, 'eval/precision_weighted': 0.329031612645058, 'split': 10, 'test/f1_macro': 0.3294609203660477, 'test/recall_weighted': 0.32710280373831774, 'test/precision_weighted': 0.3378949710725412, 'eval/f1_macro': 0.2719389978213507, 'eval/f1_micro': 0.2619047619047619, 'eval/precision_macro': 0.3258403361344538, '_step': 20, 'test/accuracy': 0.32710280373831774, 'test/recall_micro': 0.32710280373831774, '_wandb': {'runtime': 1}, 'eval/f1_weighted': 0.2750119306982052, 'eval/recall_macro': 0.2590909090909091, 'test/recall_macro': 0.32911975636113566, 'test/precision_micro': 0.32710280373831774, 'eval/loss': 1.4135044553534104, 'test/loss': 1.382398839207746, 'test/f1_micro': 0.32710280373831774, 'eval/recall_micro': 0.2619047619047619, 'eval/precision_micro': 0.2619047619047619, 'test/f1_weighted': 0.328688864034678, 'eval/recall_weighted': 0.2619047619047619}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 5, 'dt_min_samples_leaf': 69}",comic-bee-732,DecisionTree,"['TfIdf', 'preprocessed']"
606,"{'_runtime': 3.000980854034424, 'eval/loss': 1.3586067356838083, 'test/recall_micro': 0.2523364485981308, 'test/recall_weighted': 0.2523364485981308, 'eval/precision_weighted': 0.3922902494331066, 'eval/accuracy': 0.30952380952380953, 'eval/f1_macro': 0.2166501976284585, 'eval/recall_micro': 0.30952380952380953, 'split': 10, '_wandb': {'runtime': 1}, 'eval/f1_weighted': 0.21668548842461885, 'eval/recall_weighted': 0.30952380952380953, '_timestamp': 1704570145.115732, 'test/recall_macro': 0.282521645021645, 'eval/precision_macro': 0.4047619047619047, 'eval/precision_micro': 0.30952380952380953, 'test/precision_weighted': 0.25937102675036355, '_step': 20, 'test/f1_macro': 0.1942454416138627, 'eval/f1_micro': 0.30952380952380953, 'test/accuracy': 0.2523364485981308, 'test/f1_micro': 0.2523364485981308, 'test/f1_weighted': 0.1861143708659695, 'eval/recall_macro': 0.30227272727272725, 'test/loss': 1.3600250149009845, 'test/precision_macro': 0.2507972747698775, 'test/precision_micro': 0.2523364485981308}","{'rf_max_depth': 2, 'trial.number': 9}",graceful-sunset-731,RandomForest,"['BoW', 'preprocessed']"
607,"{'test/precision_micro': 0.2897196261682243, 'test/recall_weighted': 0.2897196261682243, 'eval/accuracy': 0.380952380952381, 'eval/f1_macro': 0.3618464052287582, 'test/precision_macro': 0.35226883561643835, 'test/f1_micro': 0.2897196261682243, 'eval/recall_macro': 0.375, 'test/recall_micro': 0.2897196261682243, '_step': 20, 'eval/loss': 1.3368485349583064, '_timestamp': 1704570140.7621827, 'test/f1_macro': 0.2586098468640189, 'test/f1_weighted': 0.25705909163013285, 'eval/recall_weighted': 0.380952380952381, 'eval/f1_weighted': 0.36360099595393713, 'eval/precision_macro': 0.43833333333333335, 'eval/precision_micro': 0.380952380952381, 'split': 10, '_wandb': {'runtime': 2}, 'test/accuracy': 0.2897196261682243, 'eval/precision_weighted': 0.4369841269841269, '_runtime': 3.5040225982666016, 'eval/f1_micro': 0.380952380952381, 'eval/recall_micro': 0.380952380952381, 'test/loss': 1.3627535007982432, 'test/recall_macro': 0.2945054945054945, 'test/precision_weighted': 0.35535942901037}","{'rf_max_depth': 2, 'trial.number': 1}",pretty-water-730,RandomForest,"['TfIdf', 'preprocessed']"
608,"{'_timestamp': 1704570140.4593625, 'test/f1_weighted': 0.2693213598289872, 'test/precision_macro': 0.2440331416361694, 'test/precision_weighted': 0.23112895403283149, 'test/loss': 1.395613100671975, '_runtime': 4.461653470993042, 'eval/f1_macro': 0.18250517598343685, 'eval/f1_micro': 0.21428571428571427, 'eval/f1_weighted': 0.1889283249531697, 'eval/precision_weighted': 0.1721253892306524, '_wandb': {'runtime': 1}, 'test/recall_macro': 0.34615384615384615, 'eval/recall_weighted': 0.21428571428571427, 'eval/accuracy': 0.21428571428571427, 'eval/recall_macro': 0.2068181818181818, 'test/recall_micro': 0.32710280373831774, 'test/recall_weighted': 0.32710280373831774, '_step': 20, 'test/f1_macro': 0.28465644949618524, 'eval/precision_macro': 0.16636762360446572, 'eval/loss': 1.4678844826358557, 'test/precision_micro': 0.32710280373831774, 'eval/recall_micro': 0.21428571428571427, 'test/accuracy': 0.32710280373831774, 'test/f1_micro': 0.32710280373831774, 'eval/precision_micro': 0.21428571428571427, 'split': 10}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 4, 'dt_min_samples_leaf': 48}",wobbly-disco-729,DecisionTree,"['BoW', 'preprocessed']"
609,"{'eval/f1_macro': 0.6340277777777777, 'eval/recall_micro': 0.6190476190476191, 'test/recall_macro': 0.6757154882154882, 'test/recall_weighted': 0.6822429906542056, '_timestamp': 1704570137.564252, 'test/accuracy': 0.6822429906542056, 'eval/recall_macro': 0.6181818181818182, 'test/recall_micro': 0.6822429906542056, 'eval/precision_micro': 0.6190476190476191, 'eval/precision_weighted': 0.691624895572264, 'test/precision_weighted': 0.7215916793486886, '_step': 20, 'split': 10, '_runtime': 3.666645050048828, 'eval/loss': 1.0195848509734946, 'test/loss': 0.9558308267036814, 'test/precision_micro': 0.6822429906542056, 'eval/accuracy': 0.6190476190476191, 'test/f1_macro': 0.6814709350909438, 'eval/f1_weighted': 0.6308201058201057, 'test/precision_macro': 0.7083349983349982, 'eval/recall_weighted': 0.6190476190476191, '_wandb': {'runtime': 2}, 'eval/f1_micro': 0.6190476190476191, 'eval/precision_macro': 0.6990131578947368, 'test/f1_micro': 0.6822429906542056, 'test/f1_weighted': 0.6907318547035918}","{'rf_max_depth': 30, 'trial.number': 8}",hopeful-oath-727,RandomForest,"['BoW', 'preprocessed']"
610,"{'_step': 20, '_runtime': 2.9055862426757812, 'eval/loss': 1.4126097533160988, 'test/f1_weighted': 0.328688864034678, 'test/recall_micro': 0.32710280373831774, 'eval/precision_weighted': 0.329031612645058, 'split': 10, 'eval/f1_macro': 0.2719389978213507, 'eval/f1_micro': 0.2619047619047619, 'eval/recall_micro': 0.2619047619047619, 'test/recall_macro': 0.32911975636113566, 'eval/recall_weighted': 0.2619047619047619, 'test/accuracy': 0.32710280373831774, 'test/f1_macro': 0.3294609203660477, 'eval/f1_weighted': 0.2750119306982052, 'eval/recall_macro': 0.2590909090909091, 'eval/precision_macro': 0.3258403361344538, 'eval/precision_micro': 0.2619047619047619, 'test/loss': 1.3832589430039728, '_timestamp': 1704570137.6063342, 'eval/accuracy': 0.2619047619047619, 'test/precision_macro': 0.3377380952380952, 'test/precision_micro': 0.32710280373831774, 'test/f1_micro': 0.32710280373831774, 'test/recall_weighted': 0.32710280373831774, '_wandb': {'runtime': 1}, 'test/precision_weighted': 0.3378949710725412}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 4, 'dt_min_samples_leaf': 72}",dainty-elevator-728,DecisionTree,"['TfIdf', 'preprocessed']"
611,"{'test/accuracy': 0.6261682242990654, 'test/f1_weighted': 0.6151373886847271, 'eval/recall_macro': 0.7886363636363637, 'test/recall_micro': 0.6261682242990654, 'eval/precision_macro': 0.7964743589743589, 'eval/recall_micro': 0.7857142857142857, 'test/precision_macro': 0.6170138888888889, 'split': 10, 'test/f1_micro': 0.6261682242990654, 'eval/recall_weighted': 0.7857142857142857, 'test/recall_weighted': 0.6261682242990654, 'eval/loss': 0.8149895556758269, 'eval/accuracy': 0.7857142857142857, 'eval/f1_micro': 0.7857142857142857, 'test/f1_macro': 0.6145106704889314, 'eval/f1_weighted': 0.7823915850231639, 'eval/precision_weighted': 0.7947191697191697, '_step': 20, '_wandb': {'runtime': 2}, '_timestamp': 1704570132.7885404, 'test/recall_macro': 0.6264285714285714, 'eval/precision_micro': 0.7857142857142857, '_runtime': 2.7781403064727783, 'test/loss': 1.2071468417617184, 'eval/f1_macro': 0.7848883572567782, 'test/precision_micro': 0.6261682242990654, 'test/precision_weighted': 0.6190550363447559}","{'rf_max_depth': 30, 'trial.number': 0}",laced-durian-726,RandomForest,"['TfIdf', 'preprocessed']"
612,"{'eval/f1_macro': 0.33085317460317465, 'test/recall_micro': 0.40186915887850466, 'test/precision_weighted': 0.39732067937849025, 'test/loss': 1.311202656538066, 'eval/f1_micro': 0.380952380952381, 'test/f1_macro': 0.34817298797409807, 'test/f1_micro': 0.40186915887850466, 'eval/recall_macro': 0.3772727272727273, 'test/recall_macro': 0.4279220779220779, 'eval/recall_micro': 0.380952380952381, 'test/recall_weighted': 0.40186915887850466, '_step': 20, 'split': 10, 'eval/loss': 1.3533123718348588, '_timestamp': 1704570129.3549092, 'eval/precision_micro': 0.380952380952381, 'test/precision_macro': 0.38304953560371513, 'test/accuracy': 0.40186915887850466, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.380952380952381, 'test/f1_weighted': 0.34838804499122483, 'eval/f1_weighted': 0.3304043839758125, 'eval/precision_weighted': 0.37007936507936506, '_runtime': 2.9725141525268555, 'eval/precision_macro': 0.37125, 'eval/recall_weighted': 0.380952380952381, 'test/precision_micro': 0.40186915887850466}","{'rf_max_depth': 5, 'trial.number': 7}",dandy-eon-725,RandomForest,"['BoW', 'preprocessed']"
613,"{'eval/f1_micro': 0.2619047619047619, 'test/f1_micro': 0.2523364485981308, 'eval/recall_weighted': 0.2619047619047619, 'test/loss': 1.3900560897006944, 'eval/precision_weighted': 0.13822751322751323, 'test/f1_weighted': 0.15892875087930863, 'test/recall_macro': 0.2676282051282051, '_runtime': 3.220163106918335, 'test/accuracy': 0.2523364485981308, 'test/precision_micro': 0.2523364485981308, 'test/f1_macro': 0.1695228494623656, 'eval/precision_macro': 0.13194444444444445, 'eval/recall_micro': 0.2619047619047619, 'test/recall_micro': 0.2523364485981308, 'test/recall_weighted': 0.2523364485981308, '_wandb': {'runtime': 1}, 'eval/loss': 1.4242427129976538, 'eval/f1_macro': 0.17192118226600986, 'eval/f1_weighted': 0.18010790523105794, 'eval/recall_macro': 0.25, 'eval/precision_micro': 0.2619047619047619, 'test/precision_macro': 0.12593283582089554, 'test/precision_weighted': 0.11772911145208537, '_step': 20, '_timestamp': 1704570129.0055192, 'split': 10, 'eval/accuracy': 0.2619047619047619}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 3, 'dt_min_samples_leaf': 12}",clear-sunset-724,DecisionTree,"['BoW', 'preprocessed']"
614,"{'_timestamp': 1704570128.3665946, 'eval/f1_macro': 0.37764705882352945, 'test/f1_weighted': 0.30562620747283553, 'eval/recall_micro': 0.4047619047619048, 'test/recall_weighted': 0.3644859813084112, '_runtime': 3.891331434249878, 'test/loss': 1.2358014027085713, 'test/f1_macro': 0.294121821604946, '_step': 20, 'eval/precision_macro': 0.3833333333333333, 'eval/precision_micro': 0.4047619047619048, 'eval/precision_weighted': 0.380952380952381, 'test/f1_micro': 0.36448598130841114, 'eval/accuracy': 0.4047619047619048, 'eval/f1_weighted': 0.3708683473389356, 'eval/loss': 1.2567347148972488, 'eval/recall_macro': 0.4159090909090909, 'test/recall_micro': 0.3644859813084112, 'eval/recall_weighted': 0.4047619047619048, 'test/precision_macro': 0.27297794117647056, 'test/precision_micro': 0.3644859813084112, 'test/accuracy': 0.3644859813084112, 'test/recall_macro': 0.34879801552215345, 'test/precision_weighted': 0.2814389774601429, 'split': 10, 'eval/f1_micro': 0.4047619047619048, '_wandb': {'runtime': 2}}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 3, 'dt_min_samples_leaf': 21}",jumping-salad-723,DecisionTree,"['TfIdf', 'preprocessed']"
615,"{'eval/recall_weighted': 0.21428571428571427, 'test/precision_micro': 0.2803738317757009, 'eval/precision_weighted': 0.2439139292080469, '_wandb': {'runtime': 1}, 'test/accuracy': 0.2803738317757009, 'eval/precision_macro': 0.24625668449197863, 'test/precision_weighted': 0.28520959865142914, 'test/loss': 1.4389132828586424, 'eval/accuracy': 0.21428571428571427, 'eval/loss': 1.5010333157773927, 'test/f1_weighted': 0.26812777787410635, 'test/recall_macro': 0.2870657568238213, 'test/recall_weighted': 0.2803738317757009, '_runtime': 3.1552278995513916, 'test/recall_micro': 0.2803738317757009, 'eval/recall_macro': 0.21136363636363636, 'eval/recall_micro': 0.21428571428571427, 'eval/f1_macro': 0.20833333333333337, 'test/f1_macro': 0.27183055040197895, 'test/precision_macro': 0.2832592838196286, 'split': 10, '_timestamp': 1704570121.474097, 'eval/f1_micro': 0.21428571428571427, 'test/f1_micro': 0.2803738317757009, 'eval/f1_weighted': 0.20918367346938777, 'eval/precision_micro': 0.21428571428571427, '_step': 20}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 2, 'dt_min_samples_leaf': 55}",trim-glitter-722,DecisionTree,"['BoW', 'preprocessed']"
616,"{'_step': 20, '_wandb': {'runtime': 2}, 'eval/precision_micro': 0.5238095238095238, 'eval/f1_weighted': 0.5267195767195767, 'test/precision_micro': 0.5327102803738317, 'test/precision_weighted': 0.554069408701672, 'test/f1_macro': 0.5301346801346801, 'test/recall_micro': 0.5327102803738317, 'eval/precision_macro': 0.5578022875816994, 'test/recall_weighted': 0.5327102803738317, '_runtime': 3.575101613998413, 'test/f1_weighted': 0.536429717738129, 'eval/precision_weighted': 0.5516262060379707, 'split': 10, 'eval/recall_macro': 0.525, 'eval/recall_micro': 0.5238095238095238, 'test/recall_macro': 0.5337722462722463, 'test/loss': 1.2203701593781402, 'eval/f1_micro': 0.5238095238095238, 'test/f1_micro': 0.5327102803738317, 'eval/loss': 1.2360359934466172, '_timestamp': 1704570121.6949136, 'eval/accuracy': 0.5238095238095238, 'eval/f1_macro': 0.5305555555555554, 'test/accuracy': 0.5327102803738317, 'eval/recall_weighted': 0.5238095238095238, 'test/precision_macro': 0.5416712413995023}","{'rf_max_depth': 10, 'trial.number': 6}",amber-surf-721,RandomForest,"['BoW', 'preprocessed']"
617,"{'test/precision_macro': 0.4332609594706369, 'test/recall_weighted': 0.40186915887850466, 'eval/loss': 2.687051216119955, 'eval/f1_weighted': 0.46574311235965365, 'eval/recall_macro': 0.475, 'eval/recall_weighted': 0.47619047619047616, 'split': 10, '_runtime': 3.087461471557617, 'test/precision_micro': 0.40186915887850466, '_timestamp': 1704570119.0743134, 'eval/accuracy': 0.47619047619047616, 'eval/precision_macro': 0.46875, 'eval/f1_macro': 0.4665027954501638, 'eval/recall_micro': 0.47619047619047616, 'test/recall_micro': 0.40186915887850466, 'eval/precision_micro': 0.47619047619047616, '_wandb': {'runtime': 1}, 'test/f1_weighted': 0.4092820402176892, '_step': 20, 'test/loss': 3.138415232544311, 'test/precision_weighted': 0.43402866352821134, 'eval/f1_micro': 0.47619047619047616, 'test/accuracy': 0.40186915887850466, 'test/f1_micro': 0.40186915887850466, 'eval/precision_weighted': 0.4662698412698412, 'test/f1_macro': 0.411771597821706, 'test/recall_macro': 0.4085249042145594}","{'n_neighbours': 7, 'trial.number': 9}",whole-glitter-720,KNeighbours,"['BoW', 'preprocessed']"
618,"{'eval/precision_micro': 0.47619047619047616, 'eval/precision_weighted': 0.4734432234432234, 'test/loss': 3.108850982160294, 'test/accuracy': 0.3925233644859813, 'eval/f1_weighted': 0.46964573268921095, 'test/recall_micro': 0.3925233644859813, 'test/precision_macro': 0.3943452380952381, 'split': 10, 'eval/recall_macro': 0.4818181818181818, 'test/recall_macro': 0.3878809313292072, 'test/recall_weighted': 0.3925233644859813, 'eval/accuracy': 0.47619047619047616, 'eval/f1_macro': 0.47475845410628015, 'eval/f1_micro': 0.47619047619047616, 'test/f1_macro': 0.38613369467028, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.3925233644859813, 'test/precision_micro': 0.3925233644859813, '_runtime': 3.936243772506714, '_timestamp': 1704570118.1245418, 'eval/recall_micro': 0.47619047619047616, 'eval/precision_macro': 0.4783653846153846, 'test/precision_weighted': 0.3951008752410621, '_step': 20, 'test/f1_weighted': 0.3889792231255646, 'eval/recall_weighted': 0.47619047619047616, 'eval/loss': 1.2215203525702936}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 2, 'dt_min_samples_leaf': 14}",rose-universe-719,DecisionTree,"['TfIdf', 'preprocessed']"
619,"{'test/precision_macro': 0.3100675675675676, 'eval/precision_weighted': 0.2447278911564626, '_runtime': 4.198496103286743, 'eval/f1_weighted': 0.18190980095742, 'test/f1_weighted': 0.30102757613949005, 'split': 10, 'test/precision_weighted': 0.31791614043950495, 'eval/precision_macro': 0.24821428571428572, 'eval/recall_weighted': 0.1904761904761905, '_step': 20, 'eval/loss': 1.5058414684211567, 'eval/accuracy': 0.1904761904761905, 'test/recall_macro': 0.29854218362282875, 'test/loss': 1.4585903405802905, 'test/recall_micro': 0.29906542056074764, 'eval/recall_macro': 0.18863636363636363, 'eval/recall_micro': 0.1904761904761905, 'eval/precision_micro': 0.1904761904761905, 'test/recall_weighted': 0.29906542056074764, '_wandb': {'runtime': 1}, '_timestamp': 1704570113.042833, 'test/f1_micro': 0.29906542056074764, 'eval/f1_macro': 0.1812169312169312, 'test/f1_macro': 0.29745231425903695, 'eval/f1_micro': 0.1904761904761905, 'test/accuracy': 0.29906542056074764, 'test/precision_micro': 0.29906542056074764}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 1, 'dt_min_samples_leaf': 25}",quiet-paper-718,DecisionTree,"['BoW', 'preprocessed']"
620,"{'eval/recall_macro': 0.43181818181818177, '_timestamp': 1704570112.3449905, 'test/f1_weighted': 0.4588682345691692, 'eval/recall_weighted': 0.42857142857142855, 'test/precision_micro': 0.45794392523364486, '_runtime': 3.7449045181274414, 'test/loss': 1.2963296049580375, 'test/accuracy': 0.45794392523364486, 'test/recall_micro': 0.45794392523364486, 'eval/precision_micro': 0.42857142857142855, '_step': 20, 'eval/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.4537124060150376, 'test/precision_macro': 0.5596049783549784, 'test/recall_weighted': 0.45794392523364486, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.42729618163054695, 'eval/f1_weighted': 0.4205661211853162, 'test/recall_macro': 0.47834295334295335, 'eval/accuracy': 0.42857142857142855, 'test/f1_micro': 0.45794392523364486, 'eval/precision_weighted': 0.4438551736484067, 'test/precision_weighted': 0.5799550916373346, 'split': 10, 'eval/loss': 1.3238728789395928, 'eval/f1_micro': 0.42857142857142855, 'test/f1_macro': 0.4567155067155067}","{'rf_max_depth': 5, 'trial.number': 5}",fragrant-thunder-717,RandomForest,"['BoW', 'preprocessed']"
621,"{'test/loss': 4.029203607472121, 'test/f1_micro': 0.4392523364485981, 'test/recall_macro': 0.4415418553349588, 'eval/recall_weighted': 0.4523809523809524, 'split': 10, 'eval/accuracy': 0.4523809523809524, 'eval/precision_micro': 0.4523809523809524, 'test/precision_macro': 0.4510635307346327, '_timestamp': 1704570110.6185343, 'test/recall_micro': 0.4392523364485981, '_step': 20, '_runtime': 3.073805332183838, 'test/f1_weighted': 0.4430464906456939, 'eval/precision_macro': 0.44375, 'test/precision_micro': 0.4392523364485981, 'test/recall_weighted': 0.4392523364485981, 'eval/precision_weighted': 0.4426587301587302, '_wandb': {'runtime': 1}, 'eval/loss': 3.5329867558710024, 'eval/f1_micro': 0.4523809523809524, 'test/accuracy': 0.4392523364485981, 'test/f1_macro': 0.4451472897431066, 'eval/recall_micro': 0.4523809523809524, 'test/precision_weighted': 0.4491822429906542, 'eval/recall_macro': 0.4522727272727272, 'eval/f1_macro': 0.4425101214574899, 'eval/f1_weighted': 0.4417775207248892}","{'n_neighbours': 6, 'trial.number': 8}",toasty-pond-716,KNeighbours,"['BoW', 'preprocessed']"
622,"{'_wandb': {'runtime': 1}, 'eval/loss': 1.305453350243781, 'eval/accuracy': 0.2857142857142857, '_step': 20, 'eval/f1_macro': 0.2735876623376623, 'test/accuracy': 0.308411214953271, 'test/recall_micro': 0.308411214953271, 'eval/precision_macro': 0.27294372294372293, 'eval/precision_weighted': 0.2715110286538858, 'eval/precision_micro': 0.2857142857142857, 'split': 10, 'test/loss': 1.3723185122273838, 'test/f1_macro': 0.29991566298650607, 'test/f1_weighted': 0.30130402858247635, 'eval/f1_micro': 0.2857142857142857, 'test/f1_micro': 0.308411214953271, 'eval/recall_macro': 0.2886363636363637, 'test/precision_micro': 0.308411214953271, 'eval/recall_micro': 0.2857142857142857, 'test/recall_macro': 0.308435995677375, 'test/recall_weighted': 0.308411214953271, 'test/precision_weighted': 0.30631037026915797, 'test/precision_macro': 0.3030408295303062, '_runtime': 3.0013904571533203, '_timestamp': 1704570110.0178044, 'eval/f1_weighted': 0.27115491651205936, 'eval/recall_weighted': 0.2857142857142857}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 1, 'dt_min_samples_leaf': 42}",glorious-forest-715,DecisionTree,"['TfIdf', 'preprocessed']"
623,"{'_step': 20, 'eval/recall_weighted': 0.47619047619047616, '_runtime': 3.6228513717651367, 'test/loss': 3.138415232544311, 'eval/recall_macro': 0.475, 'test/recall_macro': 0.4085249042145594, 'eval/loss': 2.687051216119955, '_timestamp': 1704570102.6811614, 'eval/f1_macro': 0.4665027954501638, 'test/f1_micro': 0.40186915887850466, 'split': 10, '_wandb': {'runtime': 2}, 'eval/f1_weighted': 0.46574311235965365, 'test/recall_weighted': 0.40186915887850466, 'eval/accuracy': 0.47619047619047616, 'eval/f1_micro': 0.47619047619047616, 'test/accuracy': 0.40186915887850466, 'test/f1_macro': 0.411771597821706, 'eval/recall_micro': 0.47619047619047616, 'eval/precision_macro': 0.46875, 'eval/precision_micro': 0.47619047619047616, 'eval/precision_weighted': 0.4662698412698412, 'test/precision_weighted': 0.43402866352821134, 'test/f1_weighted': 0.4092820402176892, 'test/recall_micro': 0.40186915887850466, 'test/precision_macro': 0.4332609594706369, 'test/precision_micro': 0.40186915887850466}","{'n_neighbours': 7, 'trial.number': 7}",copper-yogurt-714,KNeighbours,"['BoW', 'preprocessed']"
624,"{'eval/f1_micro': 0.30952380952380953, '_runtime': 4.0101330280303955, 'test/loss': 1.3406906095700122, 'test/precision_macro': 0.5370892018779343, '_wandb': {'runtime': 2}, 'eval/recall_macro': 0.3068181818181818, 'test/f1_micro': 0.383177570093458, 'test/precision_weighted': 0.5619674432890176, 'eval/loss': 1.3485049531497626, 'test/accuracy': 0.38317757009345793, 'eval/recall_weighted': 0.30952380952380953, 'eval/accuracy': 0.30952380952380953, 'eval/precision_macro': 0.378021978021978, 'eval/precision_micro': 0.30952380952380953, 'eval/precision_weighted': 0.36983254840397695, 'test/recall_macro': 0.41073833573833574, 'test/recall_micro': 0.38317757009345793, 'eval/f1_macro': 0.2938009438009438, 'test/f1_macro': 0.36721680420105024, 'test/f1_weighted': 0.3669680899736077, 'split': 10, '_timestamp': 1704570102.403533, 'test/precision_micro': 0.38317757009345793, 'test/recall_weighted': 0.38317757009345793, '_step': 20, 'eval/f1_weighted': 0.29146493432207715, 'eval/recall_micro': 0.30952380952380953}","{'rf_max_depth': 3, 'trial.number': 4}",lyric-glade-711,RandomForest,"['BoW', 'preprocessed']"
625,"{'_step': 20, 'test/loss': 2.4752638296250744, '_timestamp': 1704570102.1586103, 'test/recall_micro': 0.3925233644859813, 'split': 10, '_wandb': {'runtime': 2}, 'test/accuracy': 0.3925233644859813, 'eval/precision_micro': 0.3333333333333333, 'eval/recall_weighted': 0.3333333333333333, 'test/recall_weighted': 0.3925233644859813, 'test/precision_macro': 0.5032865462002786, 'eval/precision_weighted': 0.446078431372549, '_runtime': 2.540151357650757, 'eval/loss': 3.764933865473723, 'eval/f1_micro': 0.3333333333333333, 'test/f1_macro': 0.3703030825091296, 'test/f1_micro': 0.3925233644859813, 'test/precision_weighted': 0.5160366404031667, 'test/recall_macro': 0.40281224152191897, 'eval/accuracy': 0.3333333333333333, 'eval/f1_macro': 0.26495726495726496, 'test/f1_weighted': 0.373923746258939, 'eval/recall_micro': 0.3333333333333333, 'test/precision_micro': 0.3925233644859813, 'eval/f1_weighted': 0.26658526658526654, 'eval/recall_macro': 0.32499999999999996, 'eval/precision_macro': 0.44852941176470584}","{'dt_criterion': 'gini', 'dt_max_depth': 9, 'trial.number': 0, 'dt_min_samples_leaf': 7}",lucky-resonance-713,DecisionTree,"['BoW', 'preprocessed']"
626,"{'eval/f1_micro': 0.3333333333333333, 'test/f1_macro': 0.3539725163831482, 'test/precision_weighted': 0.4412362373240443, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.3031837255975187, 'eval/recall_macro': 0.325, 'test/recall_weighted': 0.34579439252336447, 'eval/loss': 1.3748750550724391, 'test/accuracy': 0.34579439252336447, 'test/recall_micro': 0.34579439252336447, 'eval/precision_weighted': 0.34771825396825395, '_timestamp': 1704570102.6999211, 'test/precision_micro': 0.34579439252336447, 'eval/precision_micro': 0.3333333333333333, '_runtime': 3.249605178833008, 'eval/accuracy': 0.3333333333333333, 'eval/recall_micro': 0.3333333333333333, 'eval/precision_macro': 0.3489583333333333, 'eval/f1_weighted': 0.3074169642314142, 'test/f1_weighted': 0.3552335241349481, 'test/recall_macro': 0.34919343746929954, 'eval/recall_weighted': 0.3333333333333333, '_step': 20, 'split': 10, 'test/loss': 1.3611575792898447, 'test/f1_micro': 0.34579439252336447, 'test/precision_macro': 0.4324638592080452}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 0, 'dt_min_samples_leaf': 33}",exalted-morning-712,DecisionTree,"['TfIdf', 'preprocessed']"
627,"{'test/recall_micro': 0.5794392523364486, 'eval/recall_weighted': 0.5, 'eval/precision_weighted': 0.6256613756613757, '_step': 20, 'test/f1_weighted': 0.5911582852959587, 'eval/precision_micro': 0.5, '_wandb': {'runtime': 1}, 'test/loss': 1.1124701816897646, 'eval/precision_macro': 0.63510101010101, 'eval/loss': 1.1918993192221796, 'eval/recall_macro': 0.4977272727272727, 'test/precision_micro': 0.5794392523364486, 'split': 10, 'test/f1_micro': 0.5794392523364486, 'eval/recall_micro': 0.5, 'test/precision_macro': 0.6168042062560051, '_runtime': 3.1825947761535645, 'eval/f1_micro': 0.5, 'test/accuracy': 0.5794392523364486, 'test/recall_macro': 0.5824374699374699, 'eval/f1_macro': 0.5227272727272727, 'eval/accuracy': 0.5, 'eval/f1_weighted': 0.5198412698412698, 'test/recall_weighted': 0.5794392523364486, 'test/precision_weighted': 0.630723149174523, '_timestamp': 1704570094.0467618, 'test/f1_macro': 0.5863228681512815}","{'rf_max_depth': 14, 'trial.number': 3}",fanciful-cosmos-710,RandomForest,"['BoW', 'preprocessed']"
628,"{'eval/loss': 11.15636890615531, 'eval/f1_macro': 0.655952380952381, 'eval/f1_weighted': 0.6609977324263038, 'test/recall_micro': 0.7476635514018691, '_runtime': 3.2346932888031006, 'test/loss': 9.095127490711803, 'eval/precision_micro': 0.6904761904761905, 'test/precision_micro': 0.7476635514018691, 'test/recall_weighted': 0.7476635514018691, 'test/precision_weighted': 0.7609479305740988, 'test/accuracy': 0.7476635514018691, 'test/f1_micro': 0.7476635514018691, 'eval/recall_micro': 0.6904761904761905, 'eval/precision_macro': 0.6574175824175824, 'test/precision_macro': 0.75625, '_wandb': {'runtime': 1}, '_timestamp': 1704570093.9236543, 'test/recall_macro': 0.761755485893417, 'eval/precision_weighted': 0.6621925693354265, 'split': 10, 'test/f1_weighted': 0.7223092946024334, '_step': 20, 'eval/accuracy': 0.6904761904761905, 'eval/f1_micro': 0.6904761904761905, 'test/f1_macro': 0.7278958282007062, 'eval/recall_macro': 0.6863636363636364, 'eval/recall_weighted': 0.6904761904761905}","{'n_neighbours': 1, 'trial.number': 6}",lucky-sky-709,KNeighbours,"['BoW', 'preprocessed']"
629,"{'eval/f1_macro': 0.41001683501683506, 'test/f1_macro': 0.3626648115020208, 'eval/recall_macro': 0.4272727272727273, '_timestamp': 1704570085.5452492, 'eval/f1_weighted': 0.41121532788199455, 'test/recall_macro': 0.36203993962614656, 'eval/precision_micro': 0.42857142857142855, '_step': 20, 'eval/precision_weighted': 0.41385582010582017, 'eval/recall_micro': 0.42857142857142855, 'test/precision_macro': 0.3885416666666666, 'eval/loss': 1.9221931121375124, 'test/recall_weighted': 0.35514018691588783, '_wandb': {'runtime': 1}, 'test/loss': 2.5296958882647855, 'test/f1_micro': 0.35514018691588783, 'test/f1_weighted': 0.35844443577545076, 'test/recall_micro': 0.35514018691588783, 'eval/precision_macro': 0.4128472222222222, 'eval/recall_weighted': 0.42857142857142855, 'split': 10, 'eval/accuracy': 0.42857142857142855, 'eval/f1_micro': 0.42857142857142855, 'test/accuracy': 0.35514018691588783, '_runtime': 3.2657241821289062, 'test/precision_weighted': 0.3865654205607477, 'test/precision_micro': 0.35514018691588783}","{'n_neighbours': 9, 'trial.number': 5}",divine-flower-707,KNeighbours,"['BoW', 'preprocessed']"
630,"{'test/accuracy': 0.5233644859813084, 'test/f1_micro': 0.5233644859813084, 'test/precision_micro': 0.5233644859813084, 'test/recall_weighted': 0.5233644859813084, '_step': 20, 'eval/f1_macro': 0.4072317098882563, 'eval/precision_micro': 0.4047619047619048, 'eval/recall_weighted': 0.4047619047619048, 'eval/accuracy': 0.4047619047619048, 'eval/loss': 1.3146758486897336, 'test/f1_macro': 0.5175278595276214, 'test/f1_weighted': 0.5213480575558233, 'eval/recall_macro': 0.4022727272727272, 'test/recall_micro': 0.5233644859813084, '_runtime': 3.140497922897339, 'test/loss': 1.223240251960399, 'test/recall_macro': 0.5221681096681097, 'test/precision_macro': 0.53011031311469, '_wandb': {'runtime': 1}, 'eval/f1_weighted': 0.40763832414686296, 'eval/precision_macro': 0.45, 'test/precision_weighted': 0.5381835592599998, 'split': 10, '_timestamp': 1704570085.600559, 'eval/precision_weighted': 0.4493197278911564, 'eval/f1_micro': 0.4047619047619048, 'eval/recall_micro': 0.4047619047619048}","{'rf_max_depth': 8, 'trial.number': 2}",dry-serenity-708,RandomForest,"['BoW', 'preprocessed']"
631,"{'split': 10, 'eval/accuracy': 0.3333333333333333, '_timestamp': 1704570078.6819236, 'test/precision_macro': 0.15517631103074142, 'test/precision_weighted': 0.1496510114752159, '_step': 20, 'eval/f1_weighted': 0.22843340234644585, 'test/precision_micro': 0.27102803738317754, 'test/recall_weighted': 0.27102803738317754, 'eval/recall_micro': 0.3333333333333333, 'eval/precision_weighted': 0.2965986394557823, '_runtime': 3.4282915592193604, 'test/f1_weighted': 0.17608957157397984, 'test/recall_micro': 0.27102803738317754, '_wandb': {'runtime': 2}, 'eval/loss': 1.3714005051788154, 'test/loss': 1.3745028279691422, 'test/accuracy': 0.27102803738317754, 'test/f1_micro': 0.27102803738317754, 'eval/precision_macro': 0.3035714285714286, 'eval/precision_micro': 0.3333333333333333, 'eval/f1_macro': 0.2278985507246377, 'eval/f1_micro': 0.3333333333333333, 'test/f1_macro': 0.18732319660537483, 'eval/recall_macro': 0.325, 'test/recall_macro': 0.3027597402597403, 'eval/recall_weighted': 0.3333333333333333}","{'rf_max_depth': 2, 'trial.number': 1}",lively-shadow-706,RandomForest,"['BoW', 'preprocessed']"
632,"{'_wandb': {'runtime': 2}, 'eval/f1_micro': 0.4047619047619048, 'test/recall_micro': 0.5700934579439252, 'eval/recall_weighted': 0.4047619047619048, 'test/accuracy': 0.5700934579439252, 'test/precision_micro': 0.5700934579439252, 'eval/accuracy': 0.4047619047619048, 'test/f1_micro': 0.5700934579439252, 'eval/f1_weighted': 0.3949463579898362, 'test/precision_macro': 0.6054213352007469, 'test/precision_weighted': 0.5994354127944012, '_step': 20, 'eval/loss': 11.436928479239096, 'eval/precision_weighted': 0.4546485260770975, 'eval/f1_macro': 0.3981719367588933, 'test/f1_weighted': 0.5763708636556645, 'test/recall_macro': 0.56478578892372, 'eval/precision_macro': 0.4523809523809524, '_runtime': 3.404442548751831, 'test/loss': 7.067510037298135, '_timestamp': 1704570076.3106456, 'eval/recall_macro': 0.4113636363636364, 'eval/recall_micro': 0.4047619047619048, 'eval/precision_micro': 0.4047619047619048, 'test/recall_weighted': 0.5700934579439252, 'split': 10, 'test/f1_macro': 0.5763439046333783}","{'n_neighbours': 2, 'trial.number': 4}",restful-glade-705,KNeighbours,"['BoW', 'preprocessed']"
633,"{'eval/precision_macro': 0.226010101010101, 'eval/recall_weighted': 0.21428571428571427, 'eval/precision_weighted': 0.2271524771524772, '_timestamp': 1704570071.499994, 'test/f1_macro': 0.2812871037008968, 'eval/f1_weighted': 0.16784406070120356, 'test/precision_macro': 0.42665816326530615, 'test/f1_weighted': 0.2773147574307742, 'eval/recall_micro': 0.21428571428571427, 'eval/precision_micro': 0.21428571428571427, 'test/precision_weighted': 0.40086782376502006, 'test/precision_micro': 0.29906542056074764, '_step': 20, 'eval/loss': 1.3649933121103663, 'eval/accuracy': 0.21428571428571427, 'test/accuracy': 0.29906542056074764, 'test/recall_macro': 0.2923220298220298, 'split': 10, 'test/loss': 1.3441016921504072, 'eval/f1_micro': 0.21428571428571427, 'test/f1_micro': 0.29906542056074764, 'test/recall_micro': 0.29906542056074764, '_wandb': {'runtime': 2}, '_runtime': 2.573270082473755, 'eval/f1_macro': 0.1723901098901099, 'test/recall_weighted': 0.29906542056074764, 'eval/recall_macro': 0.22272727272727277}","{'rf_max_depth': 3, 'trial.number': 0}",clean-blaze-704,RandomForest,"['BoW', 'preprocessed']"
634,"{'eval/recall_macro': 0.4113636363636364, 'eval/loss': 11.436928479239096, 'split': 10, 'eval/accuracy': 0.4047619047619048, 'eval/f1_macro': 0.3981719367588933, 'eval/f1_micro': 0.4047619047619048, '_step': 20, 'test/precision_macro': 0.6054213352007469, 'test/precision_micro': 0.5700934579439252, 'test/recall_weighted': 0.5700934579439252, 'test/precision_weighted': 0.5994354127944012, 'test/recall_macro': 0.56478578892372, '_runtime': 4.7181291580200195, 'test/loss': 7.067510037298135, '_timestamp': 1704570067.1245472, 'test/f1_weighted': 0.5763708636556645, '_wandb': {'runtime': 2}, 'test/recall_micro': 0.5700934579439252, 'test/accuracy': 0.5700934579439252, 'eval/recall_weighted': 0.4047619047619048, 'test/f1_macro': 0.5763439046333783, 'eval/precision_micro': 0.4047619047619048, 'eval/precision_macro': 0.4523809523809524, 'eval/f1_weighted': 0.3949463579898362, 'eval/recall_micro': 0.4047619047619048, 'eval/precision_weighted': 0.4546485260770975, 'test/f1_micro': 0.5700934579439252}","{'n_neighbours': 2, 'trial.number': 3}",ruby-voice-703,KNeighbours,"['BoW', 'preprocessed']"
635,"{'eval/precision_weighted': 0.6621925693354265, 'test/recall_weighted': 0.7476635514018691, '_wandb': {'runtime': 2}, '_runtime': 3.4912357330322266, '_timestamp': 1704570057.6550918, 'eval/accuracy': 0.6904761904761905, 'eval/recall_weighted': 0.6904761904761905, 'test/precision_micro': 0.7476635514018691, 'test/recall_macro': 0.761755485893417, 'test/precision_macro': 0.75625, 'eval/f1_macro': 0.655952380952381, 'test/f1_macro': 0.7278958282007062, 'test/recall_micro': 0.7476635514018691, 'eval/precision_macro': 0.6574175824175824, 'split': 10, 'eval/loss': 11.15636890615531, 'test/f1_micro': 0.7476635514018691, 'eval/precision_micro': 0.6904761904761905, 'test/precision_weighted': 0.7609479305740988, '_step': 20, 'eval/f1_micro': 0.6904761904761905, 'eval/recall_micro': 0.6904761904761905, 'test/loss': 9.095127490711803, 'eval/f1_weighted': 0.6609977324263038, 'eval/recall_macro': 0.6863636363636364, 'test/accuracy': 0.7476635514018691, 'test/f1_weighted': 0.7223092946024334}","{'n_neighbours': 1, 'trial.number': 2}",cerulean-glade-702,KNeighbours,"['BoW', 'preprocessed']"
636,"{'eval/precision_weighted': 0.4546485260770975, '_step': 20, 'eval/accuracy': 0.4047619047619048, 'eval/f1_macro': 0.3981719367588933, 'test/f1_weighted': 0.5763708636556645, 'split': 10, 'test/f1_macro': 0.5763439046333783, 'eval/f1_weighted': 0.3949463579898362, 'test/recall_micro': 0.5700934579439252, 'eval/recall_macro': 0.4113636363636364, 'eval/recall_weighted': 0.4047619047619048, 'eval/loss': 11.436928479239096, 'eval/f1_micro': 0.4047619047619048, 'test/precision_macro': 0.6054213352007469, '_wandb': {'runtime': 1}, 'test/loss': 7.067510037298135, '_timestamp': 1704570049.7538872, 'eval/precision_micro': 0.4047619047619048, '_runtime': 2.8061511516571045, 'test/accuracy': 0.5700934579439252, 'eval/precision_macro': 0.4523809523809524, 'test/precision_micro': 0.5700934579439252, 'eval/recall_micro': 0.4047619047619048, 'test/recall_weighted': 0.5700934579439252, 'test/precision_weighted': 0.5994354127944012, 'test/f1_micro': 0.5700934579439252, 'test/recall_macro': 0.56478578892372}","{'n_neighbours': 2, 'trial.number': 1}",clear-glade-701,KNeighbours,"['BoW', 'preprocessed']"
637,"{'eval/precision_macro': 0.4523809523809524, 'eval/precision_micro': 0.4047619047619048, 'test/f1_weighted': 0.5763708636556645, 'eval/accuracy': 0.4047619047619048, 'eval/f1_micro': 0.4047619047619048, 'test/recall_macro': 0.56478578892372, 'eval/recall_weighted': 0.4047619047619048, '_step': 20, 'test/accuracy': 0.5700934579439252, 'test/recall_weighted': 0.5700934579439252, '_wandb': {'runtime': 2}, 'test/precision_weighted': 0.5994354127944012, 'test/f1_micro': 0.5700934579439252, 'eval/recall_macro': 0.4113636363636364, 'eval/recall_micro': 0.4047619047619048, 'test/recall_micro': 0.5700934579439252, 'eval/f1_macro': 0.3981719367588933, '_runtime': 3.706455707550049, 'split': 10, 'test/loss': 7.067510037298135, '_timestamp': 1704570042.1877627, 'test/f1_macro': 0.5763439046333783, 'eval/f1_weighted': 0.3949463579898362, 'test/precision_macro': 0.6054213352007469, 'test/precision_micro': 0.5700934579439252, 'eval/precision_weighted': 0.4546485260770975, 'eval/loss': 11.436928479239096}","{'n_neighbours': 2, 'trial.number': 0}",earnest-universe-700,KNeighbours,"['BoW', 'preprocessed']"
638,"{'test/precision_micro': 0.6822429906542056, 'test/recall_weighted': 0.6822429906542056, 'eval/accuracy': 0.7142857142857143, 'eval/f1_micro': 0.7142857142857143, 'test/recall_macro': 0.6796296296296296, '_runtime': 3.2917239665985107, 'eval/f1_macro': 0.7188405797101449, 'eval/recall_micro': 0.7142857142857143, 'eval/precision_macro': 0.7318376068376068, 'eval/loss': 2.4952752911665805, 'eval/f1_weighted': 0.7195307108350586, 'eval/recall_macro': 0.715909090909091, 'split': 10, 'test/f1_weighted': 0.678499476157525, 'eval/precision_weighted': 0.7348188848188847, 'test/loss': 2.606602018988913, 'eval/recall_weighted': 0.7142857142857143, 'test/precision_macro': 0.675705371017871, '_wandb': {'runtime': 1}, 'test/f1_micro': 0.6822429906542056, 'test/recall_micro': 0.6822429906542056, 'eval/precision_micro': 0.7142857142857143, 'test/f1_macro': 0.6745424472197442, 'test/precision_weighted': 0.681050938936453, '_step': 20, '_timestamp': 1704570039.015318, 'test/accuracy': 0.6822429906542056}","{'smoothing': 0.2481948758082705, 'trial.number': 4}",sleek-bird-699,Bernolli,"['BoW', 'preprocessed']"
639,"{'split': 10, 'eval/f1_macro': 0.6935272965021249, 'test/f1_micro': 0.6542056074766355, 'eval/f1_weighted': 0.6939190626670195, 'test/precision_macro': 0.6617826617826618, '_step': 20, 'test/f1_macro': 0.6492063492063492, 'eval/recall_micro': 0.6904761904761905, 'eval/precision_macro': 0.7101835664335664, '_runtime': 3.4603774547576904, 'test/recall_macro': 0.655911680911681, 'eval/recall_weighted': 0.6904761904761905, 'test/precision_weighted': 0.667958988052446, 'test/f1_weighted': 0.6507877169559412, 'eval/precision_weighted': 0.7138653013653014, 'eval/precision_micro': 0.6904761904761905, 'test/recall_weighted': 0.6542056074766355, 'eval/loss': 1.9254133200185943, 'test/precision_micro': 0.6542056074766355, 'eval/accuracy': 0.6904761904761905, 'eval/recall_macro': 0.6931818181818181, 'test/recall_micro': 0.6542056074766355, '_wandb': {'runtime': 2}, 'test/loss': 1.887102543546867, '_timestamp': 1704570030.9586763, 'eval/f1_micro': 0.6904761904761905, 'test/accuracy': 0.6542056074766355}","{'smoothing': 0.9930811326718592, 'trial.number': 3}",colorful-cherry-698,Bernolli,"['BoW', 'preprocessed']"
640,"{'eval/loss': 2.0163904919025777, 'eval/precision_macro': 0.7318376068376068, 'eval/precision_micro': 0.7142857142857143, 'test/recall_weighted': 0.6822429906542056, 'test/f1_macro': 0.6765023894862605, 'eval/f1_weighted': 0.7195307108350586, 'test/recall_macro': 0.6809116809116809, 'eval/f1_micro': 0.7142857142857143, 'eval/recall_micro': 0.7142857142857143, 'test/recall_micro': 0.6822429906542056, 'eval/recall_weighted': 0.7142857142857143, 'test/precision_weighted': 0.6921265650237614, 'split': 10, 'test/loss': 1.9984124762663684, 'eval/f1_macro': 0.7188405797101449, '_step': 20, 'test/f1_weighted': 0.6801976350785517, 'eval/recall_macro': 0.715909090909091, 'test/precision_macro': 0.6855561105561105, 'test/precision_micro': 0.6822429906542056, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.7142857142857143, 'test/f1_micro': 0.6822429906542056, '_timestamp': 1704570023.9917223, '_runtime': 2.9814932346343994, 'test/accuracy': 0.6822429906542056, 'eval/precision_weighted': 0.7348188848188847}","{'smoothing': 0.7179934228442519, 'trial.number': 2}",fancy-vortex-697,Bernolli,"['BoW', 'preprocessed']"
641,"{'_wandb': {'runtime': 2}, 'eval/recall_micro': 0.7142857142857143, 'eval/precision_micro': 0.7142857142857143, 'eval/recall_weighted': 0.7142857142857143, 'eval/accuracy': 0.7142857142857143, '_runtime': 3.556790590286255, 'test/loss': 2.4672583530514105, 'test/f1_macro': 0.6740394643058109, 'test/precision_macro': 0.6799082453494218, 'test/recall_weighted': 0.6822429906542056, 'eval/precision_weighted': 0.7348188848188847, 'test/precision_weighted': 0.6847408409805332, 'test/f1_weighted': 0.6777716922384365, 'eval/recall_macro': 0.715909090909091, 'test/recall_macro': 0.6796296296296296, 'split': 10, 'eval/f1_weighted': 0.7195307108350586, 'test/precision_micro': 0.6822429906542056, 'eval/loss': 2.388507944337837, 'eval/f1_micro': 0.7142857142857143, 'test/accuracy': 0.6822429906542056, 'test/recall_micro': 0.6822429906542056, 'eval/precision_macro': 0.7318376068376068, '_step': 20, '_timestamp': 1704570017.1142285, 'eval/f1_macro': 0.7188405797101449, 'test/f1_micro': 0.6822429906542056}","{'smoothing': 0.3065305956428305, 'trial.number': 1}",smooth-butterfly-696,Bernolli,"['BoW', 'preprocessed']"
642,"{'split': 10, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.7188405797101449, 'test/accuracy': 0.6822429906542056, 'eval/precision_weighted': 0.7348188848188847, '_step': 20, '_runtime': 1.9234888553619385, 'eval/f1_weighted': 0.7195307108350586, '_timestamp': 1704570009.8180518, 'eval/accuracy': 0.7142857142857143, 'eval/f1_micro': 0.7142857142857143, 'eval/loss': 2.1403762440606893, 'eval/recall_micro': 0.7142857142857143, 'eval/precision_macro': 0.7318376068376068, 'eval/precision_micro': 0.7142857142857143, 'eval/recall_weighted': 0.7142857142857143, 'test/precision_weighted': 0.6847408409805332, 'test/loss': 2.153118385590842, 'test/f1_weighted': 0.6777716922384365, 'test/recall_micro': 0.6822429906542056, 'test/precision_macro': 0.6799082453494218, 'test/precision_micro': 0.6822429906542056, 'test/f1_macro': 0.6740394643058109, 'test/f1_micro': 0.6822429906542056, 'eval/recall_macro': 0.715909090909091, 'test/recall_macro': 0.6796296296296296, 'test/recall_weighted': 0.6822429906542056}","{'smoothing': 0.5217374530923798, 'trial.number': 0}",fallen-pine-695,Bernolli,"['BoW', 'preprocessed']"
643,"{'test/f1_weighted': 0.7755055055531962, 'test/precision_macro': 0.786525974025974, 'eval/precision_weighted': 0.8525641025641025, '_step': 20, 'eval/precision_micro': 0.8333333333333334, 'eval/loss': 0.5882131246835761, 'eval/recall_macro': 0.8295454545454545, 'eval/recall_micro': 0.8333333333333334, 'test/recall_macro': 0.7879641909814323, 'test/recall_micro': 0.7850467289719626, 'test/recall_weighted': 0.7850467289719626, 'test/accuracy': 0.7850467289719626, 'test/f1_micro': 0.7850467289719625, 'eval/f1_weighted': 0.8277417027417028, 'test/precision_micro': 0.7850467289719626, 'test/precision_weighted': 0.7916818384108104, 'eval/accuracy': 0.8333333333333334, 'test/f1_macro': 0.775122550846304, 'eval/precision_macro': 0.8535839160839161, '_wandb': {'runtime': 6}, 'test/loss': 0.7410770272350948, '_timestamp': 1704569618.7157085, 'eval/f1_macro': 0.8257575757575758, 'eval/f1_micro': 0.8333333333333334, 'split': 10, '_runtime': 7.4431703090667725, 'eval/recall_weighted': 0.8333333333333334}",{'trial.number': 0},robust-deluge-694,LogisticRegression,"['BoW', 'preprocessed']"
644,"{'eval/loss': 0, '_timestamp': 1704566479.3788352, 'train/learning_rate': 1.1297133401609334e-06, 'test/samples_per_second': 135.46292577725, 'test/total_time_in_seconds': 0.4650718980010424, 'eval/precision_micro': 1, 'test/latency_in_seconds': 0.007382093619064165, '_wandb': {'runtime': 2924}, 'eval/f1_macro': 1, 'train/global_step': 750, 'train/train_runtime': 292.7523, 'train/train_samples_per_second': 38.77, 'eval/accuracy': 1, 'test/accuracy': 0.3968253968253968, 'train/train_loss': 2.4350421881536025e-08, 'eval/recall_macro': 1, 'eval/recall_micro': 1, 'eval/steps_per_second': 10.862, '_step': 520, 'train/epoch': 50, 'eval/f1_weighted': 1, 'eval/precision_macro': 1, 'train/train_steps_per_second': 2.562, '_runtime': 2925.563132286072, 'eval/runtime': 0.1841, 'eval/recall_weighted': 1, 'eval/samples_per_second': 135.77, 'train/loss': 0, 'eval/f1_micro': 1, 'train/total_flos': 2702801863949304.0, 'eval/precision_weighted': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan06_17-52-35_erc-hpc-comp038', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 3.3891400204828005e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",deft-river-690,Fine-Tuned LLM:bert-base-uncased,[]
645,"{'eval/runtime': 0.2185, 'eval/recall_micro': 1, 'eval/precision_macro': 1, 'eval/recall_weighted': 1, 'train/train_steps_per_second': 1.314, '_wandb': {'runtime': 608}, 'train/total_flos': 583980334942992.0, 'eval/precision_weighted': 1, 'train/train_samples_per_second': 37.274, '_step': 110, 'eval/accuracy': 1, 'train/train_runtime': 60.9005, 'test/latency_in_seconds': 0.007655427984106595, 'eval/steps_per_second': 4.577, 'test/total_time_in_seconds': 0.48229196299871546, '_runtime': 610.2236158847809, 'eval/f1_micro': 1, 'train/train_loss': 4.180331529823888e-08, 'eval/recall_macro': 1, 'eval/f1_macro': 1, 'eval/f1_weighted': 1, 'eval/samples_per_second': 114.423, 'test/samples_per_second': 130.62626963196522, 'eval/loss': 0, 'train/epoch': 10, 'train/global_step': 80, 'eval/precision_micro': 1, '_timestamp': 1704563549.1471848, 'test/accuracy': 0.3968253968253968}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan06_17-42-20_erc-hpc-comp038', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 7.693025593924606e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",exalted-disco-689,Fine-Tuned LLM:bert-base-uncased,[]
646,"{'train/epoch': 100, 'eval/runtime': 0.1811, 'eval/precision_macro': 1, 'eval/samples_per_second': 138.068, 'train/train_steps_per_second': 2.565, 'train/loss': 0, 'eval/accuracy': 1, 'train/train_runtime': 584.6976, 'eval/steps_per_second': 11.045, 'eval/precision_weighted': 1, 'eval/f1_weighted': 1, 'train/global_step': 1500, 'eval/precision_micro': 1, 'train/total_flos': 5400623542303080.0, 'eval/recall_macro': 1, 'train/learning_rate': 0, 'test/latency_in_seconds': 0.007081820460342218, '_runtime': 5849.92346072197, 'train/train_loss': 2.5062973084762536e-08, 'eval/recall_weighted': 1, '_wandb': {'runtime': 5848}, 'test/samples_per_second': 141.20662979243002, '_step': 1040, 'eval/loss': 0, 'eval/f1_micro': 1, 'test/accuracy': 0.3968253968253968, 'train/train_samples_per_second': 38.823, '_timestamp': 1704562934.6044476, 'eval/f1_macro': 1, 'eval/recall_micro': 1, 'test/total_time_in_seconds': 0.44615468900155975}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan06_16-04-49_erc-hpc-comp038', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 2.185965485243546e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",prime-paper-688,Fine-Tuned LLM:bert-base-uncased,[]
647,"{'train/train_runtime': 60.8888, 'train/total_flos': 583980334942992.0, 'train/train_loss': 5.195491894482985e-08, 'train/global_step': 80, '_wandb': {'runtime': 610}, 'eval/f1_macro': 1, 'eval/recall_weighted': 1, 'test/total_time_in_seconds': 0.4433308030002081, '_step': 110, 'eval/runtime': 0.2193, 'eval/accuracy': 1, 'eval/precision_micro': 1, 'test/accuracy': 0.3968253968253968, 'eval/recall_macro': 1, 'eval/recall_micro': 1, 'train/train_samples_per_second': 37.281, '_timestamp': 1704557079.1769266, 'eval/steps_per_second': 4.56, 'eval/samples_per_second': 113.988, 'eval/precision_macro': 1, 'eval/loss': 0, 'eval/f1_weighted': 1, 'eval/precision_weighted': 1, 'test/latency_in_seconds': 0.007036996873019176, 'test/samples_per_second': 142.10607423091787, 'train/train_steps_per_second': 1.314, '_runtime': 615.6833355426788, 'train/epoch': 10, 'eval/f1_micro': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan06_15-54-29_erc-hpc-comp038', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 4.652444883785543e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",warm-firebrand-687,Fine-Tuned LLM:bert-base-uncased,[]
648,"{'_timestamp': 1704556458.629456, 'eval/runtime': 0.2188, 'test/latency_in_seconds': 0.007356123349208723, 'train/epoch': 100, 'eval/accuracy': 1, 'test/accuracy': 0.3968253968253968, 'eval/recall_weighted': 1, '_wandb': {'runtime': 6018}, 'eval/loss': 0, 'train/train_runtime': 603.1648, 'eval/precision_macro': 1, 'eval/precision_micro': 1, 'train/train_steps_per_second': 1.326, 'train/loss': 0, 'eval/f1_micro': 1, 'train/total_flos': 5821789682555496.0, 'eval/steps_per_second': 4.57, 'eval/recall_macro': 1, 'eval/precision_weighted': 1, 'eval/samples_per_second': 114.243, 'train/train_samples_per_second': 37.635, 'eval/recall_micro': 1, 'test/total_time_in_seconds': 0.46343577100014954, '_step': 1020, '_runtime': 6019.453537940979, 'eval/f1_weighted': 1, 'eval/f1_macro': 1, 'train/train_loss': 1.6594817253690052e-08, 'train/global_step': 800, 'train/learning_rate': 4.476414807158189e-06, 'test/samples_per_second': 135.9411679940858}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan06_14-14-00_erc-hpc-comp038', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.1937106152421838e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",jolly-puddle-686,Fine-Tuned LLM:bert-base-uncased,[]
649,"{'_wandb': {'runtime': 5852}, 'train/learning_rate': 0, 'eval/recall_macro': 1, 'train/train_runtime': 585.1843, 'eval/steps_per_second': 11.024, 'eval/precision_weighted': 1, '_timestamp': 1704550431.797046, 'eval/accuracy': 1, 'eval/loss': 6.211589607119095e-06, 'test/latency_in_seconds': 0.007189568301587964, '_runtime': 5852.902010917664, 'test/total_time_in_seconds': 0.45294280300004175, 'test/samples_per_second': 139.09040961181626, 'train/epoch': 100, 'eval/runtime': 0.1814, 'train/train_loss': 0.0013509315205737949, 'eval/precision_macro': 1, 'eval/precision_micro': 1, 'train/train_steps_per_second': 2.563, 'train/loss': 0, 'test/accuracy': 0.4603174603174603, 'eval/recall_weighted': 1, 'eval/recall_micro': 1, 'train/global_step': 1500, 'eval/f1_micro': 1, 'eval/f1_weighted': 1, 'train/total_flos': 5400623542303080.0, 'eval/samples_per_second': 137.798, 'train/train_samples_per_second': 38.791, '_step': 1040, 'eval/f1_macro': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'bert', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 30522, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan06_12-36-19_erc-hpc-comp038', 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': None, 'disable_tqdm': False, 'eos_token_id': None, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 0, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['BertForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 2.989366386932643e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-12, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 2, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 512, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",driven-yogurt-684,Fine-Tuned LLM:bert-base-uncased,[]
650,"{'_step': 510, '_runtime': 3246.1225521564484, 'eval/precision_weighted': 1, 'eval/loss': 0, 'eval/runtime': 0.2206, 'eval/recall_weighted': 1, 'eval/f1_micro': 1, 'eval/steps_per_second': 4.533, 'train/train_steps_per_second': 1.232, 'train/train_samples_per_second': 34.958, 'train/epoch': 50, 'test/accuracy': 0.3968253968253968, 'eval/recall_macro': 1, 'eval/precision_micro': 1, 'eval/recall_micro': 1, 'test/samples_per_second': 127.60484246120448, 'test/total_time_in_seconds': 0.4937116710061673, 'train/train_runtime': 324.6786, 'eval/samples_per_second': 113.337, 'eval/accuracy': 1, 'eval/f1_weighted': 1, 'train/total_flos': 2975233587134328.0, 'train/global_step': 400, 'train/train_loss': 1.1759247087184122e-09, 'test/latency_in_seconds': 0.007836693190574085, '_wandb': {'runtime': 3244}, '_timestamp': 1704479198.4447942, 'eval/f1_macro': 1, 'eval/precision_macro': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan05_17-32-34_erc-hpc-comp038', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.0302180063046358e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",royal-night-683,Fine-Tuned LLM:microsoft/codebert-base,[]
651,"{'train/total_flos': 593805550957944.0, 'eval/recall_macro': 1, 'eval/precision_macro': 1, 'eval/precision_micro': 1, 'eval/recall_weighted': 1, 'test/latency_in_seconds': 0.007774308285978993, 'eval/f1_weighted': 1, '_step': 110, 'eval/accuracy': 1, 'eval/recall_micro': 1, '_wandb': {'runtime': 662}, 'eval/runtime': 0.2193, 'eval/f1_macro': 1, 'train/train_samples_per_second': 34.652, '_timestamp': 1704475948.0119414, 'test/accuracy': 0.3968253968253968, 'eval/samples_per_second': 113.988, 'test/total_time_in_seconds': 0.4897814220166765, 'train/train_steps_per_second': 1.221, 'eval/loss': 0, 'train/epoch': 10, 'eval/f1_micro': 1, 'train/train_runtime': 65.5094, '_runtime': 663.4834945201874, 'train/train_loss': 1.6731600993580287e-09, 'train/global_step': 80, 'eval/steps_per_second': 4.56, 'eval/precision_weighted': 1, 'test/samples_per_second': 128.62880699026374}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan05_17-21-29_erc-hpc-comp038', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.5207845892927943e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",brisk-wildflower-682,Fine-Tuned LLM:microsoft/codebert-base,[]
652,"{'_step': 510, 'train/train_loss': 1.1458381976581223e-09, 'eval/recall_micro': 1, 'test/latency_in_seconds': 0.00787276536501604, '_timestamp': 1704475278.741823, 'eval/samples_per_second': 83.038, 'train/train_steps_per_second': 1.228, 'eval/f1_macro': 1, 'test/accuracy': 0.3968253968253968, 'eval/f1_weighted': 1, 'train/total_flos': 2975233587134328.0, 'eval/precision_micro': 1, 'eval/accuracy': 1, 'eval/f1_micro': 1, 'train/global_step': 400, 'train/train_runtime': 325.691, 'train/train_samples_per_second': 34.849, '_wandb': {'runtime': 3253}, 'eval/recall_macro': 1, 'eval/steps_per_second': 3.322, 'test/total_time_in_seconds': 0.49598421799601056, '_runtime': 3254.979124069214, 'train/epoch': 50, 'eval/runtime': 0.3011, 'eval/precision_macro': 1, 'eval/recall_weighted': 1, 'test/samples_per_second': 127.02017063072506, 'eval/loss': 0, 'eval/precision_weighted': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan05_16-27-05_erc-hpc-comp038', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 4.32662154639013e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",avid-spaceship-681,Fine-Tuned LLM:microsoft/codebert-base,[]
653,"{'test/latency_in_seconds': 0.008164013206075493, 'eval/f1_macro': 1, 'train/total_flos': 593805550957944.0, 'eval/recall_macro': 1, 'train/train_steps_per_second': 1.222, 'train/train_loss': 1.6731600993580287e-09, 'train/global_step': 80, 'eval/precision_macro': 1, '_timestamp': 1704472018.4278965, 'train/train_runtime': 65.4801, 'eval/accuracy': 1, 'eval/recall_micro': 1, 'eval/precision_weighted': 1, 'eval/samples_per_second': 112.585, 'test/samples_per_second': 122.48877785447728, 'train/train_samples_per_second': 34.667, '_runtime': 659.3132433891296, 'eval/loss': 0, 'eval/f1_micro': 1, 'eval/precision_micro': 1, 'eval/steps_per_second': 4.503, 'test/total_time_in_seconds': 0.514332831982756, '_wandb': {'runtime': 657}, 'train/epoch': 10, 'eval/runtime': 0.2221, 'eval/recall_weighted': 1, '_step': 110, 'test/accuracy': 0.3968253968253968, 'eval/f1_weighted': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan05_16-16-00_erc-hpc-comp038', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.3860611547685724e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",honest-breeze-680,Fine-Tuned LLM:microsoft/codebert-base,[]
654,"{'_runtime': 3323.6171848773956, 'eval/accuracy': 1, 'eval/precision_macro': 1, '_timestamp': 1704471351.9818578, 'train/epoch': 50, 'eval/f1_weighted': 1, 'train/total_flos': 2924197348163832.0, 'eval/steps_per_second': 9.247, 'train/train_steps_per_second': 2.252, '_step': 520, '_wandb': {'runtime': 3322}, 'eval/runtime': 0.2163, 'train/train_loss': 1.8789671685226495e-10, 'eval/recall_macro': 1, 'train/learning_rate': 2.3234378910836885e-05, 'test/latency_in_seconds': 0.008045927602945575, 'train/train_samples_per_second': 34.081, 'train/loss': 0, 'train/global_step': 750, 'eval/precision_weighted': 1, 'eval/loss': 0, 'eval/f1_macro': 1, 'eval/recall_micro': 1, 'eval/recall_weighted': 1, 'test/total_time_in_seconds': 0.5068934389855713, 'eval/f1_micro': 1, 'test/accuracy': 0.3968253968253968, 'train/train_runtime': 333.0269, 'eval/precision_micro': 1, 'eval/samples_per_second': 115.591, 'test/samples_per_second': 124.28647750122742}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan05_15-20-29_erc-hpc-comp038', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 6.970313673251066e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",twilight-blaze-679,Fine-Tuned LLM:microsoft/codebert-base,[]
655,"{'_wandb': {'runtime': 6628}, 'eval/loss': 0, 'eval/f1_micro': 1, 'train/train_steps_per_second': 2.258, '_runtime': 6629.716194391251, '_timestamp': 1704468021.1306224, 'train/loss': 0, 'train/total_flos': 5855671492120944.0, 'train/global_step': 1500, 'eval/accuracy': 1, 'eval/precision_micro': 1, 'test/samples_per_second': 128.61246434753178, 'train/epoch': 100, 'eval/f1_macro': 1, 'test/accuracy': 0.3968253968253968, 'train/train_loss': 4.313947025972691e-09, 'test/total_time_in_seconds': 0.4898436579969712, 'train/learning_rate': 0, 'eval/precision_weighted': 1, 'test/latency_in_seconds': 0.0077752961586820815, 'train/train_samples_per_second': 34.172, 'eval/runtime': 0.231, 'eval/recall_micro': 1, 'eval/steps_per_second': 8.657, 'eval/samples_per_second': 108.216, '_step': 1040, 'eval/f1_weighted': 1, 'eval/recall_macro': 1, 'train/train_runtime': 664.2931, 'eval/precision_macro': 1, 'eval/recall_weighted': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan05_13-29-54_erc-hpc-comp038', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 3.0034261036849183e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",volcanic-deluge-678,Fine-Tuned LLM:microsoft/codebert-base,[]
656,"{'eval/runtime': 0.2164, 'eval/f1_micro': 1, 'eval/samples_per_second': 115.504, 'train/train_samples_per_second': 34.025, '_wandb': {'runtime': 674}, 'train/train_runtime': 66.716, 'eval/loss': 0, 'eval/f1_macro': 1, 'train/total_flos': 582335347419384.0, 'train/global_step': 150, 'eval/precision_macro': 1, 'eval/precision_weighted': 1, 'train/train_steps_per_second': 2.248, '_runtime': 675.9546055793762, 'eval/f1_weighted': 1, 'eval/recall_micro': 1, 'eval/precision_micro': 1, 'test/total_time_in_seconds': 0.4919692910043522, 'eval/accuracy': 1, 'test/samples_per_second': 128.05677336360952, 'test/latency_in_seconds': 0.007809036365148449, 'train/epoch': 10, 'test/accuracy': 0.3968253968253968, 'eval/steps_per_second': 9.24, '_step': 110, 'train/train_loss': 1.5819702336254223e-08, '_timestamp': 1704461386.4994805, 'eval/recall_weighted': 1, 'eval/recall_macro': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan05_13-18-34_erc-hpc-comp038', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 1.0005979472429748e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 16, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 16, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 16, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 16, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",flowing-haze-677,Fine-Tuned LLM:microsoft/codebert-base,[]
657,"{'train/train_loss': 1.6788634127351544e-08, 'eval/recall_weighted': 1, 'test/latency_in_seconds': 0.007841801174753716, 'train/epoch': 10, 'eval/f1_macro': 1, 'eval/f1_micro': 1, 'train/total_flos': 593805550957944.0, 'eval/accuracy': 1, 'eval/samples_per_second': 114.667, 'test/samples_per_second': 127.52172335348794, 'train/train_steps_per_second': 1.227, 'eval/recall_macro': 1, 'eval/precision_macro': 1, 'eval/steps_per_second': 4.587, 'test/total_time_in_seconds': 0.49403347400948405, 'eval/f1_weighted': 1, 'eval/precision_micro': 1, 'train/train_runtime': 65.2185, 'eval/precision_weighted': 1, '_wandb': {'runtime': 657}, '_runtime': 658.9790267944336, 'test/accuracy': 0.3968253968253968, 'eval/recall_micro': 1, 'train/global_step': 80, 'train/train_samples_per_second': 34.806, 'eval/loss': 0, '_timestamp': 1704460705.9108667, '_step': 110, 'eval/runtime': 0.218}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan05_13-07-29_erc-hpc-comp038', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 9.250669730174324e-05, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 10, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",spring-dust-676,Fine-Tuned LLM:microsoft/codebert-base,[]
658,"{'_wandb': {'runtime': 6507}, 'eval/accuracy': 1, 'train/global_step': 800, 'train/train_loss': 1.535153910481313e-07, 'eval/precision_macro': 1, 'eval/precision_micro': 1, 'eval/recall_weighted': 1, 'eval/recall_micro': 1, 'train/learning_rate': 3.2419360714178506e-06, 'eval/steps_per_second': 4.591, 'test/latency_in_seconds': 0.007743589619326125, '_runtime': 6508.535305261612, 'eval/f1_macro': 1, 'eval/f1_weighted': 1, 'train/train_samples_per_second': 34.84, '_step': 1020, '_timestamp': 1704460040.6013212, 'eval/runtime': 0.2178, 'train/train_runtime': 651.5574, 'eval/precision_weighted': 1, 'train/train_steps_per_second': 1.228, 'eval/loss': 0, 'eval/f1_micro': 1, 'test/accuracy': 0.3968253968253968, 'train/total_flos': 5950796068993776.0, 'test/samples_per_second': 129.1390749200141, 'train/loss': 0, 'eval/recall_macro': 1, 'eval/samples_per_second': 114.77, 'test/total_time_in_seconds': 0.48784614601754583, 'train/epoch': 100}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan05_11-18-54_erc-hpc-comp038', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 8.645162857114268e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 100, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",different-smoke-675,Fine-Tuned LLM:microsoft/codebert-base,[]
659,"{'eval/f1_macro': 1, 'test/samples_per_second': 130.58335510391672, 'train/train_samples_per_second': 35.014, '_timestamp': 1704453527.970219, 'eval/f1_weighted': 1, 'train/global_step': 400, 'train/train_runtime': 324.156, 'eval/recall_macro': 1, 'eval/steps_per_second': 4.365, 'eval/precision_weighted': 1, 'test/latency_in_seconds': 0.007657943841343421, 'train/train_loss': 0.015864673852920532, 'train/train_steps_per_second': 1.234, '_step': 510, '_runtime': 3241.7023639678955, 'train/epoch': 50, 'train/total_flos': 2975233587134328.0, '_wandb': {'runtime': 3241}, 'eval/recall_weighted': 1, 'eval/accuracy': 1, 'test/accuracy': 0.4126984126984127, 'eval/precision_micro': 1, 'eval/precision_macro': 1, 'eval/samples_per_second': 109.13, 'test/total_time_in_seconds': 0.4824504620046355, 'eval/loss': 0.007448530290275812, 'eval/runtime': 0.2291, 'eval/f1_micro': 1, 'eval/recall_micro': 1}","{'bf16': False, 'fp16': False, 'fsdp': '[]', 'seed': 42, 'tf32': 'None', 'debug': '[]', 'optim': 'adamw_hf', 'top_k': 50, 'top_p': 1, 'prefix': None, 'do_eval': True, 'no_cuda': False, 'do_train': False, 'id2label': {'0': 'irrelevant', '1': 'partially irrelevant', '2': 'partially relevant', '3': 'relevant'}, 'label2id': {'relevant': 1, 'irrelevant': 0, 'partially relevant': 2, 'partially irrelevant': 1}, 'run_name': 'huggingface_models', 'use_ipex': False, 'adafactor': False, 'data_seed': 'None', 'deepspeed': 'None', 'do_sample': False, 'hub_token': '<HUB_TOKEN>', 'log_level': 'passive', 'max_steps': -1, 'num_beams': 1, 'ray_scope': 'last', 'report_to': ""['wandb']"", 'typical_p': 1, 'use_cache': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'do_predict': False, 'eval_delay': 0, 'eval_steps': 'None', 'hidden_act': 'gelu', 'is_decoder': False, 'local_rank': 0, 'max_length': 20, 'min_length': 0, 'model_type': 'roberta', 'optim_args': 'None', 'output_dir': 'huggingface_models', 'past_index': -1, 'save_steps': 500, 'vocab_size': 50265, 'ddp_backend': 'None', 'ddp_timeout': 1800, 'fsdp_config': ""{'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}"", 'hidden_size': 768, 'label_names': 'None', 'logging_dir': 'huggingface_models/runs/Jan05_10-24-49_erc-hpc-comp038', 'output_past': True, 'push_to_hub': False, 'return_dict': True, 'sharded_ddp': '[]', 'temperature': 1, 'torch_dtype': 'float32', 'torchdynamo': 'None', 'torchscript': False, 'xpu_backend': 'None', 'adam_epsilon': 1e-08, 'bos_token_id': 0, 'disable_tqdm': False, 'eos_token_id': 2, 'fp16_backend': 'auto', 'hub_model_id': 'None', 'hub_strategy': 'every_save', 'pad_token_id': 1, 'problem_type': None, 'pruned_heads': {}, 'sep_token_id': None, 'use_bfloat16': False, 'warmup_ratio': 0, 'warmup_steps': 0, 'weight_decay': 0, 'architectures': ['RobertaForSequenceClassification'], 'bad_words_ids': None, 'jit_mode_eval': False, 'learning_rate': 2.1873371867905687e-06, 'logging_steps': 500, 'max_grad_norm': 1, 'mp_parameters': '', 'output_scores': False, 'save_strategy': 'epoch', 'torch_compile': False, 'tpu_num_cores': 'None', 'bf16_full_eval': False, 'early_stopping': False, 'fp16_full_eval': False, 'fp16_opt_level': 'O1', 'layer_norm_eps': 1e-05, 'length_penalty': 1, 'tf_legacy_loss': False, 'use_mps_device': False, 'eval_batch_size': 32, 'finetuning_task': None, 'group_by_length': False, 'num_beam_groups': 1, 'suppress_tokens': None, 'tokenizer_class': None, 'type_vocab_size': 1, 'full_determinism': False, 'hub_private_repo': False, 'ignore_data_skip': False, 'log_on_each_node': True, 'logging_strategy': 'steps', 'num_train_epochs': 50, 'save_safetensors': False, 'save_total_limit': 5, 'train_batch_size': 32, 'ddp_bucket_cap_mb': 'None', 'diversity_penalty': 0, 'greater_is_better': False, 'initializer_range': 0.02, 'intermediate_size': 3072, 'log_level_replica': 'warning', 'lr_scheduler_type': 'linear', 'num_hidden_layers': 12, 'output_attentions': False, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'save_on_each_node': False, 'tpu_metrics_debug': False, 'classifier_dropout': None, 'is_encoder_decoder': False, 'length_column_name': 'length', 'logging_first_step': False, 'repetition_penalty': 1, 'torch_compile_mode': 'None', 'add_cross_attention': False, 'evaluation_strategy': 'epoch', 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'fsdp_min_num_params': 0, 'hidden_dropout_prob': 0.1, 'num_attention_heads': 12, 'skip_memory_metrics': True, 'tie_encoder_decoder': False, 'tie_word_embeddings': True, 'auto_find_batch_size': False, 'dataloader_drop_last': False, 'no_repeat_ngram_size': 0, 'num_return_sequences': 1, 'output_hidden_states': False, 'overwrite_output_dir': False, 'prediction_loss_only': False, 'push_to_hub_model_id': 'None', 'task_specific_params': None, 'transformers_version': '4.30.2', 'begin_suppress_tokens': None, 'dataloader_pin_memory': True, 'metric_for_best_model': 'loss', 'remove_invalid_values': False, 'remove_unused_columns': True, 'torch_compile_backend': 'None', 'dataloader_num_workers': 0, 'decoder_start_token_id': None, 'gradient_checkpointing': False, 'half_precision_backend': 'auto', 'label_smoothing_factor': 0, 'load_best_model_at_end': True, 'logging_nan_inf_filter': True, 'resume_from_checkpoint': 'None', 'chunk_size_feed_forward': 0, 'eval_accumulation_steps': 'None', 'max_position_embeddings': 514, 'per_gpu_eval_batch_size': 'None', 'position_embedding_type': 'absolute', 'return_dict_in_generate': False, 'per_gpu_train_batch_size': 'None', 'push_to_hub_organization': 'None', 'ddp_find_unused_parameters': 'None', 'include_inputs_for_metrics': False, 'per_device_eval_batch_size': 32, 'use_legacy_prediction_loop': False, 'cross_attention_hidden_size': None, 'gradient_accumulation_steps': 1, 'per_device_train_batch_size': 32, 'attention_probs_dropout_prob': 0.1, 'encoder_no_repeat_ngram_size': 0, 'exponential_decay_length_penalty': None, 'fsdp_transformer_layer_cls_to_wrap': 'None'}",smart-vortex-674,Fine-Tuned LLM:microsoft/codebert-base,[]
660,"{'_runtime': 938.6505692005156, '_timestamp': 1704373339.140478, 'eval/accuracy': 0.48, 'eval/precision_weighted': 0.41952380952380947, 'eval/loss': 5.263553641754619, 'eval/recall_micro': 0.48, 'eval/precision_micro': 0.48, 'eval/recall_weighted': 0.48, 'split': 10, 'eval/f1_macro': 0.3527583527583527, 'eval/f1_micro': 0.48, 'eval/f1_weighted': 0.446122766122766, 'eval/recall_macro': 0.375, 'eval/precision_macro': 0.3363095238095238, '_step': 18}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 78, 'dt_min_samples_leaf': 13}",noble-frost-670,DecisionTree,['pre-trained:openai-gpt']
661,"{'eval/f1_macro': 0.4004329004329004, 'eval/recall_micro': 0.52, 'eval/precision_weighted': 0.4475151515151515, 'eval/accuracy': 0.52, 'eval/recall_macro': 0.44166666666666665, 'test/recall_macro': 0.280411877394636, 'test/recall_micro': 0.3333333333333333, 'test/recall_weighted': 0.3333333333333333, '_timestamp': 1704372394.1276467, 'eval/f1_micro': 0.52, 'test/f1_weighted': 0.3031515988037727, '_wandb': {'runtime': 1059}, 'eval/loss': 1.00779026490755, 'test/f1_macro': 0.24347826086956523, 'test/f1_micro': 0.3333333333333333, 'eval/precision_macro': 0.3752525252525253, 'test/precision_micro': 0.3333333333333333, 'test/precision_weighted': 0.2812035208348572, 'split': 10, 'eval/f1_weighted': 0.47584415584415574, '_step': 20, '_runtime': 1060.7063047885897, 'test/loss': 4.249406436861694, 'test/accuracy': 0.3333333333333333, 'eval/precision_micro': 0.52, 'test/precision_macro': 0.21806195596518177, 'eval/recall_weighted': 0.52}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 77, 'dt_min_samples_leaf': 21}",atomic-mountain-669,DecisionTree,['pre-trained:openai-gpt']
662,"{'test/f1_micro': 0.4444444444444444, 'eval/precision_macro': 0.1, 'eval/precision_weighted': 0.16, 'eval/f1_macro': 0.14285714285714288, '_runtime': 1063.7283282279968, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.11475409836065574, 'test/recall_weighted': 0.4444444444444444, '_wandb': {'runtime': 1062}, 'test/loss': 1.9452566482131808, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.15555555555555556, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.4444444444444444, 'eval/precision_micro': 0.4, 'eval/loss': 1.159746845488376, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.2413793103448276, '_step': 20, 'split': 10, 'test/precision_weighted': 0.21129326047358837, '_timestamp': 1704371330.2812502, 'test/accuracy': 0.4444444444444444, 'test/f1_weighted': 0.28641975308641976, 'test/precision_micro': 0.4444444444444444}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 76, 'dt_min_samples_leaf': 11}",fragrant-resonance-668,DecisionTree,['pre-trained:openai-gpt']
663,"{'eval/precision_weighted': 0.4881818181818181, 'eval/loss': 5.1177196587089115, 'test/f1_macro': 0.3609025032938076, 'eval/f1_weighted': 0.4599999999999999, 'test/recall_micro': 0.380952380952381, 'test/precision_micro': 0.380952380952381, '_runtime': 1068.635446548462, 'test/recall_macro': 0.38496536987916297, 'eval/f1_micro': 0.48, 'test/loss': 12.257637878371694, 'eval/accuracy': 0.48, 'test/f1_weighted': 0.3756415082502039, 'eval/precision_macro': 0.4176136363636363, 'eval/recall_weighted': 0.48, '_wandb': {'runtime': 1067}, 'test/precision_macro': 0.35288461538461535, '_step': 20, 'test/f1_micro': 0.380952380952381, 'test/recall_weighted': 0.380952380952381, 'test/accuracy': 0.380952380952381, 'eval/f1_macro': 0.3839285714285714, 'eval/recall_macro': 0.4, 'eval/precision_micro': 0.48, 'test/precision_weighted': 0.38070818070818074, 'split': 10, 'eval/recall_micro': 0.48, '_timestamp': 1704370260.2420106}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 75, 'dt_min_samples_leaf': 8}",firm-haze-667,DecisionTree,['pre-trained:openai-gpt']
664,"{'_timestamp': 1704369185.394226, 'eval/recall_macro': 0.4083333333333333, 'test/recall_micro': 0.31746031746031744, 'eval/precision_weighted': 0.48, 'test/loss': 4.005022429391996, 'eval/recall_micro': 0.44, 'test/precision_weighted': 0.39961765793046583, 'eval/f1_micro': 0.44, '_runtime': 1068.6162180900574, 'test/f1_micro': 0.31746031746031744, 'eval/f1_weighted': 0.4342857142857142, '_step': 20, 'test/recall_macro': 0.3398725316828765, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.33307909762651144, 'test/precision_micro': 0.31746031746031744, 'test/recall_weighted': 0.31746031746031744, 'test/f1_weighted': 0.3251716247139589, 'test/f1_macro': 0.2994851258581236, '_wandb': {'runtime': 1067}, 'eval/f1_macro': 0.3857142857142858, 'split': 10, 'eval/accuracy': 0.44, 'test/accuracy': 0.31746031746031744, 'eval/precision_macro': 0.4, 'eval/precision_micro': 0.44, 'eval/loss': 1.105653538559102}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 74, 'dt_min_samples_leaf': 12}",happy-dawn-666,DecisionTree,['pre-trained:openai-gpt']
665,"{'_step': 8, '_runtime': 390.79370951652527, 'eval/loss': 1.3513580518155894, 'eval/f1_micro': 0.44, 'eval/recall_micro': 0.44, 'eval/recall_weighted': 0.44, 'eval/precision_macro': 0.21825396825396823, 'eval/precision_micro': 0.44, 'eval/precision_weighted': 0.2806349206349206, 'split': 5, '_timestamp': 1704367546.1096916, 'eval/f1_macro': 0.2582417582417582, 'eval/recall_macro': 0.325, 'eval/accuracy': 0.44, 'eval/f1_weighted': 0.33934065934065927}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 85, 'dt_min_samples_leaf': 46}",firm-wind-665,DecisionTree,['pre-trained:bert-base-uncased']
666,"{'eval/recall_weighted': 0.56, '_step': 20, 'eval/loss': 0.9268594519757553, 'test/f1_micro': 0.3968253968253968, 'eval/precision_micro': 0.56, 'eval/accuracy': 0.56, 'test/accuracy': 0.3968253968253968, 'eval/f1_weighted': 0.5219740259740261, 'eval/recall_micro': 0.56, 'test/precision_macro': 0.3091168091168091, 'test/recall_weighted': 0.3968253968253968, 'test/precision_weighted': 0.3595622484511373, '_runtime': 1074.8972613811493, 'test/loss': 8.334587267179918, 'eval/f1_micro': 0.56, 'eval/precision_macro': 0.42708333333333337, 'split': 10, 'test/recall_macro': 0.3915229885057471, 'test/precision_micro': 0.3968253968253968, '_wandb': {'runtime': 1073}, '_timestamp': 1704368111.6844964, 'eval/f1_macro': 0.4376623376623376, 'test/f1_weighted': 0.36984126984126986, 'test/recall_micro': 0.3968253968253968, 'test/f1_macro': 0.33611111111111114, 'eval/recall_macro': 0.4666666666666666, 'eval/precision_weighted': 0.5033333333333334}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 73, 'dt_min_samples_leaf': 15}",visionary-grass-664,DecisionTree,['pre-trained:openai-gpt']
667,"{'test/f1_micro': 0.3968253968253968, 'test/f1_weighted': 0.33978174603174605, '_step': 20, 'test/accuracy': 0.3968253968253968, 'split': 10, 'test/loss': 1.2745313625984234, 'test/f1_macro': 0.2234375, '_runtime': 997.227172613144, 'eval/f1_micro': 0.32, 'test/recall_macro': 0.3032258064516129, '_timestamp': 1704367151.7630987, 'eval/recall_weighted': 0.32, 'test/precision_macro': 0.19393939393939397, 'eval/precision_weighted': 0.2016666666666667, 'test/precision_weighted': 0.3150553150553151, 'eval/precision_macro': 0.1371527777777778, 'eval/recall_micro': 0.32, 'test/recall_micro': 0.3968253968253968, 'eval/accuracy': 0.32, 'eval/f1_macro': 0.1679487179487179, 'eval/f1_weighted': 0.24738461538461537, 'eval/recall_macro': 0.21666666666666665, 'eval/loss': 1.3605355632158649, 'eval/precision_micro': 0.32, 'test/precision_micro': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, '_wandb': {'runtime': 995}}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 84, 'dt_min_samples_leaf': 74}",lunar-thunder-663,DecisionTree,['pre-trained:bert-base-uncased']
668,"{'split': 10, 'test/loss': 10.477031963713166, 'eval/f1_micro': 0.48, 'test/recall_micro': 0.4444444444444444, 'test/precision_macro': 0.4053030303030303, 'test/precision_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'test/precision_weighted': 0.4331409331409331, 'eval/recall_micro': 0.48, '_runtime': 1073.158046722412, 'eval/loss': 1.08579659636716, 'eval/accuracy': 0.48, 'eval/f1_macro': 0.3588636363636364, 'test/f1_micro': 0.4444444444444444, 'eval/recall_macro': 0.3666666666666667, 'test/f1_weighted': 0.416558491351452, 'eval/precision_macro': 0.4083333333333333, 'eval/precision_micro': 0.48, '_timestamp': 1704367032.1095195, 'eval/f1_weighted': 0.44690909090909087, 'eval/recall_weighted': 0.48, '_step': 20, '_wandb': {'runtime': 1071}, 'test/accuracy': 0.4444444444444444, 'test/recall_macro': 0.4088380489242558, 'eval/precision_weighted': 0.4773333333333334, 'test/f1_macro': 0.37903295376121465}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 72, 'dt_min_samples_leaf': 9}",polished-valley-662,DecisionTree,['pre-trained:openai-gpt']
669,"{'test/recall_micro': 0.4444444444444444, 'test/precision_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'eval/precision_weighted': 0.15, '_wandb': {'runtime': 995}, 'test/loss': 1.386505578650803, '_timestamp': 1704366150.8241467, 'eval/accuracy': 0.36, 'eval/loss': 1.3911535509349091, 'test/f1_macro': 0.18646012621916236, 'test/f1_weighted': 0.33525485160597035, 'eval/recall_micro': 0.36, 'test/precision_macro': 0.15253496503496505, 'test/accuracy': 0.4444444444444444, '_step': 20, '_runtime': 997.1285908222198, 'test/f1_micro': 0.4444444444444444, 'test/recall_macro': 0.24274193548387096, 'eval/recall_weighted': 0.36, 'eval/precision_micro': 0.36, 'split': 10, 'eval/f1_macro': 0.13235294117647062, 'eval/f1_micro': 0.36, 'eval/f1_weighted': 0.21176470588235297, 'eval/recall_macro': 0.225, 'eval/precision_macro': 0.09375, 'test/precision_weighted': 0.26992451992451993}","{'dt_criterion': 'gini', 'dt_max_depth': 14, 'trial.number': 83, 'dt_min_samples_leaf': 52}",tough-bee-661,DecisionTree,['pre-trained:bert-base-uncased']
670,"{'test/recall_micro': 0.4603174603174603, '_runtime': 1078.8030240535736, 'eval/accuracy': 0.48, 'test/accuracy': 0.4603174603174603, 'eval/recall_macro': 0.3666666666666667, '_step': 20, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_weighted': 0.4773333333333334, 'test/loss': 9.373514412296164, 'eval/recall_micro': 0.48, 'eval/precision_macro': 0.4083333333333333, 'test/precision_macro': 0.4305555555555555, 'test/f1_macro': 0.3929258241758242, 'test/f1_micro': 0.4603174603174603, 'eval/f1_weighted': 0.44690909090909087, 'test/recall_macro': 0.4174587385794282, '_timestamp': 1704365954.905317, 'eval/recall_weighted': 0.48, 'test/precision_weighted': 0.4523809523809524, 'test/f1_weighted': 0.4309654631083203, 'eval/precision_micro': 0.48, 'test/precision_micro': 0.4603174603174603, 'split': 10, '_wandb': {'runtime': 1077}, 'eval/loss': 1.0962911669458597, 'eval/f1_micro': 0.48, 'eval/f1_macro': 0.3588636363636364}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 71, 'dt_min_samples_leaf': 13}",trim-frog-660,DecisionTree,['pre-trained:openai-gpt']
671,"{'_wandb': {'runtime': 996}, 'test/loss': 1.2745313625984234, 'test/recall_macro': 0.3032258064516129, 'eval/recall_macro': 0.21666666666666665, 'eval/precision_micro': 0.32, 'test/precision_macro': 0.19393939393939397, 'test/precision_weighted': 0.3150553150553151, '_timestamp': 1704365149.083202, 'test/f1_macro': 0.2234375, 'eval/f1_weighted': 0.24738461538461537, 'eval/loss': 1.3605355632158649, 'eval/accuracy': 0.32, 'test/f1_micro': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, '_runtime': 998.30380320549, 'eval/precision_macro': 0.1371527777777778, 'test/precision_micro': 0.3968253968253968, 'eval/precision_weighted': 0.2016666666666667, 'eval/f1_micro': 0.32, 'eval/recall_weighted': 0.32, '_step': 20, 'eval/f1_macro': 0.1679487179487179, 'test/f1_weighted': 0.33978174603174605, 'split': 10, 'test/accuracy': 0.3968253968253968, 'eval/recall_micro': 0.32, 'test/recall_micro': 0.3968253968253968}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 82, 'dt_min_samples_leaf': 65}",charmed-sun-659,DecisionTree,['pre-trained:bert-base-uncased']
672,"{'eval/f1_micro': 0.4000000000000001, 'test/recall_micro': 0.31746031746031744, '_runtime': 1080.5538187026978, '_timestamp': 1704364871.0356526, 'eval/precision_weighted': 0.40461538461538465, 'test/f1_macro': 0.2902226345083488, 'test/f1_weighted': 0.3134835232794416, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.32210144927536233, 'eval/f1_weighted': 0.39269565217391306, 'eval/recall_macro': 0.3166666666666667, 'test/precision_micro': 0.31746031746031744, 'split': 10, '_wandb': {'runtime': 1079}, 'eval/precision_macro': 0.3445512820512821, 'test/recall_weighted': 0.31746031746031744, 'eval/loss': 5.198476821992818, 'test/loss': 11.130300923533854, 'test/accuracy': 0.31746031746031744, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.3453136810279668, 'test/precision_macro': 0.2922619047619048, '_step': 20, 'test/f1_micro': 0.31746031746031744, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.33460433244916, 'eval/recall_weighted': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 70, 'dt_min_samples_leaf': 14}",comfy-leaf-658,DecisionTree,['pre-trained:openai-gpt']
673,"{'eval/loss': 1.4342635304745612, 'eval/recall_macro': 0.175, 'eval/precision_weighted': 0.14736842105263157, '_step': 20, '_wandb': {'runtime': 995}, 'eval/accuracy': 0.28, 'test/f1_macro': 0.25554323725055433, 'eval/recall_weighted': 0.28, 'test/precision_macro': 0.21568627450980393, 'eval/f1_macro': 0.12068965517241378, 'eval/f1_micro': 0.28, 'test/accuracy': 0.492063492063492, 'test/f1_micro': 0.492063492063492, 'eval/f1_weighted': 0.19310344827586207, 'eval/precision_macro': 0.09210526315789472, 'test/precision_weighted': 0.31341425459072514, 'test/recall_macro': 0.317741935483871, 'split': 10, 'test/loss': 1.2659004575108088, 'eval/recall_micro': 0.28, 'test/recall_micro': 0.492063492063492, '_runtime': 997.2546980381012, '_timestamp': 1704364147.178126, 'test/f1_weighted': 0.3817618695667476, 'test/precision_micro': 0.492063492063492, 'test/recall_weighted': 0.492063492063492, 'eval/precision_micro': 0.28}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 81, 'dt_min_samples_leaf': 59}",colorful-smoke-657,DecisionTree,['pre-trained:bert-base-uncased']
674,"{'_timestamp': 1704363785.2000344, 'eval/f1_micro': 0.52, 'eval/f1_macro': 0.4214285714285714, 'eval/recall_micro': 0.52, 'test/recall_weighted': 0.3492063492063492, 'test/f1_macro': 0.3331519274376417, 'eval/f1_weighted': 0.49599999999999994, 'test/f1_weighted': 0.3440751538710722, 'eval/recall_macro': 0.44166666666666665, 'test/precision_macro': 0.32532051282051283, 'test/loss': 8.52075842740393, 'test/recall_macro': 0.37627099911582673, 'test/recall_micro': 0.3492063492063492, 'eval/precision_micro': 0.52, 'eval/recall_weighted': 0.52, 'split': 10, '_runtime': 1080.3339552879331, 'eval/loss': 1.024735223551852, 'eval/accuracy': 0.52, 'test/accuracy': 0.3492063492063492, 'test/f1_micro': 0.3492063492063492, 'eval/precision_macro': 0.4176136363636363, 'test/precision_weighted': 0.3682336182336182, '_step': 20, '_wandb': {'runtime': 1079}, 'test/precision_micro': 0.3492063492063492, 'eval/precision_weighted': 0.4881818181818181}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 69, 'dt_min_samples_leaf': 15}",ancient-dawn-656,DecisionTree,['pre-trained:openai-gpt']
675,"{'test/f1_macro': 0.2234375, 'eval/precision_macro': 0.1371527777777778, 'test/precision_weighted': 0.3150553150553151, 'test/loss': 1.2745313625984234, 'test/f1_weighted': 0.33978174603174605, 'eval/f1_micro': 0.32, 'eval/recall_micro': 0.32, 'eval/recall_macro': 0.21666666666666665, 'test/recall_macro': 0.3032258064516129, 'test/recall_micro': 0.3968253968253968, 'test/precision_macro': 0.19393939393939397, 'eval/precision_weighted': 0.2016666666666667, '_timestamp': 1704363145.4551072, 'test/accuracy': 0.3968253968253968, 'eval/accuracy': 0.32, 'eval/f1_weighted': 0.24738461538461537, 'eval/precision_micro': 0.32, 'eval/recall_weighted': 0.32, 'split': 10, '_wandb': {'runtime': 996}, 'test/recall_weighted': 0.3968253968253968, '_step': 20, '_runtime': 997.4321300983428, 'test/precision_micro': 0.3968253968253968, 'eval/loss': 1.3605355632158649, 'test/f1_micro': 0.3968253968253968, 'eval/f1_macro': 0.1679487179487179}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 80, 'dt_min_samples_leaf': 90}",daily-donkey-655,DecisionTree,['pre-trained:bert-base-uncased']
676,"{'eval/accuracy': 0.48, 'eval/f1_macro': 0.4355072463768116, 'test/recall_macro': 0.25996536987916297, 'eval/loss': 1.2352668522447527, 'test/recall_micro': 0.30158730158730157, 'test/precision_macro': 0.25815295815295813, 'test/precision_micro': 0.30158730158730157, '_wandb': {'runtime': 1073}, 'test/precision_weighted': 0.3072035548226024, 'split': 10, 'test/f1_micro': 0.30158730158730157, 'test/recall_weighted': 0.30158730158730157, 'eval/f1_weighted': 0.4674782608695651, 'eval/precision_macro': 0.4679487179487179, 'eval/precision_micro': 0.48, '_step': 20, 'eval/recall_macro': 0.42499999999999993, 'eval/recall_micro': 0.48, 'eval/precision_weighted': 0.47538461538461535, '_runtime': 1074.9756536483765, '_timestamp': 1704362699.8320055, 'test/f1_macro': 0.2562732589048379, 'test/loss': 4.308936622025366, 'eval/f1_micro': 0.48, 'test/accuracy': 0.30158730158730157, 'test/f1_weighted': 0.30223538644591275, 'eval/recall_weighted': 0.48}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 68, 'dt_min_samples_leaf': 10}",lemon-sponge-654,DecisionTree,['pre-trained:openai-gpt']
677,"{'test/recall_macro': 0.2685483870967742, 'test/precision_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, 'eval/accuracy': 0.4, 'test/accuracy': 0.42857142857142855, 'test/f1_macro': 0.213365539452496, 'eval/recall_macro': 0.275, 'test/recall_micro': 0.42857142857142855, 'test/f1_micro': 0.42857142857142855, 'test/f1_weighted': 0.3330010479768934, 'eval/recall_weighted': 0.4, '_runtime': 997.4836769104004, '_timestamp': 1704362144.665709, 'eval/f1_macro': 0.20312500000000003, 'eval/f1_micro': 0.4000000000000001, 'split': 10, 'test/loss': 1.3360556596587518, 'eval/precision_macro': 0.1856060606060606, 'eval/loss': 1.3697666409433995, 'test/precision_macro': 0.1776923076923077, 'eval/precision_weighted': 0.23030303030303031, '_wandb': {'runtime': 996}, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.2728205128205128, '_step': 20, 'eval/f1_weighted': 0.275, 'eval/recall_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 79, 'dt_min_samples_leaf': 61}",fancy-terrain-653,DecisionTree,['pre-trained:bert-base-uncased']
678,"{'eval/f1_weighted': 0.497703081232493, 'eval/recall_weighted': 0.52, '_step': 20, '_runtime': 1075.9885656833649, 'eval/loss': 0.9718240138249692, 'eval/f1_micro': 0.52, 'split': 10, 'test/loss': 4.055234718918359, '_timestamp': 1704361619.9580448, 'eval/recall_micro': 0.52, 'test/f1_weighted': 0.287717616405189, 'eval/precision_macro': 0.4471590909090909, 'test/precision_micro': 0.30158730158730157, 'eval/accuracy': 0.52, 'eval/recall_macro': 0.475, 'eval/f1_macro': 0.42955182072829134, 'eval/precision_micro': 0.52, 'test/precision_macro': 0.28405448717948717, 'eval/precision_weighted': 0.5572727272727273, '_wandb': {'runtime': 1074}, 'test/f1_macro': 0.26100141953800493, 'test/f1_micro': 0.30158730158730157, 'test/recall_weighted': 0.30158730158730157, 'test/accuracy': 0.30158730158730157, 'test/recall_macro': 0.3397988505747126, 'test/recall_micro': 0.30158730158730157, 'test/precision_weighted': 0.37355006105006106}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 67, 'dt_min_samples_leaf': 19}",feasible-wave-652,DecisionTree,['pre-trained:openai-gpt']
679,"{'test/recall_micro': 0.492063492063492, 'test/f1_macro': 0.16489361702127658, 'eval/f1_micro': 0.4000000000000001, 'eval/loss': 1.3296549549719356, 'test/loss': 1.275518815596098, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.492063492063492, '_runtime': 996.5924422740936, 'test/f1_weighted': 0.3245525160418777, 'split': 10, '_timestamp': 1704361143.0111833, '_wandb': {'runtime': 995}, 'eval/accuracy': 0.4, 'test/accuracy': 0.492063492063492, 'test/f1_micro': 0.492063492063492, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.1, '_step': 20, 'eval/precision_weighted': 0.16, 'test/precision_micro': 0.492063492063492, 'eval/recall_macro': 0.25, 'test/precision_weighted': 0.24212648022171832, 'eval/f1_macro': 0.14285714285714288, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.123015873015873, 'eval/f1_weighted': 0.22857142857142865}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 78, 'dt_min_samples_leaf': 83}",rich-moon-651,DecisionTree,['pre-trained:bert-base-uncased']
680,"{'eval/recall_weighted': 0.56, '_step': 20, '_runtime': 1078.9124093055725, 'eval/recall_macro': 0.48333333333333334, 'eval/recall_micro': 0.56, 'test/recall_micro': 0.2857142857142857, 'test/recall_macro': 0.2545498084291188, 'eval/precision_macro': 0.425, 'eval/precision_micro': 0.56, '_timestamp': 1704360539.138317, 'eval/accuracy': 0.56, 'eval/f1_macro': 0.4375, 'test/f1_macro': 0.2241234221598878, 'eval/f1_weighted': 0.516, 'test/precision_macro': 0.207272990167727, 'test/precision_micro': 0.2857142857142857, 'test/precision_weighted': 0.26528317129820883, 'test/accuracy': 0.2857142857142857, 'test/f1_weighted': 0.2704156370355529, 'split': 10, 'test/loss': 7.336107917669723, 'test/f1_micro': 0.2857142857142857, 'test/recall_weighted': 0.2857142857142857, 'eval/precision_weighted': 0.504, '_wandb': {'runtime': 1077}, 'eval/loss': 2.343898819686117, 'eval/f1_micro': 0.56}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 66, 'dt_min_samples_leaf': 17}",rare-tree-650,DecisionTree,['pre-trained:openai-gpt']
681,"{'test/loss': 1.2745313625984234, 'test/precision_weighted': 0.3150553150553151, 'eval/f1_macro': 0.1679487179487179, 'eval/recall_macro': 0.21666666666666665, 'eval/precision_micro': 0.32, 'test/precision_micro': 0.3968253968253968, '_step': 20, 'test/f1_macro': 0.2234375, 'test/f1_micro': 0.3968253968253968, 'eval/recall_weighted': 0.32, 'eval/loss': 1.3605355632158649, 'eval/recall_micro': 0.32, 'test/recall_weighted': 0.3968253968253968, '_wandb': {'runtime': 995}, 'eval/accuracy': 0.32, 'test/accuracy': 0.3968253968253968, 'eval/f1_weighted': 0.24738461538461537, 'eval/precision_macro': 0.1371527777777778, 'eval/precision_weighted': 0.2016666666666667, '_runtime': 996.4595351219176, '_timestamp': 1704360141.9536512, 'test/recall_macro': 0.3032258064516129, 'test/recall_micro': 0.3968253968253968, 'eval/f1_micro': 0.32, 'test/precision_macro': 0.19393939393939397, 'split': 10, 'test/f1_weighted': 0.33978174603174605}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 77, 'dt_min_samples_leaf': 72}",cool-wood-649,DecisionTree,['pre-trained:bert-base-uncased']
682,"{'eval/recall_macro': 0.3416666666666667, 'test/recall_micro': 0.4126984126984127, 'eval/precision_macro': 0.4, 'eval/recall_weighted': 0.44, '_step': 20, 'test/f1_macro': 0.3873822017562647, 'test/loss': 9.562979050505996, '_timestamp': 1704359454.8861668, 'test/recall_macro': 0.40220674918950783, 'test/precision_weighted': 0.416931216931217, 'eval/f1_micro': 0.44, 'eval/f1_weighted': 0.4242424242424242, 'test/f1_micro': 0.4126984126984127, '_runtime': 1079.3122217655182, 'eval/f1_macro': 0.3446969696969697, 'eval/recall_micro': 0.44, 'eval/precision_weighted': 0.464, 'eval/precision_micro': 0.44, 'test/recall_weighted': 0.4126984126984127, 'split': 10, 'eval/loss': 1.2129610736249128, 'test/f1_weighted': 0.4083357980873509, 'test/precision_micro': 0.4126984126984127, 'test/accuracy': 0.4126984126984127, 'test/precision_macro': 0.392911877394636, '_wandb': {'runtime': 1077}, 'eval/accuracy': 0.44}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 65, 'dt_min_samples_leaf': 11}",cool-thunder-648,DecisionTree,['pre-trained:openai-gpt']
683,"{'eval/precision_micro': 0.32, '_runtime': 997.4174392223358, 'eval/f1_macro': 0.1679487179487179, 'test/f1_weighted': 0.33978174603174605, 'test/precision_macro': 0.19393939393939397, 'test/recall_weighted': 0.3968253968253968, 'test/f1_macro': 0.2234375, 'test/recall_micro': 0.3968253968253968, 'eval/recall_weighted': 0.32, '_timestamp': 1704359141.9767892, 'eval/accuracy': 0.32, 'eval/precision_weighted': 0.2016666666666667, 'eval/f1_weighted': 0.24738461538461537, 'eval/recall_macro': 0.21666666666666665, 'test/recall_macro': 0.3032258064516129, 'test/accuracy': 0.3968253968253968, 'eval/precision_macro': 0.1371527777777778, 'test/precision_micro': 0.3968253968253968, 'split': 10, 'eval/loss': 1.3605355632158649, 'eval/f1_micro': 0.32, '_step': 20, 'test/f1_micro': 0.3968253968253968, 'test/precision_weighted': 0.3150553150553151, '_wandb': {'runtime': 996}, 'test/loss': 1.2745313625984234, 'eval/recall_micro': 0.32}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 76, 'dt_min_samples_leaf': 100}",vital-energy-647,DecisionTree,['pre-trained:bert-base-uncased']
684,"{'test/loss': 10.477031963713166, 'eval/f1_weighted': 0.44690909090909087, '_wandb': {'runtime': 1079}, 'test/accuracy': 0.4444444444444444, 'test/f1_weighted': 0.416558491351452, 'eval/loss': 1.08579659636716, 'eval/precision_weighted': 0.4773333333333334, 'test/precision_weighted': 0.4331409331409331, 'eval/precision_macro': 0.4083333333333333, 'eval/precision_micro': 0.48, '_step': 20, '_runtime': 1080.8502004146576, '_timestamp': 1704358370.5332675, 'eval/f1_micro': 0.48, 'test/f1_macro': 0.37903295376121465, 'eval/accuracy': 0.48, 'eval/recall_micro': 0.48, 'test/recall_micro': 0.4444444444444444, 'eval/recall_weighted': 0.48, 'eval/recall_macro': 0.3666666666666667, 'test/precision_macro': 0.4053030303030303, 'test/precision_micro': 0.4444444444444444, 'split': 10, 'eval/f1_macro': 0.3588636363636364, 'test/f1_micro': 0.4444444444444444, 'test/recall_macro': 0.4088380489242558, 'test/recall_weighted': 0.4444444444444444}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 64, 'dt_min_samples_leaf': 9}",gallant-rain-646,DecisionTree,['pre-trained:openai-gpt']
685,"{'eval/loss': 1.3296549549719356, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.14285714285714288, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1, 'eval/precision_micro': 0.4, 'eval/precision_weighted': 0.16, 'test/precision_weighted': 0.24212648022171832, '_step': 20, 'split': 10, 'test/f1_weighted': 0.3245525160418777, 'eval/recall_macro': 0.25, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.123015873015873, 'test/precision_micro': 0.492063492063492, 'test/loss': 1.275518815596098, '_timestamp': 1704358141.173669, 'test/f1_macro': 0.16489361702127658, 'test/f1_micro': 0.492063492063492, '_wandb': {'runtime': 996}, '_runtime': 997.489509344101, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.492063492063492, 'test/recall_macro': 0.25, 'test/recall_micro': 0.492063492063492, 'test/recall_weighted': 0.492063492063492}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 75, 'dt_min_samples_leaf': 65}",snowy-waterfall-645,DecisionTree,['pre-trained:bert-base-uncased']
686,"{'eval/loss': 1.105653538559102, 'eval/f1_macro': 0.3857142857142858, 'eval/f1_weighted': 0.4342857142857142, 'eval/recall_weighted': 0.44, 'test/precision_weighted': 0.39961765793046583, '_wandb': {'runtime': 1076}, 'eval/precision_macro': 0.4, '_timestamp': 1704357285.564953, 'test/recall_micro': 0.31746031746031744, 'test/precision_macro': 0.33307909762651144, '_runtime': 1077.7013013362885, 'eval/precision_micro': 0.44, 'eval/f1_micro': 0.44, 'test/recall_macro': 0.3398725316828765, 'test/precision_micro': 0.31746031746031744, 'eval/recall_macro': 0.4083333333333333, 'test/f1_macro': 0.2994851258581236, 'test/f1_micro': 0.31746031746031744, 'eval/precision_weighted': 0.48, 'test/loss': 4.005022429391996, 'test/accuracy': 0.31746031746031744, 'split': 10, 'eval/accuracy': 0.44, 'test/f1_weighted': 0.3251716247139589, 'eval/recall_micro': 0.44, 'test/recall_weighted': 0.31746031746031744, '_step': 20}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 63, 'dt_min_samples_leaf': 12}",splendid-snowball-644,DecisionTree,['pre-trained:openai-gpt']
687,"{'_runtime': 997.0629360675812, 'test/recall_macro': 0.2346774193548387, 'test/loss': 1.334079841552857, 'eval/recall_micro': 0.36, 'eval/f1_weighted': 0.21176470588235297, 'test/precision_micro': 0.42857142857142855, 'test/f1_macro': 0.18126385809312637, 'eval/precision_macro': 0.09375, '_wandb': {'runtime': 995}, 'eval/f1_macro': 0.13235294117647062, 'eval/f1_micro': 0.36, 'test/accuracy': 0.42857142857142855, 'test/f1_weighted': 0.32647027768978987, 'eval/recall_macro': 0.225, '_step': 20, 'split': 10, 'eval/accuracy': 0.36, 'test/precision_weighted': 0.26408341114223466, '_timestamp': 1704357139.847942, 'test/f1_micro': 0.42857142857142855, 'eval/recall_weighted': 0.36, 'test/precision_macro': 0.1482843137254902, 'test/recall_weighted': 0.42857142857142855, 'eval/precision_weighted': 0.15, 'eval/loss': 1.4044902447444871, 'test/recall_micro': 0.42857142857142855, 'eval/precision_micro': 0.36}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 74, 'dt_min_samples_leaf': 57}",wise-jazz-643,DecisionTree,['pre-trained:bert-base-uncased']
688,"{'test/precision_micro': 0.492063492063492, 'split': 10, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.3245525160418777, '_step': 20, 'eval/loss': 1.3296549549719356, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.492063492063492, 'eval/f1_macro': 0.14285714285714288, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1, 'test/accuracy': 0.492063492063492, 'test/recall_macro': 0.25, 'test/precision_macro': 0.123015873015873, 'test/precision_weighted': 0.24212648022171832, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.16489361702127658, '_timestamp': 1704356138.7421937, 'eval/recall_macro': 0.25, 'eval/precision_weighted': 0.16, '_wandb': {'runtime': 995}, 'test/loss': 1.275518815596098, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_micro': 0.492063492063492, 'eval/precision_micro': 0.4, '_runtime': 996.7658894062042, 'test/f1_micro': 0.492063492063492}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 73, 'dt_min_samples_leaf': 80}",confused-puddle-642,DecisionTree,['pre-trained:bert-base-uncased']
689,"{'eval/recall_macro': 0.3666666666666667, 'test/recall_macro': 0.4174587385794282, 'test/precision_micro': 0.4603174603174603, '_wandb': {'runtime': 1078}, 'test/f1_macro': 0.3929258241758242, 'test/precision_macro': 0.4305555555555555, 'eval/recall_weighted': 0.48, 'test/precision_weighted': 0.4523809523809524, 'eval/f1_macro': 0.3588636363636364, 'eval/f1_weighted': 0.44690909090909087, 'test/recall_micro': 0.4603174603174603, 'test/accuracy': 0.4603174603174603, 'eval/accuracy': 0.48, 'test/f1_weighted': 0.4309654631083203, 'eval/precision_macro': 0.4083333333333333, '_step': 20, 'split': 10, '_runtime': 1079.9143040180206, 'eval/loss': 1.08579659636716, 'test/loss': 9.369349900161762, 'eval/precision_micro': 0.48, '_timestamp': 1704356201.919022, 'eval/f1_micro': 0.48, 'eval/precision_weighted': 0.4773333333333334, 'test/f1_micro': 0.4603174603174603, 'eval/recall_micro': 0.48, 'test/recall_weighted': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 62, 'dt_min_samples_leaf': 13}",feasible-star-641,DecisionTree,['pre-trained:openai-gpt']
690,"{'eval/recall_macro': 0.25, 'test/recall_micro': 0.492063492063492, 'eval/f1_macro': 0.14285714285714288, 'test/f1_micro': 0.492063492063492, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1, '_runtime': 995.5633215904236, 'test/recall_macro': 0.25, 'test/precision_macro': 0.123015873015873, 'test/precision_weighted': 0.24212648022171832, '_timestamp': 1704355136.6766026, 'test/accuracy': 0.492063492063492, 'eval/f1_weighted': 0.22857142857142865, '_wandb': {'runtime': 994}, 'eval/loss': 1.3296549549719356, 'eval/recall_weighted': 0.4, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.3245525160418777, 'test/f1_macro': 0.16489361702127658, 'eval/precision_micro': 0.4, '_step': 20, 'test/loss': 1.275518815596098, 'test/precision_micro': 0.492063492063492, 'test/recall_weighted': 0.492063492063492, 'eval/precision_weighted': 0.16, 'split': 10, 'eval/f1_micro': 0.4000000000000001}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 72, 'dt_min_samples_leaf': 94}",northern-moon-640,DecisionTree,['pre-trained:bert-base-uncased']
691,"{'_runtime': 1079.3006455898285, 'test/accuracy': 0.4603174603174603, 'test/recall_macro': 0.4174587385794282, 'eval/precision_weighted': 0.4773333333333334, '_wandb': {'runtime': 1078}, '_timestamp': 1704355117.7548747, 'eval/recall_macro': 0.3666666666666667, 'test/f1_micro': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603, 'test/precision_weighted': 0.4523809523809524, 'test/loss': 9.37529503028509, 'eval/f1_macro': 0.3588636363636364, 'eval/f1_weighted': 0.44690909090909087, '_step': 20, 'eval/accuracy': 0.48, 'test/f1_macro': 0.3929258241758242, 'eval/recall_micro': 0.48, 'eval/recall_weighted': 0.48, 'test/recall_weighted': 0.4603174603174603, 'test/precision_macro': 0.4305555555555555, 'eval/loss': 1.1112728948566426, 'test/f1_weighted': 0.4309654631083203, 'eval/precision_micro': 0.48, 'test/precision_micro': 0.4603174603174603, 'split': 10, 'eval/f1_micro': 0.48, 'eval/precision_macro': 0.4083333333333333}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 61, 'dt_min_samples_leaf': 11}",balmy-totem-639,DecisionTree,['pre-trained:openai-gpt']
692,"{'eval/precision_micro': 0.4, 'test/loss': 1.275518815596098, 'test/accuracy': 0.492063492063492, 'test/precision_weighted': 0.24212648022171832, 'eval/precision_weighted': 0.16, '_timestamp': 1704354136.5326104, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.492063492063492, 'test/precision_micro': 0.492063492063492, '_step': 20, '_wandb': {'runtime': 994}, '_runtime': 996.0993723869324, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_macro': 0.25, 'test/recall_weighted': 0.492063492063492, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.16489361702127658, 'test/f1_micro': 0.492063492063492, 'eval/accuracy': 0.4, 'eval/precision_macro': 0.1, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.123015873015873, 'eval/loss': 1.3296549549719356, 'test/f1_weighted': 0.3245525160418777, 'test/recall_macro': 0.25, 'split': 10, 'eval/f1_macro': 0.14285714285714288}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 71, 'dt_min_samples_leaf': 71}",effortless-serenity-638,DecisionTree,['pre-trained:bert-base-uncased']
693,"{'eval/recall_macro': 0.3833333333333333, 'test/recall_macro': 0.3935860595343354, 'test/recall_micro': 0.3968253968253968, 'test/precision_macro': 0.37073018514666106, '_timestamp': 1704354033.2438574, 'test/f1_micro': 0.3968253968253968, 'eval/f1_weighted': 0.48121212121212126, 'eval/precision_macro': 0.4375, 'test/recall_weighted': 0.3968253968253968, 'eval/precision_weighted': 0.5133333333333333, 'eval/f1_micro': 0.48, 'test/accuracy': 0.3968253968253968, 'test/f1_weighted': 0.39988169180715755, 'eval/precision_micro': 0.48, 'test/precision_weighted': 0.4256233469048114, '_wandb': {'runtime': 1077}, 'test/loss': 11.614972314530062, 'split': 10, 'eval/recall_weighted': 0.48, '_runtime': 1078.4269623756409, 'eval/accuracy': 0.48, 'test/f1_macro': 0.36645962732919257, 'eval/recall_micro': 0.48, 'test/precision_micro': 0.3968253968253968, '_step': 20, 'eval/loss': 5.133580958141449, 'eval/f1_macro': 0.3952020202020202}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 60, 'dt_min_samples_leaf': 10}",eternal-elevator-637,DecisionTree,['pre-trained:openai-gpt']
694,"{'split': 10, 'test/loss': 1.386505578650803, 'test/recall_macro': 0.24274193548387096, 'eval/recall_macro': 0.225, 'test/recall_micro': 0.4444444444444444, 'test/precision_weighted': 0.26992451992451993, 'eval/f1_micro': 0.36, 'test/f1_micro': 0.4444444444444444, 'test/f1_weighted': 0.33525485160597035, '_runtime': 996.7548797130584, '_timestamp': 1704353135.5980546, 'eval/f1_macro': 0.13235294117647062, '_step': 20, 'test/f1_macro': 0.18646012621916236, 'eval/precision_macro': 0.09375, 'eval/precision_micro': 0.36, 'test/precision_micro': 0.4444444444444444, '_wandb': {'runtime': 995}, 'test/accuracy': 0.4444444444444444, 'test/precision_macro': 0.15253496503496505, 'eval/precision_weighted': 0.15, 'eval/loss': 1.3911535509349091, 'eval/accuracy': 0.36, 'eval/recall_weighted': 0.36, 'eval/f1_weighted': 0.21176470588235297, 'eval/recall_micro': 0.36, 'test/recall_weighted': 0.4444444444444444}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 70, 'dt_min_samples_leaf': 50}",bumbling-pond-636,DecisionTree,['pre-trained:bert-base-uncased']
695,"{'_step': 20, '_wandb': {'runtime': 1079}, 'test/f1_macro': 0.2708060556464812, 'test/recall_micro': 0.3333333333333333, '_runtime': 1080.4680261611938, 'test/loss': 1.9405482044194855, '_timestamp': 1704352950.4381511, 'eval/f1_macro': 0.3686868686868687, 'eval/loss': 0.9892031650021578, 'test/recall_macro': 0.3431513409961686, 'test/precision_macro': 0.2602124183006536, 'test/precision_micro': 0.3333333333333333, 'test/recall_weighted': 0.3333333333333333, 'split': 10, 'eval/accuracy': 0.48, 'eval/f1_weighted': 0.42505050505050507, 'eval/precision_macro': 0.35, 'eval/precision_micro': 0.48, 'test/precision_weighted': 0.3369644153957879, 'eval/f1_micro': 0.48, 'test/accuracy': 0.3333333333333333, 'test/f1_micro': 0.3333333333333333, 'eval/recall_weighted': 0.48, 'eval/precision_weighted': 0.416, 'test/f1_weighted': 0.3065024809705661, 'eval/recall_macro': 0.4333333333333333, 'eval/recall_micro': 0.48}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 59, 'dt_min_samples_leaf': 29}",scarlet-planet-635,DecisionTree,['pre-trained:openai-gpt']
696,"{'eval/recall_weighted': 0.4, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.3245525160418777, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.4, 'test/f1_micro': 0.492063492063492, 'test/precision_micro': 0.492063492063492, 'eval/precision_weighted': 0.16, 'test/precision_weighted': 0.24212648022171832, 'eval/loss': 1.3296549549719356, 'test/accuracy': 0.492063492063492, 'test/f1_macro': 0.16489361702127658, 'eval/precision_macro': 0.1, 'split': 10, 'eval/f1_macro': 0.14285714285714288, 'test/recall_weighted': 0.492063492063492, '_wandb': {'runtime': 995}, 'test/recall_macro': 0.25, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.123015873015873, 'test/loss': 1.275518815596098, '_timestamp': 1704352135.051978, 'test/recall_micro': 0.492063492063492, '_step': 20, '_runtime': 997.0602328777312, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.22857142857142865}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 69, 'dt_min_samples_leaf': 84}",dauntless-frog-634,DecisionTree,['pre-trained:bert-base-uncased']
697,"{'_runtime': 1074.9099261760712, 'eval/precision_micro': 0.28, 'eval/f1_weighted': 0.21670329670329672, 'test/f1_weighted': 0.31179751179751175, '_step': 20, 'test/loss': 1.425239344250644, 'test/accuracy': 0.3968253968253968, 'eval/recall_macro': 0.20833333333333331, 'test/recall_macro': 0.2521551724137931, 'eval/precision_macro': 0.14087301587301587, 'eval/precision_weighted': 0.1796825396825397, '_wandb': {'runtime': 1073}, 'eval/f1_micro': 0.28, 'split': 10, 'test/precision_micro': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, 'eval/f1_macro': 0.1662087912087912, 'test/recall_micro': 0.3968253968253968, 'eval/recall_micro': 0.28, 'eval/recall_weighted': 0.28, 'test/precision_macro': 0.1638888888888889, '_timestamp': 1704351865.9598022, 'test/f1_micro': 0.3968253968253968, 'eval/accuracy': 0.28, 'test/precision_weighted': 0.2567901234567901, 'eval/loss': 1.5931809217507706, 'test/f1_macro': 0.19864864864864865}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 58, 'dt_min_samples_leaf': 23}",rich-dragon-633,DecisionTree,['pre-trained:openai-gpt']
698,"{'split': 10, 'test/recall_micro': 0.3968253968253968, 'eval/precision_micro': 0.32, 'test/precision_weighted': 0.3150553150553151, 'eval/recall_micro': 0.32, 'eval/recall_weighted': 0.32, 'test/precision_macro': 0.19393939393939397, 'test/recall_weighted': 0.3968253968253968, '_timestamp': 1704351133.9093478, 'eval/accuracy': 0.32, 'test/recall_macro': 0.3032258064516129, 'test/accuracy': 0.3968253968253968, 'test/precision_micro': 0.3968253968253968, '_step': 20, '_wandb': {'runtime': 995}, 'eval/loss': 1.3605355632158649, 'eval/f1_weighted': 0.24738461538461537, 'eval/f1_macro': 0.1679487179487179, 'eval/recall_macro': 0.21666666666666665, 'eval/precision_macro': 0.1371527777777778, 'eval/precision_weighted': 0.2016666666666667, 'test/f1_micro': 0.3968253968253968, 'test/f1_weighted': 0.33978174603174605, '_runtime': 996.8137857913972, 'test/loss': 1.2745313625984234, 'eval/f1_micro': 0.32, 'test/f1_macro': 0.2234375}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 68, 'dt_min_samples_leaf': 71}",lilac-dust-632,DecisionTree,['pre-trained:bert-base-uncased']
699,"{'_timestamp': 1704350786.246102, 'test/f1_weighted': 0.2341029341029341, 'test/recall_macro': 0.1954022988505747, 'test/precision_micro': 0.2698412698412698, 'eval/loss': 1.4824089384976713, 'test/loss': 1.3744851134316307, 'eval/recall_macro': 0.175, 'split': 10, 'test/recall_micro': 0.2698412698412698, 'eval/recall_weighted': 0.2, 'eval/precision_weighted': 0.12153846153846154, 'eval/f1_micro': 0.20000000000000004, 'eval/recall_micro': 0.2, 'eval/precision_macro': 0.10096153846153846, '_step': 20, 'eval/f1_macro': 0.12681159420289856, 'test/f1_macro': 0.15378787878787878, 'eval/precision_micro': 0.2, 'test/recall_weighted': 0.2698412698412698, '_wandb': {'runtime': 1076}, 'eval/accuracy': 0.2, 'test/accuracy': 0.2698412698412698, 'test/precision_weighted': 0.2168458781362007, '_runtime': 1078.0672540664673, 'test/f1_micro': 0.2698412698412698, 'eval/f1_weighted': 0.14956521739130435, 'test/precision_macro': 0.13608870967741937}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 57, 'dt_min_samples_leaf': 96}",hardy-butterfly-631,DecisionTree,['pre-trained:openai-gpt']
700,"{'test/precision_macro': 0.1776923076923077, 'split': 10, '_wandb': {'runtime': 995}, 'eval/loss': 1.3697666409433995, 'eval/recall_micro': 0.4, 'test/precision_weighted': 0.2728205128205128, '_runtime': 996.7247858047484, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.42857142857142855, 'test/f1_micro': 0.42857142857142855, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/loss': 1.3360556596587518, '_timestamp': 1704350133.0183587, 'eval/accuracy': 0.4, 'test/recall_micro': 0.42857142857142855, 'eval/precision_weighted': 0.23030303030303031, 'test/recall_weighted': 0.42857142857142855, 'eval/f1_macro': 0.20312500000000003, 'test/f1_macro': 0.213365539452496, 'test/precision_micro': 0.42857142857142855, 'test/f1_weighted': 0.3330010479768934, 'eval/recall_macro': 0.275, '_step': 20, 'eval/precision_macro': 0.1856060606060606, 'eval/f1_weighted': 0.275, 'test/recall_macro': 0.2685483870967742}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 67, 'dt_min_samples_leaf': 63}",electric-silence-630,DecisionTree,['pre-trained:bert-base-uncased']
701,"{'test/recall_weighted': 0.31746031746031744, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.3857142857142858, 'eval/precision_macro': 0.4, 'eval/recall_weighted': 0.44, '_runtime': 1079.224685907364, 'eval/f1_weighted': 0.4342857142857142, 'test/precision_micro': 0.31746031746031744, 'eval/recall_macro': 0.4083333333333333, 'eval/precision_weighted': 0.48, 'test/precision_weighted': 0.39961765793046583, 'test/recall_macro': 0.3398725316828765, 'test/precision_macro': 0.33307909762651144, 'split': 10, 'test/loss': 4.005022429391996, 'eval/f1_micro': 0.44, 'eval/recall_micro': 0.44, '_step': 20, 'test/f1_macro': 0.2994851258581236, 'test/recall_micro': 0.31746031746031744, 'test/f1_weighted': 0.3251716247139589, 'eval/precision_micro': 0.44, '_wandb': {'runtime': 1077}, 'eval/loss': 1.105653538559102, '_timestamp': 1704349703.749812, 'test/accuracy': 0.31746031746031744, 'test/f1_micro': 0.31746031746031744}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 56, 'dt_min_samples_leaf': 8}",toasty-waterfall-629,DecisionTree,['pre-trained:openai-gpt']
702,"{'eval/precision_micro': 0.32, '_step': 20, '_wandb': {'runtime': 995}, 'eval/recall_micro': 0.32, 'test/precision_macro': 0.19393939393939397, 'eval/recall_macro': 0.21666666666666665, 'eval/precision_weighted': 0.2016666666666667, 'eval/loss': 1.3605355632158649, 'eval/accuracy': 0.32, 'test/f1_macro': 0.2234375, 'eval/recall_weighted': 0.32, 'test/precision_micro': 0.3968253968253968, 'test/f1_weighted': 0.33978174603174605, 'eval/precision_macro': 0.1371527777777778, '_timestamp': 1704349133.3347127, 'eval/f1_macro': 0.1679487179487179, 'test/recall_macro': 0.3032258064516129, 'test/recall_weighted': 0.3968253968253968, 'test/precision_weighted': 0.3150553150553151, 'split': 10, 'eval/f1_weighted': 0.24738461538461537, 'eval/f1_micro': 0.32, 'test/accuracy': 0.3968253968253968, 'test/f1_micro': 0.3968253968253968, 'test/recall_micro': 0.3968253968253968, '_runtime': 996.8876447677612, 'test/loss': 1.2745313625984234}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 66, 'dt_min_samples_leaf': 77}",fearless-star-628,DecisionTree,['pre-trained:bert-base-uncased']
703,"{'test/f1_weighted': 0.3821771741026399, 'eval/precision_micro': 0.48, 'eval/f1_macro': 0.3996486605182258, 'test/precision_macro': 0.35986061992926976, 'eval/f1_micro': 0.48, 'test/accuracy': 0.380952380952381, 'test/f1_micro': 0.380952380952381, 'eval/recall_macro': 0.3833333333333333, 'eval/recall_micro': 0.48, '_step': 20, 'eval/loss': 5.180224247128299, 'test/precision_micro': 0.380952380952381, '_runtime': 1078.131355047226, 'eval/accuracy': 0.48, 'test/recall_micro': 0.380952380952381, 'eval/precision_weighted': 0.5193846153846153, '_timestamp': 1704348619.047141, 'test/f1_macro': 0.35684424271380794, 'test/precision_weighted': 0.4056095442823131, 'eval/precision_macro': 0.4512820512820512, 'eval/recall_weighted': 0.48, 'test/loss': 12.728915626785083, 'eval/f1_weighted': 0.4810540184453227, 'test/recall_macro': 0.38496536987916297, 'test/recall_weighted': 0.380952380952381, 'split': 10, '_wandb': {'runtime': 1076}}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 55, 'dt_min_samples_leaf': 9}",kind-spaceship-627,DecisionTree,['pre-trained:openai-gpt']
704,"{'eval/precision_macro': 0.09375, 'eval/f1_micro': 0.36, 'test/f1_weighted': 0.32647027768978987, 'eval/recall_weighted': 0.36, 'eval/precision_weighted': 0.15, 'test/loss': 1.334079841552857, 'test/f1_macro': 0.18126385809312637, 'eval/recall_macro': 0.225, 'test/precision_micro': 0.42857142857142855, '_wandb': {'runtime': 995}, 'eval/accuracy': 0.36, 'split': 10, '_timestamp': 1704348132.8026743, 'test/recall_micro': 0.42857142857142855, 'test/precision_weighted': 0.26408341114223466, 'eval/f1_macro': 0.13235294117647062, 'eval/f1_weighted': 0.21176470588235297, 'test/recall_macro': 0.2346774193548387, 'eval/precision_micro': 0.36, 'eval/loss': 1.4044902447444871, 'test/f1_micro': 0.42857142857142855, '_step': 20, 'test/recall_weighted': 0.42857142857142855, 'eval/recall_micro': 0.36, 'test/precision_macro': 0.1482843137254902, '_runtime': 997.252233505249, 'test/accuracy': 0.42857142857142855}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 65, 'dt_min_samples_leaf': 57}",pretty-violet-626,DecisionTree,['pre-trained:bert-base-uncased']
705,"{'eval/loss': 1.0645933006884916, 'test/loss': 9.341777534559215, 'test/f1_micro': 0.42857142857142855, 'test/f1_weighted': 0.39506681192863863, 'test/recall_macro': 0.39655172413793105, 'eval/precision_macro': 0.325, 'test/recall_weighted': 0.42857142857142855, '_wandb': {'runtime': 1077}, 'eval/f1_weighted': 0.3973333333333334, 'eval/recall_micro': 0.44, 'test/precision_micro': 0.42857142857142855, 'eval/precision_weighted': 0.3866666666666667, 'eval/f1_micro': 0.44, 'test/precision_weighted': 0.3796199035169623, '_runtime': 1079.0329484939575, '_timestamp': 1704347537.1003904, 'eval/f1_macro': 0.3205555555555556, 'eval/recall_macro': 0.3416666666666667, '_step': 20, 'test/precision_macro': 0.3321589052287582, 'test/recall_micro': 0.42857142857142855, 'eval/recall_weighted': 0.44, 'eval/precision_micro': 0.44, 'test/f1_macro': 0.34996697291779255, 'eval/accuracy': 0.44, 'test/accuracy': 0.42857142857142855, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 54, 'dt_min_samples_leaf': 14}",vivid-blaze-625,DecisionTree,['pre-trained:openai-gpt']
706,"{'test/recall_weighted': 0.492063492063492, '_step': 20, 'test/loss': 1.275518815596098, 'test/accuracy': 0.492063492063492, 'eval/f1_macro': 0.14285714285714288, 'test/f1_macro': 0.16489361702127658, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.492063492063492, 'split': 10, '_runtime': 997.23202586174, 'eval/accuracy': 0.4, 'test/precision_macro': 0.123015873015873, 'test/precision_weighted': 0.24212648022171832, 'test/f1_weighted': 0.3245525160418777, 'test/recall_macro': 0.25, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, '_timestamp': 1704347131.9407208, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.25, 'eval/loss': 1.3296549549719356, 'test/precision_micro': 0.492063492063492, '_wandb': {'runtime': 995}, 'test/f1_micro': 0.492063492063492, 'eval/precision_macro': 0.1, 'eval/precision_weighted': 0.16}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 64, 'dt_min_samples_leaf': 92}",quiet-cherry-624,DecisionTree,['pre-trained:bert-base-uncased']
707,"{'test/recall_macro': 0.40220674918950783, 'test/precision_macro': 0.392911877394636, 'eval/precision_weighted': 0.464, '_wandb': {'runtime': 1077}, '_runtime': 1078.9113132953644, 'eval/f1_micro': 0.44, 'eval/f1_weighted': 0.4242424242424242, 'eval/recall_macro': 0.3416666666666667, '_step': 20, 'test/f1_weighted': 0.4083357980873509, 'test/precision_micro': 0.4126984126984127, 'test/loss': 9.5478145871194, 'eval/accuracy': 0.44, 'test/recall_micro': 0.4126984126984127, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.4126984126984127, 'split': 10, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.416931216931217, 'eval/loss': 1.18748477513543, '_timestamp': 1704346453.4039924, 'eval/f1_macro': 0.3446969696969697, 'test/f1_micro': 0.4126984126984127, 'test/accuracy': 0.4126984126984127, 'eval/precision_macro': 0.4, 'test/f1_macro': 0.3873822017562647, 'eval/recall_micro': 0.44}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 53, 'dt_min_samples_leaf': 11}",zany-music-623,DecisionTree,['pre-trained:openai-gpt']
708,"{'_step': 20, 'split': 10, 'test/loss': 1.275518815596098, 'eval/f1_weighted': 0.22857142857142865, 'eval/loss': 1.3296549549719356, 'eval/accuracy': 0.4, 'test/recall_weighted': 0.492063492063492, 'eval/precision_weighted': 0.16, 'test/accuracy': 0.492063492063492, 'test/f1_micro': 0.492063492063492, 'test/recall_macro': 0.25, 'test/recall_micro': 0.492063492063492, 'test/precision_micro': 0.492063492063492, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.16489361702127658, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, '_wandb': {'runtime': 995}, 'test/f1_weighted': 0.3245525160418777, 'eval/precision_macro': 0.1, 'eval/recall_weighted': 0.4, '_runtime': 997.1242892742156, 'test/precision_weighted': 0.24212648022171832, '_timestamp': 1704346129.0793474, 'eval/f1_macro': 0.14285714285714288, 'test/precision_macro': 0.123015873015873}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 63, 'dt_min_samples_leaf': 79}",prime-spaceship-622,DecisionTree,['pre-trained:bert-base-uncased']
709,"{'test/accuracy': 0.31746031746031744, 'test/recall_micro': 0.31746031746031744, 'test/precision_macro': 0.33307909762651144, 'test/precision_micro': 0.31746031746031744, 'test/precision_weighted': 0.39961765793046583, '_wandb': {'runtime': 1076}, 'test/f1_macro': 0.2994851258581236, 'eval/f1_weighted': 0.4342857142857142, 'eval/recall_micro': 0.44, 'eval/precision_weighted': 0.48, 'eval/loss': 1.105653538559102, 'eval/f1_macro': 0.3857142857142858, '_runtime': 1077.6274826526642, '_timestamp': 1704345369.2923727, 'eval/precision_macro': 0.4, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, 'split': 10, 'test/f1_weighted': 0.3251716247139589, 'test/recall_macro': 0.3398725316828765, '_step': 20, 'eval/accuracy': 0.44, 'test/f1_micro': 0.31746031746031744, 'test/recall_weighted': 0.31746031746031744, 'test/loss': 4.005022429391996, 'eval/f1_micro': 0.44, 'eval/recall_macro': 0.4083333333333333}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 52, 'dt_min_samples_leaf': 12}",stellar-spaceship-621,DecisionTree,['pre-trained:openai-gpt']
710,"{'test/f1_micro': 0.492063492063492, 'test/precision_macro': 0.123015873015873, '_step': 20, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.25, 'test/precision_weighted': 0.24212648022171832, 'eval/loss': 1.3296549549719356, '_timestamp': 1704345126.9907107, 'eval/recall_macro': 0.25, 'eval/precision_macro': 0.1, 'split': 10, '_wandb': {'runtime': 994}, 'test/precision_micro': 0.492063492063492, 'eval/precision_weighted': 0.16, '_runtime': 995.884093761444, 'eval/f1_macro': 0.14285714285714288, 'test/f1_macro': 0.16489361702127658, 'eval/f1_weighted': 0.22857142857142865, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.492063492063492, 'test/loss': 1.275518815596098, 'eval/accuracy': 0.4, 'test/accuracy': 0.492063492063492, 'test/recall_micro': 0.492063492063492, 'eval/f1_micro': 0.4000000000000001, 'test/f1_weighted': 0.3245525160418777}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 62, 'dt_min_samples_leaf': 94}",ruby-wood-620,DecisionTree,['pre-trained:bert-base-uncased']
711,"{'test/f1_micro': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, 'eval/precision_weighted': 0.4773333333333334, 'eval/loss': 1.0962911669458597, 'test/recall_micro': 0.4603174603174603, 'test/f1_macro': 0.3929258241758242, '_timestamp': 1704344286.0155497, 'eval/recall_weighted': 0.48, 'test/precision_macro': 0.4305555555555555, '_wandb': {'runtime': 1076}, 'eval/precision_micro': 0.48, 'test/recall_weighted': 0.4603174603174603, 'test/f1_weighted': 0.4309654631083203, 'test/loss': 9.373514412296164, 'eval/f1_macro': 0.3588636363636364, 'eval/f1_micro': 0.48, 'test/accuracy': 0.4603174603174603, 'test/recall_macro': 0.4174587385794282, 'split': 10, 'eval/recall_macro': 0.3666666666666667, 'eval/precision_macro': 0.4083333333333333, 'test/precision_weighted': 0.4523809523809524, '_runtime': 1077.9434866905212, 'eval/f1_weighted': 0.44690909090909087, 'eval/accuracy': 0.48, 'eval/recall_micro': 0.48, '_step': 20}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 51, 'dt_min_samples_leaf': 13}",colorful-glitter-619,DecisionTree,['pre-trained:openai-gpt']
712,"{'eval/f1_macro': 0.14285714285714288, 'test/f1_weighted': 0.3245525160418777, 'eval/recall_weighted': 0.4, '_wandb': {'runtime': 995}, 'test/f1_micro': 0.492063492063492, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.492063492063492, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.123015873015873, 'test/recall_weighted': 0.492063492063492, 'split': 10, 'eval/accuracy': 0.4, 'test/accuracy': 0.492063492063492, 'eval/recall_micro': 0.4, 'eval/precision_weighted': 0.16, 'test/precision_weighted': 0.24212648022171832, '_step': 20, 'eval/precision_macro': 0.1, 'test/precision_micro': 0.492063492063492, 'test/f1_macro': 0.16489361702127658, '_runtime': 996.6374568939208, '_timestamp': 1704344127.780129, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_macro': 0.25, 'eval/loss': 1.3296549549719356, 'test/loss': 1.275518815596098}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 61, 'dt_min_samples_leaf': 70}",celestial-shadow-618,DecisionTree,['pre-trained:bert-base-uncased']
713,"{'_runtime': 996.6067397594452, 'eval/recall_weighted': 0.36, 'test/recall_micro': 0.4444444444444444, 'test/precision_weighted': 0.26992451992451993, 'eval/loss': 1.3454972575428616, 'test/loss': 1.3819680708660866, 'test/f1_micro': 0.4444444444444444, '_step': 20, '_wandb': {'runtime': 995}, 'eval/f1_macro': 0.13235294117647062, 'test/accuracy': 0.4444444444444444, 'test/f1_weighted': 0.33525485160597035, 'eval/recall_macro': 0.225, 'eval/recall_micro': 0.36, 'eval/accuracy': 0.36, 'eval/f1_weighted': 0.21176470588235297, 'test/recall_macro': 0.24274193548387096, 'eval/precision_macro': 0.09375, 'eval/precision_micro': 0.36, 'split': 10, 'eval/f1_micro': 0.36, 'test/precision_macro': 0.15253496503496505, 'test/precision_micro': 0.4444444444444444, 'eval/precision_weighted': 0.15, '_timestamp': 1704343126.8615696, 'test/f1_macro': 0.18646012621916236, 'test/recall_weighted': 0.4444444444444444}","{'dt_criterion': 'gini', 'dt_max_depth': 12, 'trial.number': 60, 'dt_min_samples_leaf': 46}",noble-wind-617,DecisionTree,['pre-trained:bert-base-uncased']
714,"{'_wandb': {'runtime': 1078}, 'test/precision_macro': 0.4053030303030303, 'test/recall_weighted': 0.4444444444444444, 'eval/recall_macro': 0.3666666666666667, 'eval/accuracy': 0.48, 'test/f1_micro': 0.4444444444444444, 'test/recall_macro': 0.4088380489242558, 'eval/precision_macro': 0.4083333333333333, 'eval/recall_weighted': 0.48, '_timestamp': 1704343201.8804233, 'eval/f1_macro': 0.3588636363636364, 'test/accuracy': 0.4444444444444444, 'eval/recall_micro': 0.48, 'eval/precision_weighted': 0.4773333333333334, '_runtime': 1079.407692193985, 'test/recall_micro': 0.4444444444444444, 'test/f1_weighted': 0.416558491351452, 'eval/f1_micro': 0.48, 'test/f1_macro': 0.37903295376121465, 'test/precision_micro': 0.4444444444444444, 'test/precision_weighted': 0.4331409331409331, 'eval/loss': 1.108181227884577, 'split': 10, 'test/loss': 10.481925636088633, 'eval/precision_micro': 0.48, '_step': 20, 'eval/f1_weighted': 0.44690909090909087}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 50, 'dt_min_samples_leaf': 7}",ruby-salad-616,DecisionTree,['pre-trained:openai-gpt']
715,"{'_step': 20, '_wandb': {'runtime': 995}, '_runtime': 996.8869307041168, 'eval/precision_macro': 0.09375, 'eval/recall_weighted': 0.36, 'test/precision_macro': 0.1482843137254902, '_timestamp': 1704342126.2709956, 'eval/accuracy': 0.36, 'eval/precision_weighted': 0.15, 'split': 10, 'eval/f1_macro': 0.13235294117647062, 'eval/f1_micro': 0.36, 'test/f1_macro': 0.18126385809312637, 'test/precision_weighted': 0.26408341114223466, 'test/loss': 1.346700877126801, 'test/f1_micro': 0.42857142857142855, 'test/f1_weighted': 0.32647027768978987, 'test/recall_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, 'eval/loss': 1.3988320792306457, 'test/accuracy': 0.42857142857142855, 'eval/recall_macro': 0.225, 'eval/f1_weighted': 0.21176470588235297, 'eval/recall_micro': 0.36, 'test/recall_macro': 0.2346774193548387, 'eval/precision_micro': 0.36, 'test/precision_micro': 0.42857142857142855}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 59, 'dt_min_samples_leaf': 54}",decent-pyramid-615,DecisionTree,['pre-trained:bert-base-uncased']
716,"{'_wandb': {'runtime': 1077}, 'test/f1_weighted': 0.2684955141476881, 'eval/recall_micro': 0.56, 'test/precision_micro': 0.2857142857142857, 'test/precision_weighted': 0.2627769056340485, 'eval/loss': 2.3362566102156084, 'test/f1_macro': 0.2216032608695652, 'eval/precision_macro': 0.425, 'test/loss': 7.410275224127417, 'test/accuracy': 0.2857142857142857, 'test/f1_micro': 0.2857142857142857, 'eval/precision_weighted': 0.504, 'split': 10, 'eval/f1_macro': 0.4375, 'eval/recall_macro': 0.48333333333333334, 'eval/recall_weighted': 0.56, '_runtime': 1078.699861049652, 'test/recall_macro': 0.2545498084291188, 'eval/precision_micro': 0.56, 'eval/accuracy': 0.56, 'eval/f1_weighted': 0.516, 'test/recall_micro': 0.2857142857142857, '_step': 20, '_timestamp': 1704342118.146454, 'eval/f1_micro': 0.56, 'test/precision_macro': 0.20398351648351648, 'test/recall_weighted': 0.2857142857142857}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 49, 'dt_min_samples_leaf': 18}",rosy-night-614,DecisionTree,['pre-trained:openai-gpt']
717,"{'_wandb': {'runtime': 994}, 'eval/f1_macro': 0.1679487179487179, 'test/f1_weighted': 0.33978174603174605, 'test/recall_micro': 0.3968253968253968, 'split': 10, '_runtime': 996.106552362442, '_timestamp': 1704341124.6055045, 'test/recall_weighted': 0.3968253968253968, 'eval/precision_weighted': 0.2016666666666667, 'eval/accuracy': 0.32, 'test/f1_macro': 0.2234375, 'test/f1_micro': 0.3968253968253968, 'eval/recall_micro': 0.32, 'test/recall_macro': 0.3032258064516129, 'eval/loss': 1.3605355632158649, 'eval/precision_micro': 0.32, 'eval/recall_weighted': 0.32, 'test/precision_micro': 0.3968253968253968, 'test/accuracy': 0.3968253968253968, '_step': 20, 'eval/f1_micro': 0.32, 'eval/recall_macro': 0.21666666666666665, 'test/precision_weighted': 0.3150553150553151, 'test/loss': 1.2745313625984234, 'eval/f1_weighted': 0.24738461538461537, 'eval/precision_macro': 0.1371527777777778, 'test/precision_macro': 0.19393939393939397}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 58, 'dt_min_samples_leaf': 66}",still-meadow-613,DecisionTree,['pre-trained:bert-base-uncased']
718,"{'eval/f1_weighted': 0.516, 'test/f1_weighted': 0.27246376811594203, 'test/precision_weighted': 0.2680679109250538, '_runtime': 1079.0246269702911, 'eval/recall_weighted': 0.56, 'test/precision_micro': 0.2857142857142857, 'eval/accuracy': 0.56, 'test/recall_micro': 0.2857142857142857, 'eval/precision_macro': 0.425, 'test/loss': 7.366810691340852, '_timestamp': 1704341034.8370829, 'test/f1_micro': 0.2857142857142857, 'test/precision_macro': 0.2109279609279609, '_wandb': {'runtime': 1077}, 'eval/f1_micro': 0.56, 'test/accuracy': 0.2857142857142857, 'test/f1_macro': 0.22681159420289856, 'eval/precision_micro': 0.56, '_step': 20, 'eval/f1_macro': 0.4375, 'eval/recall_macro': 0.48333333333333334, 'test/recall_macro': 0.2545498084291188, 'eval/precision_weighted': 0.504, 'split': 10, 'eval/loss': 2.3456012042628687, 'eval/recall_micro': 0.56, 'test/recall_weighted': 0.2857142857142857}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 48, 'dt_min_samples_leaf': 16}",sunny-bee-612,DecisionTree,['pre-trained:openai-gpt']
719,"{'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.492063492063492, 'eval/accuracy': 0.4, 'test/recall_weighted': 0.492063492063492, 'eval/precision_weighted': 0.16, '_wandb': {'runtime': 995}, 'test/recall_macro': 0.25, '_timestamp': 1704340124.4323866, 'test/recall_micro': 0.492063492063492, 'eval/recall_weighted': 0.4, 'test/precision_weighted': 0.24212648022171832, 'eval/recall_micro': 0.4, 'test/f1_micro': 0.492063492063492, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.3245525160418777, 'split': 10, 'eval/loss': 1.3296549549719356, 'eval/recall_macro': 0.25, 'test/precision_macro': 0.123015873015873, 'test/precision_micro': 0.492063492063492, '_step': 20, 'eval/precision_macro': 0.1, 'eval/precision_micro': 0.4, '_runtime': 996.7289485931396, 'eval/f1_macro': 0.14285714285714288, 'test/f1_macro': 0.16489361702127658, 'test/loss': 1.275518815596098}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 57, 'dt_min_samples_leaf': 78}",fallen-sun-611,DecisionTree,['pre-trained:bert-base-uncased']
720,"{'test/accuracy': 0.4444444444444444, 'test/f1_macro': 0.15555555555555556, 'test/recall_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'test/precision_weighted': 0.21129326047358837, 'split': 10, '_timestamp': 1704339952.3532326, 'eval/recall_macro': 0.25, 'eval/recall_weighted': 0.4, '_runtime': 1079.4524517059326, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.4444444444444444, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_weighted': 0.16, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_macro': 0.2413793103448276, '_wandb': {'runtime': 1078}, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.14285714285714288, 'eval/precision_macro': 0.1, 'test/precision_macro': 0.11475409836065574, 'test/loss': 1.9452566482131808, 'test/f1_micro': 0.4444444444444444, '_step': 20, 'eval/loss': 1.159746845488376, 'test/f1_weighted': 0.28641975308641976}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 47, 'dt_min_samples_leaf': 6}",skilled-wave-610,DecisionTree,['pre-trained:openai-gpt']
721,"{'eval/precision_macro': 0.1, 'test/precision_weighted': 0.24212648022171832, '_step': 20, 'test/loss': 1.275518815596098, 'test/f1_macro': 0.16489361702127658, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.4, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.3245525160418777, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.492063492063492, '_runtime': 995.6684658527374, 'eval/f1_micro': 0.4000000000000001, 'test/recall_weighted': 0.492063492063492, 'split': 10, '_timestamp': 1704339122.562347, 'test/f1_micro': 0.492063492063492, 'eval/recall_macro': 0.25, 'test/precision_macro': 0.123015873015873, 'eval/precision_weighted': 0.16, '_wandb': {'runtime': 994}, 'eval/loss': 1.3296549549719356, 'test/accuracy': 0.492063492063492, 'eval/f1_weighted': 0.22857142857142865, 'eval/f1_macro': 0.14285714285714288, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.492063492063492}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 56, 'dt_min_samples_leaf': 92}",sleek-durian-609,DecisionTree,['pre-trained:bert-base-uncased']
722,"{'eval/precision_micro': 0.44, 'eval/precision_weighted': 0.41857142857142854, 'test/precision_weighted': 0.3883454508454508, 'test/loss': 10.07729719519087, 'test/f1_macro': 0.3167741935483871, 'eval/precision_macro': 0.3526785714285714, 'test/recall_weighted': 0.3333333333333333, 'test/f1_micro': 0.3333333333333333, 'eval/recall_macro': 0.39166666666666666, '_timestamp': 1704338867.6625354, 'eval/recall_weighted': 0.44, '_runtime': 1079.3777503967283, 'eval/recall_micro': 0.44, '_step': 20, 'split': 10, 'test/accuracy': 0.3333333333333333, '_wandb': {'runtime': 1078}, 'eval/accuracy': 0.44, 'test/f1_weighted': 0.33212493599590376, 'test/recall_micro': 0.3333333333333333, 'eval/loss': 5.1411741454144195, 'eval/f1_weighted': 0.42305250305250314, 'test/recall_macro': 0.36765030946065425, 'test/precision_macro': 0.32579399766899764, 'test/precision_micro': 0.3333333333333333, 'eval/f1_macro': 0.36660561660561664, 'eval/f1_micro': 0.44}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 46, 'dt_min_samples_leaf': 15}",fine-firefly-608,DecisionTree,['pre-trained:openai-gpt']
723,"{'test/accuracy': 0.492063492063492, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'test/precision_macro': 0.123015873015873, '_wandb': {'runtime': 996}, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.14285714285714288, 'test/recall_micro': 0.492063492063492, 'eval/recall_micro': 0.4, 'test/precision_micro': 0.492063492063492, '_step': 20, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.492063492063492, 'test/f1_weighted': 0.3245525160418777, 'eval/precision_weighted': 0.16, 'test/precision_weighted': 0.24212648022171832, 'eval/loss': 1.3296549549719356, '_timestamp': 1704338122.3473687, 'test/f1_macro': 0.16489361702127658, 'eval/precision_macro': 0.1, 'test/loss': 1.275518815596098, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.492063492063492, 'split': 10, '_runtime': 997.3188107013702, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_weighted': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 55, 'dt_min_samples_leaf': 76}",valiant-brook-607,DecisionTree,['pre-trained:bert-base-uncased']
724,"{'_step': 20, 'test/precision_micro': 0.3492063492063492, 'split': 10, 'test/f1_micro': 0.3492063492063492, 'eval/recall_weighted': 0.4, 'eval/precision_macro': 0.30965909090909094, '_wandb': {'runtime': 1074}, 'eval/accuracy': 0.4, 'eval/f1_weighted': 0.3662745098039216, 'test/recall_macro': 0.3448275862068965, 'test/precision_macro': 0.2469565217391304, '_timestamp': 1704337782.87917, 'test/f1_macro': 0.27863756613756613, 'test/f1_weighted': 0.31032585873855717, 'eval/recall_micro': 0.4, 'test/precision_weighted': 0.2973636991028295, '_runtime': 1075.56885099411, 'eval/loss': 1.251635997795682, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.36666666666666664, 'test/loss': 1.396850123786344, 'test/recall_weighted': 0.3492063492063492, 'eval/precision_weighted': 0.35727272727272724, 'eval/f1_macro': 0.32598039215686275, 'test/accuracy': 0.3492063492063492, 'test/recall_micro': 0.3492063492063492, 'eval/precision_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 45, 'dt_min_samples_leaf': 63}",hopeful-sun-606,DecisionTree,['pre-trained:openai-gpt']
725,"{'test/recall_micro': 0.42857142857142855, 'test/precision_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.42857142857142855, 'eval/f1_weighted': 0.275, 'test/accuracy': 0.42857142857142855, 'eval/recall_macro': 0.275, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.2685483870967742, 'eval/loss': 1.3697666409433995, 'test/loss': 1.3360556596587518, 'test/f1_weighted': 0.3330010479768934, '_runtime': 996.8342945575714, 'eval/precision_micro': 0.4, 'eval/precision_weighted': 0.23030303030303031, 'test/precision_weighted': 0.2728205128205128, '_step': 20, 'eval/accuracy': 0.4, 'eval/recall_weighted': 0.4, 'split': 10, 'test/precision_macro': 0.1776923076923077, '_wandb': {'runtime': 995}, 'eval/precision_macro': 0.1856060606060606, '_timestamp': 1704337121.0604506, 'eval/f1_macro': 0.20312500000000003, 'test/f1_macro': 0.213365539452496}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 54, 'dt_min_samples_leaf': 61}",classic-totem-605,DecisionTree,['pre-trained:bert-base-uncased']
726,"{'eval/f1_weighted': 0.4342857142857142, 'test/f1_weighted': 0.3251716247139589, 'eval/precision_macro': 0.4, '_step': 20, 'eval/loss': 1.105653538559102, '_timestamp': 1704336703.0200229, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.3857142857142858, 'eval/f1_micro': 0.44, 'test/precision_weighted': 0.39961765793046583, 'split': 10, 'eval/recall_macro': 0.4083333333333333, 'test/f1_micro': 0.31746031746031744, 'test/loss': 4.005022429391996, 'test/recall_weighted': 0.31746031746031744, '_wandb': {'runtime': 1077}, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.33307909762651144, '_runtime': 1078.6061899662018, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.3398725316828765, 'test/recall_micro': 0.31746031746031744, 'eval/precision_micro': 0.44, 'test/accuracy': 0.31746031746031744, 'test/precision_micro': 0.31746031746031744, 'eval/precision_weighted': 0.48, 'test/f1_macro': 0.2994851258581236}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 44, 'dt_min_samples_leaf': 10}",daily-galaxy-604,DecisionTree,['pre-trained:openai-gpt']
727,"{'_wandb': {'runtime': 995}, 'eval/f1_macro': 0.14285714285714288, 'eval/loss': 1.3296549549719356, '_timestamp': 1704336120.5979877, 'eval/precision_weighted': 0.16, 'test/precision_weighted': 0.24212648022171832, '_step': 20, 'split': 10, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.16489361702127658, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.3245525160418777, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, 'test/loss': 1.275518815596098, 'eval/accuracy': 0.4, 'test/precision_macro': 0.123015873015873, 'eval/precision_macro': 0.1, 'test/precision_micro': 0.492063492063492, 'test/accuracy': 0.492063492063492, 'test/f1_micro': 0.492063492063492, '_runtime': 997.226328611374, 'test/recall_micro': 0.492063492063492, 'eval/recall_weighted': 0.4, 'test/recall_macro': 0.25, 'test/recall_weighted': 0.492063492063492}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 53, 'dt_min_samples_leaf': 81}",hearty-capybara-603,DecisionTree,['pre-trained:bert-base-uncased']
728,"{'test/recall_macro': 0.4174587385794282, 'eval/accuracy': 0.48, 'eval/f1_macro': 0.3588636363636364, 'eval/f1_weighted': 0.44690909090909087, 'test/precision_macro': 0.4305555555555555, 'test/precision_weighted': 0.4523809523809524, 'eval/loss': 1.106785737524559, 'eval/f1_micro': 0.48, 'test/f1_weighted': 0.4309654631083203, 'eval/precision_micro': 0.48, 'eval/precision_weighted': 0.4773333333333334, '_timestamp': 1704335618.021881, 'split': 10, 'test/recall_weighted': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.4083333333333333, 'test/loss': 9.373514412296164, '_runtime': 1078.213044166565, 'test/f1_micro': 0.4603174603174603, 'eval/recall_weighted': 0.48, 'test/precision_micro': 0.4603174603174603, '_wandb': {'runtime': 1076}, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.3929258241758242, 'eval/recall_macro': 0.3666666666666667, 'eval/recall_micro': 0.48, '_step': 20}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 43, 'dt_min_samples_leaf': 13}",solar-tree-602,DecisionTree,['pre-trained:openai-gpt']
729,"{'eval/f1_weighted': 0.22857142857142865, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.16, 'eval/recall_micro': 0.4, '_step': 20, 'split': 10, '_runtime': 996.0933463573456, 'eval/accuracy': 0.4, 'test/f1_macro': 0.16489361702127658, '_timestamp': 1704335117.6947703, 'eval/f1_macro': 0.14285714285714288, 'eval/recall_macro': 0.25, 'test/recall_weighted': 0.492063492063492, 'test/precision_weighted': 0.24212648022171832, 'test/f1_micro': 0.492063492063492, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.123015873015873, 'test/f1_weighted': 0.3245525160418777, 'test/recall_micro': 0.492063492063492, 'eval/precision_macro': 0.1, '_wandb': {'runtime': 994}, 'eval/loss': 1.3296549549719356, 'test/loss': 1.275518815596098, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.492063492063492, 'test/precision_micro': 0.492063492063492, 'test/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 52, 'dt_min_samples_leaf': 75}",summer-salad-601,DecisionTree,['pre-trained:bert-base-uncased']
730,"{'split': 10, 'test/accuracy': 0.36507936507936506, 'test/precision_micro': 0.36507936507936506, 'eval/loss': 7.743286419411919, 'test/loss': 14.292136450357496, '_timestamp': 1704334535.3488717, 'eval/precision_macro': 0.4722222222222222, 'test/precision_weighted': 0.4000656402912042, 'test/f1_micro': 0.36507936507936506, 'test/f1_weighted': 0.3668404453675084, 'eval/recall_macro': 0.44166666666666665, 'eval/recall_micro': 0.52, '_runtime': 1078.3960976600647, 'eval/accuracy': 0.52, 'eval/f1_weighted': 0.519298245614035, 'test/recall_macro': 0.3763446802239906, 'test/precision_macro': 0.3425751879699248, 'eval/f1_macro': 0.43567251461988304, 'test/f1_macro': 0.3411627192683093, 'test/recall_weighted': 0.36507936507936506, '_step': 20, 'eval/f1_micro': 0.52, 'test/recall_micro': 0.36507936507936506, 'eval/precision_micro': 0.52, 'eval/precision_weighted': 0.56, '_wandb': {'runtime': 1077}, 'eval/recall_weighted': 0.52}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 42, 'dt_min_samples_leaf': 8}",desert-wind-600,DecisionTree,['pre-trained:openai-gpt']
731,"{'eval/precision_micro': 0.4, 'split': 10, 'test/f1_weighted': 0.3245525160418777, 'eval/precision_macro': 0.1, 'test/accuracy': 0.492063492063492, 'eval/recall_macro': 0.25, 'eval/precision_weighted': 0.16, 'eval/recall_weighted': 0.4, 'test/precision_weighted': 0.24212648022171832, 'test/f1_micro': 0.492063492063492, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_micro': 0.492063492063492, 'test/precision_macro': 0.123015873015873, 'test/precision_micro': 0.492063492063492, 'eval/loss': 1.3296549549719356, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.16489361702127658, 'test/loss': 1.275518815596098, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.25, '_step': 20, 'eval/f1_macro': 0.14285714285714288, 'eval/accuracy': 0.4, 'test/recall_weighted': 0.492063492063492, '_wandb': {'runtime': 994}, '_runtime': 995.7282032966614, '_timestamp': 1704334117.4947634}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 51, 'dt_min_samples_leaf': 86}",morning-frost-599,DecisionTree,['pre-trained:bert-base-uncased']
732,"{'test/precision_micro': 0.4603174603174603, 'test/loss': 9.370240209156224, 'eval/accuracy': 0.48, 'test/f1_macro': 0.3929258241758242, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.4083333333333333, '_timestamp': 1704333451.2542417, 'eval/f1_micro': 0.48, 'eval/recall_weighted': 0.48, 'test/precision_macro': 0.4305555555555555, 'test/accuracy': 0.4603174603174603, 'split': 10, 'eval/loss': 1.0985347456119017, 'eval/f1_weighted': 0.44690909090909087, 'test/precision_weighted': 0.4523809523809524, '_runtime': 1078.0287675857544, 'eval/recall_macro': 0.3666666666666667, 'eval/recall_micro': 0.48, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_weighted': 0.4773333333333334, '_step': 20, '_wandb': {'runtime': 1076}, 'eval/f1_macro': 0.3588636363636364, 'test/f1_micro': 0.4603174603174603, 'test/f1_weighted': 0.4309654631083203, 'test/recall_macro': 0.4174587385794282, 'eval/precision_micro': 0.48}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 41, 'dt_min_samples_leaf': 11}",firm-water-598,DecisionTree,['pre-trained:openai-gpt']
733,"{'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.492063492063492, '_step': 20, 'test/recall_macro': 0.25, 'test/recall_micro': 0.492063492063492, 'test/precision_micro': 0.492063492063492, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.3245525160418777, 'eval/recall_micro': 0.4, 'test/accuracy': 0.492063492063492, '_wandb': {'runtime': 994}, 'eval/loss': 1.3296549549719356, '_timestamp': 1704333117.1453905, 'test/loss': 1.275518815596098, 'eval/f1_weighted': 0.22857142857142865, 'test/precision_weighted': 0.24212648022171832, '_runtime': 996.239218235016, 'test/f1_macro': 0.16489361702127658, 'eval/recall_macro': 0.25, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_weighted': 0.16, 'eval/f1_macro': 0.14285714285714288, 'test/f1_micro': 0.492063492063492, 'eval/precision_macro': 0.1, 'split': 10, 'test/precision_macro': 0.123015873015873}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 50, 'dt_min_samples_leaf': 68}",eager-cosmos-597,DecisionTree,['pre-trained:bert-base-uncased']
734,"{'split': 10, 'eval/f1_weighted': 0.264421052631579, 'eval/recall_micro': 0.28, 'eval/precision_macro': 0.1944444444444444, 'eval/accuracy': 0.28, 'test/f1_macro': 0.2683381433381433, 'test/f1_micro': 0.3333333333333333, '_step': 20, 'test/recall_micro': 0.3333333333333333, 'test/precision_micro': 0.3333333333333333, 'eval/precision_micro': 0.28, 'eval/recall_weighted': 0.28, '_wandb': {'runtime': 1076}, 'eval/loss': 4.265341852815655, 'test/loss': 1.481951045579226, 'test/precision_weighted': 0.3374485596707819, '_runtime': 1077.7022666931152, 'eval/f1_macro': 0.20526315789473687, 'test/precision_macro': 0.2685185185185185, 'test/recall_weighted': 0.3333333333333333, 'eval/precision_weighted': 0.2577777777777778, 'test/accuracy': 0.3333333333333333, '_timestamp': 1704332368.0213697, 'eval/f1_micro': 0.28, 'test/f1_weighted': 0.328145399573971, 'eval/recall_macro': 0.225, 'test/recall_macro': 0.29109563807839667}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 40, 'dt_min_samples_leaf': 21}",sunny-vortex-596,DecisionTree,['pre-trained:openai-gpt']
735,"{'eval/f1_weighted': 0.21176470588235297, 'eval/recall_macro': 0.225, 'eval/precision_micro': 0.36, 'eval/precision_weighted': 0.15, 'split': 10, '_timestamp': 1704332116.711788, 'test/f1_macro': 0.18646012621916236, '_step': 20, 'test/recall_macro': 0.24274193548387096, 'test/f1_micro': 0.4444444444444444, 'test/accuracy': 0.4444444444444444, 'test/precision_micro': 0.4444444444444444, '_wandb': {'runtime': 995}, 'test/loss': 1.374955792496771, 'eval/f1_micro': 0.36, 'eval/accuracy': 0.36, 'test/recall_micro': 0.4444444444444444, 'eval/recall_weighted': 0.36, 'test/recall_weighted': 0.4444444444444444, '_runtime': 996.634731054306, 'eval/loss': 1.4186722258633429, 'test/precision_macro': 0.15253496503496505, 'eval/recall_micro': 0.36, 'eval/precision_macro': 0.09375, 'eval/f1_macro': 0.13235294117647062, 'test/f1_weighted': 0.33525485160597035, 'test/precision_weighted': 0.26992451992451993}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 49, 'dt_min_samples_leaf': 42}",misunderstood-sunset-595,DecisionTree,['pre-trained:bert-base-uncased']
736,"{'eval/recall_micro': 0.56, 'test/accuracy': 0.2857142857142857, 'test/f1_macro': 0.22681159420289856, 'eval/f1_weighted': 0.516, '_timestamp': 1704331284.3017335, 'eval/precision_weighted': 0.504, 'test/recall_weighted': 0.2857142857142857, 'eval/f1_micro': 0.56, 'eval/recall_macro': 0.48333333333333334, 'eval/recall_weighted': 0.56, '_runtime': 1077.5581984519958, 'split': 10, '_wandb': {'runtime': 1076}, 'test/recall_macro': 0.2545498084291188, 'eval/precision_macro': 0.425, 'test/precision_macro': 0.2109279609279609, '_step': 20, 'test/precision_micro': 0.2857142857142857, 'eval/precision_micro': 0.56, 'test/precision_weighted': 0.2680679109250538, 'test/loss': 7.366810691340852, 'eval/accuracy': 0.56, 'eval/f1_macro': 0.4375, 'test/f1_micro': 0.2857142857142857, 'test/f1_weighted': 0.27246376811594203, 'test/recall_micro': 0.2857142857142857, 'eval/loss': 2.3456012042628687}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 39, 'dt_min_samples_leaf': 16}",rural-bush-594,DecisionTree,['pre-trained:openai-gpt']
737,"{'eval/recall_macro': 0.21666666666666665, 'test/recall_macro': 0.3032258064516129, 'test/recall_micro': 0.3968253968253968, 'test/precision_macro': 0.19393939393939397, 'test/recall_weighted': 0.3968253968253968, 'test/precision_weighted': 0.3150553150553151, 'test/f1_weighted': 0.33978174603174605, 'eval/recall_micro': 0.32, 'eval/precision_macro': 0.1371527777777778, 'eval/f1_macro': 0.1679487179487179, 'eval/f1_micro': 0.32, 'test/f1_micro': 0.3968253968253968, 'test/accuracy': 0.3968253968253968, 'eval/recall_weighted': 0.32, '_runtime': 997.1402781009674, 'eval/loss': 1.3605355632158649, '_timestamp': 1704331116.276307, 'eval/f1_weighted': 0.24738461538461537, 'eval/precision_weighted': 0.2016666666666667, '_wandb': {'runtime': 995}, 'test/loss': 1.2745313625984234, 'eval/precision_micro': 0.32, 'split': 10, 'test/f1_macro': 0.2234375, 'test/precision_micro': 0.3968253968253968, '_step': 20, 'eval/accuracy': 0.32}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 48, 'dt_min_samples_leaf': 100}",misunderstood-silence-593,DecisionTree,['pre-trained:bert-base-uncased']
738,"{'eval/precision_weighted': 0.48, 'test/loss': 4.005022429391996, 'eval/f1_weighted': 0.4342857142857142, 'eval/recall_weighted': 0.44, '_step': 20, 'eval/f1_macro': 0.3857142857142858, 'eval/precision_micro': 0.44, '_wandb': {'runtime': 1077}, 'eval/loss': 1.105653538559102, 'test/f1_micro': 0.31746031746031744, 'eval/recall_micro': 0.44, 'test/precision_macro': 0.33307909762651144, 'test/precision_weighted': 0.39961765793046583, 'test/accuracy': 0.31746031746031744, 'test/f1_macro': 0.2994851258581236, 'test/precision_micro': 0.31746031746031744, 'test/recall_weighted': 0.31746031746031744, 'test/f1_weighted': 0.3251716247139589, 'eval/recall_macro': 0.4083333333333333, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'eval/precision_macro': 0.4, 'split': 10, '_runtime': 1078.3972597122192, 'test/recall_micro': 0.31746031746031744, '_timestamp': 1704330202.2270007, 'test/recall_macro': 0.3398725316828765}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 38, 'dt_min_samples_leaf': 11}",true-voice-592,DecisionTree,['pre-trained:openai-gpt']
739,"{'eval/loss': 1.3911535509349091, 'test/loss': 1.386505578650803, 'test/f1_micro': 0.4444444444444444, 'test/precision_weighted': 0.26992451992451993, 'eval/accuracy': 0.36, 'test/recall_weighted': 0.4444444444444444, 'eval/precision_weighted': 0.15, 'eval/recall_weighted': 0.36, 'test/precision_micro': 0.4444444444444444, 'eval/f1_macro': 0.13235294117647062, 'test/accuracy': 0.4444444444444444, 'test/f1_macro': 0.18646012621916236, 'eval/precision_macro': 0.09375, 'eval/recall_macro': 0.225, 'eval/recall_micro': 0.36, '_step': 20, 'split': 10, '_timestamp': 1704330114.6136348, 'test/f1_weighted': 0.33525485160597035, '_runtime': 996.3335828781128, 'eval/f1_micro': 0.36, 'test/recall_macro': 0.24274193548387096, 'eval/precision_micro': 0.36, 'test/precision_macro': 0.15253496503496505, 'eval/f1_weighted': 0.21176470588235297, '_wandb': {'runtime': 994}, 'test/recall_micro': 0.4444444444444444}","{'dt_criterion': 'gini', 'dt_max_depth': 9, 'trial.number': 47, 'dt_min_samples_leaf': 50}",valiant-morning-591,DecisionTree,['pre-trained:bert-base-uncased']
740,"{'eval/loss': 1.4044902447444871, 'test/loss': 1.334079841552857, 'test/accuracy': 0.42857142857142855, 'eval/f1_macro': 0.13235294117647062, 'test/f1_macro': 0.18126385809312637, 'eval/f1_weighted': 0.21176470588235297, 'test/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.09375, 'eval/recall_weighted': 0.36, 'test/precision_macro': 0.1482843137254902, 'test/f1_weighted': 0.32647027768978987, 'eval/precision_micro': 0.36, 'test/precision_micro': 0.42857142857142855, '_step': 20, 'test/recall_weighted': 0.42857142857142855, 'eval/precision_weighted': 0.15, '_wandb': {'runtime': 995}, '_timestamp': 1704329114.6130395, 'eval/accuracy': 0.36, 'test/f1_micro': 0.42857142857142855, 'test/recall_macro': 0.2346774193548387, 'test/precision_weighted': 0.26408341114223466, '_runtime': 997.1107907295228, 'eval/recall_macro': 0.225, 'split': 10, 'eval/f1_micro': 0.36, 'eval/recall_micro': 0.36}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 46, 'dt_min_samples_leaf': 57}",pleasant-monkey-590,DecisionTree,['pre-trained:bert-base-uncased']
741,"{'eval/precision_weighted': 0.1796825396825397, 'eval/loss': 1.5931809217507706, 'eval/f1_macro': 0.1662087912087912, 'eval/recall_macro': 0.20833333333333331, 'test/precision_micro': 0.3968253968253968, '_runtime': 1078.5445477962494, 'test/recall_micro': 0.3968253968253968, 'test/precision_macro': 0.1638888888888889, 'eval/f1_weighted': 0.21670329670329672, 'test/recall_weighted': 0.3968253968253968, '_wandb': {'runtime': 1077}, '_timestamp': 1704329120.4672668, 'test/accuracy': 0.3968253968253968, 'eval/precision_macro': 0.14087301587301587, 'eval/precision_micro': 0.28, 'eval/recall_weighted': 0.28, 'test/precision_weighted': 0.2567901234567901, 'test/loss': 1.425239344250644, 'eval/accuracy': 0.28, 'test/recall_macro': 0.2521551724137931, 'test/f1_micro': 0.3968253968253968, 'eval/recall_micro': 0.28, 'test/f1_macro': 0.19864864864864865, '_step': 20, 'split': 10, 'eval/f1_micro': 0.28, 'test/f1_weighted': 0.31179751179751175}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 37, 'dt_min_samples_leaf': 41}",splendid-bee-589,DecisionTree,['pre-trained:openai-gpt']
742,"{'eval/loss': 1.3296549549719356, 'test/recall_micro': 0.492063492063492, '_wandb': {'runtime': 994}, 'eval/f1_macro': 0.14285714285714288, '_timestamp': 1704328112.0485084, 'eval/accuracy': 0.4, 'eval/precision_weighted': 0.16, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.4, 'test/f1_macro': 0.16489361702127658, 'test/f1_micro': 0.492063492063492, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.3245525160418777, 'eval/recall_macro': 0.25, 'test/precision_weighted': 0.24212648022171832, 'split': 10, 'test/loss': 1.275518815596098, 'test/accuracy': 0.492063492063492, 'eval/precision_macro': 0.1, 'test/precision_macro': 0.123015873015873, 'eval/f1_micro': 0.4000000000000001, 'test/recall_weighted': 0.492063492063492, '_step': 20, '_runtime': 995.430855512619, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.492063492063492}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 45, 'dt_min_samples_leaf': 67}",neat-field-588,DecisionTree,['pre-trained:bert-base-uncased']
743,"{'_wandb': {'runtime': 1079}, 'eval/f1_micro': 0.52, 'test/precision_macro': 0.31528417818740395, 'test/precision_micro': 0.3492063492063492, '_timestamp': 1704328035.5668442, 'eval/recall_micro': 0.52, 'test/recall_micro': 0.3492063492063492, 'eval/recall_weighted': 0.52, 'test/precision_weighted': 0.3605686001999366, 'eval/loss': 0.9938358482416604, 'test/loss': 4.292618636724441, 'eval/accuracy': 0.52, 'eval/f1_macro': 0.4123376623376623, 'eval/recall_macro': 0.44166666666666665, '_step': 20, 'test/f1_macro': 0.28398752012882444, '_runtime': 1080.8998582363129, 'test/f1_micro': 0.3492063492063492, 'test/f1_weighted': 0.3359999233187639, 'eval/f1_weighted': 0.4872727272727272, 'split': 10, 'test/accuracy': 0.3492063492063492, 'eval/precision_macro': 0.39261363636363633, 'eval/precision_micro': 0.52, 'test/recall_weighted': 0.3492063492063492, 'test/recall_macro': 0.2996426466254053, 'eval/precision_weighted': 0.46418181818181814}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 36, 'dt_min_samples_leaf': 20}",toasty-sponge-587,DecisionTree,['pre-trained:openai-gpt']
744,"{'eval/precision_micro': 0.4, 'split': 10, 'test/loss': 1.3360556596587518, 'test/f1_macro': 0.213365539452496, 'eval/recall_weighted': 0.4, '_step': 20, 'test/accuracy': 0.42857142857142855, 'test/recall_macro': 0.2685483870967742, 'eval/precision_macro': 0.1856060606060606, 'eval/precision_weighted': 0.23030303030303031, '_wandb': {'runtime': 994}, 'eval/accuracy': 0.4, 'test/precision_weighted': 0.2728205128205128, 'test/f1_micro': 0.42857142857142855, 'eval/f1_weighted': 0.275, 'test/precision_micro': 0.42857142857142855, 'eval/f1_macro': 0.20312500000000003, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_micro': 0.4, 'eval/recall_macro': 0.275, 'test/precision_macro': 0.1776923076923077, '_timestamp': 1704327112.5363784, 'test/f1_weighted': 0.3330010479768934, 'test/recall_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, '_runtime': 995.7999475002288, 'eval/loss': 1.3697666409433995}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 44, 'dt_min_samples_leaf': 61}",swept-cloud-586,DecisionTree,['pre-trained:bert-base-uncased']
745,"{'_wandb': {'runtime': 1072}, 'eval/loss': 1.0492607230332964, 'eval/precision_weighted': 0.42476190476190473, 'split': 10, 'eval/f1_micro': 0.48, 'test/recall_macro': 0.2698754789272031, 'test/f1_weighted': 0.30598290598290595, 'test/precision_macro': 0.20833333333333331, 'test/precision_micro': 0.3492063492063492, 'eval/accuracy': 0.48, 'test/f1_macro': 0.2341880341880342, 'eval/f1_weighted': 0.42, 'eval/recall_micro': 0.48, 'eval/precision_macro': 0.3710317460317461, 'eval/precision_micro': 0.48, '_runtime': 1073.5696918964386, 'test/f1_micro': 0.3492063492063492, 'eval/recall_weighted': 0.48, 'eval/f1_macro': 0.3541666666666667, 'test/accuracy': 0.3492063492063492, 'test/recall_weighted': 0.3492063492063492, 'test/precision_weighted': 0.27336860670194, '_step': 20, 'test/loss': 3.168866057726075, '_timestamp': 1704326949.234453, 'eval/recall_macro': 0.4, 'test/recall_micro': 0.3492063492063492}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 35, 'dt_min_samples_leaf': 24}",treasured-wind-585,DecisionTree,['pre-trained:openai-gpt']
746,"{'_timestamp': 1704326111.5996408, 'eval/recall_micro': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.16489361702127658, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.3245525160418777, 'eval/recall_macro': 0.25, 'eval/precision_macro': 0.1, 'eval/f1_macro': 0.14285714285714288, 'test/precision_macro': 0.123015873015873, 'test/recall_weighted': 0.492063492063492, 'eval/precision_weighted': 0.16, 'test/precision_weighted': 0.24212648022171832, 'split': 10, '_runtime': 995.6760218143464, 'eval/loss': 1.3296549549719356, 'test/precision_micro': 0.492063492063492, '_step': 20, '_wandb': {'runtime': 994}, 'test/f1_micro': 0.492063492063492, 'eval/precision_micro': 0.4, 'test/loss': 1.275518815596098, 'eval/accuracy': 0.4, 'test/accuracy': 0.492063492063492, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.4, 'test/recall_micro': 0.492063492063492}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 43, 'dt_min_samples_leaf': 89}",toasty-haze-584,DecisionTree,['pre-trained:bert-base-uncased']
747,"{'test/f1_weighted': 0.3039871504157219, 'eval/recall_micro': 0.4, 'test/precision_macro': 0.17524509803921567, 'test/recall_macro': 0.236737400530504, 'eval/precision_micro': 0.4, '_step': 20, 'eval/f1_macro': 0.20766129032258063, 'eval/f1_micro': 0.4000000000000001, 'eval/accuracy': 0.4, '_wandb': {'runtime': 1076}, '_runtime': 1077.6850016117096, 'test/precision_weighted': 0.25918145035792095, 'split': 10, 'eval/f1_weighted': 0.292258064516129, 'eval/recall_macro': 0.26666666666666666, 'test/f1_micro': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, 'eval/loss': 1.356200976607528, 'test/loss': 1.4182881513393395, 'test/accuracy': 0.3968253968253968, 'test/f1_macro': 0.19136904761904763, 'eval/precision_macro': 0.23214285714285715, 'eval/precision_weighted': 0.2914285714285714, 'test/precision_micro': 0.3968253968253968, '_timestamp': 1704325869.6817806, 'test/recall_micro': 0.3968253968253968, 'eval/recall_weighted': 0.4}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 34, 'dt_min_samples_leaf': 14}",desert-shadow-583,DecisionTree,['pre-trained:openai-gpt']
748,"{'eval/loss': 1.3296549549719356, 'eval/f1_macro': 0.14285714285714288, 'test/f1_macro': 0.16489361702127658, 'test/precision_weighted': 0.24212648022171832, '_step': 20, '_wandb': {'runtime': 995}, 'eval/f1_weighted': 0.22857142857142865, 'test/precision_micro': 0.492063492063492, 'test/f1_weighted': 0.3245525160418777, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.492063492063492, 'test/precision_macro': 0.123015873015873, 'split': 10, '_runtime': 996.3477132320404, 'test/loss': 1.275518815596098, '_timestamp': 1704325112.4263172, 'eval/precision_weighted': 0.16, 'eval/recall_macro': 0.25, 'test/recall_weighted': 0.492063492063492, 'eval/accuracy': 0.4, 'eval/recall_weighted': 0.4, 'test/recall_macro': 0.25, 'eval/precision_micro': 0.4, 'test/f1_micro': 0.492063492063492, 'eval/precision_macro': 0.1, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.492063492063492}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 42, 'dt_min_samples_leaf': 73}",summer-music-582,DecisionTree,['pre-trained:bert-base-uncased']
749,"{'test/precision_macro': 0.4305555555555555, 'eval/precision_weighted': 0.4773333333333334, '_step': 20, 'test/loss': 9.369349900161762, '_timestamp': 1704324787.7222393, 'eval/accuracy': 0.48, 'test/f1_weighted': 0.4309654631083203, 'test/recall_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'eval/loss': 1.117280308103259, 'eval/f1_macro': 0.3588636363636364, 'test/f1_micro': 0.4603174603174603, 'split': 10, 'eval/precision_macro': 0.4083333333333333, 'eval/f1_micro': 0.48, 'test/precision_micro': 0.4603174603174603, '_wandb': {'runtime': 1069}, 'eval/recall_macro': 0.3666666666666667, 'test/f1_macro': 0.3929258241758242, 'test/recall_macro': 0.4174587385794282, 'test/precision_weighted': 0.4523809523809524, 'eval/recall_micro': 0.48, 'eval/precision_micro': 0.48, 'eval/recall_weighted': 0.48, '_runtime': 1070.6469342708588, 'test/accuracy': 0.4603174603174603, 'eval/f1_weighted': 0.44690909090909087}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 33, 'dt_min_samples_leaf': 13}",grateful-jazz-581,DecisionTree,['pre-trained:openai-gpt']
750,"{'test/f1_macro': 0.16489361702127658, '_timestamp': 1704324111.9856462, 'test/f1_weighted': 0.3245525160418777, 'test/recall_micro': 0.492063492063492, 'eval/f1_macro': 0.14285714285714288, 'test/recall_macro': 0.25, '_step': 20, 'test/f1_micro': 0.492063492063492, 'eval/recall_macro': 0.25, 'eval/precision_macro': 0.1, 'test/precision_macro': 0.123015873015873, 'test/precision_weighted': 0.24212648022171832, 'test/loss': 1.275518815596098, 'eval/loss': 1.3296549549719356, 'eval/f1_weighted': 0.22857142857142865, '_runtime': 1028.196316242218, 'test/accuracy': 0.492063492063492, 'eval/recall_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.492063492063492, 'eval/accuracy': 0.4, 'eval/precision_weighted': 0.16, '_wandb': {'runtime': 994}, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.492063492063492, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 41, 'dt_min_samples_leaf': 84}",fanciful-wildflower-580,DecisionTree,['pre-trained:bert-base-uncased']
751,"{'_wandb': {'runtime': 1074}, 'eval/f1_macro': 0.3446969696969697, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.3968253968253968, '_step': 20, 'eval/loss': 3.820213194916552, 'test/loss': 11.698633029973308, 'test/accuracy': 0.3968253968253968, 'test/recall_macro': 0.3935860595343354, 'test/precision_micro': 0.3968253968253968, 'eval/precision_macro': 0.4, 'eval/precision_weighted': 0.464, '_timestamp': 1704323713.5556917, 'eval/accuracy': 0.44, 'eval/f1_weighted': 0.4242424242424242, 'eval/recall_weighted': 0.44, 'test/f1_macro': 0.3724120082815736, 'test/precision_macro': 0.3673400673400673, 'test/recall_weighted': 0.3968253968253968, 'split': 10, '_runtime': 1075.3269526958466, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.3968253968253968, 'eval/recall_macro': 0.3416666666666667, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.3971033082144193, 'test/f1_weighted': 0.39194518387064975}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 32, 'dt_min_samples_leaf': 9}",spring-field-579,DecisionTree,['pre-trained:openai-gpt']
752,"{'_runtime': 997.2616720199584, '_timestamp': 1704323080.234261, 'eval/f1_micro': 0.36, 'eval/recall_weighted': 0.36, 'eval/precision_weighted': 0.15, 'test/recall_macro': 0.2346774193548387, 'eval/precision_micro': 0.36, '_wandb': {'runtime': 995}, 'eval/f1_macro': 0.13235294117647062, 'test/accuracy': 0.42857142857142855, 'eval/precision_macro': 0.09375, 'test/f1_micro': 0.42857142857142855, 'test/f1_weighted': 0.32647027768978987, 'test/precision_weighted': 0.26408341114223466, 'test/f1_macro': 0.18126385809312637, 'test/recall_micro': 0.42857142857142855, 'test/precision_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, '_step': 20, 'split': 10, 'eval/accuracy': 0.36, 'eval/f1_weighted': 0.21176470588235297, 'eval/recall_micro': 0.36, 'eval/loss': 1.504645062538489, 'test/loss': 1.4063049016891371, 'eval/recall_macro': 0.225, 'test/precision_macro': 0.1482843137254902}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 40, 'dt_min_samples_leaf': 39}",twilight-voice-578,DecisionTree,['pre-trained:bert-base-uncased']
753,"{'split': 10, 'test/f1_micro': 0.4603174603174603, 'test/f1_weighted': 0.4309654631083203, 'test/recall_macro': 0.4174587385794282, 'eval/f1_weighted': 0.44690909090909087, 'eval/precision_macro': 0.4083333333333333, 'eval/recall_weighted': 0.48, 'test/recall_weighted': 0.4603174603174603, '_timestamp': 1704322631.8720472, 'eval/precision_micro': 0.48, '_step': 20, 'eval/f1_micro': 0.48, 'eval/precision_weighted': 0.4773333333333334, 'test/loss': 9.37529503028509, 'eval/accuracy': 0.48, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.3929258241758242, 'test/recall_micro': 0.4603174603174603, 'test/precision_weighted': 0.4523809523809524, 'eval/f1_macro': 0.3588636363636364, 'eval/recall_micro': 0.48, 'test/precision_micro': 0.4603174603174603, 'eval/recall_macro': 0.3666666666666667, 'test/precision_macro': 0.4305555555555555, '_wandb': {'runtime': 1079}, '_runtime': 1080.2323622703552, 'eval/loss': 1.0985347456119017}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 31, 'dt_min_samples_leaf': 11}",dutiful-thunder-577,DecisionTree,['pre-trained:openai-gpt']
754,"{'_wandb': {'runtime': 1005}, '_runtime': 1007.2336254119872, 'test/recall_weighted': 0.42857142857142855, '_step': 20, '_timestamp': 1704322078.4054763, 'eval/precision_weighted': 0.15, 'split': 10, 'test/accuracy': 0.42857142857142855, 'test/f1_macro': 0.18126385809312637, 'test/precision_weighted': 0.26408341114223466, 'eval/f1_weighted': 0.21176470588235297, 'eval/recall_macro': 0.225, 'test/recall_macro': 0.2346774193548387, 'eval/precision_micro': 0.36, 'eval/recall_weighted': 0.36, 'eval/loss': 1.3988320792306457, 'test/loss': 1.346700877126801, 'eval/f1_macro': 0.13235294117647062, 'eval/f1_micro': 0.36, 'eval/precision_macro': 0.09375, 'test/f1_weighted': 0.32647027768978987, 'test/precision_macro': 0.1482843137254902, 'eval/accuracy': 0.36, 'test/f1_micro': 0.42857142857142855, 'eval/recall_micro': 0.36, 'test/recall_micro': 0.42857142857142855, 'test/precision_micro': 0.42857142857142855}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 39, 'dt_min_samples_leaf': 54}",magic-wind-576,DecisionTree,['pre-trained:bert-base-uncased']
755,"{'test/f1_micro': 0.4444444444444444, 'eval/precision_micro': 0.36, 'test/loss': 1.255336265235084, 'eval/recall_micro': 0.36, '_step': 20, '_wandb': {'runtime': 1152}, '_timestamp': 1704322007.865719, 'test/precision_micro': 0.4444444444444444, 'eval/precision_weighted': 0.2350877192982456, 'test/f1_macro': 0.24508804448563487, 'test/precision_macro': 0.3076530612244898, 'eval/loss': 1.3313302395619693, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.4444444444444444, 'eval/recall_weighted': 0.36, 'test/precision_weighted': 0.37525105280207327, 'eval/f1_macro': 0.20043103448275865, 'eval/f1_weighted': 0.27068965517241383, 'test/recall_macro': 0.2536764705882353, 'eval/precision_macro': 0.18859649122807015, 'eval/f1_micro': 0.36, 'test/accuracy': 0.4444444444444444, 'test/f1_weighted': 0.3830472071435927, 'split': 10, '_runtime': 1153.9747021198273, 'eval/accuracy': 0.36, 'test/recall_weighted': 0.4444444444444444}","{'rf_max_depth': 6, 'trial.number': 29}",soft-moon-575,RandomForest,['pre-trained:openai-gpt']
756,"{'eval/precision_micro': 0.52, '_step': 20, 'test/loss': 4.239698044209975, '_timestamp': 1704321546.1627066, 'eval/recall_micro': 0.52, 'eval/precision_macro': 0.40625, 'eval/accuracy': 0.52, 'eval/recall_macro': 0.44166666666666665, 'eval/precision_weighted': 0.47, 'eval/loss': 1.0609015412091047, 'eval/f1_macro': 0.41493506493506493, 'test/f1_micro': 0.3333333333333333, 'test/recall_macro': 0.280411877394636, 'eval/recall_weighted': 0.52, 'test/accuracy': 0.3333333333333333, 'test/f1_macro': 0.25629877369007803, 'eval/f1_weighted': 0.4856103896103896, 'test/recall_micro': 0.3333333333333333, 'test/precision_macro': 0.2379032258064516, 'test/precision_micro': 0.3333333333333333, '_wandb': {'runtime': 1095}, '_runtime': 1096.415053606033, 'test/recall_weighted': 0.3333333333333333, 'split': 10, 'eval/f1_micro': 0.52, 'test/f1_weighted': 0.31291960857178247, 'test/precision_weighted': 0.2963206788091581}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 30, 'dt_min_samples_leaf': 17}",toasty-waterfall-574,DecisionTree,['pre-trained:openai-gpt']
757,"{'_timestamp': 1704321066.7301266, 'eval/recall_micro': 0.32, '_step': 20, 'test/f1_micro': 0.3968253968253968, 'test/f1_weighted': 0.33978174603174605, 'eval/recall_macro': 0.21666666666666665, 'split': 10, '_runtime': 1008.5747385025024, 'eval/precision_macro': 0.1371527777777778, 'eval/precision_weighted': 0.2016666666666667, 'test/precision_macro': 0.19393939393939397, 'test/loss': 1.2745313625984234, 'eval/accuracy': 0.32, 'eval/f1_weighted': 0.24738461538461537, 'eval/recall_weighted': 0.32, 'eval/loss': 1.3605355632158649, 'eval/f1_micro': 0.32, 'test/accuracy': 0.3968253968253968, 'eval/f1_macro': 0.1679487179487179, 'test/recall_macro': 0.3032258064516129, 'test/precision_weighted': 0.3150553150553151, 'test/f1_macro': 0.2234375, 'test/recall_micro': 0.3968253968253968, 'test/precision_micro': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, '_wandb': {'runtime': 1007}, 'eval/precision_micro': 0.32}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 38, 'dt_min_samples_leaf': 68}",peach-sun-573,DecisionTree,['pre-trained:bert-base-uncased']
758,"{'eval/precision_macro': 0.2, 'test/precision_macro': 0.33489583333333334, 'eval/loss': 1.4334532686695851, 'test/loss': 1.8663105333970835, 'eval/f1_macro': 0.21545454545454543, 'test/f1_micro': 0.4444444444444444, 'eval/recall_micro': 0.32, 'test/recall_macro': 0.3491233031674208, '_runtime': 1153.118753194809, 'eval/recall_macro': 0.24166666666666664, 'test/recall_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'eval/precision_weighted': 0.248, '_timestamp': 1704320847.0215173, 'test/accuracy': 0.4444444444444444, 'eval/recall_weighted': 0.32, 'split': 10, '_wandb': {'runtime': 1151}, 'eval/accuracy': 0.32, 'test/precision_weighted': 0.45416666666666666, 'test/f1_macro': 0.3277140974967062, 'test/f1_weighted': 0.4417826296087166, 'eval/f1_micro': 0.32, 'eval/precision_micro': 0.32, 'test/precision_micro': 0.4444444444444444, '_step': 20, 'eval/f1_weighted': 0.2756363636363636}","{'rf_max_depth': 12, 'trial.number': 28}",decent-disco-572,RandomForest,['pre-trained:openai-gpt']
759,"{'eval/recall_weighted': 0.44, 'eval/accuracy': 0.44, 'test/recall_macro': 0.2453580901856764, '_runtime': 1095.9513111114502, 'test/accuracy': 0.4126984126984127, 'test/precision_macro': 0.1778846153846154, 'eval/recall_micro': 0.44, 'eval/precision_macro': 0.23369565217391303, 'test/recall_weighted': 0.4126984126984127, '_timestamp': 1704320444.7431371, 'eval/f1_micro': 0.44, 'eval/f1_macro': 0.21401515151515152, 'eval/f1_weighted': 0.30242424242424243, 'eval/precision_weighted': 0.29391304347826086, 'split': 10, '_wandb': {'runtime': 1094}, 'eval/recall_macro': 0.2916666666666667, 'test/precision_weighted': 0.2640415140415141, 'eval/loss': 1.3033684555426668, 'test/loss': 1.3952101088278626, 'test/precision_micro': 0.4126984126984127, '_step': 20, 'test/f1_weighted': 0.31208532795834387, 'test/recall_micro': 0.4126984126984127, 'eval/precision_micro': 0.44, 'test/f1_macro': 0.19576719576719576, 'test/f1_micro': 0.4126984126984127}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 29, 'dt_min_samples_leaf': 12}",polar-grass-571,DecisionTree,['pre-trained:openai-gpt']
760,"{'_step': 20, 'test/loss': 1.4016811299943108, 'eval/f1_weighted': 0.21176470588235297, 'eval/precision_micro': 0.36, 'test/precision_macro': 0.15253496503496505, 'test/f1_micro': 0.4444444444444444, 'test/f1_weighted': 0.33525485160597035, 'test/recall_micro': 0.4444444444444444, '_timestamp': 1704320053.4203825, 'test/f1_macro': 0.18646012621916236, 'eval/recall_weighted': 0.36, 'test/recall_weighted': 0.4444444444444444, 'test/precision_weighted': 0.26992451992451993, 'eval/accuracy': 0.36, 'eval/recall_micro': 0.36, 'split': 10, '_wandb': {'runtime': 1007}, '_runtime': 1009.1878814697266, 'eval/loss': 1.4868241913280271, 'eval/f1_macro': 0.13235294117647062, 'test/accuracy': 0.4444444444444444, 'eval/recall_macro': 0.225, 'test/recall_macro': 0.24274193548387096, 'eval/precision_weighted': 0.15, 'eval/f1_micro': 0.36, 'eval/precision_macro': 0.09375, 'test/precision_micro': 0.4444444444444444}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 37, 'dt_min_samples_leaf': 36}",astral-oath-570,DecisionTree,['pre-trained:bert-base-uncased']
761,"{'test/accuracy': 0.492063492063492, 'eval/recall_weighted': 0.36, 'test/precision_macro': 0.4220779220779221, 'split': 10, '_runtime': 1133.2574064731598, 'eval/f1_macro': 0.20370370370370372, 'eval/f1_weighted': 0.2814814814814815, 'test/recall_weighted': 0.492063492063492, 'eval/precision_weighted': 0.23823529411764707, '_wandb': {'runtime': 1131}, 'test/f1_micro': 0.492063492063492, 'test/f1_weighted': 0.4641574206791598, 'eval/precision_macro': 0.1801470588235294, 'eval/f1_micro': 0.36, '_step': 20, '_timestamp': 1704319688.0939956, 'eval/recall_micro': 0.36, 'eval/precision_micro': 0.36, 'test/precision_micro': 0.492063492063492, 'test/precision_weighted': 0.479179550608122, 'eval/loss': 1.6193462338399718, 'test/f1_macro': 0.3458751393534002, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.492063492063492, 'test/loss': 1.2692970789615596, 'eval/accuracy': 0.36, 'test/recall_macro': 0.3351244343891403}","{'rf_max_depth': 7, 'trial.number': 27}",vocal-eon-569,RandomForest,['pre-trained:openai-gpt']
762,"{'test/precision_weighted': 0.2627769056340485, 'split': 10, 'eval/recall_macro': 0.48333333333333334, 'test/recall_micro': 0.2857142857142857, 'eval/f1_macro': 0.4375, 'test/accuracy': 0.2857142857142857, 'eval/f1_weighted': 0.516, 'test/loss': 7.410275224127417, 'eval/recall_micro': 0.56, 'test/precision_micro': 0.2857142857142857, 'test/recall_weighted': 0.2857142857142857, '_wandb': {'runtime': 1094}, '_runtime': 1096.1004304885864, 'eval/precision_micro': 0.56, 'eval/recall_weighted': 0.56, 'test/precision_macro': 0.20398351648351648, 'test/f1_macro': 0.2216032608695652, 'test/f1_micro': 0.2857142857142857, 'eval/precision_macro': 0.425, 'test/recall_macro': 0.2545498084291188, '_step': 20, 'eval/loss': 2.3362566102156084, 'eval/f1_micro': 0.56, 'eval/precision_weighted': 0.504, '_timestamp': 1704319344.0692885, 'eval/accuracy': 0.56, 'test/f1_weighted': 0.2684955141476881}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 28, 'dt_min_samples_leaf': 18}",lemon-violet-568,DecisionTree,['pre-trained:openai-gpt']
763,"{'_wandb': {'runtime': 1008}, '_runtime': 1009.53715634346, 'test/recall_micro': 0.3968253968253968, 'eval/precision_micro': 0.32, 'test/precision_micro': 0.3968253968253968, 'test/recall_macro': 0.3032258064516129, 'test/recall_weighted': 0.3968253968253968, 'eval/loss': 1.3605355632158649, 'eval/f1_weighted': 0.24738461538461537, 'test/precision_weighted': 0.3150553150553151, 'eval/f1_macro': 0.1679487179487179, 'test/f1_weighted': 0.33978174603174605, 'eval/recall_macro': 0.21666666666666665, 'eval/precision_weighted': 0.2016666666666667, '_step': 20, 'split': 10, '_timestamp': 1704319038.9771163, 'test/f1_macro': 0.2234375, 'test/f1_micro': 0.3968253968253968, 'test/loss': 1.2745313625984234, 'test/accuracy': 0.3968253968253968, 'eval/recall_micro': 0.32, 'eval/recall_weighted': 0.32, 'eval/accuracy': 0.32, 'eval/f1_micro': 0.32, 'eval/precision_macro': 0.1371527777777778, 'test/precision_macro': 0.19393939393939397}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 36, 'dt_min_samples_leaf': 86}",chocolate-mountain-567,DecisionTree,['pre-trained:bert-base-uncased']
764,"{'_runtime': 1137.2833969593048, 'eval/f1_weighted': 0.3627350427350427, 'test/recall_macro': 0.30599547511312214, 'test/recall_weighted': 0.42857142857142855, 'test/precision_weighted': 0.4106375407188416, 'test/f1_micro': 0.42857142857142855, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.40086985139616726, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.42857142857142855, 'split': 10, 'eval/loss': 2.6850575411651967, 'test/loss': 1.3967618466158822, '_timestamp': 1704318549.895658, 'test/accuracy': 0.42857142857142855, '_step': 20, 'test/precision_micro': 0.42857142857142855, 'eval/precision_weighted': 0.34, '_wandb': {'runtime': 1135}, 'test/precision_macro': 0.3551059374230106, 'eval/f1_macro': 0.31303418803418803, 'test/f1_macro': 0.298341307814992, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.33333333333333337, 'eval/precision_macro': 0.30357142857142855}","{'rf_max_depth': 10, 'trial.number': 26}",proud-puddle-566,RandomForest,['pre-trained:openai-gpt']
765,"{'test/loss': 1.9405482044194855, 'eval/f1_macro': 0.3686868686868687, 'eval/recall_macro': 0.4333333333333333, 'eval/accuracy': 0.48, 'eval/f1_micro': 0.48, 'eval/recall_weighted': 0.48, 'test/precision_macro': 0.2602124183006536, 'test/f1_weighted': 0.3065024809705661, 'test/recall_macro': 0.3431513409961686, 'test/precision_micro': 0.3333333333333333, 'eval/precision_weighted': 0.416, 'test/accuracy': 0.3333333333333333, 'eval/precision_micro': 0.48, 'test/recall_weighted': 0.3333333333333333, '_step': 20, 'eval/loss': 0.9892031650021578, 'eval/recall_micro': 0.48, 'eval/precision_macro': 0.35, 'test/f1_micro': 0.3333333333333333, 'test/precision_weighted': 0.3369644153957879, '_wandb': {'runtime': 1093}, '_timestamp': 1704318243.899396, 'eval/f1_weighted': 0.42505050505050507, 'split': 10, '_runtime': 1094.7892580032349, 'test/f1_macro': 0.2708060556464812, 'test/recall_micro': 0.3333333333333333}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 27, 'dt_min_samples_leaf': 25}",autumn-cosmos-565,DecisionTree,['pre-trained:openai-gpt']
766,"{'_step': 20, 'split': 10, 'test/f1_macro': 0.18646012621916236, 'test/recall_macro': 0.24274193548387096, 'test/precision_weighted': 0.26992451992451993, 'eval/f1_macro': 0.13235294117647062, 'eval/f1_micro': 0.36, 'eval/precision_weighted': 0.15, 'test/recall_micro': 0.4444444444444444, '_runtime': 1008.9587061405182, 'eval/loss': 1.3942088217790265, 'eval/accuracy': 0.36, 'eval/recall_macro': 0.225, 'eval/recall_micro': 0.36, 'test/precision_macro': 0.15253496503496505, '_timestamp': 1704318023.845097, 'test/accuracy': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, 'test/f1_weighted': 0.33525485160597035, 'eval/precision_macro': 0.09375, '_wandb': {'runtime': 1007}, 'eval/f1_weighted': 0.21176470588235297, 'eval/precision_micro': 0.36, 'eval/recall_weighted': 0.36, 'test/loss': 1.3771162034244453, 'test/precision_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 35, 'dt_min_samples_leaf': 43}",mild-butterfly-564,DecisionTree,['pre-trained:bert-base-uncased']
767,"{'test/f1_micro': 0.5714285714285714, 'test/recall_micro': 0.5714285714285714, '_step': 20, 'split': 10, 'eval/accuracy': 0.52, 'eval/recall_weighted': 0.52, '_wandb': {'runtime': 1149}, 'test/accuracy': 0.5714285714285714, 'eval/precision_weighted': 0.485, '_timestamp': 1704317406.6440392, 'eval/f1_macro': 0.4250610500610501, 'eval/f1_micro': 0.52, 'test/f1_macro': 0.47296956972400944, 'test/precision_weighted': 0.5806861806861806, 'test/recall_weighted': 0.5714285714285714, '_runtime': 1150.7049672603607, 'eval/f1_weighted': 0.46739926739926746, 'test/f1_weighted': 0.5584764416012776, 'eval/recall_macro': 0.44166666666666665, 'eval/recall_micro': 0.52, 'test/loss': 1.1632407610312696, 'eval/loss': 1.404281563220936, 'test/recall_macro': 0.4794966063348417, 'eval/precision_macro': 0.4739583333333333, 'test/precision_micro': 0.5714285714285714, 'eval/precision_micro': 0.52, 'test/precision_macro': 0.5317394317394317}","{'rf_max_depth': 10, 'trial.number': 25}",colorful-lake-563,RandomForest,['pre-trained:openai-gpt']
768,"{'eval/recall_macro': 0.35833333333333334, 'eval/f1_weighted': 0.3965714285714285, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.2305850279988211, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_macro': 0.3678571428571428, 'test/f1_weighted': 0.2857142857142857, 'test/recall_weighted': 0.2857142857142857, '_timestamp': 1704317144.531683, 'test/loss': 4.720814488780755, 'eval/accuracy': 0.4, 'eval/precision_macro': 0.3863636363636363, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.2857142857142857, 'eval/precision_weighted': 0.39818181818181814, '_step': 20, 'test/recall_macro': 0.2305850279988211, 'test/recall_micro': 0.2857142857142857, 'test/accuracy': 0.2857142857142857, '_wandb': {'runtime': 1092}, 'test/precision_weighted': 0.2857142857142857, 'split': 10, 'test/f1_micro': 0.2857142857142857, '_runtime': 1093.3287620544434, 'test/f1_macro': 0.2305850279988211, 'eval/recall_micro': 0.4, 'eval/loss': 2.6318096106283377}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 26, 'dt_min_samples_leaf': 14}",crisp-elevator-562,DecisionTree,['pre-trained:openai-gpt']
769,"{'_wandb': {'runtime': 1008}, 'eval/loss': 1.3151788352023233, 'test/loss': 2.55736250151603, 'test/f1_macro': 0.18509984639016897, 'eval/recall_macro': 0.20833333333333331, 'eval/recall_micro': 0.28, 'test/recall_micro': 0.30158730158730157, '_timestamp': 1704317009.3906116, 'eval/f1_weighted': 0.2224175824175824, 'eval/precision_micro': 0.28, 'test/precision_micro': 0.30158730158730157, 'test/f1_micro': 0.30158730158730157, 'test/recall_macro': 0.2040322580645161, 'eval/precision_macro': 0.140625, 'test/precision_macro': 0.17556905460131267, 'test/recall_weighted': 0.30158730158730157, 'eval/f1_macro': 0.1675824175824176, 'eval/f1_micro': 0.28, 'test/f1_weighted': 0.28956672274644624, 'test/accuracy': 0.30158730158730157, 'test/precision_weighted': 0.28351542637256927, '_step': 20, '_runtime': 1009.4253115653992, 'eval/accuracy': 0.28, 'eval/recall_weighted': 0.28, 'split': 10, 'eval/precision_weighted': 0.185}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 34, 'dt_min_samples_leaf': 30}",volcanic-voice-561,DecisionTree,['pre-trained:bert-base-uncased']
770,"{'test/precision_micro': 0.5079365079365079, 'test/precision_weighted': 0.4437977660199882, 'split': 10, '_timestamp': 1704316250.151724, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.25806451612903225, 'test/recall_micro': 0.5079365079365079, 'eval/recall_macro': 0.25, 'test/precision_macro': 0.3592592592592593, 'eval/loss': 1.3127107026584954, 'test/loss': 1.2908490662808911, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.2949660633484163, 'test/recall_weighted': 0.5079365079365079, '_runtime': 1149.0116517543793, 'eval/f1_macro': 0.16129032258064516, 'test/accuracy': 0.5079365079365079, 'eval/precision_macro': 0.11904761904761904, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.4222851222851222, 'eval/precision_micro': 0.4, 'eval/precision_weighted': 0.1904761904761905, '_step': 20, '_wandb': {'runtime': 1147}, 'test/f1_macro': 0.27502913752913755, 'test/f1_micro': 0.5079365079365079, 'eval/recall_weighted': 0.4}","{'rf_max_depth': 4, 'trial.number': 24}",charmed-plant-560,RandomForest,['pre-trained:openai-gpt']
771,"{'test/loss': 1.2745313625984234, 'eval/f1_micro': 0.32, 'test/f1_weighted': 0.33978174603174605, 'test/precision_macro': 0.19393939393939397, 'eval/f1_weighted': 0.24738461538461537, 'eval/recall_macro': 0.21666666666666665, 'test/recall_macro': 0.3032258064516129, 'test/precision_micro': 0.3968253968253968, 'eval/precision_weighted': 0.2016666666666667, '_runtime': 1009.036813735962, '_timestamp': 1704315995.1450176, 'eval/f1_macro': 0.1679487179487179, '_wandb': {'runtime': 1007}, 'eval/accuracy': 0.32, '_step': 20, 'test/recall_micro': 0.3968253968253968, 'eval/precision_micro': 0.32, 'eval/recall_weighted': 0.32, 'test/f1_micro': 0.3968253968253968, 'eval/recall_micro': 0.32, 'eval/precision_macro': 0.1371527777777778, 'test/precision_weighted': 0.3150553150553151, 'test/accuracy': 0.3968253968253968, 'test/f1_macro': 0.2234375, 'test/recall_weighted': 0.3968253968253968, 'split': 10, 'eval/loss': 1.3605355632158649}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 33, 'dt_min_samples_leaf': 85}",crisp-snowball-559,DecisionTree,['pre-trained:bert-base-uncased']
772,"{'test/loss': 1.9452566482131808, 'test/f1_micro': 0.4444444444444444, 'eval/f1_micro': 0.4000000000000001, 'split': 10, 'eval/f1_macro': 0.14285714285714288, 'test/precision_macro': 0.11475409836065574, '_step': 20, 'eval/precision_micro': 0.4, 'eval/loss': 1.159746845488376, 'test/accuracy': 0.4444444444444444, '_wandb': {'runtime': 1094}, '_runtime': 1095.7688491344452, 'test/f1_weighted': 0.28641975308641976, 'eval/recall_micro': 0.4, 'eval/accuracy': 0.4, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.4444444444444444, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.16, '_timestamp': 1704316047.1076052, 'test/f1_macro': 0.15555555555555556, 'test/precision_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'test/precision_weighted': 0.21129326047358837, 'test/recall_macro': 0.2413793103448276, 'eval/precision_macro': 0.1}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 25, 'dt_min_samples_leaf': 10}",lyric-dragon-558,DecisionTree,['pre-trained:openai-gpt']
773,"{'split': 10, 'eval/f1_micro': 0.32, 'eval/recall_micro': 0.32, 'test/recall_micro': 0.3968253968253968, 'eval/recall_weighted': 0.32, 'eval/precision_weighted': 0.2016666666666667, '_runtime': 1008.691038131714, 'test/accuracy': 0.3968253968253968, 'test/f1_macro': 0.2234375, 'eval/recall_macro': 0.21666666666666665, 'test/loss': 1.2745313625984234, '_timestamp': 1704314980.9812162, 'eval/accuracy': 0.32, 'test/recall_macro': 0.3032258064516129, 'test/recall_weighted': 0.3968253968253968, 'test/precision_weighted': 0.3150553150553151, 'eval/loss': 1.3605355632158649, 'test/f1_micro': 0.3968253968253968, 'eval/precision_micro': 0.32, 'test/precision_macro': 0.19393939393939397, 'test/f1_weighted': 0.33978174603174605, 'eval/precision_macro': 0.1371527777777778, 'test/precision_micro': 0.3968253968253968, '_step': 20, '_wandb': {'runtime': 1007}, 'eval/f1_macro': 0.1679487179487179, 'eval/f1_weighted': 0.24738461538461537}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 32, 'dt_min_samples_leaf': 63}",revived-waterfall-557,DecisionTree,['pre-trained:bert-base-uncased']
774,"{'test/accuracy': 0.5079365079365079, 'test/f1_micro': 0.5079365079365079, 'test/precision_micro': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, '_step': 20, 'eval/accuracy': 0.44, 'test/precision_weighted': 0.3347813979392927, '_wandb': {'runtime': 1147}, 'eval/recall_weighted': 0.44, 'eval/f1_weighted': 0.3019607843137255, 'eval/recall_macro': 0.3, 'test/recall_micro': 0.5079365079365079, 'eval/precision_macro': 0.3541666666666667, '_timestamp': 1704315096.807443, 'eval/f1_macro': 0.2303921568627451, 'split': 10, 'eval/precision_weighted': 0.3666666666666667, 'test/f1_macro': 0.19810744810744813, 'eval/recall_micro': 0.44, 'eval/precision_micro': 0.44, '_runtime': 1148.581378698349, 'eval/loss': 1.3500475037533213, 'eval/f1_micro': 0.44, 'test/recall_macro': 0.24717194570135748, 'test/precision_macro': 0.18596491228070175, 'test/loss': 1.265149170206296, 'test/f1_weighted': 0.3906234858615811}","{'rf_max_depth': 2, 'trial.number': 23}",helpful-snow-556,RandomForest,['pre-trained:openai-gpt']
775,"{'_timestamp': 1704314947.2806344, 'test/precision_weighted': 0.4523809523809524, '_wandb': {'runtime': 1093}, 'eval/recall_micro': 0.48, 'test/precision_macro': 0.4305555555555555, 'eval/accuracy': 0.48, 'eval/recall_macro': 0.3666666666666667, 'test/recall_macro': 0.4174587385794282, 'eval/recall_weighted': 0.48, 'eval/f1_macro': 0.3588636363636364, 'eval/f1_micro': 0.48, 'test/recall_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, '_runtime': 1094.8304843902588, 'eval/loss': 1.1112728948566426, 'test/accuracy': 0.4603174603174603, 'eval/precision_macro': 0.4083333333333333, 'eval/precision_weighted': 0.4773333333333334, 'test/loss': 9.37529503028509, 'test/f1_macro': 0.3929258241758242, 'test/f1_weighted': 0.4309654631083203, 'eval/precision_micro': 0.48, '_step': 20, 'split': 10, 'test/f1_micro': 0.4603174603174603, 'eval/f1_weighted': 0.44690909090909087, 'test/precision_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 24, 'dt_min_samples_leaf': 11}",feasible-totem-555,DecisionTree,['pre-trained:openai-gpt']
776,"{'eval/accuracy': 0.28, 'test/accuracy': 0.492063492063492, 'eval/f1_weighted': 0.19310344827586207, 'test/precision_macro': 0.21568627450980393, 'eval/loss': 1.4342635304745612, 'eval/recall_micro': 0.28, '_step': 20, 'eval/recall_weighted': 0.28, 'eval/f1_macro': 0.12068965517241378, 'eval/f1_micro': 0.28, 'test/f1_micro': 0.492063492063492, 'eval/precision_macro': 0.09210526315789472, 'eval/precision_weighted': 0.14736842105263157, '_wandb': {'runtime': 1007}, '_runtime': 1008.9570877552032, 'test/recall_micro': 0.492063492063492, 'test/precision_micro': 0.492063492063492, 'split': 10, 'test/loss': 1.2659004575108088, 'test/recall_weighted': 0.492063492063492, 'test/f1_macro': 0.25554323725055433, 'test/f1_weighted': 0.3817618695667476, 'test/recall_macro': 0.317741935483871, '_timestamp': 1704313967.4001737, 'eval/recall_macro': 0.175, 'eval/precision_micro': 0.28, 'test/precision_weighted': 0.31341425459072514}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 31, 'dt_min_samples_leaf': 60}",silvery-snow-554,DecisionTree,['pre-trained:bert-base-uncased']
777,"{'eval/f1_macro': 0.14516129032258063, 'test/f1_weighted': 0.4500326972237085, 'eval/recall_weighted': 0.36, 'test/precision_weighted': 0.5025974025974026, 'test/recall_micro': 0.5396825396825397, 'test/precision_macro': 0.4534090909090909, 'test/recall_weighted': 0.5396825396825397, 'test/accuracy': 0.5396825396825397, 'eval/recall_macro': 0.225, 'test/precision_micro': 0.5396825396825397, 'test/loss': 1.2646460726995683, 'test/f1_macro': 0.2991573033707865, 'test/f1_micro': 0.5396825396825397, 'eval/precision_macro': 0.10714285714285714, 'split': 10, 'eval/accuracy': 0.36, 'eval/f1_micro': 0.36, 'eval/recall_micro': 0.36, 'eval/precision_micro': 0.36, 'eval/precision_weighted': 0.17142857142857143, '_wandb': {'runtime': 1153}, '_runtime': 1155.069907665253, '_timestamp': 1704313943.3824255, 'eval/f1_weighted': 0.232258064516129, 'test/recall_macro': 0.3096719457013574, '_step': 20, 'eval/loss': 1.298151957564201}","{'rf_max_depth': 3, 'trial.number': 22}",pleasant-plasma-553,RandomForest,['pre-trained:openai-gpt']
778,"{'test/recall_macro': 0.3397988505747126, '_runtime': 1091.4619228839874, '_timestamp': 1704313848.0119998, 'eval/accuracy': 0.52, 'eval/precision_macro': 0.4471590909090909, 'eval/precision_weighted': 0.5572727272727273, 'split': 10, 'test/accuracy': 0.30158730158730157, 'eval/f1_weighted': 0.497703081232493, 'eval/recall_micro': 0.52, 'eval/recall_weighted': 0.52, 'test/recall_weighted': 0.30158730158730157, 'test/f1_weighted': 0.287717616405189, 'test/precision_macro': 0.28405448717948717, 'test/precision_weighted': 0.37355006105006106, 'test/precision_micro': 0.30158730158730157, 'eval/loss': 0.9718240138249692, 'eval/f1_macro': 0.42955182072829134, 'eval/f1_micro': 0.52, 'test/f1_macro': 0.26100141953800493, '_step': 20, '_wandb': {'runtime': 1090}, 'test/loss': 4.055234718918359, 'test/f1_micro': 0.30158730158730157, 'eval/recall_macro': 0.475, 'test/recall_micro': 0.30158730158730157, 'eval/precision_micro': 0.52}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 23, 'dt_min_samples_leaf': 19}",grateful-wave-552,DecisionTree,['pre-trained:openai-gpt']
779,"{'_step': 20, '_wandb': {'runtime': 1007}, '_runtime': 1009.122757434845, 'test/precision_macro': 0.1482843137254902, 'eval/recall_micro': 0.36, 'test/precision_weighted': 0.26408341114223466, 'test/f1_weighted': 0.32647027768978987, 'eval/precision_micro': 0.36, 'split': 10, 'eval/loss': 1.4052382064019215, 'eval/f1_macro': 0.13235294117647062, 'eval/f1_micro': 0.36, '_timestamp': 1704312953.6631284, 'test/recall_macro': 0.2346774193548387, 'eval/recall_weighted': 0.36, 'test/accuracy': 0.42857142857142855, 'test/f1_macro': 0.18126385809312637, 'test/f1_micro': 0.42857142857142855, 'test/precision_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, 'test/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.09375, 'eval/precision_weighted': 0.15, 'test/loss': 1.3744519401761877, 'eval/accuracy': 0.36, 'eval/f1_weighted': 0.21176470588235297, 'eval/recall_macro': 0.225}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 30, 'dt_min_samples_leaf': 46}",expert-yogurt-551,DecisionTree,['pre-trained:bert-base-uncased']
780,"{'split': 10, 'eval/f1_macro': 0.3446969696969697, 'test/recall_micro': 0.4126984126984127, 'test/recall_weighted': 0.4126984126984127, 'test/precision_macro': 0.392911877394636, '_step': 20, 'eval/accuracy': 0.44, 'test/accuracy': 0.4126984126984127, 'eval/recall_micro': 0.44, '_timestamp': 1704312750.7531967, 'eval/f1_weighted': 0.4242424242424242, 'test/recall_macro': 0.40220674918950783, 'eval/precision_weighted': 0.464, 'test/f1_weighted': 0.4083357980873509, 'eval/recall_macro': 0.3416666666666667, 'eval/precision_macro': 0.4, '_runtime': 1096.1353507041931, 'test/f1_micro': 0.4126984126984127, 'test/precision_weighted': 0.416931216931217, 'eval/loss': 1.1977611916868312, 'test/f1_macro': 0.3873822017562647, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, '_wandb': {'runtime': 1094}, 'test/loss': 9.5478145871194, 'eval/f1_micro': 0.44, 'test/precision_micro': 0.4126984126984127}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 22, 'dt_min_samples_leaf': 12}",firm-planet-550,DecisionTree,['pre-trained:openai-gpt']
781,"{'eval/f1_macro': 0.14285714285714288, 'test/recall_weighted': 0.5396825396825397, 'test/f1_weighted': 0.42430448882061783, 'test/precision_macro': 0.385593220338983, '_step': 20, 'test/f1_micro': 0.5396825396825397, '_timestamp': 1704312784.7900488, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.28577488687782804, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.5396825396825397, 'eval/precision_macro': 0.1, 'eval/loss': 1.3265135812903175, 'eval/precision_weighted': 0.16, 'test/loss': 1.218399647190931, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_micro': 0.5396825396825397, 'test/precision_micro': 0.5396825396825397, 'test/precision_weighted': 0.45937584073177296, 'split': 10, '_wandb': {'runtime': 1144}, '_runtime': 1145.393888950348, 'test/f1_macro': 0.2553763440860215, 'eval/recall_macro': 0.25, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4}","{'rf_max_depth': 2, 'trial.number': 21}",peach-firefly-549,RandomForest,['pre-trained:openai-gpt']
782,"{'test/recall_micro': 0.2857142857142857, 'test/recall_weighted': 0.2857142857142857, '_runtime': 1013.0524299144744, 'test/accuracy': 0.2857142857142857, 'test/precision_weighted': 0.2748917748917749, 'eval/recall_macro': 0.20833333333333331, 'eval/precision_micro': 0.28, 'test/f1_weighted': 0.2769568665353209, 'test/precision_micro': 0.2857142857142857, 'eval/precision_weighted': 0.185, 'test/f1_micro': 0.2857142857142857, 'eval/f1_weighted': 0.2224175824175824, 'eval/precision_macro': 0.140625, 'eval/recall_weighted': 0.28, '_step': 20, 'split': 10, 'test/precision_macro': 0.17045454545454547, '_timestamp': 1704311940.731709, 'eval/f1_macro': 0.1675824175824176, 'eval/f1_micro': 0.28, 'test/f1_macro': 0.17801034348165495, 'test/recall_macro': 0.19596774193548383, '_wandb': {'runtime': 1011}, 'test/loss': 2.54606442471111, 'eval/recall_micro': 0.28, 'eval/loss': 1.354113203969257, 'eval/accuracy': 0.28}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 29, 'dt_min_samples_leaf': 32}",lunar-salad-548,DecisionTree,['pre-trained:bert-base-uncased']
783,"{'_timestamp': 1704311629.224339, 'eval/recall_weighted': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_weighted': 0.3014625977588941, 'test/recall_micro': 0.3968253968253968, 'test/precision_macro': 0.20849056603773583, 'test/precision_micro': 0.3968253968253968, '_step': 20, 'split': 10, 'eval/loss': 1.3528901556729018, 'eval/f1_macro': 0.20071684587813615, 'eval/f1_weighted': 0.2855913978494623, '_runtime': 1001.3258340358734, 'test/f1_macro': 0.18742985409652077, 'test/f1_micro': 0.3968253968253968, 'test/loss': 1.3091900302969135, 'eval/recall_macro': 0.26666666666666666, 'test/recall_macro': 0.2347689075630252, 'eval/precision_weighted': 0.25142857142857145, '_wandb': {'runtime': 999}, 'test/accuracy': 0.3968253968253968, 'test/precision_weighted': 0.3008086253369272, 'eval/accuracy': 0.4, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1904761904761905, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.3968253968253968}","{'rf_max_depth': 4, 'trial.number': 29}",fluent-valley-547,RandomForest,['pre-trained:bert-base-uncased']
784,"{'test/recall_macro': 0.4174587385794282, 'test/f1_weighted': 0.4309654631083203, 'eval/recall_micro': 0.48, '_runtime': 1103.2946107387545, '_timestamp': 1704311651.0083387, 'eval/accuracy': 0.48, 'eval/recall_weighted': 0.48, 'test/recall_weighted': 0.4603174603174603, 'split': 10, '_wandb': {'runtime': 1102}, 'eval/precision_weighted': 0.4773333333333334, 'eval/f1_weighted': 0.44690909090909087, 'eval/precision_micro': 0.48, 'test/precision_macro': 0.4305555555555555, 'test/recall_micro': 0.4603174603174603, 'test/loss': 9.37529503028509, 'test/accuracy': 0.4603174603174603, 'test/precision_weighted': 0.4523809523809524, '_step': 20, 'eval/loss': 1.0985347456119017, 'eval/precision_macro': 0.4083333333333333, 'test/f1_macro': 0.3929258241758242, 'eval/recall_macro': 0.3666666666666667, 'test/f1_micro': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, 'eval/f1_macro': 0.3588636363636364, 'eval/f1_micro': 0.48}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 21, 'dt_min_samples_leaf': 11}",hopeful-leaf-546,DecisionTree,['pre-trained:openai-gpt']
785,"{'test/f1_weighted': 0.3674434312732185, 'test/recall_weighted': 0.5079365079365079, '_step': 20, 'eval/accuracy': 0.44, 'test/precision_micro': 0.5079365079365079, 'split': 10, 'eval/recall_weighted': 0.44, 'eval/f1_macro': 0.22767857142857145, 'test/precision_weighted': 0.2878306878306878, 'eval/f1_weighted': 0.30714285714285716, 'test/precision_macro': 0.13333333333333333, 'eval/loss': 1.3127714060311797, 'test/loss': 1.252122040484297, 'test/f1_micro': 0.5079365079365079, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.5079365079365079, '_runtime': 1156.3936166763306, 'test/f1_macro': 0.1702127659574468, 'eval/f1_micro': 0.44, 'eval/precision_macro': 0.23863636363636365, 'eval/recall_macro': 0.3, '_timestamp': 1704311634.907729, 'test/accuracy': 0.5079365079365079, 'eval/precision_micro': 0.44, 'eval/precision_weighted': 0.2818181818181818, '_wandb': {'runtime': 1155}, 'test/recall_macro': 0.2352941176470588}","{'rf_max_depth': 2, 'trial.number': 20}",super-field-545,RandomForest,['pre-trained:openai-gpt']
786,"{'_timestamp': 1704310924.3082695, 'test/precision_micro': 0.4444444444444444, 'split': 10, 'eval/f1_weighted': 0.21176470588235297, 'eval/recall_macro': 0.225, 'test/recall_macro': 0.24274193548387096, 'test/precision_macro': 0.15253496503496505, '_step': 20, 'test/loss': 1.386505578650803, 'eval/precision_macro': 0.09375, 'eval/accuracy': 0.36, 'eval/f1_macro': 0.13235294117647062, 'eval/f1_micro': 0.36, 'test/accuracy': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, 'test/recall_micro': 0.4444444444444444, 'eval/precision_micro': 0.36, 'eval/recall_weighted': 0.36, 'test/f1_macro': 0.18646012621916236, 'test/recall_weighted': 0.4444444444444444, 'eval/loss': 1.3911535509349091, '_runtime': 1015.4678015708924, 'test/f1_weighted': 0.33525485160597035, '_wandb': {'runtime': 1014}, 'eval/recall_micro': 0.36, 'eval/precision_weighted': 0.15, 'test/precision_weighted': 0.26992451992451993}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 28, 'dt_min_samples_leaf': 52}",young-sky-544,DecisionTree,['pre-trained:bert-base-uncased']
787,"{'eval/f1_micro': 0.44, 'eval/recall_micro': 0.44, 'test/recall_weighted': 0.31746031746031744, 'eval/loss': 1.3271185591073045, 'eval/recall_macro': 0.30833333333333335, 'eval/precision_macro': 0.2738095238095238, '_timestamp': 1704310623.3953755, 'test/f1_macro': 0.1642857142857143, 'test/precision_micro': 0.31746031746031744, 'eval/precision_weighted': 0.3314285714285714, '_step': 20, 'split': 10, '_wandb': {'runtime': 1002}, 'test/accuracy': 0.31746031746031744, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/recall_macro': 0.21071428571428577, 'test/recall_micro': 0.31746031746031744, 'test/loss': 1.428995643376524, 'eval/accuracy': 0.44, 'test/f1_micro': 0.31746031746031744, 'eval/f1_weighted': 0.3389247311827957, 'test/f1_weighted': 0.25124716553287985, '_runtime': 1003.3213348388672, 'eval/f1_macro': 0.25627240143369173, 'test/precision_weighted': 0.20811287477954143, 'test/precision_macro': 0.1349206349206349}","{'rf_max_depth': 6, 'trial.number': 28}",radiant-voice-543,RandomForest,['pre-trained:bert-base-uncased']
788,"{'test/recall_weighted': 0.4603174603174603, '_step': 20, 'split': 10, '_wandb': {'runtime': 1104}, 'eval/recall_micro': 0.48, 'test/recall_macro': 0.4174587385794282, 'eval/accuracy': 0.48, 'test/precision_micro': 0.4603174603174603, 'test/f1_weighted': 0.4309654631083203, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.4083333333333333, '_timestamp': 1704310543.6165411, 'test/f1_macro': 0.3929258241758242, 'test/f1_micro': 0.4603174603174603, 'eval/f1_weighted': 0.44690909090909087, 'eval/recall_macro': 0.3666666666666667, 'eval/recall_weighted': 0.48, 'test/loss': 9.380349851413955, 'eval/f1_macro': 0.3588636363636364, 'test/precision_macro': 0.4305555555555555, 'eval/precision_weighted': 0.4773333333333334, 'test/accuracy': 0.4603174603174603, 'eval/precision_micro': 0.48, '_runtime': 1105.7539820671082, 'eval/loss': 1.1112728948566428, 'eval/f1_micro': 0.48, 'test/precision_weighted': 0.4523809523809524}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 20, 'dt_min_samples_leaf': 11}",still-energy-542,DecisionTree,['pre-trained:openai-gpt']
789,"{'_timestamp': 1704310472.889351, 'eval/f1_macro': 0.17916666666666667, 'eval/recall_micro': 0.32, 'test/recall_micro': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, 'eval/recall_macro': 0.21666666666666665, '_runtime': 1158.326654672623, 'eval/loss': 1.4297439729212034, 'test/f1_weighted': 0.37013207191045766, 'eval/precision_macro': 0.2125, 'eval/precision_micro': 0.32, '_wandb': {'runtime': 1156}, 'eval/accuracy': 0.32, 'eval/f1_weighted': 0.24666666666666667, 'eval/recall_weighted': 0.32, 'eval/precision_weighted': 0.26, '_step': 20, 'test/recall_macro': 0.2416572398190045, 'test/loss': 1.324615285338996, 'test/accuracy': 0.4444444444444444, 'split': 10, 'eval/f1_micro': 0.32, 'test/f1_macro': 0.21903609386509523, 'test/precision_weighted': 0.34682539682539687, 'test/precision_macro': 0.2375, 'test/precision_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444}","{'rf_max_depth': 6, 'trial.number': 19}",still-fog-541,RandomForest,['pre-trained:openai-gpt']
790,"{'eval/accuracy': 0.4, 'test/recall_micro': 0.492063492063492, '_step': 20, 'split': 10, '_timestamp': 1704309904.9797575, 'test/loss': 1.275518815596098, 'eval/recall_micro': 0.4, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.16, 'test/f1_micro': 0.492063492063492, 'eval/recall_macro': 0.25, 'test/recall_weighted': 0.492063492063492, 'test/accuracy': 0.492063492063492, 'test/f1_weighted': 0.3245525160418777, 'eval/precision_micro': 0.4, '_wandb': {'runtime': 1017}, '_runtime': 1019.048716545105, 'eval/precision_macro': 0.1, 'test/precision_micro': 0.492063492063492, 'eval/f1_macro': 0.14285714285714288, 'test/recall_macro': 0.25, 'test/precision_macro': 0.123015873015873, 'eval/loss': 1.3296549549719356, 'test/f1_macro': 0.16489361702127658, 'test/precision_weighted': 0.24212648022171832}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 27, 'dt_min_samples_leaf': 72}",pious-firebrand-540,DecisionTree,['pre-trained:bert-base-uncased']
791,"{'eval/recall_weighted': 0.4, 'eval/precision_macro': 0.10416666666666669, '_wandb': {'runtime': 1006}, 'test/f1_macro': 0.15060240963855423, 'test/f1_weighted': 0.2677376171352075, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.202020202020202, '_step': 20, 'test/accuracy': 0.3968253968253968, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.3968253968253968, 'test/loss': 1.3310768371755326, 'eval/accuracy': 0.4, '_runtime': 1007.4292078018188, 'eval/f1_macro': 0.14705882352941177, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.3968253968253968, 'eval/f1_weighted': 0.23529411764705885, 'test/precision_macro': 0.11363636363636365, 'eval/precision_weighted': 0.16666666666666669, 'split': 10, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.22321428571428573, 'test/precision_micro': 0.3968253968253968, 'eval/loss': 1.3599382809416272, 'test/recall_weighted': 0.3968253968253968, '_timestamp': 1704309616.2421288}","{'rf_max_depth': 3, 'trial.number': 27}",charmed-cloud-539,RandomForest,['pre-trained:bert-base-uncased']
792,"{'eval/precision_weighted': 0.5133333333333333, 'test/f1_micro': 0.380952380952381, 'eval/f1_micro': 0.48, 'eval/recall_macro': 0.3833333333333333, 'test/recall_micro': 0.380952380952381, 'test/loss': 12.71864645538682, 'eval/f1_macro': 0.3952020202020202, 'test/f1_macro': 0.3527639751552796, '_timestamp': 1704309433.2709494, 'eval/f1_weighted': 0.48121212121212126, 'eval/recall_micro': 0.48, 'eval/loss': 7.802062092963455, 'eval/accuracy': 0.48, 'test/precision_macro': 0.3548004626951995, 'test/precision_micro': 0.380952380952381, '_wandb': {'runtime': 1109}, '_runtime': 1111.345886468887, 'test/f1_weighted': 0.38405008380163663, 'test/recall_macro': 0.38496536987916297, 'eval/precision_macro': 0.4375, 'eval/precision_micro': 0.48, 'test/precision_weighted': 0.415162448245155, '_step': 20, 'test/recall_weighted': 0.380952380952381, 'test/accuracy': 0.380952380952381, 'eval/recall_weighted': 0.48, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 19, 'dt_min_samples_leaf': 9}",stilted-wood-538,DecisionTree,['pre-trained:openai-gpt']
793,"{'_runtime': 1164.7067198753357, 'eval/f1_weighted': 0.27825174825174825, 'eval/recall_micro': 0.32, 'split': 10, '_wandb': {'runtime': 1163}, 'test/f1_weighted': 0.4509479717813051, 'test/recall_micro': 0.4444444444444444, 'eval/recall_weighted': 0.32, 'test/loss': 1.2336670997142103, 'eval/f1_macro': 0.22333916083916083, 'test/precision_micro': 0.4444444444444444, 'eval/f1_micro': 0.32, 'test/f1_macro': 0.37065972222222227, 'eval/recall_macro': 0.24166666666666664, 'test/precision_macro': 0.3721611721611721, 'test/recall_weighted': 0.4444444444444444, '_step': 20, '_timestamp': 1704309309.365603, 'test/f1_micro': 0.4444444444444444, 'eval/precision_micro': 0.32, 'eval/precision_weighted': 0.26466666666666666, 'test/precision_weighted': 0.46741671027385306, 'eval/loss': 1.4558063511628136, 'test/accuracy': 0.4444444444444444, 'eval/precision_macro': 0.2270833333333333, 'eval/accuracy': 0.32, 'test/recall_macro': 0.3848981900452489}","{'rf_max_depth': 9, 'trial.number': 18}",fallen-capybara-537,RandomForest,['pre-trained:openai-gpt']
794,"{'_step': 20, 'eval/f1_micro': 0.36, 'test/f1_weighted': 0.33525485160597035, 'test/precision_micro': 0.4444444444444444, 'split': 10, 'test/accuracy': 0.4444444444444444, 'eval/precision_weighted': 0.15, '_wandb': {'runtime': 1013}, 'eval/loss': 1.4156583262680966, '_timestamp': 1704308881.6703627, 'eval/accuracy': 0.36, 'eval/precision_macro': 0.09375, '_runtime': 1014.5909497737885, 'test/loss': 1.323021749070382, 'eval/f1_macro': 0.13235294117647062, 'eval/f1_weighted': 0.21176470588235297, 'test/recall_micro': 0.4444444444444444, 'test/precision_weighted': 0.26992451992451993, 'eval/recall_micro': 0.36, 'test/precision_macro': 0.15253496503496505, 'test/recall_weighted': 0.4444444444444444, 'test/f1_macro': 0.18646012621916236, 'eval/recall_macro': 0.225, 'test/recall_macro': 0.24274193548387096, 'eval/recall_weighted': 0.36, 'test/f1_micro': 0.4444444444444444, 'eval/precision_micro': 0.36}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 26, 'dt_min_samples_leaf': 54}",breezy-microwave-536,DecisionTree,['pre-trained:bert-base-uncased']
795,"{'test/recall_weighted': 0.4444444444444444, 'test/precision_weighted': 0.27859879584017516, 'eval/f1_macro': 0.14705882352941177, 'eval/recall_weighted': 0.4, 'test/f1_weighted': 0.3140853240521015, 'test/precision_micro': 0.4444444444444444, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.4444444444444444, 'eval/f1_weighted': 0.23529411764705885, 'eval/precision_micro': 0.4, '_wandb': {'runtime': 1000}, 'eval/loss': 1.3186706685824692, 'test/f1_micro': 0.4444444444444444, 'test/recall_macro': 0.28214285714285714, '_runtime': 1001.7575016021729, 'test/f1_macro': 0.22259136212624583, 'test/loss': 1.289855877935646, 'eval/recall_micro': 0.4, 'eval/precision_weighted': 0.16666666666666669, 'test/recall_micro': 0.4444444444444444, 'test/precision_macro': 0.23706896551724135, '_timestamp': 1704308605.6885395, 'eval/recall_macro': 0.25, 'eval/precision_macro': 0.10416666666666669, '_step': 20, 'split': 10}","{'rf_max_depth': 2, 'trial.number': 26}",iconic-spaceship-535,RandomForest,['pre-trained:bert-base-uncased']
796,"{'eval/loss': 7.927413871311237, 'test/f1_macro': 0.30987460815047024, 'test/recall_weighted': 0.3333333333333333, 'test/precision_weighted': 0.364284175208545, 'test/precision_macro': 0.30836565395388926, 'eval/precision_weighted': 0.45333333333333337, 'eval/f1_micro': 0.48, 'test/accuracy': 0.3333333333333333, 'test/recall_macro': 0.32773356911287943, 'test/recall_micro': 0.3333333333333333, 'eval/f1_weighted': 0.4381818181818181, 'eval/precision_macro': 0.3888888888888889, '_step': 20, 'split': 10, '_timestamp': 1704308318.4967444, 'eval/f1_macro': 0.36553030303030304, 'test/f1_micro': 0.3333333333333333, 'test/f1_weighted': 0.34004876349703944, '_wandb': {'runtime': 1103}, 'eval/recall_macro': 0.4, 'test/precision_micro': 0.3333333333333333, '_runtime': 1104.4174263477323, 'eval/precision_micro': 0.48, 'test/loss': 16.008248844479784, 'eval/accuracy': 0.48, 'eval/recall_micro': 0.48, 'eval/recall_weighted': 0.48}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 18, 'dt_min_samples_leaf': 5}",smooth-paper-534,DecisionTree,['pre-trained:openai-gpt']
797,"{'test/loss': 1.2102542393654394, 'eval/recall_micro': 0.4, 'split': 10, '_runtime': 1160.684119462967, 'eval/f1_weighted': 0.2935714285714286, 'eval/precision_weighted': 0.4036363636363636, '_step': 20, '_wandb': {'runtime': 1159}, '_timestamp': 1704308140.4406464, 'test/recall_micro': 0.492063492063492, 'eval/loss': 1.250585185508488, 'eval/f1_macro': 0.21205357142857145, 'test/accuracy': 0.492063492063492, 'eval/accuracy': 0.4, 'eval/recall_macro': 0.26666666666666666, 'test/precision_macro': 0.256578947368421, 'test/precision_micro': 0.492063492063492, 'test/f1_macro': 0.21483516483516485, 'eval/precision_macro': 0.3522727272727273, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.492063492063492, 'test/precision_weighted': 0.3475355054302423, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.492063492063492, 'test/f1_weighted': 0.3812314669457527, 'test/recall_macro': 0.25183823529411764, 'eval/recall_weighted': 0.4}","{'rf_max_depth': 3, 'trial.number': 17}",restful-eon-533,RandomForest,['pre-trained:openai-gpt']
798,"{'eval/f1_macro': 0.1679487179487179, 'eval/recall_micro': 0.32, 'test/loss': 1.2745313625984234, 'test/f1_macro': 0.2234375, 'test/recall_micro': 0.3968253968253968, 'eval/accuracy': 0.32, 'eval/recall_macro': 0.21666666666666665, 'eval/f1_micro': 0.32, 'eval/loss': 1.3605355632158649, 'test/f1_weighted': 0.33978174603174605, 'test/recall_macro': 0.3032258064516129, '_wandb': {'runtime': 1013}, 'split': 10, 'test/accuracy': 0.3968253968253968, 'test/f1_micro': 0.3968253968253968, 'eval/recall_weighted': 0.32, 'test/precision_weighted': 0.3150553150553151, '_step': 20, 'eval/f1_weighted': 0.24738461538461537, 'test/recall_weighted': 0.3968253968253968, '_timestamp': 1704307862.8370836, 'test/precision_macro': 0.19393939393939397, 'eval/precision_macro': 0.1371527777777778, 'eval/precision_micro': 0.32, 'test/precision_micro': 0.3968253968253968, 'eval/precision_weighted': 0.2016666666666667, '_runtime': 1014.6147274971008}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 25, 'dt_min_samples_leaf': 99}",dandy-jazz-532,DecisionTree,['pre-trained:bert-base-uncased']
799,"{'test/f1_macro': 0.22820872820872817, 'eval/f1_weighted': 0.35166666666666674, 'test/precision_macro': 0.2753623188405797, 'eval/precision_weighted': 0.4836363636363636, '_wandb': {'runtime': 1003}, 'eval/recall_macro': 0.3166666666666667, 'eval/loss': 1.2146439451272284, 'test/f1_micro': 0.380952380952381, 'test/recall_micro': 0.380952380952381, 'test/precision_micro': 0.380952380952381, 'eval/f1_micro': 0.44, '_timestamp': 1704307600.3325014, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.380952380952381, '_runtime': 1004.3995594978333, 'test/loss': 1.4298587219587326, 'eval/f1_macro': 0.28645833333333337, 'test/recall_macro': 0.25798319327731095, 'split': 10, 'test/f1_weighted': 0.32049860621289183, 'eval/recall_micro': 0.44, 'eval/precision_macro': 0.4772727272727273, 'test/precision_weighted': 0.3546123763515068, '_step': 20, 'test/accuracy': 0.380952380952381, 'eval/precision_micro': 0.44, 'eval/accuracy': 0.44}","{'rf_max_depth': 7, 'trial.number': 25}",radiant-voice-531,RandomForest,['pre-trained:bert-base-uncased']
800,"{'eval/f1_micro': 0.44, 'test/f1_micro': 0.31746031746031744, 'eval/recall_weighted': 0.44, 'eval/accuracy': 0.44, 'test/recall_micro': 0.31746031746031744, 'test/precision_weighted': 0.39961765793046583, '_step': 20, 'test/accuracy': 0.31746031746031744, 'eval/precision_macro': 0.4, 'eval/precision_micro': 0.44, 'eval/recall_micro': 0.44, 'test/precision_macro': 0.33307909762651144, 'test/precision_micro': 0.31746031746031744, 'test/recall_weighted': 0.31746031746031744, '_wandb': {'runtime': 1107}, 'eval/f1_macro': 0.3857142857142858, 'eval/f1_weighted': 0.4342857142857142, 'eval/recall_macro': 0.4083333333333333, 'eval/loss': 1.105653538559102, 'test/recall_macro': 0.3398725316828765, '_runtime': 1109.1684548854828, '_timestamp': 1704307209.575686, 'test/f1_macro': 0.2994851258581236, 'test/f1_weighted': 0.3251716247139589, 'split': 10, 'eval/precision_weighted': 0.48, 'test/loss': 4.005022429391996}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 17, 'dt_min_samples_leaf': 7}",efficient-plant-530,DecisionTree,['pre-trained:openai-gpt']
801,"{'eval/recall_micro': 0.4, 'test/recall_weighted': 0.492063492063492, 'test/loss': 1.275518815596098, 'eval/f1_macro': 0.14285714285714288, 'test/precision_macro': 0.123015873015873, 'eval/precision_weighted': 0.16, 'test/accuracy': 0.492063492063492, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.3245525160418777, 'test/precision_micro': 0.492063492063492, 'test/precision_weighted': 0.24212648022171832, 'eval/loss': 1.3296549549719356, 'test/f1_macro': 0.16489361702127658, 'test/f1_micro': 0.492063492063492, '_wandb': {'runtime': 1016}, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.4, '_step': 20, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.492063492063492, 'eval/precision_macro': 0.1, '_runtime': 1017.7862267494202, '_timestamp': 1704306843.0004437, 'eval/precision_micro': 0.4, 'split': 10, 'eval/accuracy': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 24, 'dt_min_samples_leaf': 77}",drawn-paper-529,DecisionTree,['pre-trained:bert-base-uncased']
802,"{'test/recall_macro': 0.2582013574660634, 'test/precision_weighted': 0.3393298059964727, '_step': 20, 'test/loss': 1.2894831089957937, 'test/f1_macro': 0.23294277060417665, 'test/f1_weighted': 0.36871803825414534, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.23055555555555557, 'test/recall_weighted': 0.42857142857142855, '_timestamp': 1704306975.2221868, 'eval/f1_micro': 0.44, 'eval/recall_macro': 0.3416666666666667, 'eval/recall_micro': 0.44, 'eval/f1_weighted': 0.3774603174603175, 'eval/loss': 1.3292339037222751, 'eval/accuracy': 0.44, 'eval/recall_weighted': 0.44, 'split': 10, 'test/f1_micro': 0.42857142857142855, 'test/recall_micro': 0.42857142857142855, 'test/accuracy': 0.42857142857142855, '_runtime': 1157.3942458629608, 'eval/f1_macro': 0.31646825396825395, 'eval/precision_weighted': 0.3977777777777778, '_wandb': {'runtime': 1156}, 'eval/precision_macro': 0.3611111111111111, 'test/precision_micro': 0.42857142857142855}","{'rf_max_depth': 5, 'trial.number': 16}",smart-galaxy-528,RandomForest,['pre-trained:openai-gpt']
803,"{'test/loss': 1.290089280277907, 'eval/f1_macro': 0.12903225806451613, 'test/f1_macro': 0.1718875502008032, 'eval/f1_weighted': 0.2064516129032258, 'eval/recall_macro': 0.2, 'eval/precision_weighted': 0.15238095238095237, 'test/precision_weighted': 0.2176046176046176, 'eval/f1_micro': 0.32, 'test/accuracy': 0.380952380952381, 'test/recall_weighted': 0.380952380952381, '_step': 20, 'eval/loss': 1.394642991447671, 'test/f1_micro': 0.380952380952381, 'eval/precision_micro': 0.32, 'eval/accuracy': 0.32, 'eval/recall_micro': 0.32, 'test/precision_macro': 0.15454545454545454, '_runtime': 1002.4191334247588, 'eval/recall_weighted': 0.32, 'test/precision_micro': 0.380952380952381, '_timestamp': 1704306590.3464625, 'test/f1_weighted': 0.26748262892841207, 'test/recall_micro': 0.380952380952381, 'eval/precision_macro': 0.09523809523809525, 'split': 10, '_wandb': {'runtime': 1001}, 'test/recall_macro': 0.23035714285714284}","{'rf_max_depth': 4, 'trial.number': 24}",revived-feather-527,RandomForest,['pre-trained:bert-base-uncased']
804,"{'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.3968253968253968, 'test/precision_macro': 0.11160714285714286, '_step': 20, 'test/loss': 1.4304616180390788, 'eval/accuracy': 0.4, 'test/f1_macro': 0.14705882352941177, 'test/f1_micro': 0.3968253968253968, 'eval/precision_macro': 0.10416666666666669, '_runtime': 1103.411681652069, 'eval/recall_macro': 0.25, 'test/precision_weighted': 0.20549886621315192, 'split': 10, 'test/f1_weighted': 0.2707749766573296, 'test/recall_micro': 0.3968253968253968, 'eval/precision_micro': 0.4, 'eval/precision_weighted': 0.16666666666666669, 'eval/f1_weighted': 0.23529411764705885, 'eval/recall_weighted': 0.4, 'eval/loss': 1.1367701204449248, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.21551724137931033, 'test/recall_weighted': 0.3968253968253968, '_wandb': {'runtime': 1102}, '_timestamp': 1704306096.9141166, 'eval/f1_macro': 0.14705882352941177, 'test/precision_micro': 0.3968253968253968}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 16, 'dt_min_samples_leaf': 15}",ancient-valley-526,DecisionTree,['pre-trained:openai-gpt']
805,"{'eval/recall_micro': 0.36, 'test/recall_macro': 0.2346774193548387, 'eval/recall_weighted': 0.36, 'test/precision_macro': 0.1482843137254902, '_step': 20, 'eval/accuracy': 0.36, 'test/f1_weighted': 0.32647027768978987, 'eval/precision_weighted': 0.15, 'eval/f1_macro': 0.13235294117647062, 'test/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.09375, '_timestamp': 1704305820.110214, 'test/f1_macro': 0.18126385809312637, 'eval/recall_macro': 0.225, 'eval/f1_micro': 0.36, 'eval/f1_weighted': 0.21176470588235297, '_runtime': 1013.7760090827942, 'test/precision_micro': 0.42857142857142855, 'test/precision_weighted': 0.26408341114223466, 'eval/precision_micro': 0.36, 'test/recall_weighted': 0.42857142857142855, 'test/accuracy': 0.42857142857142855, 'test/f1_micro': 0.42857142857142855, '_wandb': {'runtime': 1012}, 'eval/loss': 1.4052382064019215, 'test/loss': 1.3744519401761877, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 23, 'dt_min_samples_leaf': 47}",kind-bee-525,DecisionTree,['pre-trained:bert-base-uncased']
806,"{'eval/f1_micro': 0.44, 'eval/recall_weighted': 0.44, '_wandb': {'runtime': 1156}, 'eval/precision_macro': 0.3426470588235294, 'eval/precision_weighted': 0.3882352941176471, '_step': 20, '_timestamp': 1704305812.9907053, 'eval/accuracy': 0.44, 'eval/recall_micro': 0.44, 'eval/precision_micro': 0.44, 'test/recall_macro': 0.21677036199095023, 'test/precision_micro': 0.36507936507936506, 'split': 10, '_runtime': 1158.4039652347565, 'test/accuracy': 0.36507936507936506, 'test/f1_micro': 0.36507936507936506, 'eval/f1_macro': 0.3106481481481482, 'eval/recall_macro': 0.3416666666666667, 'test/recall_micro': 0.36507936507936506, 'test/f1_weighted': 0.34862651301007463, 'test/precision_macro': 0.22916666666666663, 'test/recall_weighted': 0.36507936507936506, 'test/precision_weighted': 0.34025234025234025, 'eval/loss': 2.908115342918293, 'test/loss': 2.4246102849162443, 'test/f1_macro': 0.21711450649806813, 'eval/f1_weighted': 0.3770370370370371}","{'rf_max_depth': 10, 'trial.number': 15}",glad-tree-524,RandomForest,['pre-trained:openai-gpt']
807,"{'test/recall_micro': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, 'eval/f1_weighted': 0.23529411764705885, 'eval/recall_micro': 0.4, 'eval/loss': 1.3026592790424834, 'test/recall_weighted': 0.4444444444444444, 'test/precision_weighted': 0.33597883597883593, 'eval/accuracy': 0.4, 'test/f1_macro': 0.2154761904761905, 'eval/recall_macro': 0.25, 'test/accuracy': 0.4444444444444444, 'split': 10, '_timestamp': 1704305582.4195693, 'eval/f1_micro': 0.4000000000000001, 'test/precision_macro': 0.2619047619047619, '_step': 20, '_wandb': {'runtime': 1001}, 'eval/precision_micro': 0.4, 'eval/precision_macro': 0.10416666666666669, 'test/precision_micro': 0.4444444444444444, 'eval/precision_weighted': 0.16666666666666669, '_runtime': 1002.387285232544, 'test/loss': 1.3119062307347342, 'test/f1_weighted': 0.32479213907785337, 'eval/f1_macro': 0.14705882352941177, 'test/recall_macro': 0.27184873949579835, 'eval/recall_weighted': 0.4}","{'rf_max_depth': 3, 'trial.number': 23}",elated-elevator-523,RandomForest,['pre-trained:bert-base-uncased']
808,"{'test/accuracy': 0.31746031746031744, 'test/f1_macro': 0.2994851258581236, 'test/precision_weighted': 0.39961765793046583, 'eval/recall_micro': 0.44, '_runtime': 1105.2797224521637, 'test/recall_macro': 0.3398725316828765, 'test/f1_weighted': 0.3251716247139589, 'test/loss': 4.005022429391996, 'eval/f1_macro': 0.3857142857142858, 'eval/f1_weighted': 0.4342857142857142, 'test/recall_micro': 0.31746031746031744, 'eval/precision_macro': 0.4, 'test/precision_micro': 0.31746031746031744, '_wandb': {'runtime': 1103}, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.31746031746031744, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.4083333333333333, '_step': 20, 'eval/loss': 1.105653538559102, '_timestamp': 1704304987.8635526, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.31746031746031744, 'eval/precision_weighted': 0.48, 'split': 10, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.33307909762651144}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 15, 'dt_min_samples_leaf': 8}",graceful-thunder-522,DecisionTree,['pre-trained:openai-gpt']
809,"{'eval/loss': 1.3296549549719356, 'eval/recall_macro': 0.25, 'eval/precision_micro': 0.4, '_timestamp': 1704304800.8388865, 'test/recall_macro': 0.25, 'split': 10, 'eval/accuracy': 0.4, 'test/accuracy': 0.492063492063492, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.3245525160418777, 'eval/recall_micro': 0.4, 'test/precision_weighted': 0.24212648022171832, 'eval/f1_micro': 0.4000000000000001, 'test/precision_micro': 0.492063492063492, '_wandb': {'runtime': 1014}, 'test/f1_macro': 0.16489361702127658, 'eval/precision_macro': 0.1, 'eval/recall_weighted': 0.4, '_runtime': 1015.4928712844847, 'eval/f1_macro': 0.14285714285714288, 'eval/precision_weighted': 0.16, 'test/f1_micro': 0.492063492063492, 'test/recall_micro': 0.492063492063492, 'test/recall_weighted': 0.492063492063492, '_step': 20, 'test/loss': 1.275518815596098, 'test/precision_macro': 0.123015873015873}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 22, 'dt_min_samples_leaf': 77}",earthy-hill-521,DecisionTree,['pre-trained:bert-base-uncased']
810,"{'eval/precision_weighted': 0.15238095238095237, 'split': 10, 'eval/f1_macro': 0.12903225806451613, 'eval/precision_macro': 0.09523809523809525, 'test/recall_weighted': 0.380952380952381, '_step': 20, 'test/loss': 1.3403600633595054, 'test/precision_macro': 0.3584905660377359, 'test/recall_macro': 0.23660714285714285, 'eval/recall_weighted': 0.32, 'test/accuracy': 0.380952380952381, 'test/f1_micro': 0.380952380952381, 'eval/recall_macro': 0.2, 'eval/loss': 1.27540278949011, 'test/f1_weighted': 0.28061924358220663, 'eval/precision_micro': 0.32, 'test/f1_macro': 0.19753086419753088, 'test/precision_weighted': 0.3198562443845463, 'eval/accuracy': 0.32, '_wandb': {'runtime': 1002}, '_runtime': 1004.0933570861816, '_timestamp': 1704304575.232481, 'eval/f1_micro': 0.32, 'eval/recall_micro': 0.32, 'test/precision_micro': 0.380952380952381, 'eval/f1_weighted': 0.2064516129032258, 'test/recall_micro': 0.380952380952381}","{'rf_max_depth': 4, 'trial.number': 22}",amber-dust-520,RandomForest,['pre-trained:bert-base-uncased']
811,"{'eval/accuracy': 0.4, 'test/f1_micro': 0.4126984126984127, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.21507352941176472, 'test/precision_macro': 0.17755102040816328, 'test/precision_micro': 0.4126984126984127, '_step': 20, 'eval/f1_weighted': 0.27670250896057347, 'test/loss': 1.346707197337364, 'test/recall_weighted': 0.4126984126984127, '_wandb': {'runtime': 1166}, '_runtime': 1167.4711756706238, 'test/f1_weighted': 0.34464598320020007, 'test/f1_macro': 0.1890639481000927, 'eval/precision_macro': 0.16964285714285715, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.22142857142857145, '_timestamp': 1704304650.9339795, 'test/recall_micro': 0.4126984126984127, 'eval/loss': 1.3479918673783446, 'eval/f1_macro': 0.20071684587813615, 'test/accuracy': 0.4126984126984127, 'test/precision_weighted': 0.3007450599287334, 'split': 10, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.275}","{'rf_max_depth': 4, 'trial.number': 14}",glamorous-plant-519,RandomForest,['pre-trained:openai-gpt']
812,"{'test/loss': 1.9405482044194855, 'eval/f1_micro': 0.48, 'test/f1_weighted': 0.3065024809705661, 'eval/recall_macro': 0.4333333333333333, 'eval/f1_macro': 0.3686868686868687, 'test/f1_macro': 0.2708060556464812, 'test/precision_macro': 0.2602124183006536, 'test/precision_micro': 0.3333333333333333, 'eval/recall_weighted': 0.48, 'eval/precision_weighted': 0.416, 'split': 10, '_runtime': 1105.466954946518, 'eval/loss': 0.9892031650021578, '_timestamp': 1704303878.107373, 'eval/accuracy': 0.48, 'test/f1_micro': 0.3333333333333333, '_step': 20, 'test/accuracy': 0.3333333333333333, 'eval/precision_macro': 0.35, 'eval/precision_micro': 0.48, 'test/precision_weighted': 0.3369644153957879, 'eval/f1_weighted': 0.42505050505050507, 'test/recall_macro': 0.3431513409961686, '_wandb': {'runtime': 1104}, 'eval/recall_micro': 0.48, 'test/recall_micro': 0.3333333333333333, 'test/recall_weighted': 0.3333333333333333}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 14, 'dt_min_samples_leaf': 29}",northern-moon-518,DecisionTree,['pre-trained:openai-gpt']
813,"{'test/accuracy': 0.3968253968253968, 'eval/precision_macro': 0.1371527777777778, 'eval/loss': 1.3605355632158649, 'eval/f1_micro': 0.32, 'test/recall_macro': 0.3032258064516129, '_wandb': {'runtime': 1013}, 'test/recall_weighted': 0.3968253968253968, 'eval/precision_weighted': 0.2016666666666667, 'eval/recall_weighted': 0.32, 'split': 10, '_runtime': 1014.8798632621764, '_timestamp': 1704303781.3997684, 'eval/f1_macro': 0.1679487179487179, 'test/recall_micro': 0.3968253968253968, 'test/precision_macro': 0.19393939393939397, '_step': 20, 'test/precision_weighted': 0.3150553150553151, 'test/f1_weighted': 0.33978174603174605, 'eval/accuracy': 0.32, 'test/f1_macro': 0.2234375, 'eval/precision_micro': 0.32, 'test/loss': 1.2745313625984234, 'eval/recall_macro': 0.21666666666666665, 'eval/recall_micro': 0.32, 'test/precision_micro': 0.3968253968253968, 'test/f1_micro': 0.3968253968253968, 'eval/f1_weighted': 0.24738461538461537}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 21, 'dt_min_samples_leaf': 100}",clear-violet-517,DecisionTree,['pre-trained:bert-base-uncased']
814,"{'eval/precision_micro': 0.32, 'test/precision_micro': 0.380952380952381, 'eval/loss': 1.3126651749229554, 'test/recall_macro': 0.2361344537815126, 'split': 10, 'eval/recall_micro': 0.32, 'test/accuracy': 0.380952380952381, 'test/f1_macro': 0.19153069153069155, 'test/recall_micro': 0.380952380952381, 'eval/precision_macro': 0.09090909090909093, 'test/precision_macro': 0.3808333333333333, 'test/precision_weighted': 0.4786243386243386, '_timestamp': 1704303567.0616293, 'eval/f1_macro': 0.12500000000000003, 'test/f1_micro': 0.380952380952381, 'eval/recall_weighted': 0.32, 'eval/precision_weighted': 0.14545454545454548, '_wandb': {'runtime': 1002}, 'test/loss': 1.3097866130124185, 'test/recall_weighted': 0.380952380952381, '_step': 20, 'eval/accuracy': 0.32, 'test/f1_weighted': 0.29512462845796184, 'eval/f1_micro': 0.32, 'eval/f1_weighted': 0.20000000000000004, '_runtime': 1003.7940373420716, 'eval/recall_macro': 0.2}","{'rf_max_depth': 3, 'trial.number': 21}",comic-frost-516,RandomForest,['pre-trained:bert-base-uncased']
815,"{'test/f1_macro': 0.2176962676962677, 'eval/f1_weighted': 0.2750230414746544, 'eval/recall_macro': 0.24166666666666667, 'test/recall_macro': 0.22426470588235295, 'test/precision_macro': 0.21488095238095237, '_runtime': 1152.4918720722198, 'test/loss': 1.3607435958153835, 'eval/f1_macro': 0.20046082949308755, 'test/precision_weighted': 0.336130007558579, 'test/recall_micro': 0.380952380952381, 'eval/loss': 1.4154307358133875, 'eval/f1_micro': 0.36, 'test/precision_micro': 0.380952380952381, 'split': 10, 'test/accuracy': 0.380952380952381, 'test/f1_micro': 0.380952380952381, '_step': 20, 'eval/precision_macro': 0.34523809523809523, '_wandb': {'runtime': 1151}, 'test/f1_weighted': 0.35596412739269884, 'eval/recall_micro': 0.36, 'eval/recall_weighted': 0.36, 'test/recall_weighted': 0.380952380952381, 'eval/precision_weighted': 0.3923809523809524, '_timestamp': 1704303479.030275, 'eval/accuracy': 0.36, 'eval/precision_micro': 0.36}","{'rf_max_depth': 8, 'trial.number': 13}",twilight-bush-515,RandomForest,['pre-trained:openai-gpt']
816,"{'_step': 20, 'test/precision_weighted': 0.24212648022171832, '_wandb': {'runtime': 1016}, 'test/loss': 1.275518815596098, 'eval/precision_macro': 0.1, 'eval/precision_micro': 0.4, 'split': 10, 'test/f1_micro': 0.492063492063492, '_timestamp': 1704302761.6440072, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.3245525160418777, 'eval/accuracy': 0.4, 'test/accuracy': 0.492063492063492, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.492063492063492, '_runtime': 1018.1189291477205, 'eval/loss': 1.3296549549719356, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.25, 'test/recall_micro': 0.492063492063492, 'test/precision_macro': 0.123015873015873, 'test/precision_micro': 0.492063492063492, 'eval/precision_weighted': 0.16, 'eval/f1_macro': 0.14285714285714288, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.16489361702127658, 'eval/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 20, 'dt_min_samples_leaf': 78}",cool-wildflower-514,DecisionTree,['pre-trained:bert-base-uncased']
817,"{'test/f1_macro': 0.15378787878787878, 'eval/f1_weighted': 0.14956521739130435, 'test/recall_macro': 0.1954022988505747, 'eval/recall_weighted': 0.2, 'eval/f1_micro': 0.20000000000000004, 'test/f1_weighted': 0.2341029341029341, 'test/recall_micro': 0.2698412698412698, '_timestamp': 1704302768.3879516, 'eval/accuracy': 0.2, 'test/recall_weighted': 0.2698412698412698, 'test/precision_weighted': 0.2168458781362007, 'test/loss': 1.3744851134316307, 'test/precision_micro': 0.2698412698412698, 'eval/precision_macro': 0.10096153846153846, '_runtime': 1110.6411845684052, 'eval/f1_macro': 0.12681159420289856, 'test/precision_macro': 0.13608870967741937, '_wandb': {'runtime': 1109}, 'eval/loss': 1.4824089384976713, 'test/accuracy': 0.2698412698412698, 'test/f1_micro': 0.2698412698412698, 'eval/recall_micro': 0.2, 'eval/precision_micro': 0.2, '_step': 20, 'split': 10, 'eval/recall_macro': 0.175, 'eval/precision_weighted': 0.12153846153846154}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 13, 'dt_min_samples_leaf': 100}",comfy-tree-513,DecisionTree,['pre-trained:openai-gpt']
818,"{'test/loss': 1.31762664131982, 'test/accuracy': 0.4126984126984127, 'eval/f1_weighted': 0.21176470588235297, 'eval/recall_weighted': 0.36, 'test/precision_weighted': 0.1925925925925926, '_step': 20, 'eval/accuracy': 0.36, 'test/f1_micro': 0.4126984126984127, 'test/recall_macro': 0.23214285714285715, 'eval/loss': 1.3237303744022169, 'eval/recall_macro': 0.225, 'test/precision_macro': 0.10833333333333334, 'test/recall_weighted': 0.4126984126984127, 'eval/f1_micro': 0.36, 'eval/precision_micro': 0.36, 'eval/recall_micro': 0.36, 'test/f1_weighted': 0.26262626262626265, 'test/precision_micro': 0.4126984126984127, 'eval/precision_weighted': 0.15, '_runtime': 1005.2090637683868, '_timestamp': 1704302559.611873, 'eval/f1_macro': 0.13235294117647062, 'test/f1_macro': 0.1477272727272727, 'test/recall_micro': 0.4126984126984127, '_wandb': {'runtime': 1003}, 'eval/precision_macro': 0.09375, 'split': 10}","{'rf_max_depth': 2, 'trial.number': 20}",stellar-salad-512,RandomForest,['pre-trained:bert-base-uncased']
819,"{'eval/recall_macro': 0.3041666666666667, 'test/precision_macro': 0.3867924528301887, 'split': 10, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.24448529411764705, 'test/recall_weighted': 0.47619047619047616, '_step': 20, 'test/f1_weighted': 0.3880070546737213, 'test/precision_micro': 0.47619047619047616, 'eval/precision_weighted': 0.4, 'eval/loss': 1.314768906055083, 'test/loss': 1.2639038356714667, 'test/accuracy': 0.47619047619047616, 'test/precision_weighted': 0.4222821203953279, '_timestamp': 1704302322.833543, 'eval/accuracy': 0.4, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/f1_macro': 0.2222222222222222, 'eval/f1_weighted': 0.3306666666666666, 'test/f1_micro': 0.47619047619047616, 'test/recall_micro': 0.47619047619047616, '_wandb': {'runtime': 1143}, '_runtime': 1145.2154140472412, 'eval/precision_macro': 0.43333333333333335, 'eval/f1_macro': 0.28888888888888886}","{'rf_max_depth': 4, 'trial.number': 12}",vocal-brook-511,RandomForest,['pre-trained:openai-gpt']
820,"{'eval/precision_micro': 0.2307692307692308, 'split': 3, 'eval/f1_micro': 0.2307692307692308, 'eval/f1_weighted': 0.15384615384615383, 'eval/recall_macro': 0.15, '_step': 4, 'eval/precision_macro': 0.075, 'eval/recall_weighted': 0.2307692307692308, 'eval/f1_macro': 0.1, 'eval/recall_micro': 0.2307692307692308, 'eval/precision_weighted': 0.1153846153846154, '_runtime': 246.2803735733032, 'eval/loss': 1.619448558870619, '_timestamp': 1704301124.8013406, 'eval/accuracy': 0.2307692307692308}","{'dt_criterion': 'gini', 'dt_max_depth': 9, 'trial.number': 68, 'dt_min_samples_leaf': 43}",dark-lion-510,DecisionTree,['pre-trained:microsoft/codebert-base']
821,"{'test/f1_macro': 0.2234375, '_timestamp': 1704301738.658313, 'eval/accuracy': 0.32, 'test/recall_macro': 0.3032258064516129, 'test/f1_micro': 0.3968253968253968, 'eval/recall_micro': 0.32, 'eval/precision_micro': 0.32, 'eval/recall_weighted': 0.32, 'test/precision_macro': 0.19393939393939397, '_step': 20, 'eval/loss': 1.3605355632158649, 'test/precision_micro': 0.3968253968253968, 'test/recall_micro': 0.3968253968253968, 'eval/precision_macro': 0.1371527777777778, 'eval/f1_macro': 0.1679487179487179, 'test/f1_weighted': 0.33978174603174605, 'eval/recall_macro': 0.21666666666666665, 'eval/precision_weighted': 0.2016666666666667, '_wandb': {'runtime': 1012}, 'test/loss': 1.2745313625984234, 'test/recall_weighted': 0.3968253968253968, 'test/precision_weighted': 0.3150553150553151, '_runtime': 1013.9479579925536, 'test/accuracy': 0.3968253968253968, 'eval/f1_weighted': 0.24738461538461537, 'split': 10, 'eval/f1_micro': 0.32}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 19, 'dt_min_samples_leaf': 75}",elated-breeze-509,DecisionTree,['pre-trained:bert-base-uncased']
822,"{'test/f1_micro': 0.3968253968253968, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.3, 'split': 10, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.25661764705882356, '_runtime': 1002.1191589832306, 'test/f1_weighted': 0.3290500761708192, '_wandb': {'runtime': 1000}, 'eval/f1_weighted': 0.3, 'eval/f1_macro': 0.2125, 'eval/loss': 1.3117179487371076, 'eval/accuracy': 0.4, 'eval/recall_micro': 0.4, 'test/recall_weighted': 0.3968253968253968, '_step': 20, '_timestamp': 1704301549.359195, 'eval/precision_macro': 0.2375, 'test/loss': 1.3564486769481814, 'eval/recall_macro': 0.26666666666666666, 'test/precision_macro': 0.2388392857142857, 'test/f1_macro': 0.22756965944272448, 'test/recall_micro': 0.3968253968253968, 'test/precision_weighted': 0.31831065759637184, 'test/accuracy': 0.3968253968253968, 'test/precision_micro': 0.3968253968253968}","{'rf_max_depth': 4, 'trial.number': 19}",jumping-pyramid-508,RandomForest,['pre-trained:bert-base-uncased']
823,"{'eval/loss': 0.998674891396785, 'eval/f1_macro': 0.4285714285714286, 'eval/f1_weighted': 0.4914285714285714, 'eval/precision_macro': 0.4229166666666666, 'test/precision_weighted': 0.3833180708180709, '_wandb': {'runtime': 1103}, 'test/loss': 4.029481780637284, 'eval/recall_macro': 0.475, '_step': 20, 'eval/precision_micro': 0.52, '_timestamp': 1704301652.0897894, 'eval/f1_micro': 0.52, 'test/f1_micro': 0.30158730158730157, 'eval/recall_weighted': 0.52, 'test/recall_weighted': 0.30158730158730157, '_runtime': 1105.332974433899, 'test/f1_macro': 0.26840882694541235, 'test/accuracy': 0.30158730158730157, 'test/recall_macro': 0.3397988505747126, 'test/recall_micro': 0.30158730158730157, 'test/precision_macro': 0.296875, 'split': 10, 'eval/accuracy': 0.52, 'eval/recall_micro': 0.52, 'test/f1_weighted': 0.2933613553822613, 'test/precision_micro': 0.30158730158730157, 'eval/precision_weighted': 0.5126666666666666}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 12, 'dt_min_samples_leaf': 16}",cosmic-snowball-507,DecisionTree,['pre-trained:openai-gpt']
824,"{'test/recall_micro': 0.4444444444444444, 'eval/precision_macro': 0.39166666666666666, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.26041666666666663, 'test/recall_weighted': 0.4444444444444444, 'test/precision_weighted': 0.35582010582010576, 'eval/loss': 1.3407844197157357, 'eval/accuracy': 0.4, 'split': 10, 'test/loss': 1.2125727511327842, '_wandb': {'runtime': 1156}, 'test/precision_micro': 0.4444444444444444, 'eval/precision_weighted': 0.4133333333333333, '_runtime': 1157.654680967331, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, '_step': 20, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.4444444444444444, 'test/f1_macro': 0.23970541653468488, 'eval/f1_weighted': 0.388, 'test/f1_weighted': 0.3834663207485507, 'test/recall_macro': 0.2536764705882353, '_timestamp': 1704301172.25911, 'eval/f1_macro': 0.345, 'test/f1_micro': 0.4444444444444444, 'eval/recall_macro': 0.33333333333333337}","{'rf_max_depth': 7, 'trial.number': 11}",crimson-sky-506,RandomForest,['pre-trained:openai-gpt']
825,"{'eval/accuracy': 0.36, 'test/f1_macro': 0.18126385809312637, 'test/f1_micro': 0.42857142857142855, 'eval/recall_micro': 0.36, 'eval/precision_macro': 0.09375, '_wandb': {'runtime': 1012}, 'test/f1_weighted': 0.32647027768978987, 'test/recall_macro': 0.2346774193548387, 'test/recall_micro': 0.42857142857142855, 'test/precision_macro': 0.1482843137254902, 'eval/loss': 1.4052382064019215, 'test/accuracy': 0.42857142857142855, 'eval/f1_weighted': 0.21176470588235297, 'eval/precision_weighted': 0.15, 'split': 10, '_runtime': 1013.3769989013672, 'test/loss': 1.3744519401761877, 'eval/f1_macro': 0.13235294117647062, 'eval/precision_micro': 0.36, '_step': 20, '_timestamp': 1704300720.097009, 'test/precision_micro': 0.42857142857142855, 'eval/f1_micro': 0.36, 'eval/recall_macro': 0.225, 'eval/recall_weighted': 0.36, 'test/recall_weighted': 0.42857142857142855, 'test/precision_weighted': 0.26408341114223466}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 18, 'dt_min_samples_leaf': 49}",neat-haze-505,DecisionTree,['pre-trained:bert-base-uncased']
826,"{'eval/accuracy': 0.28, 'test/recall_micro': 0.3968253968253968, 'eval/recall_weighted': 0.28, 'test/precision_macro': 0.240530303030303, '_step': 20, 'split': 10, 'eval/precision_micro': 0.28, 'eval/precision_weighted': 0.23428571428571424, '_runtime': 1254.9318203926086, 'test/f1_macro': 0.25649350649350644, 'eval/recall_macro': 0.23333333333333336, 'test/recall_weighted': 0.3968253968253968, 'test/precision_weighted': 0.35233285233285233, 'test/accuracy': 0.3968253968253968, 'test/f1_weighted': 0.37311894454751593, 'eval/f1_micro': 0.28, 'eval/f1_weighted': 0.2533333333333333, 'eval/loss': 1.849080524088798, 'test/loss': 1.4583807868708398, 'eval/recall_micro': 0.28, 'test/precision_micro': 0.3968253968253968, '_wandb': {'runtime': 1253}, '_timestamp': 1704300873.4962263, 'eval/f1_macro': 0.21666666666666667, 'test/f1_micro': 0.3968253968253968, 'test/recall_macro': 0.275, 'eval/precision_macro': 0.20476190476190476}","{'dt_criterion': 'gini', 'dt_max_depth': 8, 'trial.number': 67, 'dt_min_samples_leaf': 20}",robust-vortex-504,DecisionTree,['pre-trained:microsoft/codebert-base']
827,"{'eval/recall_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.36507936507936506, 'test/f1_micro': 0.36507936507936506, 'eval/f1_macro': 0.14285714285714288, 'test/precision_macro': 0.10454545454545454, 'eval/accuracy': 0.4, 'eval/loss': 1.29388583895189, 'split': 10, '_runtime': 1002.1817371845244, 'test/loss': 1.290546373773039, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.2463186077643909, '_step': 20, 'test/accuracy': 0.36507936507936506, 'test/f1_macro': 0.13855421686746988, 'eval/precision_micro': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.20535714285714285, 'test/recall_micro': 0.36507936507936506, 'eval/precision_macro': 0.1, 'eval/precision_weighted': 0.16, '_timestamp': 1704300542.6001582, 'eval/recall_macro': 0.25, 'test/recall_weighted': 0.36507936507936506, '_wandb': {'runtime': 1000}, 'test/precision_weighted': 0.18585858585858583}","{'rf_max_depth': 2, 'trial.number': 18}",sparkling-wind-503,RandomForest,['pre-trained:bert-base-uncased']
828,"{'test/precision_macro': 0.35678599417823553, 'eval/precision_weighted': 0.3846153846153847, 'eval/recall_micro': 0.4, 'eval/loss': 1.1213980967038548, 'test/f1_weighted': 0.3986887508626639, 'eval/precision_macro': 0.32371794871794873, 'eval/recall_weighted': 0.4, '_step': 20, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.36300599700149927, 'test/f1_micro': 0.4126984126984127, 'eval/recall_macro': 0.3166666666666667, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.31099033816425126, 'test/recall_micro': 0.4126984126984127, '_runtime': 1099.8428914546969, 'test/precision_micro': 0.4126984126984127, 'test/accuracy': 0.4126984126984127, 'test/loss': 10.428147150247293, 'eval/precision_micro': 0.4, '_wandb': {'runtime': 1098}, 'test/precision_weighted': 0.39879663986806846, 'test/recall_macro': 0.391596669613911, '_timestamp': 1704300543.7232163, 'eval/f1_weighted': 0.3820289855072464, 'test/recall_weighted': 0.4126984126984127, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 11, 'dt_min_samples_leaf': 5}",generous-water-502,DecisionTree,['pre-trained:openai-gpt']
829,"{'_timestamp': 1704300010.015439, 'test/f1_macro': 0.17741935483870966, 'eval/precision_macro': 0.30833333333333335, 'test/accuracy': 0.5238095238095238, 'test/f1_weighted': 0.38300051203277, 'eval/precision_micro': 0.4, '_runtime': 1145.341367006302, 'eval/f1_macro': 0.2583333333333333, 'eval/recall_micro': 0.4, 'test/precision_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, 'test/f1_micro': 0.5238095238095238, 'eval/f1_weighted': 0.3233333333333333, 'eval/recall_macro': 0.2916666666666667, 'test/recall_macro': 0.2426470588235294, 'test/recall_micro': 0.5238095238095238, '_wandb': {'runtime': 1144}, 'eval/loss': 1.265171497773678, 'test/loss': 1.28144573489366, 'eval/precision_weighted': 0.3466666666666666, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_weighted': 0.4, 'test/precision_weighted': 0.30185633575464077, '_step': 20, 'split': 10, 'test/precision_macro': 0.13983050847457626}","{'rf_max_depth': 2, 'trial.number': 10}",glorious-blaze-501,RandomForest,['pre-trained:openai-gpt']
830,"{'eval/accuracy': 0.28, 'test/f1_weighted': 0.3817618695667476, 'eval/recall_macro': 0.175, 'eval/precision_macro': 0.09210526315789472, 'eval/loss': 1.4342635304745612, 'eval/f1_micro': 0.28, 'eval/precision_weighted': 0.14736842105263157, 'split': 10, 'eval/f1_weighted': 0.19310344827586207, 'eval/recall_micro': 0.28, 'test/precision_macro': 0.21568627450980393, '_step': 20, '_timestamp': 1704299701.7321577, 'test/accuracy': 0.492063492063492, 'test/precision_weighted': 0.31341425459072514, '_runtime': 1013.893283367157, 'test/loss': 1.2659004575108088, 'test/f1_micro': 0.492063492063492, 'test/recall_micro': 0.492063492063492, 'eval/precision_micro': 0.28, 'test/recall_weighted': 0.492063492063492, '_wandb': {'runtime': 1012}, 'eval/f1_macro': 0.12068965517241378, 'test/f1_macro': 0.25554323725055433, 'test/recall_macro': 0.317741935483871, 'test/precision_micro': 0.492063492063492, 'eval/recall_weighted': 0.28}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 17, 'dt_min_samples_leaf': 60}",stellar-galaxy-500,DecisionTree,['pre-trained:bert-base-uncased']
831,"{'test/precision_macro': 0.2925, 'test/recall_macro': 0.25220588235294117, '_runtime': 1002.1767024993896, 'eval/accuracy': 0.32, 'test/f1_weighted': 0.3103668817954533, 'eval/precision_macro': 0.09090909090909093, '_wandb': {'runtime': 1000}, 'test/f1_macro': 0.22985347985347987, 'eval/f1_weighted': 0.20000000000000004, 'test/recall_micro': 0.380952380952381, 'eval/precision_weighted': 0.14545454545454548, '_timestamp': 1704299536.7503564, 'eval/f1_micro': 0.32, 'eval/recall_weighted': 0.32, '_step': 20, 'test/loss': 1.380394912595007, 'eval/f1_macro': 0.12500000000000003, 'test/precision_weighted': 0.33349206349206345, 'split': 10, 'test/f1_micro': 0.380952380952381, 'eval/loss': 1.3239261004316063, 'eval/recall_macro': 0.2, 'eval/recall_micro': 0.32, 'test/precision_micro': 0.380952380952381, 'test/accuracy': 0.380952380952381, 'test/recall_weighted': 0.380952380952381, 'eval/precision_micro': 0.32}","{'rf_max_depth': 7, 'trial.number': 17}",jolly-glitter-499,RandomForest,['pre-trained:bert-base-uncased']
832,"{'test/precision_weighted': 0.31405895691609975, 'split': 10, 'eval/f1_weighted': 0.214025974025974, 'test/f1_macro': 0.2607371794871795, 'test/f1_weighted': 0.3471713471713472, 'eval/precision_micro': 0.24, 'test/precision_micro': 0.3968253968253968, '_step': 20, '_wandb': {'runtime': 1253}, '_timestamp': 1704299613.9202502, 'eval/accuracy': 0.24, 'eval/f1_micro': 0.24, 'eval/precision_weighted': 0.1955555555555555, '_runtime': 1254.3134171962738, 'eval/loss': 4.115607490893121, 'test/recall_weighted': 0.3968253968253968, 'test/recall_macro': 0.3145833333333333, 'test/recall_micro': 0.3968253968253968, 'test/loss': 1.7906017751272476, 'test/f1_micro': 0.3968253968253968, 'eval/recall_weighted': 0.24, 'eval/f1_macro': 0.18912337662337655, 'test/accuracy': 0.3968253968253968, 'eval/precision_macro': 0.1736111111111111, 'test/precision_macro': 0.2294642857142857, 'eval/recall_macro': 0.2125, 'eval/recall_micro': 0.24}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 66, 'dt_min_samples_leaf': 37}",light-glade-498,DecisionTree,['pre-trained:microsoft/codebert-base']
833,"{'test/f1_micro': 0.3968253968253968, 'test/precision_micro': 0.3968253968253968, 'eval/precision_micro': 0.4, '_wandb': {'runtime': 1102}, 'test/f1_macro': 0.14705882352941177, 'test/recall_micro': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, 'test/precision_weighted': 0.20549886621315192, '_step': 20, 'eval/loss': 1.1367701204449248, 'eval/f1_weighted': 0.23529411764705885, 'split': 10, 'eval/precision_macro': 0.10416666666666669, 'eval/f1_macro': 0.14705882352941177, 'test/recall_macro': 0.21551724137931033, 'test/loss': 1.4304616180390788, 'test/accuracy': 0.3968253968253968, 'eval/recall_micro': 0.4, 'test/f1_weighted': 0.2707749766573296, 'test/precision_macro': 0.11160714285714286, 'eval/precision_weighted': 0.16666666666666669, '_runtime': 1103.8506586551666, '_timestamp': 1704299438.8019357, 'eval/f1_micro': 0.4000000000000001, 'eval/accuracy': 0.4, 'eval/recall_macro': 0.25, 'eval/recall_weighted': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 10, 'dt_min_samples_leaf': 33}",logical-sunset-497,DecisionTree,['pre-trained:openai-gpt']
834,"{'test/precision_micro': 0.31746031746031744, 'test/loss': 2.3205093899237244, 'eval/accuracy': 0.24, 'eval/recall_micro': 0.24, 'test/recall_macro': 0.18283371040723984, '_runtime': 1156.742710351944, 'test/f1_micro': 0.31746031746031744, 'eval/precision_macro': 0.14583333333333331, 'test/precision_weighted': 0.298451512737227, 'test/f1_macro': 0.18099336761308596, 'test/accuracy': 0.31746031746031744, 'split': 10, 'eval/loss': 2.858417088620359, 'eval/recall_weighted': 0.24, 'eval/precision_weighted': 0.18333333333333332, '_step': 20, '_timestamp': 1704298859.5535493, 'eval/f1_micro': 0.24, 'eval/f1_weighted': 0.20444444444444443, 'test/f1_weighted': 0.30706756707203836, 'test/recall_micro': 0.31746031746031744, 'test/precision_macro': 0.1811454311454311, '_wandb': {'runtime': 1155}, 'test/recall_weighted': 0.31746031746031744, 'eval/recall_macro': 0.175, 'eval/precision_micro': 0.24, 'eval/f1_macro': 0.15555555555555556}","{'rf_max_depth': 13, 'trial.number': 9}",wise-pyramid-496,RandomForest,['pre-trained:openai-gpt']
835,"{'test/loss': 6.656479460894657, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.3341798941798942, 'test/precision_micro': 0.3492063492063492, 'test/recall_weighted': 0.3492063492063492, '_wandb': {'runtime': 1014}, 'test/f1_macro': 0.23625143513203217, 'test/recall_macro': 0.2368279569892473, 'eval/precision_micro': 0.4, '_runtime': 1015.4953088760376, 'eval/f1_macro': 0.2820767195767196, 'eval/recall_micro': 0.4, 'split': 10, 'eval/loss': 3.9996254308083983, '_timestamp': 1704298683.517604, 'eval/recall_macro': 0.3125, 'eval/precision_macro': 0.30514705882352944, 'test/accuracy': 0.3492063492063492, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.26904761904761904, '_step': 20, 'test/f1_weighted': 0.3339893936908863, 'test/recall_micro': 0.3492063492063492, 'eval/accuracy': 0.4, 'test/f1_micro': 0.3492063492063492, 'eval/precision_weighted': 0.3282352941176471, 'test/precision_weighted': 0.3420256991685563}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 16, 'dt_min_samples_leaf': 18}",silvery-meadow-495,DecisionTree,['pre-trained:bert-base-uncased']
836,"{'test/accuracy': 0.4126984126984127, 'test/f1_weighted': 0.26564495530012777, 'test/precision_macro': 0.11016949152542373, 'test/recall_weighted': 0.4126984126984127, '_step': 20, 'test/recall_micro': 0.4126984126984127, 'eval/recall_weighted': 0.36, '_timestamp': 1704298530.4888246, 'eval/recall_micro': 0.36, 'test/precision_micro': 0.4126984126984127, 'eval/f1_micro': 0.36, 'eval/recall_macro': 0.225, 'eval/precision_weighted': 0.15, '_wandb': {'runtime': 1002}, 'eval/accuracy': 0.36, 'eval/f1_weighted': 0.21176470588235297, 'test/recall_macro': 0.23214285714285715, 'eval/precision_micro': 0.36, 'test/precision_weighted': 0.1958568738229755, 'split': 10, 'test/loss': 1.304991290998266, 'test/f1_micro': 0.4126984126984127, 'test/f1_macro': 0.14942528735632185, '_runtime': 1003.8396465778352, 'eval/loss': 1.4135578254175818, 'eval/f1_macro': 0.13235294117647062, 'eval/precision_macro': 0.09375}","{'rf_max_depth': 3, 'trial.number': 16}",stellar-meadow-494,RandomForest,['pre-trained:bert-base-uncased']
837,"{'eval/accuracy': 0.4, 'test/precision_macro': 0.11475409836065574, '_timestamp': 1704298330.0972185, 'test/precision_weighted': 0.21129326047358837, 'split': 10, '_wandb': {'runtime': 1108}, '_runtime': 1110.025764465332, 'test/f1_macro': 0.15555555555555556, 'test/f1_micro': 0.4444444444444444, 'eval/precision_macro': 0.1, 'eval/recall_weighted': 0.4, '_step': 20, 'test/loss': 1.9452566482131808, 'test/recall_micro': 0.4444444444444444, 'eval/f1_micro': 0.4000000000000001, 'test/precision_micro': 0.4444444444444444, 'eval/precision_weighted': 0.16, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_micro': 0.4, 'test/f1_weighted': 0.28641975308641976, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.2413793103448276, 'eval/precision_micro': 0.4, 'eval/loss': 1.159746845488376, 'eval/f1_macro': 0.14285714285714288, 'test/accuracy': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 9, 'dt_min_samples_leaf': 10}",hardy-dream-493,DecisionTree,['pre-trained:openai-gpt']
838,"{'eval/f1_micro': 0.28, 'test/accuracy': 0.42857142857142855, 'test/f1_macro': 0.2637801696020874, 'test/f1_weighted': 0.3815011544952836, 'eval/recall_micro': 0.28, 'eval/f1_weighted': 0.2471794871794872, 'eval/recall_macro': 0.21666666666666667, 'test/recall_weighted': 0.42857142857142855, 'split': 10, 'eval/f1_macro': 0.2003205128205128, 'test/recall_micro': 0.42857142857142855, 'test/f1_micro': 0.42857142857142855, '_timestamp': 1704298353.4994178, 'eval/accuracy': 0.28, '_wandb': {'runtime': 1252}, '_runtime': 1253.8404047489166, 'eval/precision_macro': 0.2388392857142857, 'eval/precision_micro': 0.28, 'eval/precision_weighted': 0.2735714285714286, 'test/precision_weighted': 0.38535569266466274, '_step': 20, 'eval/loss': 1.7408499980300507, 'test/loss': 1.3760304434705677, 'test/recall_macro': 0.2833333333333333, 'eval/recall_weighted': 0.28, 'test/precision_macro': 0.28862126245847175, 'test/precision_micro': 0.42857142857142855}","{'dt_criterion': 'gini', 'dt_max_depth': 15, 'trial.number': 65, 'dt_min_samples_leaf': 23}",comic-plant-492,DecisionTree,['pre-trained:microsoft/codebert-base']
839,"{'test/accuracy': 0.31746031746031744, 'test/f1_micro': 0.31746031746031744, 'eval/precision_micro': 0.28, 'test/recall_weighted': 0.31746031746031744, 'eval/precision_weighted': 0.27194805194805194, 'split': 10, '_runtime': 1064.6570312976835, 'eval/loss': 25.951430440164348, 'eval/accuracy': 0.28, 'test/f1_macro': 0.24500866265159643, 'test/recall_micro': 0.31746031746031744, 'eval/f1_macro': 0.2368131868131868, 'eval/f1_micro': 0.28, 'eval/recall_micro': 0.28, 'eval/precision_macro': 0.23782467532467533, '_timestamp': 1704297810.7120602, 'test/precision_weighted': 0.34168425991086093, 'test/f1_weighted': 0.3239307878364062, 'eval/recall_weighted': 0.28, '_step': 20, 'test/loss': 24.60122374177838, 'eval/f1_weighted': 0.27305494505494504, 'test/recall_macro': 0.25738636363636364, 'test/precision_macro': 0.25073891625615763, '_wandb': {'runtime': 1063}, 'eval/recall_macro': 0.24166666666666667, 'test/precision_micro': 0.31746031746031744}","{'n_neighbours': 1, 'trial.number': 9}",absurd-frost-491,KNeighbours,['pre-trained:openai-gpt']
840,"{'test/f1_weighted': 0.3245525160418777, 'test/precision_micro': 0.492063492063492, '_runtime': 1023.4994125366212, 'test/recall_macro': 0.25, 'eval/f1_macro': 0.14285714285714288, 'test/accuracy': 0.492063492063492, 'test/precision_macro': 0.123015873015873, 'test/recall_weighted': 0.492063492063492, 'eval/loss': 1.3296549549719356, '_timestamp': 1704297663.6178446, 'eval/recall_macro': 0.25, 'eval/recall_weighted': 0.4, 'split': 10, 'test/loss': 1.275518815596098, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.22857142857142865, 'eval/precision_micro': 0.4, '_step': 20, 'test/f1_macro': 0.16489361702127658, 'test/recall_micro': 0.492063492063492, 'test/precision_weighted': 0.24212648022171832, '_wandb': {'runtime': 1022}, 'eval/precision_macro': 0.1, 'eval/precision_weighted': 0.16, 'test/f1_micro': 0.492063492063492, 'eval/recall_micro': 0.4, 'eval/accuracy': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 15, 'dt_min_samples_leaf': 95}",dulcet-breeze-490,DecisionTree,['pre-trained:bert-base-uncased']
841,"{'eval/f1_weighted': 0.30714285714285716, 'test/precision_micro': 0.4603174603174603, 'eval/precision_weighted': 0.2818181818181818, 'eval/recall_macro': 0.3, 'split': 10, 'test/loss': 1.2886612965739872, 'test/precision_weighted': 0.3333333333333333, '_step': 20, '_wandb': {'runtime': 1176}, '_timestamp': 1704297699.4058423, 'test/recall_macro': 0.2371323529411765, 'eval/precision_macro': 0.23863636363636365, '_runtime': 1177.5356936454773, 'test/accuracy': 0.4603174603174603, 'eval/loss': 1.3644443445682963, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.22767857142857145, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.20555555555555555, 'eval/recall_micro': 0.44, 'eval/precision_micro': 0.44, 'test/f1_micro': 0.4603174603174603, 'test/f1_weighted': 0.3611992945326279, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603}","{'rf_max_depth': 3, 'trial.number': 8}",grateful-haze-489,RandomForest,['pre-trained:openai-gpt']
842,"{'test/recall_macro': 0.2476890756302521, 'eval/recall_weighted': 0.28, 'eval/loss': 1.4810150077462143, 'test/f1_macro': 0.22879795396419433, 'test/precision_weighted': 0.33562271062271065, 'eval/precision_macro': 0.08333333333333333, 'test/precision_micro': 0.380952380952381, 'eval/precision_weighted': 0.13333333333333333, '_wandb': {'runtime': 1010}, 'eval/f1_micro': 0.28, 'test/recall_weighted': 0.380952380952381, '_step': 20, '_timestamp': 1704297521.261207, 'eval/accuracy': 0.28, 'test/f1_micro': 0.380952380952381, 'eval/recall_micro': 0.28, 'eval/precision_micro': 0.28, 'test/precision_macro': 0.2379807692307692, 'split': 10, '_runtime': 1011.466046333313, 'eval/f1_weighted': 0.18064516129032257, 'eval/recall_macro': 0.175, 'test/loss': 1.3480761461214028, 'eval/f1_macro': 0.1129032258064516, 'test/f1_weighted': 0.3400024357569114, 'test/recall_micro': 0.380952380952381, 'test/accuracy': 0.380952380952381}","{'rf_max_depth': 5, 'trial.number': 15}",scarlet-frog-488,RandomForest,['pre-trained:bert-base-uncased']
843,"{'eval/recall_micro': 0.24, 'test/recall_micro': 0.2698412698412698, 'eval/f1_macro': 0.2178321678321678, 'test/accuracy': 0.2698412698412698, 'eval/recall_macro': 0.21666666666666667, 'test/recall_weighted': 0.2698412698412698, '_wandb': {'runtime': 1115}, 'test/recall_macro': 0.23211391099322137, 'eval/precision_micro': 0.24, 'test/precision_micro': 0.2698412698412698, 'eval/precision_weighted': 0.24457142857142855, 'eval/f1_weighted': 0.2411188811188811, '_step': 20, 'split': 10, '_timestamp': 1704297215.3777492, 'eval/recall_weighted': 0.24, 'test/f1_macro': 0.23384604867377629, 'test/f1_micro': 0.2698412698412698, 'test/precision_weighted': 0.31664777021919877, 'test/precision_macro': 0.2571428571428571, 'eval/loss': 12.418375674928756, 'test/loss': 12.346877416542917, 'eval/f1_micro': 0.24, 'test/f1_weighted': 0.28520905764548093, 'eval/precision_macro': 0.22142857142857145, '_runtime': 1117.2451181411743, 'eval/accuracy': 0.24}","{'dt_criterion': 'gini', 'dt_max_depth': 18, 'trial.number': 8, 'dt_min_samples_leaf': 6}",crisp-universe-487,DecisionTree,['pre-trained:openai-gpt']
844,"{'test/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.24019607843137256, 'test/precision_weighted': 0.40816326530612246, 'test/loss': 1.898910952643904, 'test/f1_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, '_runtime': 1254.8809583187103, 'eval/recall_macro': 0.21666666666666667, 'test/recall_macro': 0.3333333333333333, 'test/precision_micro': 0.42857142857142855, '_step': 20, 'eval/loss': 3.1110615714852554, '_timestamp': 1704297095.3679163, 'test/accuracy': 0.42857142857142855, 'eval/recall_micro': 0.28, 'eval/recall_weighted': 0.28, 'split': 10, 'test/f1_weighted': 0.39340076206435654, 'test/precision_macro': 0.31646825396825395, 'test/f1_macro': 0.29601312665828794, 'eval/f1_micro': 0.28, 'eval/precision_weighted': 0.27098039215686276, 'eval/f1_macro': 0.20054713804713803, 'eval/accuracy': 0.28, 'eval/precision_micro': 0.28, '_wandb': {'runtime': 1253}, 'eval/f1_weighted': 0.24451178451178449}","{'dt_criterion': 'gini', 'dt_max_depth': 19, 'trial.number': 64, 'dt_min_samples_leaf': 27}",glamorous-frog-486,DecisionTree,['pre-trained:microsoft/codebert-base']
845,"{'_timestamp': 1704296742.573093, 'test/recall_micro': 0.4126984126984127, '_runtime': 1066.3431189060211, 'eval/f1_macro': 0.15555555555555556, 'test/f1_weighted': 0.3597069597069597, 'test/recall_macro': 0.26799242424242425, 'eval/precision_weighted': 0.2, 'test/precision_weighted': 0.3221466364323507, '_wandb': {'runtime': 1065}, 'split': 10, 'eval/accuracy': 0.28, 'test/accuracy': 0.4126984126984127, 'test/f1_macro': 0.24743589743589745, '_step': 20, 'eval/recall_micro': 0.28, 'eval/precision_micro': 0.28, 'test/precision_macro': 0.23492063492063492, 'eval/f1_weighted': 0.21333333333333332, 'test/loss': 18.54993883212806, 'eval/f1_micro': 0.28, 'eval/precision_macro': 0.15833333333333333, 'test/precision_micro': 0.4126984126984127, 'test/recall_weighted': 0.4126984126984127, 'eval/loss': 20.461704770129582, 'eval/recall_macro': 0.19166666666666665, 'eval/recall_weighted': 0.28, 'test/f1_micro': 0.4126984126984127}","{'n_neighbours': 2, 'trial.number': 8}",glorious-tree-485,KNeighbours,['pre-trained:openai-gpt']
846,"{'_runtime': 1023.610799074173, 'eval/accuracy': 0.32, 'eval/precision_weighted': 0.2016666666666667, '_timestamp': 1704296634.8187351, 'test/recall_macro': 0.3032258064516129, 'test/loss': 1.2745313625984234, 'eval/f1_macro': 0.1679487179487179, 'eval/precision_macro': 0.1371527777777778, 'eval/recall_weighted': 0.32, 'test/precision_micro': 0.3968253968253968, 'test/precision_weighted': 0.3150553150553151, '_wandb': {'runtime': 1022}, 'test/f1_macro': 0.2234375, 'split': 10, 'eval/f1_weighted': 0.24738461538461537, 'test/f1_weighted': 0.33978174603174605, 'eval/recall_micro': 0.32, 'test/recall_weighted': 0.3968253968253968, '_step': 20, 'eval/f1_micro': 0.32, 'test/accuracy': 0.3968253968253968, 'test/f1_micro': 0.3968253968253968, 'eval/recall_macro': 0.21666666666666665, 'test/recall_micro': 0.3968253968253968, 'eval/loss': 1.3605355632158649, 'eval/precision_micro': 0.32, 'test/precision_macro': 0.19393939393939397}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 14, 'dt_min_samples_leaf': 65}",grateful-sound-484,DecisionTree,['pre-trained:bert-base-uncased']
847,"{'_wandb': {'runtime': 1009}, 'eval/loss': 1.274136581220517, 'eval/f1_macro': 0.14285714285714288, 'test/f1_macro': 0.15294117647058825, 'eval/recall_weighted': 0.4, '_step': 20, 'test/f1_weighted': 0.27189542483660134, 'eval/precision_weighted': 0.16, 'split': 10, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.4, '_timestamp': 1704296504.7172053, 'eval/accuracy': 0.4, 'test/recall_macro': 0.23214285714285715, 'eval/precision_macro': 0.1, 'test/loss': 1.2948567991612576, 'test/f1_micro': 0.4126984126984127, 'test/recall_micro': 0.4126984126984127, 'test/precision_micro': 0.4126984126984127, 'eval/f1_micro': 0.4000000000000001, 'test/precision_macro': 0.11403508771929824, 'test/recall_weighted': 0.4126984126984127, '_runtime': 1010.844392299652, 'test/accuracy': 0.4126984126984127, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.202729044834308}","{'rf_max_depth': 2, 'trial.number': 14}",atomic-donkey-483,RandomForest,['pre-trained:bert-base-uncased']
848,"{'eval/recall_macro': 0.35416666666666663, 'test/precision_macro': 0.23414634146341465, '_step': 20, '_wandb': {'runtime': 1174}, '_runtime': 1175.6594405174255, 'test/loss': 2.8698641016930546, 'eval/f1_macro': 0.3772296544035674, 'eval/f1_weighted': 0.3989520624303234, 'eval/precision_macro': 0.44276556776556775, 'eval/loss': 4.174075902186906, '_timestamp': 1704296517.5726185, 'test/accuracy': 0.4126984126984127, 'test/recall_macro': 0.2627262443438914, 'test/recall_micro': 0.4126984126984127, 'eval/recall_weighted': 0.4, 'test/f1_macro': 0.24570048309178744, 'eval/recall_micro': 0.4, 'eval/precision_weighted': 0.43223443223443225, 'test/precision_weighted': 0.3562524196670539, 'test/f1_weighted': 0.38071926999463235, 'split': 10, 'eval/accuracy': 0.4, 'test/f1_micro': 0.4126984126984127, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.4126984126984127, 'eval/f1_micro': 0.4000000000000001, 'test/precision_micro': 0.4126984126984127}","{'rf_max_depth': 32, 'trial.number': 7}",generous-moon-482,RandomForest,['pre-trained:openai-gpt']
849,"{'eval/recall_macro': 0.44166666666666665, 'test/recall_macro': 0.3290229885057471, 'eval/precision_macro': 0.3863636363636363, 'test/precision_micro': 0.36507936507936506, '_step': 20, '_timestamp': 1704296093.34885, 'eval/f1_micro': 0.52, 'test/accuracy': 0.36507936507936506, 'test/f1_weighted': 0.32934683451924834, 'eval/recall_micro': 0.52, 'test/recall_weighted': 0.36507936507936506, '_runtime': 1116.1114959716797, 'test/loss': 1.3932605849330717, 'eval/accuracy': 0.52, 'test/f1_micro': 0.36507936507936506, 'eval/loss': 1.1606507351094577, 'eval/f1_weighted': 0.4857142857142857, 'test/recall_micro': 0.36507936507936506, 'eval/precision_weighted': 0.45818181818181813, 'split': 10, '_wandb': {'runtime': 1114}, 'eval/f1_macro': 0.4107142857142857, 'test/f1_macro': 0.28261494252873565, 'eval/precision_micro': 0.52, 'eval/recall_weighted': 0.52, 'test/precision_macro': 0.2511385199240987, 'test/precision_weighted': 0.3036836239872293}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 7, 'dt_min_samples_leaf': 44}",zesty-gorge-481,DecisionTree,['pre-trained:openai-gpt']
850,"{'test/precision_macro': 0.25073891625615763, '_runtime': 1063.764315366745, 'test/loss': 24.60122374177838, 'test/accuracy': 0.31746031746031744, 'test/f1_macro': 0.24500866265159643, 'eval/recall_macro': 0.24166666666666667, 'eval/recall_micro': 0.28, 'split': 10, '_timestamp': 1704295669.8018253, 'eval/loss': 25.951430440164348, 'eval/accuracy': 0.28, 'eval/precision_micro': 0.28, 'eval/f1_weighted': 0.27305494505494504, 'test/recall_micro': 0.31746031746031744, 'test/recall_macro': 0.25738636363636364, 'test/precision_weighted': 0.34168425991086093, 'eval/f1_micro': 0.28, 'test/f1_weighted': 0.3239307878364062, 'eval/recall_weighted': 0.28, 'test/precision_micro': 0.31746031746031744, '_step': 20, 'eval/f1_macro': 0.2368131868131868, 'eval/precision_weighted': 0.27194805194805194, 'test/f1_micro': 0.31746031746031744, 'eval/precision_macro': 0.23782467532467533, '_wandb': {'runtime': 1062}, 'test/recall_weighted': 0.31746031746031744}","{'n_neighbours': 1, 'trial.number': 7}",noble-haze-480,KNeighbours,['pre-trained:openai-gpt']
851,"{'test/precision_weighted': 0.3420256991685563, 'split': 10, 'eval/f1_weighted': 0.3341798941798942, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.3282352941176471, '_step': 20, 'eval/accuracy': 0.4, 'test/f1_micro': 0.3492063492063492, 'eval/precision_macro': 0.30514705882352944, 'test/precision_micro': 0.3492063492063492, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.3125, 'test/recall_macro': 0.2368279569892473, 'test/f1_weighted': 0.3339893936908863, 'test/recall_weighted': 0.3492063492063492, '_wandb': {'runtime': 1022}, 'eval/f1_macro': 0.2820767195767196, 'test/accuracy': 0.3492063492063492, '_timestamp': 1704295607.0161617, 'eval/recall_micro': 0.4, 'eval/loss': 3.9996254308083983, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.26904761904761904, 'test/recall_micro': 0.3492063492063492, '_runtime': 1023.7168686389924, 'test/loss': 6.656479460894657, 'test/f1_macro': 0.23625143513203217}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 13, 'dt_min_samples_leaf': 18}",daily-universe-479,DecisionTree,['pre-trained:bert-base-uncased']
852,"{'eval/f1_micro': 0.28, 'eval/recall_macro': 0.21666666666666667, 'test/recall_micro': 0.42857142857142855, 'eval/loss': 3.092916916476667, 'eval/accuracy': 0.28, 'test/recall_macro': 0.2833333333333333, 'eval/f1_weighted': 0.2471794871794872, 'test/f1_weighted': 0.3815011544952836, 'test/recall_weighted': 0.42857142857142855, 'test/f1_micro': 0.42857142857142855, 'test/precision_weighted': 0.38535569266466274, 'test/precision_micro': 0.42857142857142855, 'split': 10, 'eval/precision_macro': 0.2388392857142857, 'eval/recall_weighted': 0.28, 'test/accuracy': 0.42857142857142855, 'eval/precision_micro': 0.28, 'test/precision_macro': 0.28862126245847175, 'eval/precision_weighted': 0.2735714285714286, '_wandb': {'runtime': 1252}, '_runtime': 1253.7511048316956, 'test/loss': 1.878621827458272, 'test/f1_macro': 0.2637801696020874, 'eval/recall_micro': 0.28, '_step': 20, '_timestamp': 1704295835.271396, 'eval/f1_macro': 0.2003205128205128}","{'dt_criterion': 'gini', 'dt_max_depth': 18, 'trial.number': 63, 'dt_min_samples_leaf': 24}",earthy-totem-478,DecisionTree,['pre-trained:microsoft/codebert-base']
853,"{'test/loss': 1.3185537112910322, '_timestamp': 1704295486.041541, 'eval/accuracy': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.49388789505068575, 'test/precision_micro': 0.4126984126984127, 'eval/f1_macro': 0.26785714285714285, 'eval/f1_weighted': 0.34857142857142853, 'eval/recall_micro': 0.44, '_wandb': {'runtime': 1008}, 'eval/loss': 1.2958890668067802, 'test/recall_macro': 0.29816176470588235, 'test/recall_micro': 0.4126984126984127, 'test/recall_weighted': 0.4126984126984127, '_step': 20, '_runtime': 1009.5062243938446, 'eval/f1_micro': 0.44, 'eval/precision_macro': 0.2361111111111111, 'eval/precision_micro': 0.44, 'split': 10, 'test/f1_weighted': 0.3656636544981105, 'eval/precision_weighted': 0.2977777777777778, 'test/f1_macro': 0.29039940123834795, 'eval/recall_macro': 0.325, 'test/precision_weighted': 0.4584055049171328, 'test/accuracy': 0.4126984126984127, 'test/f1_micro': 0.4126984126984127}","{'rf_max_depth': 5, 'trial.number': 13}",deft-dew-477,RandomForest,['pre-trained:bert-base-uncased']
854,"{'test/precision_macro': 0.4016795865633075, 'eval/precision_weighted': 0.16428571428571426, '_step': 20, 'split': 10, 'eval/recall_weighted': 0.2, 'eval/f1_weighted': 0.17777777777777778, 'test/f1_weighted': 0.504888987861124, '_timestamp': 1704295338.0748134, 'eval/accuracy': 0.2, 'eval/f1_micro': 0.20000000000000004, 'test/f1_macro': 0.3701963671003919, 'test/accuracy': 0.5396825396825397, 'test/precision_micro': 0.5396825396825397, 'test/loss': 1.2298669902632422, 'eval/recall_micro': 0.2, 'eval/precision_macro': 0.13392857142857142, '_runtime': 1180.0678672790527, 'test/f1_micro': 0.5396825396825397, 'test/recall_macro': 0.36934389140271495, 'eval/f1_macro': 0.1388888888888889, 'eval/precision_micro': 0.2, 'test/recall_weighted': 0.5396825396825397, 'test/precision_weighted': 0.4992166030925721, '_wandb': {'runtime': 1178}, 'eval/loss': 1.564519837717712, 'eval/recall_macro': 0.15000000000000002, 'test/recall_micro': 0.5396825396825397}","{'rf_max_depth': 7, 'trial.number': 6}",gallant-fire-476,RandomForest,['pre-trained:openai-gpt']
855,"{'eval/f1_weighted': 0.14956521739130435, 'test/recall_micro': 0.2698412698412698, 'test/f1_micro': 0.2698412698412698, 'eval/precision_macro': 0.10096153846153846, 'split': 10, '_runtime': 1117.0853898525238, '_timestamp': 1704294974.3501108, 'test/f1_weighted': 0.2341029341029341, 'test/recall_macro': 0.1954022988505747, 'test/precision_micro': 0.2698412698412698, 'eval/loss': 1.4824089384976713, 'test/accuracy': 0.2698412698412698, 'eval/precision_micro': 0.2, 'test/recall_weighted': 0.2698412698412698, '_wandb': {'runtime': 1115}, 'eval/f1_macro': 0.12681159420289856, 'eval/f1_micro': 0.20000000000000004, 'test/f1_macro': 0.15378787878787878, 'eval/recall_macro': 0.175, 'eval/recall_micro': 0.2, 'test/precision_macro': 0.13608870967741937, 'test/precision_weighted': 0.2168458781362007, 'eval/accuracy': 0.2, '_step': 20, 'test/loss': 1.3744851134316307, 'eval/recall_weighted': 0.2, 'eval/precision_weighted': 0.12153846153846154}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 6, 'dt_min_samples_leaf': 70}",ancient-sea-475,DecisionTree,['pre-trained:openai-gpt']
856,"{'_runtime': 1022.9682323932648, 'eval/loss': 1.3605355632158649, 'test/accuracy': 0.3968253968253968, 'eval/f1_weighted': 0.24738461538461537, 'eval/precision_micro': 0.32, 'test/recall_weighted': 0.3968253968253968, '_step': 20, 'eval/f1_micro': 0.32, 'eval/recall_macro': 0.21666666666666665, 'eval/recall_micro': 0.32, 'eval/recall_weighted': 0.32, 'test/precision_macro': 0.19393939393939397, 'test/precision_weighted': 0.3150553150553151, '_wandb': {'runtime': 1021}, 'test/loss': 1.2745313625984234, 'test/recall_macro': 0.3032258064516129, 'test/precision_micro': 0.3968253968253968, 'eval/f1_macro': 0.1679487179487179, 'test/f1_micro': 0.3968253968253968, 'eval/precision_macro': 0.1371527777777778, 'split': 10, 'test/f1_weighted': 0.33978174603174605, '_timestamp': 1704294579.3975534, 'eval/accuracy': 0.32, 'test/f1_macro': 0.2234375, 'test/recall_micro': 0.3968253968253968, 'eval/precision_weighted': 0.2016666666666667}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 12, 'dt_min_samples_leaf': 62}",neat-sky-474,DecisionTree,['pre-trained:bert-base-uncased']
857,"{'eval/loss': 25.951430440164348, 'test/recall_micro': 0.31746031746031744, '_wandb': {'runtime': 1065}, '_runtime': 1067.0131978988647, 'eval/f1_micro': 0.28, 'test/f1_macro': 0.24500866265159643, 'eval/accuracy': 0.28, 'test/precision_weighted': 0.34168425991086093, 'test/recall_macro': 0.25738636363636364, 'eval/recall_weighted': 0.28, 'test/recall_weighted': 0.31746031746031744, '_step': 20, '_timestamp': 1704294601.1315098, 'eval/f1_macro': 0.2368131868131868, 'eval/f1_weighted': 0.27305494505494504, 'eval/recall_macro': 0.24166666666666667, 'test/f1_micro': 0.31746031746031744, 'test/precision_macro': 0.25073891625615763, 'test/precision_micro': 0.31746031746031744, 'eval/precision_weighted': 0.27194805194805194, 'eval/recall_micro': 0.28, 'eval/precision_micro': 0.28, 'split': 10, 'test/loss': 24.60122374177838, 'test/accuracy': 0.31746031746031744, 'test/f1_weighted': 0.3239307878364062, 'eval/precision_macro': 0.23782467532467533}","{'n_neighbours': 1, 'trial.number': 6}",ancient-frog-473,KNeighbours,['pre-trained:openai-gpt']
858,"{'_runtime': 1010.4383063316344, 'eval/recall_macro': 0.225, 'test/recall_micro': 0.5238095238095238, 'eval/f1_weighted': 0.21818181818181817, 'eval/loss': 1.3997397044331692, 'eval/f1_micro': 0.36, 'test/f1_macro': 0.33696172248803824, 'split': 10, 'eval/precision_macro': 0.09782608695652174, 'test/precision_micro': 0.5238095238095238, 'test/loss': 1.246900636195048, 'test/f1_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, '_wandb': {'runtime': 1009}, '_timestamp': 1704294473.0597212, 'test/precision_weighted': 0.5042328042328043, 'eval/precision_micro': 0.36, 'eval/recall_weighted': 0.36, 'test/precision_macro': 0.4104166666666667, 'test/accuracy': 0.5238095238095238, 'test/f1_weighted': 0.4498367129946077, 'eval/recall_micro': 0.36, 'test/recall_macro': 0.3659663865546219, 'eval/precision_weighted': 0.1565217391304348, '_step': 20, 'eval/accuracy': 0.36, 'eval/f1_macro': 0.13636363636363635}","{'rf_max_depth': 4, 'trial.number': 12}",silver-haze-472,RandomForest,['pre-trained:bert-base-uncased']
859,"{'eval/precision_micro': 0.28, 'test/precision_macro': 0.30238095238095236, 'test/f1_macro': 0.29498082562598693, 'test/recall_macro': 0.3333333333333333, 'eval/precision_macro': 0.20312499999999997, 'test/precision_micro': 0.42857142857142855, '_runtime': 1254.477402925491, 'eval/f1_micro': 0.28, 'eval/loss': 1.7791070521412888, 'test/recall_micro': 0.42857142857142855, 'eval/recall_weighted': 0.28, 'eval/f1_macro': 0.19716394716394717, 'eval/recall_micro': 0.28, 'eval/f1_weighted': 0.24354312354312355, 'test/accuracy': 0.42857142857142855, '_wandb': {'runtime': 1253}, 'eval/accuracy': 0.28, 'test/f1_micro': 0.42857142857142855, 'test/precision_weighted': 0.3983371126228269, '_step': 20, '_timestamp': 1704294578.0395858, 'test/f1_weighted': 0.394526620333072, 'eval/recall_macro': 0.21666666666666667, 'test/recall_weighted': 0.42857142857142855, 'eval/precision_weighted': 0.2383333333333333, 'split': 10, 'test/loss': 1.32614138813784}","{'dt_criterion': 'gini', 'dt_max_depth': 17, 'trial.number': 62, 'dt_min_samples_leaf': 31}",astral-microwave-471,DecisionTree,['pre-trained:microsoft/codebert-base']
860,"{'_wandb': {'runtime': 1176}, 'eval/f1_weighted': 0.3060606060606061, 'eval/recall_weighted': 0.36, 'test/recall_weighted': 0.3492063492063492, 'eval/f1_micro': 0.36, 'eval/recall_macro': 0.275, 'eval/precision_weighted': 0.26666666666666666, '_timestamp': 1704294153.317583, 'eval/f1_macro': 0.23674242424242423, 'test/precision_weighted': 0.37356100689434024, '_step': 20, 'split': 10, 'test/accuracy': 0.3492063492063492, 'test/recall_macro': 0.23331447963800905, 'eval/precision_micro': 0.36, 'eval/loss': 3.972204928558421, 'test/f1_macro': 0.2390777754583725, 'eval/recall_micro': 0.36, 'test/recall_micro': 0.3492063492063492, 'test/precision_macro': 0.25754419191919187, '_runtime': 1178.2248313426971, 'test/loss': 3.983747705406313, 'test/f1_micro': 0.3492063492063492, 'test/precision_micro': 0.3492063492063492, 'eval/accuracy': 0.36, 'test/f1_weighted': 0.3576147456744472, 'eval/precision_macro': 0.20833333333333331}","{'rf_max_depth': 23, 'trial.number': 5}",eager-planet-470,RandomForest,['pre-trained:openai-gpt']
861,"{'split': 10, 'eval/accuracy': 0.48, 'test/accuracy': 0.36507936507936506, 'eval/recall_macro': 0.35, 'test/precision_macro': 0.15416666666666667, 'eval/f1_micro': 0.48, 'eval/precision_micro': 0.48, '_step': 20, 'eval/loss': 1.1998380080609297, 'test/loss': 1.363290292539984, '_timestamp': 1704293852.4747825, 'eval/precision_macro': 0.24342105263157893, '_runtime': 1117.2426793575287, 'test/recall_macro': 0.2557471264367816, 'eval/recall_weighted': 0.48, 'test/precision_micro': 0.36507936507936506, 'eval/precision_weighted': 0.3094736842105263, 'eval/f1_weighted': 0.3682758620689656, 'test/f1_weighted': 0.27484023912595346, 'test/recall_micro': 0.36507936507936506, 'test/f1_macro': 0.19237012987012989, 'test/f1_micro': 0.36507936507936506, 'test/recall_weighted': 0.36507936507936506, 'test/precision_weighted': 0.2203703703703704, '_wandb': {'runtime': 1115}, 'eval/f1_macro': 0.2801724137931034, 'eval/recall_micro': 0.48}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 5, 'dt_min_samples_leaf': 75}",polished-donkey-469,DecisionTree,['pre-trained:openai-gpt']
862,"{'eval/recall_micro': 0.36, 'eval/precision_micro': 0.36, 'eval/recall_weighted': 0.36, 'test/precision_macro': 0.1482843137254902, 'split': 10, 'test/f1_macro': 0.18126385809312637, 'eval/precision_macro': 0.09375, 'test/precision_micro': 0.42857142857142855, 'eval/f1_micro': 0.36, 'test/f1_weighted': 0.32647027768978987, 'test/recall_weighted': 0.42857142857142855, 'eval/loss': 1.4044902447444871, 'eval/f1_weighted': 0.21176470588235297, 'eval/f1_macro': 0.13235294117647062, 'test/recall_micro': 0.42857142857142855, '_timestamp': 1704293552.2049146, 'test/accuracy': 0.42857142857142855, 'eval/recall_macro': 0.225, 'eval/precision_weighted': 0.15, 'eval/accuracy': 0.36, 'test/f1_micro': 0.42857142857142855, 'test/recall_macro': 0.2346774193548387, 'test/precision_weighted': 0.26408341114223466, '_runtime': 1023.659042596817, 'test/loss': 1.334079841552857, '_step': 20, '_wandb': {'runtime': 1022}}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 11, 'dt_min_samples_leaf': 58}",curious-breeze-468,DecisionTree,['pre-trained:bert-base-uncased']
863,"{'eval/precision_weighted': 0.29555555555555557, 'split': 10, 'eval/loss': 13.553247530326276, 'eval/f1_weighted': 0.30133333333333334, 'test/recall_macro': 0.3568181818181818, 'eval/precision_macro': 0.24305555555555555, 'test/precision_micro': 0.47619047619047616, '_runtime': 1068.934963464737, 'test/f1_weighted': 0.42697219238572626, 'test/recall_micro': 0.47619047619047616, 'test/accuracy': 0.47619047619047616, 'test/f1_micro': 0.47619047619047616, 'eval/recall_weighted': 0.36, '_wandb': {'runtime': 1067}, 'test/loss': 12.005203269732986, '_timestamp': 1704293529.0784276, 'eval/f1_macro': 0.23055555555555557, 'test/f1_macro': 0.3293233082706767, 'eval/recall_macro': 0.2583333333333333, 'eval/precision_micro': 0.36, 'test/precision_macro': 0.3478682170542636, 'test/recall_weighted': 0.47619047619047616, '_step': 20, 'eval/accuracy': 0.36, 'eval/f1_micro': 0.36, 'eval/recall_micro': 0.36, 'test/precision_weighted': 0.4140519256798327}","{'n_neighbours': 4, 'trial.number': 5}",polished-pyramid-467,KNeighbours,['pre-trained:openai-gpt']
864,"{'eval/accuracy': 0.36, 'eval/f1_macro': 0.13235294117647062, 'eval/recall_weighted': 0.36, '_step': 20, 'test/loss': 1.2838450257023828, 'test/precision_micro': 0.4444444444444444, 'eval/precision_micro': 0.36, 'test/precision_weighted': 0.19753086419753085, '_wandb': {'runtime': 1009}, 'eval/f1_micro': 0.36, 'test/recall_micro': 0.4444444444444444, 'test/accuracy': 0.4444444444444444, 'test/f1_macro': 0.15384615384615383, 'eval/recall_micro': 0.36, '_runtime': 1011.189738035202, 'eval/loss': 1.3386023172196075, '_timestamp': 1704293457.923226, 'test/f1_weighted': 0.2735042735042735, 'eval/recall_macro': 0.225, 'test/recall_macro': 0.25, 'test/f1_micro': 0.4444444444444444, 'eval/precision_macro': 0.09375, 'test/recall_weighted': 0.4444444444444444, 'split': 10, 'eval/f1_weighted': 0.21176470588235297, 'test/precision_macro': 0.1111111111111111, 'eval/precision_weighted': 0.15}","{'rf_max_depth': 2, 'trial.number': 11}",misty-forest-466,RandomForest,['pre-trained:bert-base-uncased']
865,"{'split': 10, 'eval/f1_weighted': 0.24354312354312355, 'test/f1_weighted': 0.394526620333072, 'eval/precision_micro': 0.28, 'test/precision_macro': 0.30238095238095236, 'test/precision_weighted': 0.3983371126228269, 'eval/accuracy': 0.28, 'eval/f1_macro': 0.19716394716394717, 'test/recall_macro': 0.3333333333333333, '_wandb': {'runtime': 1253}, 'test/f1_macro': 0.29498082562598693, 'eval/precision_macro': 0.20312499999999997, 'test/precision_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, 'eval/recall_weighted': 0.28, '_step': 20, '_timestamp': 1704293318.4928553, 'test/accuracy': 0.42857142857142855, 'eval/f1_micro': 0.28, 'eval/recall_macro': 0.21666666666666667, 'eval/recall_micro': 0.28, 'test/recall_micro': 0.42857142857142855, '_runtime': 1254.8143184185028, 'eval/loss': 1.5609715043432888, 'test/loss': 1.337114875930426, 'test/f1_micro': 0.42857142857142855, 'eval/precision_weighted': 0.2383333333333333}","{'dt_criterion': 'gini', 'dt_max_depth': 15, 'trial.number': 61, 'dt_min_samples_leaf': 33}",stoic-fog-465,DecisionTree,['pre-trained:microsoft/codebert-base']
866,"{'test/f1_macro': 0.2779017857142857, 'test/recall_micro': 0.3492063492063492, 'test/accuracy': 0.3492063492063492, 'eval/f1_macro': 0.305012077294686, 'test/precision_micro': 0.3492063492063492, 'eval/loss': 4.084450234361339, 'test/loss': 1.402759703685188, 'eval/f1_weighted': 0.31957487922705313, 'eval/recall_micro': 0.32, 'test/recall_weighted': 0.3492063492063492, '_step': 20, 'eval/precision_macro': 0.3269230769230769, 'eval/f1_micro': 0.32, 'test/f1_weighted': 0.36106386999244144, 'eval/precision_weighted': 0.33307692307692305, 'split': 10, '_runtime': 1177.1343562602997, 'eval/accuracy': 0.32, 'test/f1_micro': 0.3492063492063492, 'eval/recall_macro': 0.29583333333333334, 'test/precision_macro': 0.28882575757575757, 'test/precision_weighted': 0.3819143819143819, '_wandb': {'runtime': 1175}, 'test/recall_macro': 0.28096719457013575, 'eval/recall_weighted': 0.32, '_timestamp': 1704292970.2546532, 'eval/precision_micro': 0.32}","{'rf_max_depth': 17, 'trial.number': 4}",faithful-sun-464,RandomForest,['pre-trained:openai-gpt']
867,"{'_runtime': 1131.0233302116394, 'test/f1_weighted': 0.416558491351452, 'eval/recall_micro': 0.48, 'test/recall_weighted': 0.4444444444444444, 'eval/recall_macro': 0.3666666666666667, 'test/recall_micro': 0.4444444444444444, 'eval/recall_weighted': 0.48, 'eval/loss': 1.108181227884577, 'eval/accuracy': 0.48, 'eval/f1_macro': 0.3588636363636364, '_wandb': {'runtime': 1129}, '_timestamp': 1704292730.3732722, 'test/accuracy': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, 'test/precision_weighted': 0.4331409331409331, 'eval/precision_macro': 0.4083333333333333, 'test/precision_micro': 0.4444444444444444, 'split': 10, 'test/loss': 10.481925636088633, 'eval/f1_micro': 0.48, 'eval/precision_micro': 0.48, 'test/precision_macro': 0.4053030303030303, '_step': 20, 'test/f1_macro': 0.37903295376121465, 'eval/f1_weighted': 0.44690909090909087, 'test/recall_macro': 0.4088380489242558, 'eval/precision_weighted': 0.4773333333333334}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 4, 'dt_min_samples_leaf': 7}",divine-star-463,DecisionTree,['pre-trained:openai-gpt']
868,"{'eval/f1_macro': 0.14638157894736842, '_timestamp': 1704292674.0192337, 'test/precision_weighted': 0.4467120181405896, 'test/f1_macro': 0.28065953654188946, 'eval/recall_macro': 0.19545454545454544, 'split': 10, 'test/loss': 11.281685211416525, 'eval/recall_micro': 0.2, 'test/recall_micro': 0.31746031746031744, 'eval/precision_micro': 0.2, 'eval/recall_weighted': 0.2, 'test/precision_macro': 0.3257575757575758, 'eval/loss': 6.612299397161262, 'eval/f1_weighted': 0.16763157894736844, 'test/f1_weighted': 0.3400729988965283, 'test/recall_macro': 0.2946775446775447, 'eval/f1_micro': 0.20000000000000004, '_runtime': 1133.9320013523102, 'test/f1_micro': 0.31746031746031744, 'eval/precision_weighted': 0.16454545454545452, '_step': 20, '_wandb': {'runtime': 1132}, 'eval/precision_macro': 0.13068181818181818, 'test/precision_micro': 0.31746031746031744, 'test/recall_weighted': 0.31746031746031744, 'eval/accuracy': 0.2, 'test/accuracy': 0.31746031746031744}","{'smoothing': 0.5376291925046077, 'trial.number': 4}",genial-plant-462,Bernolli,['pre-trained:openai-gpt']
869,"{'_wandb': {'runtime': 1029}, 'eval/loss': 1.3605355632158649, 'eval/f1_macro': 0.1679487179487179, 'test/f1_weighted': 0.33978174603174605, 'eval/recall_weighted': 0.32, 'test/precision_micro': 0.3968253968253968, 'test/loss': 1.2745313625984234, '_timestamp': 1704292523.4644277, 'test/f1_micro': 0.3968253968253968, 'test/recall_micro': 0.3968253968253968, 'eval/f1_micro': 0.32, 'test/recall_macro': 0.3032258064516129, 'eval/precision_macro': 0.1371527777777778, 'test/recall_weighted': 0.3968253968253968, 'test/accuracy': 0.3968253968253968, 'test/f1_macro': 0.2234375, 'eval/recall_micro': 0.32, 'eval/accuracy': 0.32, 'eval/precision_micro': 0.32, 'eval/precision_weighted': 0.2016666666666667, '_step': 20, '_runtime': 1030.9908876419067, 'eval/f1_weighted': 0.24738461538461537, 'split': 10, 'test/precision_macro': 0.19393939393939397, 'eval/recall_macro': 0.21666666666666665, 'test/precision_weighted': 0.3150553150553151}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 10, 'dt_min_samples_leaf': 100}",fallen-energy-461,DecisionTree,['pre-trained:bert-base-uncased']
870,"{'_step': 20, 'eval/accuracy': 0.28, 'eval/recall_weighted': 0.28, 'test/precision_macro': 0.30753968253968256, 'test/precision_micro': 0.380952380952381, 'split': 10, '_runtime': 1019.2785642147064, 'test/f1_macro': 0.27226194857773806, 'test/f1_weighted': 0.33928878139404456, 'test/recall_micro': 0.380952380952381, 'eval/loss': 2.829783569949163, 'test/loss': 2.448004932508523, 'test/accuracy': 0.380952380952381, 'eval/f1_weighted': 0.2177777777777778, 'eval/f1_micro': 0.28, 'test/f1_micro': 0.380952380952381, 'eval/precision_weighted': 0.1811764705882353, '_wandb': {'runtime': 1017}, 'eval/f1_macro': 0.16111111111111112, 'eval/recall_macro': 0.2, 'eval/recall_micro': 0.28, 'eval/precision_macro': 0.13823529411764707, 'eval/precision_micro': 0.28, 'test/recall_weighted': 0.380952380952381, '_timestamp': 1704292442.3893063, 'test/recall_macro': 0.2803046218487395, 'test/precision_weighted': 0.3386243386243386}","{'rf_max_depth': 26, 'trial.number': 10}",decent-dew-460,RandomForest,['pre-trained:bert-base-uncased']
871,"{'test/precision_macro': 0.25073891625615763, 'test/recall_weighted': 0.31746031746031744, 'split': 10, 'test/accuracy': 0.31746031746031744, 'test/f1_macro': 0.24500866265159643, 'eval/recall_micro': 0.28, '_step': 20, 'test/f1_micro': 0.31746031746031744, 'test/f1_weighted': 0.3239307878364062, 'eval/precision_micro': 0.28, 'test/recall_micro': 0.31746031746031744, '_wandb': {'runtime': 1078}, 'eval/accuracy': 0.28, 'eval/f1_micro': 0.28, 'eval/recall_macro': 0.24166666666666667, '_runtime': 1079.945491552353, 'test/loss': 24.60122374177838, '_timestamp': 1704292455.4602215, 'eval/precision_macro': 0.23782467532467533, 'eval/recall_weighted': 0.28, 'test/precision_micro': 0.31746031746031744, 'eval/loss': 25.951430440164348, 'eval/f1_weighted': 0.27305494505494504, 'test/precision_weighted': 0.34168425991086093, 'eval/f1_macro': 0.2368131868131868, 'test/recall_macro': 0.25738636363636364, 'eval/precision_weighted': 0.27194805194805194}","{'n_neighbours': 1, 'trial.number': 4}",zesty-frog-459,KNeighbours,['pre-trained:openai-gpt']
872,"{'test/f1_weighted': 0.394526620333072, 'eval/recall_macro': 0.21666666666666667, 'test/recall_micro': 0.42857142857142855, '_runtime': 1256.1448428630829, 'eval/recall_micro': 0.28, 'test/recall_macro': 0.3333333333333333, 'eval/precision_macro': 0.20312499999999997, 'test/precision_weighted': 0.3983371126228269, 'eval/loss': 1.803922042531786, 'eval/accuracy': 0.28, '_step': 20, 'test/loss': 1.3491318246994408, 'eval/precision_micro': 0.28, 'test/f1_micro': 0.42857142857142855, '_wandb': {'runtime': 1254}, 'eval/f1_macro': 0.19716394716394717, 'test/f1_macro': 0.29498082562598693, 'test/precision_micro': 0.42857142857142855, 'eval/precision_weighted': 0.2383333333333333, '_timestamp': 1704292059.848342, 'eval/f1_micro': 0.28, 'test/accuracy': 0.42857142857142855, 'eval/f1_weighted': 0.24354312354312355, 'eval/recall_weighted': 0.28, 'test/recall_weighted': 0.42857142857142855, 'split': 10, 'test/precision_macro': 0.30238095238095236}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 60, 'dt_min_samples_leaf': 28}",exalted-oath-458,DecisionTree,['pre-trained:microsoft/codebert-base']
873,"{'test/f1_weighted': 0.404322863897332, 'test/precision_micro': 0.5396825396825397, 'eval/recall_weighted': 0.36, '_step': 20, 'test/accuracy': 0.5396825396825397, 'test/loss': 1.2462345805244963, '_timestamp': 1704291788.6080513, 'test/f1_micro': 0.5396825396825397, 'test/recall_macro': 0.27389705882352944, 'test/precision_macro': 0.2625, 'test/precision_weighted': 0.3603174603174604, 'split': 10, 'eval/recall_micro': 0.36, 'eval/precision_macro': 0.10227272727272728, 'eval/precision_weighted': 0.16363636363636364, '_wandb': {'runtime': 1194}, 'eval/loss': 1.2996343476570875, 'eval/accuracy': 0.36, 'eval/f1_macro': 0.14062500000000003, 'test/f1_macro': 0.225531914893617, 'eval/f1_weighted': 0.22500000000000003, 'test/recall_weighted': 0.5396825396825397, '_runtime': 1195.3495213985443, 'eval/f1_micro': 0.36, 'eval/recall_macro': 0.225, 'test/recall_micro': 0.5396825396825397, 'eval/precision_micro': 0.36}","{'rf_max_depth': 2, 'trial.number': 3}",rich-dust-457,RandomForest,['pre-trained:openai-gpt']
874,"{'split': 10, 'eval/loss': 1.518229429065357, 'test/loss': 1.4808276177471222, 'test/recall_macro': 0.29109563807839667, 'test/precision_macro': 0.2685185185185185, '_runtime': 1137.7948234081268, '_timestamp': 1704291594.5181017, 'eval/f1_macro': 0.20526315789473687, 'test/f1_micro': 0.3333333333333333, '_wandb': {'runtime': 1136}, 'eval/precision_micro': 0.28, 'eval/recall_weighted': 0.28, '_step': 20, 'eval/f1_micro': 0.28, 'test/precision_micro': 0.3333333333333333, 'test/precision_weighted': 0.3374485596707819, 'eval/precision_macro': 0.1944444444444444, 'test/accuracy': 0.3333333333333333, 'test/f1_macro': 0.2683381433381433, 'test/f1_weighted': 0.328145399573971, 'eval/recall_micro': 0.28, 'eval/recall_macro': 0.225, 'test/recall_micro': 0.3333333333333333, 'eval/accuracy': 0.28, 'eval/f1_weighted': 0.264421052631579, 'test/recall_weighted': 0.3333333333333333, 'eval/precision_weighted': 0.2577777777777778}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 3, 'dt_min_samples_leaf': 22}",whole-universe-456,DecisionTree,['pre-trained:openai-gpt']
875,"{'eval/precision_macro': 0.175, 'eval/f1_macro': 0.20166666666666663, 'test/f1_weighted': 0.1794729587741529, 'eval/recall_macro': 0.24166666666666667, 'test/precision_micro': 0.1746031746031746, 'eval/loss': 13.556624840449103, 'test/accuracy': 0.1746031746031746, 'test/recall_micro': 0.1746031746031746, 'eval/recall_micro': 0.36, 'eval/precision_micro': 0.36, 'eval/precision_weighted': 0.2533333333333333, '_wandb': {'runtime': 1033}, 'eval/accuracy': 0.36, 'eval/f1_micro': 0.36, 'test/precision_weighted': 0.1917165726689536, 'split': 10, '_runtime': 1034.8771150112152, 'test/precision_macro': 0.14041514041514042, 'test/recall_weighted': 0.1746031746031746, 'test/loss': 22.603966725079612, 'eval/f1_weighted': 0.29600000000000004, 'eval/recall_weighted': 0.36, 'test/f1_micro': 0.1746031746031746, '_step': 20, '_timestamp': 1704291488.422911, 'test/f1_macro': 0.13530148901665928, 'test/recall_macro': 0.13951612903225807}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 9, 'dt_min_samples_leaf': 6}",sweet-water-455,DecisionTree,['pre-trained:bert-base-uncased']
876,"{'eval/loss': 6.52460388337008, 'eval/precision_micro': 0.2, 'eval/recall_weighted': 0.2, 'test/recall_weighted': 0.31746031746031744, 'test/precision_micro': 0.31746031746031744, '_timestamp': 1704291534.8996751, 'eval/accuracy': 0.2, 'eval/recall_micro': 0.2, 'test/recall_micro': 0.31746031746031744, 'test/f1_macro': 0.2817035905271199, 'test/f1_micro': 0.31746031746031744, 'test/recall_macro': 0.2946775446775447, 'eval/precision_weighted': 0.16454545454545452, '_step': 20, '_runtime': 1134.833475112915, 'eval/recall_macro': 0.19545454545454544, 'test/precision_macro': 0.3326086956521739, 'test/loss': 11.227114740164922, 'test/accuracy': 0.31746031746031744, 'eval/f1_weighted': 0.16763157894736844, 'split': 10, '_wandb': {'runtime': 1133}, 'eval/f1_micro': 0.20000000000000004, 'test/f1_weighted': 0.34049983629815567, 'eval/precision_macro': 0.13068181818181818, 'eval/f1_macro': 0.14638157894736842, 'test/precision_weighted': 0.4504387262151238}","{'smoothing': 0.4842414465677245, 'trial.number': 3}",fresh-fire-454,Bernolli,['pre-trained:openai-gpt']
877,"{'_wandb': {'runtime': 1020}, 'test/f1_weighted': 0.35209235209235207, 'test/recall_macro': 0.23739495798319327, 'eval/loss': 1.575995380824885, 'test/loss': 2.9807417194098376, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.40470588235294114, '_step': 20, 'split': 10, '_runtime': 1022.1487505435944, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.23376623376623373, 'test/recall_micro': 0.380952380952381, 'test/precision_micro': 0.380952380952381, 'eval/f1_macro': 0.3296296296296296, 'test/f1_micro': 0.380952380952381, 'eval/recall_micro': 0.4, 'test/precision_weighted': 0.4275132275132275, 'test/accuracy': 0.380952380952381, 'eval/recall_macro': 0.3375, 'test/precision_macro': 0.319047619047619, '_timestamp': 1704291419.3370397, 'eval/accuracy': 0.4, 'eval/precision_micro': 0.4, 'eval/f1_weighted': 0.3514074074074074, 'eval/precision_macro': 0.45294117647058824, 'test/recall_weighted': 0.380952380952381}","{'rf_max_depth': 11, 'trial.number': 9}",lilac-serenity-453,RandomForest,['pre-trained:bert-base-uncased']
878,"{'eval/f1_weighted': 0.2323809523809524, 'test/f1_weighted': 0.23420120736466632, 'eval/recall_macro': 0.18333333333333335, 'eval/recall_micro': 0.24, 'test/precision_micro': 0.23809523809523808, 'split': 10, '_timestamp': 1704291325.2689424, 'eval/f1_macro': 0.17857142857142858, 'test/precision_macro': 0.20510912698412695, 'eval/precision_weighted': 0.22545454545454544, '_step': 20, 'eval/f1_micro': 0.24, 'test/f1_macro': 0.21089726213065868, '_runtime': 1009.8788464069366, 'eval/loss': 27.393176575729036, 'test/recall_macro': 0.23333333333333336, 'test/loss': 27.461831153613076, 'test/accuracy': 0.23809523809523808, 'test/recall_micro': 0.23809523809523808, 'eval/precision_macro': 0.17424242424242423, 'test/recall_weighted': 0.23809523809523808, 'eval/recall_weighted': 0.24, '_wandb': {'runtime': 1008}, 'eval/accuracy': 0.24, 'eval/precision_micro': 0.24, 'test/f1_micro': 0.23809523809523808, 'test/precision_weighted': 0.24573255228017135}","{'n_neighbours': 1, 'trial.number': 9}",proud-night-452,KNeighbours,['pre-trained:bert-base-uncased']
879,"{'test/accuracy': 0.3333333333333333, 'test/f1_weighted': 0.2894736842105264, 'eval/precision_macro': 0.225, 'test/precision_weighted': 0.25581395348837205, '_timestamp': 1704291371.257556, 'test/loss': 6.229021513540017, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.30933333333333335, 'test/recall_weighted': 0.3333333333333333, 'split': 10, 'eval/recall_macro': 0.2833333333333333, 'test/precision_micro': 0.3333333333333333, 'eval/accuracy': 0.4, 'eval/recall_weighted': 0.4, 'test/recall_macro': 0.1590909090909091, '_step': 20, '_runtime': 1086.6933360099792, 'eval/f1_macro': 0.23333333333333336, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.3333333333333333, 'test/precision_macro': 0.12209302325581396, '_wandb': {'runtime': 1085}, 'eval/precision_weighted': 0.28, 'test/f1_macro': 0.13815789473684212, 'test/f1_micro': 0.3333333333333333, 'eval/precision_micro': 0.4, 'eval/loss': 2.621309268473446}","{'n_neighbours': 9, 'trial.number': 3}",earthy-thunder-451,KNeighbours,['pre-trained:openai-gpt']
880,"{'test/loss': 2.491956299236284, 'test/f1_weighted': 0.3566919191919192, 'eval/f1_micro': 0.28, 'eval/f1_weighted': 0.2533333333333333, 'eval/recall_micro': 0.28, 'test/precision_micro': 0.380952380952381, 'test/precision_weighted': 0.3353563647681295, 'eval/loss': 3.1476298130154903, 'eval/accuracy': 0.28, 'eval/precision_macro': 0.20476190476190476, 'eval/recall_weighted': 0.28, 'test/recall_micro': 0.380952380952381, 'test/recall_weighted': 0.380952380952381, '_step': 20, '_wandb': {'runtime': 1251}, 'eval/precision_weighted': 0.23428571428571424, '_timestamp': 1704290798.9379714, 'test/f1_micro': 0.380952380952381, 'test/recall_macro': 0.25833333333333336, 'eval/precision_micro': 0.28, 'eval/f1_macro': 0.21666666666666667, 'test/accuracy': 0.380952380952381, 'test/f1_macro': 0.2414772727272727, 'eval/recall_macro': 0.23333333333333336, 'test/precision_macro': 0.2267156862745098, 'split': 10, '_runtime': 1253.176804304123}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 59, 'dt_min_samples_leaf': 19}",dry-wood-450,DecisionTree,['pre-trained:microsoft/codebert-base']
881,"{'test/f1_micro': 0.42857142857142855, 'eval/recall_macro': 0.225, 'eval/precision_weighted': 0.15, 'eval/accuracy': 0.36, 'eval/f1_micro': 0.36, '_wandb': {'runtime': 1033}, 'test/f1_macro': 0.18126385809312637, 'test/accuracy': 0.42857142857142855, 'eval/precision_micro': 0.36, 'test/precision_macro': 0.1482843137254902, 'eval/loss': 1.504645062538489, 'eval/f1_macro': 0.13235294117647062, '_step': 20, 'test/loss': 1.4063049016891371, '_timestamp': 1704290449.8812592, 'eval/f1_weighted': 0.21176470588235297, 'test/precision_weighted': 0.26408341114223466, 'eval/recall_micro': 0.36, 'test/recall_weighted': 0.42857142857142855, 'eval/recall_weighted': 0.36, 'test/f1_weighted': 0.32647027768978987, 'test/recall_micro': 0.42857142857142855, 'test/recall_macro': 0.2346774193548387, 'eval/precision_macro': 0.09375, 'test/precision_micro': 0.42857142857142855, 'split': 10, '_runtime': 1035.1815831661224}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 8, 'dt_min_samples_leaf': 41}",vibrant-capybara-449,DecisionTree,['pre-trained:bert-base-uncased']
882,"{'eval/loss': 1.3178220932846365, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_macro': 0.25, 'test/loss': 1.2412926271091036, 'test/recall_macro': 0.2426470588235294, 'eval/precision_weighted': 0.16, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.13983050847457626, 'test/recall_weighted': 0.5238095238095238, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.5238095238095238, '_timestamp': 1704290586.544891, 'eval/accuracy': 0.4, 'eval/precision_macro': 0.1, 'test/precision_micro': 0.5238095238095238, 'test/precision_weighted': 0.30185633575464077, '_wandb': {'runtime': 1195}, '_runtime': 1197.0125880241394, 'test/f1_macro': 0.17741935483870966, 'test/f1_micro': 0.5238095238095238, 'test/f1_weighted': 0.38300051203277, 'eval/f1_macro': 0.14285714285714288, 'test/accuracy': 0.5238095238095238, '_step': 20, 'split': 10}","{'rf_max_depth': 2, 'trial.number': 2}",radiant-snowflake-448,RandomForest,['pre-trained:openai-gpt']
883,"{'eval/f1_micro': 0.32, '_wandb': {'runtime': 1022}, '_runtime': 1023.3624846935272, 'eval/accuracy': 0.32, 'eval/f1_macro': 0.12903225806451613, '_timestamp': 1704290391.7290118, 'test/recall_macro': 0.2111344537815126, 'eval/recall_micro': 0.32, 'test/precision_weighted': 0.25549450549450553, 'split': 10, 'eval/recall_macro': 0.2, 'eval/precision_micro': 0.32, 'test/precision_micro': 0.36507936507936506, '_step': 20, 'eval/loss': 1.4130968324736322, 'test/recall_micro': 0.36507936507936506, 'eval/precision_weighted': 0.15238095238095237, 'test/f1_macro': 0.16130952380952382, 'test/f1_micro': 0.36507936507936506, 'eval/precision_macro': 0.09523809523809525, 'test/precision_macro': 0.16826923076923078, 'test/recall_weighted': 0.36507936507936506, 'test/loss': 1.3475426833603654, 'eval/f1_weighted': 0.2064516129032258, 'test/f1_weighted': 0.2701436130007559, 'eval/recall_weighted': 0.32, 'test/accuracy': 0.36507936507936506}","{'rf_max_depth': 3, 'trial.number': 8}",graceful-sea-447,RandomForest,['pre-trained:bert-base-uncased']
884,"{'split': 10, 'eval/f1_micro': 0.44, 'eval/recall_micro': 0.44, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.3968253968253968, 'test/accuracy': 0.3968253968253968, 'test/f1_weighted': 0.30733756231043763, 'test/precision_micro': 0.3968253968253968, 'test/recall_micro': 0.3968253968253968, 'test/precision_macro': 0.1775, '_timestamp': 1704290451.1610372, 'eval/recall_macro': 0.2916666666666667, 'test/recall_macro': 0.236737400530504, 'eval/f1_weighted': 0.30242424242424243, 'eval/precision_macro': 0.23369565217391303, '_step': 20, 'eval/accuracy': 0.44, 'test/f1_macro': 0.1931886678722122, '_runtime': 1139.0877211093905, 'test/loss': 1.4663716803253783, 'test/precision_weighted': 0.2633333333333333, '_wandb': {'runtime': 1137}, 'eval/loss': 1.2930442514256355, 'eval/f1_macro': 0.21401515151515152, 'test/f1_micro': 0.3968253968253968, 'eval/precision_weighted': 0.29391304347826086}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 2, 'dt_min_samples_leaf': 13}",youthful-night-446,DecisionTree,['pre-trained:openai-gpt']
885,"{'test/loss': 27.461831153613076, 'test/accuracy': 0.23809523809523808, 'eval/recall_macro': 0.18333333333333335, 'test/recall_micro': 0.23809523809523808, 'test/precision_micro': 0.23809523809523808, 'test/precision_macro': 0.20510912698412695, 'test/recall_weighted': 0.23809523809523808, '_step': 20, 'eval/loss': 27.393176575729036, 'test/f1_weighted': 0.23420120736466632, 'eval/precision_macro': 0.17424242424242423, 'eval/f1_micro': 0.24, 'test/f1_micro': 0.23809523809523808, '_runtime': 1009.6494274139404, 'eval/f1_macro': 0.17857142857142858, 'test/f1_macro': 0.21089726213065868, 'eval/recall_weighted': 0.24, 'eval/accuracy': 0.24, 'eval/f1_weighted': 0.2323809523809524, 'eval/recall_micro': 0.24, 'eval/precision_micro': 0.24, 'test/precision_weighted': 0.24573255228017135, 'split': 10, '_wandb': {'runtime': 1008}, '_timestamp': 1704290311.1597085, 'test/recall_macro': 0.23333333333333336, 'eval/precision_weighted': 0.22545454545454544}","{'n_neighbours': 1, 'trial.number': 8}",devout-sky-445,KNeighbours,['pre-trained:bert-base-uncased']
886,"{'eval/loss': 6.033314142801187, 'test/accuracy': 0.3333333333333333, 'eval/recall_weighted': 0.24, '_timestamp': 1704290396.7609398, 'test/f1_weighted': 0.3415852237731621, 'eval/recall_macro': 0.2727272727272727, '_runtime': 1136.6590478420258, 'eval/f1_weighted': 0.1871266968325792, 'test/recall_micro': 0.3333333333333333, 'split': 10, 'test/recall_weighted': 0.3333333333333333, 'eval/precision_weighted': 0.188, '_step': 20, 'test/f1_micro': 0.3333333333333333, 'eval/precision_micro': 0.24, 'test/precision_macro': 0.2870923913043478, 'test/f1_macro': 0.2674146797568957, '_wandb': {'runtime': 1135}, 'eval/accuracy': 0.24, 'eval/f1_macro': 0.196408371040724, 'eval/f1_micro': 0.24, 'eval/precision_macro': 0.175, 'test/precision_micro': 0.3333333333333333, 'test/loss': 10.868423894814946, 'eval/recall_micro': 0.24, 'test/recall_macro': 0.2979603729603729, 'test/precision_weighted': 0.4161318150448585}","{'smoothing': 0.05813035348323414, 'trial.number': 2}",proud-field-444,Bernolli,['pre-trained:openai-gpt']
887,"{'eval/f1_macro': 0.2368131868131868, 'eval/f1_micro': 0.28, 'test/accuracy': 0.31746031746031744, 'eval/recall_micro': 0.28, 'test/precision_macro': 0.25073891625615763, 'eval/precision_weighted': 0.27194805194805194, '_timestamp': 1704290279.7482991, 'test/f1_macro': 0.24500866265159643, 'test/f1_micro': 0.31746031746031744, 'test/recall_macro': 0.25738636363636364, 'eval/recall_weighted': 0.28, '_step': 20, 'test/loss': 24.60122374177838, 'test/f1_weighted': 0.3239307878364062, 'test/recall_micro': 0.31746031746031744, 'eval/precision_macro': 0.23782467532467533, 'test/recall_weighted': 0.31746031746031744, 'test/precision_weighted': 0.34168425991086093, '_runtime': 1088.2407250404358, 'eval/accuracy': 0.28, 'eval/precision_micro': 0.28, 'eval/recall_macro': 0.24166666666666667, 'split': 10, '_wandb': {'runtime': 1086}, 'eval/loss': 25.951430440164348, 'eval/f1_weighted': 0.27305494505494504, 'test/precision_micro': 0.31746031746031744}","{'n_neighbours': 1, 'trial.number': 2}",golden-shadow-443,KNeighbours,['pre-trained:openai-gpt']
888,"{'eval/recall_weighted': 0.36, 'eval/f1_micro': 0.36, 'test/accuracy': 0.4444444444444444, 'eval/precision_macro': 0.09375, 'test/recall_weighted': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, 'test/precision_micro': 0.4444444444444444, 'test/precision_weighted': 0.26992451992451993, '_step': 20, 'eval/accuracy': 0.36, 'eval/f1_macro': 0.13235294117647062, 'test/recall_macro': 0.24274193548387096, 'test/loss': 1.374955792496771, 'eval/precision_weighted': 0.15, 'test/recall_micro': 0.4444444444444444, 'eval/precision_micro': 0.36, 'split': 10, '_runtime': 1033.5055196285248, '_timestamp': 1704289410.3212757, 'eval/recall_micro': 0.36, 'test/f1_macro': 0.18646012621916236, 'eval/recall_macro': 0.225, 'test/precision_macro': 0.15253496503496505, '_wandb': {'runtime': 1032}, 'eval/loss': 1.4186722258633429, 'eval/f1_weighted': 0.21176470588235297, 'test/f1_weighted': 0.33525485160597035}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 7, 'dt_min_samples_leaf': 38}",earnest-totem-442,DecisionTree,['pre-trained:bert-base-uncased']
889,"{'_step': 20, 'split': 10, 'eval/f1_macro': 0.14285714285714288, 'test/f1_micro': 0.4444444444444444, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.2991822991822992, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.2375, 'test/loss': 1.268817472432547, 'eval/recall_macro': 0.25, 'test/recall_weighted': 0.4444444444444444, 'test/precision_weighted': 0.27936507936507937, '_runtime': 1022.011946439743, 'eval/loss': 1.3648515920921032, 'eval/accuracy': 0.4, 'eval/recall_weighted': 0.4, '_wandb': {'runtime': 1020}, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.26607142857142857, 'eval/precision_weighted': 0.16, '_timestamp': 1704289363.3877904, 'test/f1_macro': 0.19507575757575757, 'eval/precision_macro': 0.1, 'test/precision_micro': 0.4444444444444444, 'test/recall_micro': 0.4444444444444444, 'test/accuracy': 0.4444444444444444}","{'rf_max_depth': 3, 'trial.number': 7}",summer-jazz-441,RandomForest,['pre-trained:bert-base-uncased']
890,"{'eval/accuracy': 0.32, 'test/accuracy': 0.2222222222222222, 'eval/precision_macro': 0.16544117647058823, 'eval/precision_micro': 0.32, 'split': 10, '_step': 20, 'test/loss': 17.58964172609802, 'test/recall_weighted': 0.2222222222222222, 'eval/f1_micro': 0.32, 'eval/recall_macro': 0.21666666666666665, 'test/precision_weighted': 0.2297702297702298, '_wandb': {'runtime': 1008}, 'test/f1_macro': 0.1656936813186813, 'eval/recall_weighted': 0.32, 'test/recall_micro': 0.2222222222222222, '_runtime': 1009.825873851776, 'eval/loss': 14.993451067180532, '_timestamp': 1704289297.429509, 'eval/f1_macro': 0.17962962962962964, 'eval/f1_weighted': 0.2554074074074074, 'eval/recall_micro': 0.32, 'test/f1_micro': 0.2222222222222222, 'test/f1_weighted': 0.21945316588173733, 'test/recall_macro': 0.18333333333333332, 'test/precision_macro': 0.1660839160839161, 'test/precision_micro': 0.2222222222222222, 'eval/precision_weighted': 0.22470588235294117}","{'n_neighbours': 3, 'trial.number': 7}",lyric-dew-440,KNeighbours,['pre-trained:bert-base-uncased']
891,"{'eval/accuracy': 0.28, 'test/accuracy': 0.42857142857142855, 'eval/recall_macro': 0.21666666666666667, 'eval/loss': 3.092916916476667, 'test/loss': 1.878621827458272, 'eval/f1_macro': 0.2003205128205128, 'test/recall_weighted': 0.42857142857142855, 'test/recall_macro': 0.2833333333333333, 'eval/precision_macro': 0.2388392857142857, 'eval/precision_micro': 0.28, 'test/precision_weighted': 0.38535569266466274, 'test/f1_macro': 0.2637801696020874, 'test/f1_weighted': 0.3815011544952836, '_runtime': 1253.5997540950775, '_timestamp': 1704289540.328283, 'eval/f1_micro': 0.28, 'test/f1_micro': 0.42857142857142855, '_step': 20, 'split': 10, 'eval/recall_micro': 0.28, 'test/recall_micro': 0.42857142857142855, 'eval/recall_weighted': 0.28, 'eval/precision_weighted': 0.2735714285714286, '_wandb': {'runtime': 1252}, 'test/precision_macro': 0.28862126245847175, 'test/precision_micro': 0.42857142857142855, 'eval/f1_weighted': 0.2471794871794872}","{'dt_criterion': 'gini', 'dt_max_depth': 18, 'trial.number': 58, 'dt_min_samples_leaf': 24}",winter-violet-439,DecisionTree,['pre-trained:microsoft/codebert-base']
892,"{'eval/f1_macro': 0.3371794871794872, 'test/f1_weighted': 0.3756613756613757, 'eval/recall_macro': 0.3333333333333333, 'eval/recall_micro': 0.44, 'test/precision_weighted': 0.3924963924963925, '_runtime': 1195.9866545200348, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.36507936507936506, 'test/loss': 2.8282319453498252, 'eval/f1_weighted': 0.4088205128205129, 'eval/precision_macro': 0.5, 'test/precision_micro': 0.36507936507936506, '_step': 20, 'split': 10, '_wandb': {'runtime': 1194}, 'eval/loss': 2.548943258906288, 'test/accuracy': 0.36507936507936506, 'eval/precision_weighted': 0.52, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.25735294117647056, '_timestamp': 1704289385.6382897, 'test/f1_micro': 0.36507936507936506, 'test/recall_macro': 0.24052601809954752, 'test/recall_micro': 0.36507936507936506, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.2857620320855615}","{'rf_max_depth': 16, 'trial.number': 1}",super-morning-438,RandomForest,['pre-trained:openai-gpt']
893,"{'_wandb': {'runtime': 1135}, 'split': 10, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.16, 'test/f1_macro': 0.15760869565217392, 'eval/precision_micro': 0.4, 'eval/loss': 1.2104642742254073, '_timestamp': 1704289309.001474, 'eval/f1_macro': 0.14285714285714288, 'test/accuracy': 0.4603174603174603, 'test/f1_micro': 0.4603174603174603, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, '_runtime': 1136.8883299827576, 'test/recall_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'eval/accuracy': 0.4, 'test/precision_micro': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, '_step': 20, 'test/f1_weighted': 0.290200138026225, 'test/precision_macro': 0.11507936507936509, 'test/loss': 1.357826422376692}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 1, 'dt_min_samples_leaf': 87}",dashing-dust-437,DecisionTree,['pre-trained:openai-gpt']
894,"{'_wandb': {'runtime': 1134}, 'eval/f1_micro': 0.16, 'test/precision_macro': 0.31195267580716496, 'test/precision_weighted': 0.4180050967755523, 'test/f1_macro': 0.2891803675048356, 'eval/f1_weighted': 0.14133333333333334, 'test/recall_weighted': 0.3333333333333333, '_timestamp': 1704289254.8449943, 'test/accuracy': 0.3333333333333333, 'test/f1_micro': 0.3333333333333333, 'test/precision_micro': 0.3333333333333333, 'split': 10, 'test/loss': 11.411410223915608, '_runtime': 1135.5996403694153, 'eval/accuracy': 0.16, 'eval/precision_macro': 0.10555555555555556, '_step': 20, 'eval/recall_macro': 0.14545454545454545, 'test/recall_micro': 0.3333333333333333, 'eval/recall_weighted': 0.16, 'eval/precision_weighted': 0.13777777777777778, 'eval/f1_macro': 0.11666666666666668, 'test/f1_weighted': 0.3507115225200332, 'test/recall_macro': 0.303010878010878, 'eval/precision_micro': 0.16, 'eval/loss': 7.05115130123206, 'eval/recall_micro': 0.16}","{'smoothing': 0.8151456575592437, 'trial.number': 1}",vague-plasma-436,Bernolli,['pre-trained:openai-gpt']
895,"{'eval/recall_micro': 0.28, 'test/recall_macro': 0.26799242424242425, 'test/precision_weighted': 0.3221466364323507, 'test/loss': 18.54993883212806, 'test/f1_micro': 0.4126984126984127, 'eval/precision_macro': 0.15833333333333333, 'test/recall_weighted': 0.4126984126984127, '_wandb': {'runtime': 1085}, 'eval/loss': 20.461704770129582, 'eval/f1_weighted': 0.21333333333333332, 'split': 10, 'eval/accuracy': 0.28, 'eval/recall_weighted': 0.28, 'test/precision_micro': 0.4126984126984127, '_step': 20, '_runtime': 1086.6078519821167, 'test/f1_macro': 0.24743589743589745, 'eval/precision_weighted': 0.2, 'test/precision_macro': 0.23492063492063492, 'eval/f1_macro': 0.15555555555555556, 'eval/f1_micro': 0.28, 'test/accuracy': 0.4126984126984127, 'test/f1_weighted': 0.3597069597069597, 'eval/recall_macro': 0.19166666666666665, '_timestamp': 1704289188.135535, 'test/recall_micro': 0.4126984126984127, 'eval/precision_micro': 0.28}","{'n_neighbours': 2, 'trial.number': 1}",elated-sky-435,KNeighbours,['pre-trained:openai-gpt']
896,"{'_runtime': 1034.6989586353302, 'eval/f1_micro': 0.32, 'test/recall_weighted': 0.3968253968253968, 'test/precision_weighted': 0.3150553150553151, 'eval/recall_weighted': 0.32, 'test/accuracy': 0.3968253968253968, 'test/f1_macro': 0.2234375, 'test/f1_micro': 0.3968253968253968, '_timestamp': 1704288372.4828317, 'eval/accuracy': 0.32, 'test/f1_weighted': 0.33978174603174605, 'test/recall_macro': 0.3032258064516129, 'eval/precision_macro': 0.1371527777777778, 'eval/precision_weighted': 0.2016666666666667, 'eval/loss': 1.3605355632158649, 'test/loss': 1.2745313625984234, 'eval/recall_macro': 0.21666666666666665, 'eval/recall_micro': 0.32, 'test/precision_micro': 0.3968253968253968, '_wandb': {'runtime': 1033}, 'eval/precision_micro': 0.32, '_step': 20, 'split': 10, 'eval/f1_macro': 0.1679487179487179, 'eval/f1_weighted': 0.24738461538461537, 'test/recall_micro': 0.3968253968253968, 'test/precision_macro': 0.19393939393939397}","{'dt_criterion': 'gini', 'dt_max_depth': 13, 'trial.number': 6, 'dt_min_samples_leaf': 88}",crisp-paper-434,DecisionTree,['pre-trained:bert-base-uncased']
897,"{'eval/precision_weighted': 0.16666666666666669, 'eval/f1_micro': 0.4000000000000001, 'test/recall_micro': 0.380952380952381, 'test/recall_weighted': 0.380952380952381, 'test/precision_weighted': 0.1871345029239766, 'eval/f1_macro': 0.14705882352941177, 'eval/precision_micro': 0.4, 'eval/f1_weighted': 0.23529411764705885, 'test/f1_weighted': 0.25098039215686274, 'eval/recall_macro': 0.25, 'test/precision_micro': 0.380952380952381, '_step': 20, 'split': 10, 'eval/loss': 1.3255855523039453, 'eval/recall_weighted': 0.4, 'test/loss': 1.3585501694669568, 'test/f1_macro': 0.1411764705882353, 'test/f1_micro': 0.380952380952381, '_wandb': {'runtime': 1021}, '_timestamp': 1704288337.463001, 'test/accuracy': 0.380952380952381, 'test/recall_macro': 0.21428571428571427, 'eval/precision_macro': 0.10416666666666669, 'test/precision_macro': 0.10526315789473684, '_runtime': 1022.9530930519104, 'eval/accuracy': 0.4, 'eval/recall_micro': 0.4}","{'rf_max_depth': 3, 'trial.number': 6}",peachy-firefly-433,RandomForest,['pre-trained:bert-base-uncased']
898,"{'test/loss': 27.461831153613076, 'eval/recall_weighted': 0.24, '_runtime': 1010.2223794460295, 'eval/recall_macro': 0.18333333333333335, 'eval/recall_micro': 0.24, 'test/accuracy': 0.23809523809523808, 'eval/precision_weighted': 0.22545454545454544, 'eval/accuracy': 0.24, 'test/recall_macro': 0.23333333333333336, 'eval/precision_macro': 0.17424242424242423, 'eval/precision_micro': 0.24, '_wandb': {'runtime': 1008}, 'test/f1_macro': 0.21089726213065868, 'test/f1_weighted': 0.23420120736466632, 'test/precision_macro': 0.20510912698412695, 'test/precision_micro': 0.23809523809523808, 'test/recall_weighted': 0.23809523809523808, 'eval/loss': 27.393176575729036, '_timestamp': 1704288282.8823037, 'eval/f1_macro': 0.17857142857142858, 'eval/f1_micro': 0.24, 'eval/f1_weighted': 0.2323809523809524, '_step': 20, 'split': 10, 'test/f1_micro': 0.23809523809523808, 'test/recall_micro': 0.23809523809523808, 'test/precision_weighted': 0.24573255228017135}","{'n_neighbours': 1, 'trial.number': 6}",toasty-firebrand-432,KNeighbours,['pre-trained:bert-base-uncased']
899,"{'_wandb': {'runtime': 1135}, 'eval/accuracy': 0.2, 'eval/f1_weighted': 0.14956521739130435, 'eval/precision_weighted': 0.12153846153846154, '_step': 20, 'test/loss': 1.3744851134316307, '_timestamp': 1704288168.352516, 'eval/f1_micro': 0.20000000000000004, 'test/f1_micro': 0.2698412698412698, 'test/f1_weighted': 0.2341029341029341, 'test/precision_weighted': 0.2168458781362007, 'split': 10, '_runtime': 1136.2422409057615, 'eval/recall_micro': 0.2, 'test/precision_macro': 0.13608870967741937, 'test/precision_micro': 0.2698412698412698, 'test/accuracy': 0.2698412698412698, 'test/recall_macro': 0.1954022988505747, 'test/recall_weighted': 0.2698412698412698, 'eval/recall_weighted': 0.2, 'eval/loss': 1.4824089384976713, 'eval/f1_macro': 0.12681159420289856, 'test/f1_macro': 0.15378787878787878, 'eval/recall_macro': 0.175, 'eval/precision_macro': 0.10096153846153846, 'eval/precision_micro': 0.2, 'test/recall_micro': 0.2698412698412698}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 0, 'dt_min_samples_leaf': 71}",devout-snow-431,DecisionTree,['pre-trained:openai-gpt']
900,"{'test/loss': 1.8369468040984616, 'eval/precision_micro': 0.24, 'test/precision_micro': 0.3968253968253968, 'eval/precision_weighted': 0.1955555555555555, 'test/precision_macro': 0.2294642857142857, 'test/recall_weighted': 0.3968253968253968, '_wandb': {'runtime': 1252}, 'test/accuracy': 0.3968253968253968, 'eval/f1_weighted': 0.214025974025974, 'eval/precision_macro': 0.1736111111111111, 'test/recall_micro': 0.3968253968253968, '_step': 20, 'eval/f1_macro': 0.18912337662337655, 'eval/f1_micro': 0.24, 'eval/recall_micro': 0.24, 'split': 10, 'eval/recall_weighted': 0.24, '_timestamp': 1704288282.817306, 'eval/accuracy': 0.24, 'test/f1_macro': 0.2607371794871795, '_runtime': 1254.0276341438291, 'eval/loss': 4.138867652760737, 'test/f1_micro': 0.3968253968253968, 'test/f1_weighted': 0.3471713471713472, 'eval/recall_macro': 0.2125, 'test/recall_macro': 0.3145833333333333, 'test/precision_weighted': 0.31405895691609975}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 57, 'dt_min_samples_leaf': 35}",deft-morning-430,DecisionTree,['pre-trained:microsoft/codebert-base']
901,"{'test/recall_micro': 0.5079365079365079, 'eval/accuracy': 0.44, 'test/f1_micro': 0.5079365079365079, 'eval/recall_micro': 0.44, 'test/precision_macro': 0.2575, 'eval/precision_weighted': 0.3882352941176471, '_step': 20, 'split': 10, '_runtime': 1177.4282746315002, 'eval/f1_weighted': 0.3837037037037037, 'test/precision_micro': 0.5079365079365079, '_wandb': {'runtime': 1177}, '_timestamp': 1704288185.1021435, 'eval/f1_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.5079365079365079, 'test/recall_macro': 0.2829468325791855, 'test/precision_weighted': 0.39, 'eval/loss': 1.4050809070935864, 'test/loss': 1.22581035801093, 'eval/precision_macro': 0.33431372549019606, 'test/f1_macro': 0.2586996336996337, 'test/f1_weighted': 0.4314785743357172, 'eval/precision_micro': 0.44, 'eval/f1_macro': 0.3092592592592593, 'test/accuracy': 0.5079365079365079, 'eval/recall_macro': 0.3333333333333333}","{'rf_max_depth': 6, 'trial.number': 0}",ethereal-donkey-429,RandomForest,['pre-trained:openai-gpt']
902,"{'eval/accuracy': 0.32, 'test/recall_micro': 0.4126984126984127, '_runtime': 1090.6695992946625, 'eval/loss': 6.787085350150724, 'test/f1_micro': 0.4126984126984127, '_step': 20, '_wandb': {'runtime': 1090}, 'test/loss': 7.214833055811802, 'eval/f1_macro': 0.13333333333333333, 'test/precision_micro': 0.4126984126984127, 'eval/precision_weighted': 0.16, 'split': 10, 'test/precision_macro': 0.18958333333333333, 'test/precision_weighted': 0.3142857142857143, 'test/accuracy': 0.4126984126984127, 'eval/f1_weighted': 0.21333333333333332, 'test/recall_weighted': 0.4126984126984127, '_timestamp': 1704288098.2127893, 'test/f1_macro': 0.20782342657342656, 'test/f1_weighted': 0.3555333555333555, 'eval/recall_macro': 0.2, 'test/recall_macro': 0.23390151515151517, 'eval/f1_micro': 0.32, 'eval/precision_micro': 0.32, 'eval/recall_micro': 0.32, 'eval/precision_macro': 0.1, 'eval/recall_weighted': 0.32}","{'n_neighbours': 6, 'trial.number': 0}",hearty-snowflake-428,KNeighbours,['pre-trained:openai-gpt']
903,"{'test/precision_micro': 0.31746031746031744, '_timestamp': 1704288115.4250386, 'eval/f1_micro': 0.24, 'test/f1_micro': 0.31746031746031744, 'eval/f1_weighted': 0.2061111111111111, 'test/precision_macro': 0.3326086956521739, 'eval/precision_weighted': 0.2088311688311688, '_step': 20, 'eval/loss': 6.491340809194254, 'eval/recall_micro': 0.24, 'eval/recall_weighted': 0.24, 'test/recall_weighted': 0.31746031746031744, 'test/accuracy': 0.31746031746031744, 'test/f1_macro': 0.2817035905271199, 'test/precision_weighted': 0.4504387262151238, 'test/loss': 11.206901386951357, 'eval/f1_macro': 0.1909722222222222, 'eval/precision_macro': 0.17532467532467533, 'eval/precision_micro': 0.24, '_runtime': 1137.119621515274, 'test/f1_weighted': 0.34049983629815567, 'eval/recall_macro': 0.24545454545454545, 'test/recall_macro': 0.2946775446775447, '_wandb': {'runtime': 1136}, 'eval/accuracy': 0.24, 'split': 10, 'test/recall_micro': 0.31746031746031744}","{'smoothing': 0.4641061647586451, 'trial.number': 0}",trim-haze-427,Bernolli,['pre-trained:openai-gpt']
904,"{'eval/precision_macro': 0.09210526315789472, 'eval/precision_micro': 0.28, 'test/recall_weighted': 0.492063492063492, 'eval/loss': 1.4342635304745612, 'eval/f1_micro': 0.28, 'test/f1_micro': 0.492063492063492, '_step': 20, '_timestamp': 1704287333.950384, 'eval/precision_weighted': 0.14736842105263157, 'test/loss': 1.2659004575108088, 'eval/f1_weighted': 0.19310344827586207, 'eval/recall_macro': 0.175, '_runtime': 1009.0338020324708, 'eval/recall_weighted': 0.28, 'test/precision_weighted': 0.31341425459072514, 'test/accuracy': 0.492063492063492, 'test/f1_macro': 0.25554323725055433, 'test/recall_micro': 0.492063492063492, '_wandb': {'runtime': 1007}, 'eval/f1_macro': 0.12068965517241378, 'test/recall_macro': 0.317741935483871, 'test/precision_macro': 0.21568627450980393, 'test/precision_micro': 0.492063492063492, 'split': 10, 'eval/accuracy': 0.28, 'test/f1_weighted': 0.3817618695667476, 'eval/recall_micro': 0.28}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 5, 'dt_min_samples_leaf': 59}",classic-planet-426,DecisionTree,['pre-trained:bert-base-uncased']
905,"{'eval/precision_weighted': 0.16, 'test/f1_macro': 0.15384615384615383, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.2735042735042735, 'test/recall_macro': 0.25, 'test/recall_micro': 0.4444444444444444, 'split': 10, 'test/loss': 1.2885155585810744, 'eval/accuracy': 0.4, 'eval/precision_macro': 0.1, '_runtime': 994.5949172973632, 'eval/loss': 1.363906302949254, 'test/precision_macro': 0.1111111111111111, 'eval/f1_macro': 0.14285714285714288, 'eval/recall_micro': 0.4, '_timestamp': 1704287307.9158232, 'test/accuracy': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, '_wandb': {'runtime': 993}, 'eval/recall_macro': 0.25, 'test/precision_micro': 0.4444444444444444, '_step': 20, 'test/f1_micro': 0.4444444444444444, 'eval/recall_weighted': 0.4, 'test/precision_weighted': 0.19753086419753085, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_micro': 0.4}","{'rf_max_depth': 2, 'trial.number': 5}",ancient-yogurt-425,RandomForest,['pre-trained:bert-base-uncased']
906,"{'test/precision_micro': 0.30158730158730157, 'test/recall_micro': 0.30158730158730157, 'eval/precision_micro': 0.28, 'eval/f1_micro': 0.28, 'test/f1_micro': 0.30158730158730157, 'eval/recall_micro': 0.28, 'test/f1_macro': 0.20353037766830867, 'eval/f1_weighted': 0.2539130434782609, 'test/accuracy': 0.30158730158730157, '_runtime': 981.5366547107697, 'test/loss': 12.162271163367295, 'eval/f1_macro': 0.2128623188405797, 'test/recall_macro': 0.20833333333333331, '_step': 20, 'split': 10, 'eval/accuracy': 0.28, 'test/precision_weighted': 0.328396749449381, '_wandb': {'runtime': 980}, 'eval/loss': 8.126421831027029, 'eval/precision_macro': 0.20032051282051283, 'eval/recall_weighted': 0.28, 'test/precision_macro': 0.23995215311004783, '_timestamp': 1704287268.3371136, 'test/f1_weighted': 0.2962702322308234, 'eval/precision_weighted': 0.23384615384615387, 'eval/recall_macro': 0.22916666666666663, 'test/recall_weighted': 0.30158730158730157}","{'n_neighbours': 5, 'trial.number': 5}",stilted-wind-424,KNeighbours,['pre-trained:bert-base-uncased']
907,"{'test/accuracy': 0.42857142857142855, 'test/f1_weighted': 0.394526620333072, 'eval/recall_macro': 0.21666666666666667, 'eval/precision_micro': 0.28, '_wandb': {'runtime': 1252}, 'test/f1_micro': 0.42857142857142855, 'eval/f1_weighted': 0.24354312354312355, 'test/recall_macro': 0.3333333333333333, 'eval/precision_macro': 0.20312499999999997, 'eval/recall_weighted': 0.28, 'eval/loss': 1.7791070521412888, 'test/f1_macro': 0.29498082562598693, '_runtime': 1253.6603367328644, '_timestamp': 1704287025.3066535, 'test/recall_micro': 0.42857142857142855, 'test/precision_macro': 0.30238095238095236, 'eval/precision_weighted': 0.2383333333333333, 'test/precision_weighted': 0.3983371126228269, 'eval/f1_micro': 0.28, 'eval/recall_micro': 0.28, 'split': 10, 'eval/accuracy': 0.28, 'eval/f1_macro': 0.19716394716394717, 'test/precision_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, '_step': 20, 'test/loss': 1.32614138813784}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 56, 'dt_min_samples_leaf': 31}",pious-donkey-423,DecisionTree,['pre-trained:microsoft/codebert-base']
908,"{'test/precision_macro': 0.196875, 'eval/loss': 2.9534355867600266, 'eval/recall_macro': 0.3041666666666667, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.3017543859649123, '_step': 20, '_runtime': 990.3912789821624, 'test/precision_micro': 0.31746031746031744, 'test/f1_macro': 0.19806663924310983, 'test/precision_weighted': 0.2615079365079365, '_wandb': {'runtime': 989}, 'test/f1_micro': 0.31746031746031744, 'eval/f1_weighted': 0.31973727422003284, 'test/recall_macro': 0.23256302521008404, 'eval/precision_micro': 0.4, 'eval/f1_macro': 0.26491516146688565, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.31746031746031744, 'eval/precision_macro': 0.27192982456140347, 'test/recall_weighted': 0.31746031746031744, 'test/loss': 2.0512480275521816, '_timestamp': 1704286308.074665, 'eval/accuracy': 0.4, 'split': 10, 'test/accuracy': 0.31746031746031744, 'test/f1_weighted': 0.2703113879584468}","{'rf_max_depth': 11, 'trial.number': 4}",honest-pyramid-422,RandomForest,['pre-trained:bert-base-uncased']
909,"{'eval/accuracy': 0.4, 'test/f1_macro': 0.16489361702127658, 'test/f1_weighted': 0.3245525160418777, 'test/recall_macro': 0.25, '_timestamp': 1704286319.9421847, 'test/recall_weighted': 0.492063492063492, 'eval/f1_macro': 0.14285714285714288, 'eval/f1_weighted': 0.22857142857142865, 'eval/precision_weighted': 0.16, 'test/precision_weighted': 0.24212648022171832, 'test/f1_micro': 0.492063492063492, 'eval/precision_macro': 0.1, 'eval/recall_weighted': 0.4, 'split': 10, 'test/loss': 1.275518815596098, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_micro': 0.4, '_wandb': {'runtime': 1002}, '_runtime': 1004.2293207645416, 'test/precision_micro': 0.492063492063492, 'eval/recall_micro': 0.4, 'test/precision_macro': 0.123015873015873, '_step': 20, 'eval/loss': 1.3296549549719356, 'test/accuracy': 0.492063492063492, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.492063492063492}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 4, 'dt_min_samples_leaf': 70}",robust-violet-421,DecisionTree,['pre-trained:bert-base-uncased']
910,"{'eval/accuracy': 0.28, 'eval/f1_weighted': 0.2539130434782609, 'eval/precision_micro': 0.28, 'test/f1_weighted': 0.2962702322308234, 'eval/precision_weighted': 0.23384615384615387, '_runtime': 978.436324596405, 'eval/loss': 8.126421831027029, 'eval/recall_weighted': 0.28, '_step': 20, 'test/recall_weighted': 0.30158730158730157, 'split': 10, 'eval/f1_micro': 0.28, 'eval/f1_macro': 0.2128623188405797, 'eval/recall_macro': 0.22916666666666663, 'eval/recall_micro': 0.28, 'test/recall_macro': 0.20833333333333331, 'test/precision_macro': 0.23995215311004783, '_timestamp': 1704286282.3421235, 'test/accuracy': 0.30158730158730157, 'test/f1_micro': 0.30158730158730157, 'test/recall_micro': 0.30158730158730157, 'test/precision_micro': 0.30158730158730157, '_wandb': {'runtime': 977}, 'test/loss': 12.162271163367295, 'test/f1_macro': 0.20353037766830867, 'eval/precision_macro': 0.20032051282051283, 'test/precision_weighted': 0.328396749449381}","{'n_neighbours': 5, 'trial.number': 4}",neat-breeze-420,KNeighbours,['pre-trained:bert-base-uncased']
911,"{'test/f1_micro': 0.47619047619047616, 'eval/loss': 2.423662143289269, 'test/loss': 2.228697941994217, 'eval/accuracy': 0.4, 'test/accuracy': 0.47619047619047616, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.47619047619047616, '_step': 20, 'split': 10, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.30721966205837176, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.1, 'test/recall_weighted': 0.47619047619047616, '_wandb': {'runtime': 966}, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.47619047619047616, '_timestamp': 1704286234.5997522, 'eval/precision_micro': 0.4, 'eval/recall_macro': 0.25, 'eval/precision_weighted': 0.16, 'test/precision_weighted': 0.22675736961451248, '_runtime': 967.7376372814178, 'test/f1_macro': 0.16129032258064516, 'test/precision_macro': 0.11904761904761904, 'eval/f1_macro': 0.14285714285714288}","{'smoothing': 0.5782805101000408, 'trial.number': 4}",morning-energy-419,Bernolli,['pre-trained:bert-base-uncased']
912,"{'eval/recall_micro': 0.32, 'eval/recall_macro': 0.2791666666666667, 'test/precision_weighted': 0.3825212255444813, 'eval/f1_macro': 0.2856379731379732, 'test/recall_micro': 0.4126984126984127, 'eval/precision_macro': 0.3489583333333333, 'test/precision_micro': 0.4126984126984127, 'eval/precision_weighted': 0.3483333333333333, 'test/accuracy': 0.4126984126984127, '_runtime': 1256.189181804657, 'test/recall_macro': 0.25833333333333336, 'eval/recall_weighted': 0.32, '_step': 20, 'eval/loss': 1.7173084784257475, '_timestamp': 1704285766.3318698, 'eval/accuracy': 0.32, 'eval/f1_weighted': 0.30400488400488407, 'test/f1_weighted': 0.3726828123436081, 'test/recall_weighted': 0.4126984126984127, '_wandb': {'runtime': 1253}, 'test/f1_macro': 0.2498912807131985, 'test/loss': 1.403081672012247, 'eval/f1_micro': 0.32, 'test/f1_micro': 0.4126984126984127, 'eval/precision_micro': 0.32, 'test/precision_macro': 0.28415697674418605, 'split': 10}","{'dt_criterion': 'gini', 'dt_max_depth': 14, 'trial.number': 55, 'dt_min_samples_leaf': 21}",quiet-monkey-418,DecisionTree,['pre-trained:microsoft/codebert-base']
913,"{'test/recall_weighted': 0.31746031746031744, '_timestamp': 1704285314.2560463, 'eval/f1_macro': 0.2768199233716475, 'test/accuracy': 0.31746031746031744, 'test/f1_macro': 0.2339318667443668, 'test/f1_micro': 0.31746031746031744, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.31746031746031744, 'eval/loss': 1.6263421575616317, 'test/loss': 4.184967176771978, 'test/f1_weighted': 0.3022640939307606, 'test/precision_micro': 0.31746031746031744, '_wandb': {'runtime': 988}, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/precision_weighted': 0.30476190476190473, '_step': 20, 'eval/f1_weighted': 0.31846743295019153, 'test/precision_macro': 0.25, '_runtime': 990.6484246253968, 'eval/precision_macro': 0.29276315789473684, 'eval/recall_weighted': 0.4, 'eval/recall_macro': 0.3125, 'eval/precision_micro': 0.4, 'eval/precision_weighted': 0.2984210526315789, 'split': 10, 'test/recall_macro': 0.23429621848739496}","{'rf_max_depth': 12, 'trial.number': 3}",usual-breeze-417,RandomForest,['pre-trained:bert-base-uncased']
914,"{'test/accuracy': 0.23809523809523808, 'test/f1_macro': 0.21089726213065868, '_step': 20, '_wandb': {'runtime': 976}, 'test/recall_micro': 0.23809523809523808, 'eval/recall_macro': 0.18333333333333335, 'test/recall_macro': 0.23333333333333336, '_timestamp': 1704285299.2921338, 'eval/f1_macro': 0.17857142857142858, 'eval/precision_micro': 0.24, 'test/precision_micro': 0.23809523809523808, 'eval/precision_weighted': 0.22545454545454544, 'split': 10, 'eval/loss': 27.393176575729036, 'eval/f1_weighted': 0.2323809523809524, 'test/precision_weighted': 0.24573255228017135, 'test/loss': 27.461831153613076, 'eval/accuracy': 0.24, '_runtime': 978.2257459163666, 'test/f1_micro': 0.23809523809523808, 'eval/recall_weighted': 0.24, 'test/precision_macro': 0.20510912698412695, 'eval/f1_micro': 0.24, 'eval/precision_macro': 0.17424242424242423, 'test/recall_weighted': 0.23809523809523808, 'test/f1_weighted': 0.23420120736466632, 'eval/recall_micro': 0.24}","{'n_neighbours': 1, 'trial.number': 3}",worldly-dawn-416,KNeighbours,['pre-trained:bert-base-uncased']
915,"{'_wandb': {'runtime': 1003}, 'test/f1_micro': 0.23809523809523808, '_step': 20, '_runtime': 1004.8089661598206, '_timestamp': 1704285308.613069, 'test/accuracy': 0.23809523809523808, 'eval/precision_macro': 0.2638888888888889, 'test/precision_macro': 0.1785929951690821, 'eval/accuracy': 0.36, 'test/f1_macro': 0.1673923923923924, 'eval/precision_weighted': 0.30666666666666664, 'eval/loss': 1.3385799900212518, 'test/loss': 2.5780409613501134, 'eval/f1_weighted': 0.32799999999999996, 'eval/f1_macro': 0.29166666666666663, 'test/f1_weighted': 0.24525795636906747, 'test/recall_micro': 0.23809523809523808, 'eval/precision_micro': 0.36, 'test/precision_micro': 0.23809523809523808, 'test/recall_weighted': 0.23809523809523808, 'eval/recall_macro': 0.3333333333333333, 'eval/recall_micro': 0.36, 'test/recall_macro': 0.18454301075268817, 'test/precision_weighted': 0.2767809217084579, 'split': 10, 'eval/f1_micro': 0.36, 'eval/recall_weighted': 0.36}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 3, 'dt_min_samples_leaf': 26}",olive-armadillo-415,DecisionTree,['pre-trained:bert-base-uncased']
916,"{'eval/accuracy': 0.4, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.47619047619047616, 'test/accuracy': 0.47619047619047616, '_runtime': 967.1103310585022, 'eval/f1_macro': 0.14285714285714288, 'test/f1_weighted': 0.30721966205837176, 'eval/recall_macro': 0.25, 'eval/precision_weighted': 0.16, 'split': 10, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_micro': 0.47619047619047616, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.11904761904761904, 'test/recall_weighted': 0.47619047619047616, 'test/precision_weighted': 0.22675736961451248, '_step': 20, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.16129032258064516, 'eval/precision_micro': 0.4, 'test/loss': 2.413470859762047, 'test/precision_micro': 0.47619047619047616, '_timestamp': 1704285261.98811, 'eval/loss': 2.626296094008646, 'eval/precision_macro': 0.1, '_wandb': {'runtime': 965}}","{'smoothing': 0.646612541117718, 'trial.number': 3}",cerulean-surf-414,Bernolli,['pre-trained:bert-base-uncased']
917,"{'_wandb': {'runtime': 978}, 'test/accuracy': 0.30158730158730157, 'test/f1_weighted': 0.2998866213151927, 'eval/loss': 12.266349435197904, 'eval/recall_macro': 0.24166666666666667, 'eval/recall_micro': 0.36, 'eval/recall_weighted': 0.36, '_step': 20, '_timestamp': 1704284314.8660672, 'eval/f1_micro': 0.36, 'eval/f1_weighted': 0.29415384615384615, 'test/loss': 13.241204068050871, 'test/recall_macro': 0.23333333333333336, 'eval/precision_macro': 0.1875, 'eval/precision_micro': 0.36, 'test/precision_weighted': 0.31216931216931215, 'eval/f1_macro': 0.20384615384615384, 'test/f1_macro': 0.2244047619047619, 'test/precision_macro': 0.23333333333333336, 'test/precision_micro': 0.30158730158730157, 'split': 10, 'eval/accuracy': 0.36, 'eval/precision_weighted': 0.26, '_runtime': 979.830045223236, 'test/f1_micro': 0.30158730158730157, 'test/recall_micro': 0.30158730158730157, 'test/recall_weighted': 0.30158730158730157}","{'n_neighbours': 4, 'trial.number': 2}",graceful-aardvark-413,KNeighbours,['pre-trained:bert-base-uncased']
918,"{'_step': 20, 'test/accuracy': 0.4126984126984127, 'test/f1_macro': 0.14606741573033707, 'test/recall_macro': 0.23214285714285715, 'test/precision_macro': 0.10655737704918032, 'test/recall_weighted': 0.4126984126984127, 'test/recall_micro': 0.4126984126984127, 'eval/precision_macro': 0.09375, 'split': 10, '_runtime': 990.0063374042512, 'test/loss': 1.310690888158376, 'test/f1_weighted': 0.2596754057428215, 'eval/recall_macro': 0.225, 'eval/precision_weighted': 0.15, 'test/precision_weighted': 0.18943533697632056, 'eval/precision_micro': 0.36, 'eval/recall_weighted': 0.36, 'test/precision_micro': 0.4126984126984127, '_wandb': {'runtime': 988}, 'eval/loss': 1.301524058594694, 'eval/accuracy': 0.36, 'eval/f1_micro': 0.36, 'eval/recall_micro': 0.36, '_timestamp': 1704284319.9983275, 'eval/f1_macro': 0.13235294117647062, 'test/f1_micro': 0.4126984126984127, 'eval/f1_weighted': 0.21176470588235297}","{'rf_max_depth': 2, 'trial.number': 2}",rich-pine-412,RandomForest,['pre-trained:bert-base-uncased']
919,"{'eval/recall_weighted': 0.4, 'test/precision_macro': 0.11904761904761904, 'test/precision_weighted': 0.22675736961451248, 'split': 10, '_wandb': {'runtime': 966}, 'test/loss': 2.18154835122889, 'eval/accuracy': 0.4, '_step': 20, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.22857142857142865, 'eval/precision_macro': 0.1, 'eval/precision_weighted': 0.16, 'test/f1_weighted': 0.30721966205837176, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.47619047619047616, 'eval/f1_macro': 0.14285714285714288, 'test/f1_macro': 0.16129032258064516, '_runtime': 967.8183441162108, 'test/precision_micro': 0.47619047619047616, 'test/accuracy': 0.47619047619047616, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'test/recall_micro': 0.47619047619047616, 'eval/loss': 2.371863730389274, '_timestamp': 1704284290.809976, 'test/f1_micro': 0.47619047619047616, 'eval/recall_micro': 0.4}","{'smoothing': 0.5605536108296049, 'trial.number': 2}",hearty-gorge-411,Bernolli,['pre-trained:bert-base-uncased']
920,"{'test/precision_macro': 0.1673469387755102, 'test/recall_weighted': 0.3968253968253968, 'test/precision_weighted': 0.2627146096533852, '_step': 20, '_timestamp': 1704284298.0910454, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_micro': 0.4, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.3968253968253968, 'eval/loss': 5.336669789989191, 'test/loss': 11.575995043407776, 'test/f1_weighted': 0.31468253968253973, 'eval/precision_weighted': 0.24, 'split': 10, '_wandb': {'runtime': 1003}, '_runtime': 1004.542378425598, 'test/f1_macro': 0.19375000000000003, 'eval/recall_macro': 0.26666666666666666, 'eval/recall_weighted': 0.4, 'eval/f1_macro': 0.2, 'test/recall_macro': 0.23548387096774193, 'test/precision_micro': 0.3968253968253968, 'eval/accuracy': 0.4, 'test/accuracy': 0.3968253968253968, 'test/f1_micro': 0.3968253968253968, 'eval/f1_weighted': 0.28800000000000003, 'eval/precision_macro': 0.175}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 2, 'dt_min_samples_leaf': 5}",dandy-morning-410,DecisionTree,['pre-trained:bert-base-uncased']
921,"{'eval/accuracy': 0.28, 'test/recall_weighted': 0.42857142857142855, 'eval/precision_weighted': 0.2177777777777778, 'eval/f1_weighted': 0.24259740259740256, 'test/recall_micro': 0.42857142857142855, '_step': 20, '_wandb': {'runtime': 1252}, 'test/loss': 3.9656082978384193, 'test/f1_micro': 0.42857142857142855, 'eval/f1_micro': 0.28, 'test/f1_weighted': 0.3746341841579937, '_runtime': 1253.5104236602783, 'eval/recall_macro': 0.2625, 'split': 10, 'test/f1_macro': 0.30885225885225887, 'test/precision_weighted': 0.3368102796674225, 'eval/precision_micro': 0.28, 'eval/recall_weighted': 0.28, 'test/precision_micro': 0.42857142857142855, '_timestamp': 1704284505.7600756, 'eval/f1_macro': 0.2248376623376623, 'eval/recall_micro': 0.28, 'test/recall_macro': 0.37083333333333335, 'eval/loss': 6.860243673865673, 'test/accuracy': 0.42857142857142855, 'eval/precision_macro': 0.20138888888888887, 'test/precision_macro': 0.26904761904761904}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 54, 'dt_min_samples_leaf': 26}",silvery-star-409,DecisionTree,['pre-trained:microsoft/codebert-base']
922,"{'_wandb': {'runtime': 978}, 'eval/recall_macro': 0.24166666666666667, 'eval/recall_weighted': 0.36, 'eval/accuracy': 0.36, 'test/f1_micro': 0.30158730158730157, 'eval/loss': 12.266349435197904, '_timestamp': 1704283330.881916, 'test/accuracy': 0.30158730158730157, 'eval/recall_micro': 0.36, '_runtime': 979.6747291088104, 'eval/f1_macro': 0.20384615384615384, 'test/recall_macro': 0.23333333333333336, 'eval/precision_micro': 0.36, '_step': 20, 'test/precision_macro': 0.23333333333333336, 'test/recall_weighted': 0.30158730158730157, 'test/loss': 13.241204068050871, 'test/f1_weighted': 0.2998866213151927, 'eval/precision_macro': 0.1875, 'test/f1_macro': 0.2244047619047619, 'test/recall_micro': 0.30158730158730157, 'test/precision_micro': 0.30158730158730157, 'eval/precision_weighted': 0.26, 'test/precision_weighted': 0.31216931216931215, 'split': 10, 'eval/f1_micro': 0.36, 'eval/f1_weighted': 0.29415384615384615}","{'n_neighbours': 4, 'trial.number': 1}",morning-puddle-408,KNeighbours,['pre-trained:bert-base-uncased']
923,"{'eval/f1_macro': 0.14285714285714288, 'eval/f1_weighted': 0.22857142857142865, '_timestamp': 1704283317.4472284, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.30721966205837176, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.4, 'test/precision_weighted': 0.22675736961451248, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.47619047619047616, '_runtime': 969.2802493572236, 'eval/loss': 1.6215486521898088, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.47619047619047616, '_wandb': {'runtime': 967}, 'eval/precision_macro': 0.1, 'test/precision_macro': 0.11904761904761904, '_step': 20, 'test/loss': 1.5080017753340684, 'test/recall_micro': 0.47619047619047616, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.47619047619047616, 'eval/precision_weighted': 0.16, 'split': 10, 'test/f1_macro': 0.16129032258064516, 'test/f1_micro': 0.47619047619047616, 'test/recall_macro': 0.25}","{'smoothing': 0.27124135726467113, 'trial.number': 1}",effortless-moon-407,Bernolli,['pre-trained:bert-base-uncased']
924,"{'_step': 20, 'eval/f1_macro': 0.3968253968253968, 'eval/recall_micro': 0.52, 'test/f1_weighted': 0.3288056548926114, 'eval/recall_weighted': 0.52, '_timestamp': 1704283324.535349, 'test/recall_macro': 0.2713760504201681, 'test/recall_micro': 0.36507936507936506, 'eval/f1_weighted': 0.4638095238095238, 'split': 10, 'test/loss': 3.5588938906034393, 'test/precision_weighted': 0.3410025256715153, 'eval/recall_macro': 0.4083333333333333, 'eval/accuracy': 0.52, 'eval/f1_micro': 0.52, 'test/f1_macro': 0.26301054018445325, 'test/f1_micro': 0.36507936507936506, 'eval/precision_weighted': 0.4933333333333333, '_wandb': {'runtime': 991}, 'eval/precision_macro': 0.45833333333333326, 'eval/precision_micro': 0.52, 'test/recall_weighted': 0.36507936507936506, 'test/precision_micro': 0.36507936507936506, '_runtime': 992.3361856937408, 'eval/loss': 1.1245102910597171, 'test/accuracy': 0.36507936507936506, 'test/precision_macro': 0.30618466898954705}","{'rf_max_depth': 14, 'trial.number': 1}",crimson-night-406,RandomForest,['pre-trained:bert-base-uncased']
925,"{'eval/accuracy': 0.32, 'eval/f1_macro': 0.19435736677115983, 'test/f1_micro': 0.3333333333333333, 'eval/recall_micro': 0.32, 'test/recall_micro': 0.3333333333333333, 'test/recall_weighted': 0.3333333333333333, 'test/precision_weighted': 0.2717996289424861, '_step': 20, 'split': 10, 'test/loss': 2.4788723386264166, 'eval/precision_micro': 0.32, 'test/recall_macro': 0.2032258064516129, 'eval/recall_weighted': 0.32, 'test/precision_micro': 0.3333333333333333, 'eval/precision_weighted': 0.22231578947368424, '_timestamp': 1704283288.1099095, '_runtime': 1006.3982696533204, 'test/accuracy': 0.3333333333333333, 'test/f1_macro': 0.18232401656314703, 'eval/f1_weighted': 0.2527899686520376, 'eval/precision_macro': 0.17894736842105263, '_wandb': {'runtime': 1005}, 'test/f1_weighted': 0.2993361595846068, 'eval/loss': 1.3674314192299877, 'eval/f1_micro': 0.32, 'eval/recall_macro': 0.23333333333333336, 'test/precision_macro': 0.16558441558441558}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 1, 'dt_min_samples_leaf': 35}",summer-sun-405,DecisionTree,['pre-trained:bert-base-uncased']
926,"{'test/recall_macro': 0.2833333333333333, 'eval/precision_weighted': 0.2735714285714286, '_step': 20, 'eval/recall_macro': 0.21666666666666667, 'eval/recall_micro': 0.28, 'eval/precision_macro': 0.2388392857142857, 'test/precision_macro': 0.28862126245847175, 'eval/f1_macro': 0.2003205128205128, 'test/precision_weighted': 0.38535569266466274, 'test/loss': 1.3760304434705677, 'split': 10, '_timestamp': 1704283247.5060704, 'test/f1_weighted': 0.3815011544952836, 'eval/precision_micro': 0.28, 'test/precision_micro': 0.42857142857142855, 'test/recall_micro': 0.42857142857142855, 'eval/recall_weighted': 0.28, 'test/recall_weighted': 0.42857142857142855, '_wandb': {'runtime': 1252}, '_runtime': 1254.1783394813538, 'eval/accuracy': 0.28, 'test/accuracy': 0.42857142857142855, 'eval/f1_weighted': 0.2471794871794872, 'eval/loss': 1.7408499980300507, 'eval/f1_micro': 0.28, 'test/f1_macro': 0.2637801696020874, 'test/f1_micro': 0.42857142857142855}","{'dt_criterion': 'gini', 'dt_max_depth': 9, 'trial.number': 53, 'dt_min_samples_leaf': 22}",lively-morning-404,DecisionTree,['pre-trained:microsoft/codebert-base']
927,"{'_step': 20, 'eval/recall_macro': 0.25, 'test/recall_weighted': 0.47619047619047616, 'eval/loss': 1.3093803340842771, '_timestamp': 1704282599.7907376, 'test/recall_micro': 0.47619047619047616, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.16, 'test/precision_weighted': 0.22675736961451248, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_micro': 0.47619047619047616, 'test/precision_macro': 0.11904761904761904, 'split': 10, 'eval/accuracy': 0.4, 'test/accuracy': 0.47619047619047616, 'eval/precision_macro': 0.1, '_wandb': {'runtime': 1081}, 'eval/f1_macro': 0.14285714285714288, 'test/recall_macro': 0.25, 'test/f1_macro': 0.16129032258064516, 'test/f1_weighted': 0.30721966205837176, 'test/precision_micro': 0.47619047619047616, '_runtime': 1081.9380955696106, 'test/loss': 1.2950473981961883, 'eval/recall_micro': 0.4}",{'trial.number': 0},gentle-brook-403,LogisticRegression,['pre-trained:openai-gpt']
928,"{'test/loss': 23.093903682465488, '_timestamp': 1704282348.2816334, 'test/accuracy': 0.2063492063492063, 'eval/recall_micro': 0.32, 'eval/recall_weighted': 0.32, '_step': 20, '_runtime': 986.9819793701172, 'eval/loss': 23.317471154036557, 'eval/f1_weighted': 0.2607407407407407, 'eval/f1_macro': 0.18518518518518515, 'test/recall_micro': 0.2063492063492063, 'eval/precision_macro': 0.18627450980392157, 'test/recall_weighted': 0.2063492063492063, 'eval/accuracy': 0.32, 'test/f1_macro': 0.1367127496159754, 'eval/recall_macro': 0.21666666666666665, 'test/precision_micro': 0.2063492063492063, 'test/precision_weighted': 0.20360922146636432, 'eval/f1_micro': 0.32, 'test/f1_weighted': 0.1967668787945286, 'test/precision_macro': 0.1436011904761905, 'split': 10, '_wandb': {'runtime': 986}, 'test/f1_micro': 0.2063492063492063, 'test/recall_macro': 0.15, 'eval/precision_micro': 0.32, 'eval/precision_weighted': 0.24470588235294116}","{'n_neighbours': 2, 'trial.number': 0}",sage-cherry-402,KNeighbours,['pre-trained:bert-base-uncased']
929,"{'split': 10, 'test/accuracy': 0.47619047619047616, 'eval/recall_macro': 0.25, 'eval/precision_weighted': 0.16, '_step': 20, '_runtime': 982.7245109081268, 'test/precision_macro': 0.11904761904761904, 'eval/loss': 1.7936783486724692, 'eval/precision_macro': 0.1, 'eval/recall_weighted': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.16129032258064516, 'test/f1_micro': 0.47619047619047616, 'test/f1_weighted': 0.30721966205837176, '_wandb': {'runtime': 982}, 'eval/accuracy': 0.4, 'test/precision_micro': 0.47619047619047616, 'test/recall_weighted': 0.47619047619047616, 'test/recall_micro': 0.47619047619047616, 'eval/precision_micro': 0.4, 'test/loss': 1.6598024875120936, 'eval/f1_macro': 0.14285714285714288, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_micro': 0.4, '_timestamp': 1704282343.992553, 'test/recall_macro': 0.25, 'test/precision_weighted': 0.22675736961451248}","{'smoothing': 0.3472329967245673, 'trial.number': 0}",sage-lake-401,Bernolli,['pre-trained:bert-base-uncased']
930,"{'eval/f1_micro': 0.44, 'test/f1_micro': 0.42857142857142855, 'eval/recall_weighted': 0.44, 'test/precision_weighted': 0.46141215106732353, 'eval/loss': 1.3222229107951773, 'test/loss': 1.2629062966078304, 'eval/f1_weighted': 0.31, 'split': 10, '_wandb': {'runtime': 1000}, 'test/recall_macro': 0.25262605042016806, 'test/precision_micro': 0.42857142857142855, 'eval/recall_macro': 0.2916666666666667, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.23863636363636365, '_runtime': 1000.8808722496032, 'eval/precision_micro': 0.44, 'eval/precision_weighted': 0.3018181818181818, 'eval/accuracy': 0.44, 'test/accuracy': 0.42857142857142855, 'test/f1_weighted': 0.31520662120417314, 'test/precision_macro': 0.35775862068965514, '_step': 20, '_timestamp': 1704282326.1554172, 'eval/f1_macro': 0.21875, 'test/f1_macro': 0.19798041615667072, 'test/recall_weighted': 0.42857142857142855}","{'rf_max_depth': 5, 'trial.number': 0}",treasured-dew-400,RandomForest,['pre-trained:bert-base-uncased']
931,"{'_wandb': {'runtime': 1009}, 'test/f1_macro': 0.26365130276391857, 'eval/precision_macro': 0.55, 'test/precision_macro': 0.2676282051282051, 'eval/f1_weighted': 0.552, 'eval/precision_micro': 0.56, 'test/precision_micro': 0.3333333333333333, 'test/precision_weighted': 0.3418803418803419, 'split': 10, 'test/f1_micro': 0.3333333333333333, 'eval/recall_micro': 0.56, 'eval/precision_weighted': 0.56, 'eval/loss': 10.430136359084829, 'test/loss': 12.72059748040748, 'eval/accuracy': 0.56, 'test/recall_micro': 0.3333333333333333, 'eval/recall_weighted': 0.56, 'test/recall_weighted': 0.3333333333333333, '_runtime': 1009.7644431591034, '_timestamp': 1704282276.563286, 'eval/f1_macro': 0.55, 'test/accuracy': 0.3333333333333333, '_step': 20, 'eval/f1_micro': 0.56, 'test/f1_weighted': 0.33662308406903324, 'eval/recall_macro': 0.5708333333333333, 'test/recall_macro': 0.26263440860215054}","{'dt_criterion': 'gini', 'dt_max_depth': 11, 'trial.number': 0, 'dt_min_samples_leaf': 7}",crimson-sound-399,DecisionTree,['pre-trained:bert-base-uncased']
932,"{'eval/f1_macro': 0.17545454545454547, 'eval/f1_weighted': 0.21163636363636365, '_wandb': {'runtime': 1252}, '_runtime': 1253.6310458183289, 'test/loss': 1.4463200005947086, 'eval/recall_weighted': 0.24, 'eval/precision_weighted': 0.19466666666666668, 'test/recall_macro': 0.2916666666666667, 'eval/loss': 1.749520572735801, 'eval/f1_micro': 0.24, 'eval/recall_micro': 0.24, 'test/recall_micro': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, 'eval/recall_macro': 0.19166666666666665, '_step': 20, 'split': 10, 'eval/accuracy': 0.24, 'test/precision_macro': 0.2653846153846154, 'test/precision_micro': 0.3968253968253968, 'test/precision_weighted': 0.33618233618233617, 'test/f1_macro': 0.276048817696415, 'test/f1_micro': 0.3968253968253968, 'test/f1_weighted': 0.3620645817442156, 'eval/precision_micro': 0.24, '_timestamp': 1704281989.026353, 'test/accuracy': 0.3968253968253968, 'eval/precision_macro': 0.16666666666666669}","{'dt_criterion': 'gini', 'dt_max_depth': 13, 'trial.number': 52, 'dt_min_samples_leaf': 34}",young-deluge-398,DecisionTree,['pre-trained:microsoft/codebert-base']
933,"{'eval/precision_macro': 0.3058035714285714, 'eval/loss': 3.0030399810369635, 'test/loss': 1.8746312523659312, 'test/precision_micro': 0.3968253968253968, 'test/f1_macro': 0.26375506214215894, 'test/recall_weighted': 0.3968253968253968, 'eval/precision_weighted': 0.35214285714285715, '_step': 20, '_timestamp': 1704280729.6443906, 'test/accuracy': 0.3968253968253968, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.3968253968253968, '_runtime': 1254.2076745033264, 'eval/f1_micro': 0.4000000000000001, 'test/f1_weighted': 0.37291945126046505, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'split': 10, 'eval/f1_macro': 0.28044871794871795, 'eval/recall_macro': 0.31666666666666665, 'test/precision_macro': 0.2926587301587301, 'test/recall_macro': 0.2833333333333333, 'test/precision_weighted': 0.3930461073318216, '_wandb': {'runtime': 1252}, 'eval/accuracy': 0.4, 'test/f1_micro': 0.3968253968253968, 'eval/f1_weighted': 0.34205128205128205}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 51, 'dt_min_samples_leaf': 26}",bumbling-smoke-397,DecisionTree,['pre-trained:microsoft/codebert-base']
934,"{'test/accuracy': 0.3492063492063492, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.0873015873015873, 'test/loss': 1.366245083500712, '_timestamp': 1704279605.1280842, 'eval/f1_macro': 0.1527777777777778, 'eval/f1_micro': 0.44, '_wandb': {'runtime': 949}, '_runtime': 950.192458152771, 'eval/recall_micro': 0.44, 'eval/precision_micro': 0.44, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.25, 'eval/precision_macro': 0.11, 'eval/precision_weighted': 0.1936, 'split': 10, 'test/f1_weighted': 0.18076563958916897, 'eval/loss': 1.2851011078555243, 'test/recall_macro': 0.25, 'test/f1_micro': 0.3492063492063492, 'eval/f1_weighted': 0.26888888888888896, 'test/precision_micro': 0.3492063492063492, 'test/precision_weighted': 0.12194507432602668, '_step': 20, 'test/f1_macro': 0.12941176470588234, 'test/recall_micro': 0.3492063492063492, 'test/recall_weighted': 0.3492063492063492}",{'trial.number': 0},visionary-sun-396,LogisticRegression,['pre-trained:bert-base-uncased']
935,"{'_runtime': 1253.444545030594, 'test/f1_weighted': 0.3144328221133137, 'eval/f1_weighted': 0.3098181818181818, 'test/recall_micro': 0.31746031746031744, 'test/precision_macro': 0.2139423076923077, 'split': 10, 'test/loss': 5.828670791675353, 'eval/f1_micro': 0.32, 'test/f1_macro': 0.21038146441372252, '_timestamp': 1704279468.555306, 'test/f1_micro': 0.31746031746031744, 'eval/precision_macro': 0.2791666666666667, 'eval/f1_macro': 0.2761363636363636, 'test/recall_macro': 0.20833333333333337, 'eval/precision_weighted': 0.3066666666666667, '_step': 20, 'eval/loss': 7.083432274482229, 'eval/recall_macro': 0.2791666666666667, 'eval/precision_micro': 0.32, 'eval/recall_micro': 0.32, 'eval/recall_weighted': 0.32, 'test/recall_weighted': 0.31746031746031744, 'test/precision_weighted': 0.3128815628815629, '_wandb': {'runtime': 1252}, 'eval/accuracy': 0.32, 'test/accuracy': 0.31746031746031744, 'test/precision_micro': 0.31746031746031744}","{'dt_criterion': 'gini', 'dt_max_depth': 8, 'trial.number': 50, 'dt_min_samples_leaf': 16}",olive-plasma-394,DecisionTree,['pre-trained:microsoft/codebert-base']
936,"{'test/f1_micro': 0.36507936507936506, 'test/recall_macro': 0.24166666666666667, 'eval/precision_weighted': 0.3376190476190476, '_wandb': {'runtime': 1252}, 'eval/precision_macro': 0.34226190476190477, 'eval/recall_macro': 0.29583333333333334, 'eval/precision_micro': 0.32, 'eval/recall_weighted': 0.32, 'test/recall_weighted': 0.36507936507936506, '_runtime': 1254.1788787841797, 'eval/loss': 7.204752227491018, 'eval/f1_macro': 0.3103174603174604, 'test/precision_micro': 0.36507936507936506, 'test/precision_macro': 0.23026960784313727, '_step': 20, 'test/accuracy': 0.36507936507936506, 'eval/accuracy': 0.32, 'test/f1_macro': 0.23506944444444444, 'eval/f1_micro': 0.32, 'eval/f1_weighted': 0.3194920634920635, 'test/f1_weighted': 0.3489858906525573, 'test/recall_micro': 0.36507936507936506, 'test/loss': 3.5678813482519796, '_timestamp': 1704278209.4246728, 'test/precision_weighted': 0.3354341736694678, 'split': 10, 'eval/recall_micro': 0.32}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 49, 'dt_min_samples_leaf': 18}",confused-sun-393,DecisionTree,['pre-trained:microsoft/codebert-base']
937,"{'test/f1_weighted': 0.41414141414141414, 'eval/accuracy': 0.36, 'test/recall_weighted': 0.4444444444444444, 'eval/f1_macro': 0.2356254856254856, 'eval/recall_weighted': 0.36, 'eval/precision_weighted': 0.28833333333333333, '_step': 20, 'eval/loss': 3.0294529378784487, 'test/loss': 1.8927905872624295, 'eval/f1_weighted': 0.30508158508158506, 'test/recall_macro': 0.325, 'test/precision_weighted': 0.38888888888888895, 'split': 10, '_wandb': {'runtime': 1250}, 'test/accuracy': 0.4444444444444444, 'eval/recall_micro': 0.36, 'eval/precision_macro': 0.23437499999999997, 'test/precision_micro': 0.4444444444444444, 'eval/f1_micro': 0.36, 'test/f1_micro': 0.4444444444444444, 'eval/precision_micro': 0.36, 'test/precision_macro': 0.2902777777777778, 'eval/recall_macro': 0.26666666666666666, 'test/recall_micro': 0.4444444444444444, '_runtime': 1251.9067478179932, '_timestamp': 1704276950.2857587, 'test/f1_macro': 0.3060606060606061}","{'dt_criterion': 'gini', 'dt_max_depth': 8, 'trial.number': 48, 'dt_min_samples_leaf': 25}",legendary-bush-392,DecisionTree,['pre-trained:microsoft/codebert-base']
938,"{'eval/loss': 6.860243673865673, 'test/f1_weighted': 0.3746341841579937, 'eval/recall_macro': 0.2625, 'test/f1_macro': 0.30885225885225887, 'eval/recall_weighted': 0.28, 'test/precision_weighted': 0.3368102796674225, 'eval/f1_macro': 0.2248376623376623, 'eval/f1_micro': 0.28, 'test/accuracy': 0.42857142857142855, 'eval/precision_micro': 0.28, 'test/recall_weighted': 0.42857142857142855, 'split': 10, 'test/loss': 3.9656082978384193, 'test/precision_micro': 0.42857142857142855, 'eval/precision_weighted': 0.2177777777777778, '_timestamp': 1704275693.8915584, 'test/recall_macro': 0.37083333333333335, 'test/precision_macro': 0.26904761904761904, '_runtime': 1253.3785064220428, 'eval/precision_macro': 0.20138888888888887, 'test/f1_micro': 0.42857142857142855, 'eval/f1_weighted': 0.24259740259740256, 'eval/recall_micro': 0.28, 'test/recall_micro': 0.42857142857142855, '_step': 20, '_wandb': {'runtime': 1252}, 'eval/accuracy': 0.28}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 47, 'dt_min_samples_leaf': 30}",glorious-dawn-391,DecisionTree,['pre-trained:microsoft/codebert-base']
939,"{'split': 10, 'eval/recall_micro': 0.36, 'test/precision_micro': 0.4126984126984127, '_step': 20, 'test/f1_micro': 0.4126984126984127, 'test/f1_weighted': 0.3212660355517498, 'test/recall_macro': 0.25, 'test/recall_weighted': 0.4126984126984127, '_wandb': {'runtime': 1252}, 'test/accuracy': 0.4126984126984127, 'eval/precision_macro': 0.16544117647058823, 'eval/recall_weighted': 0.36, '_runtime': 1253.6195323467257, '_timestamp': 1704274436.0540464, 'eval/precision_micro': 0.36, 'test/loss': 1.3706803808059724, 'test/f1_macro': 0.19430569430569428, 'test/recall_micro': 0.4126984126984127, 'eval/f1_macro': 0.20655270655270655, 'eval/f1_micro': 0.36, 'test/precision_macro': 0.1589095744680851, 'test/precision_weighted': 0.2630023640661938, 'eval/loss': 1.496078348360896, 'eval/accuracy': 0.36, 'eval/precision_weighted': 0.21470588235294116, 'eval/f1_weighted': 0.2689458689458689, 'eval/recall_macro': 0.275}","{'dt_criterion': 'gini', 'dt_max_depth': 15, 'trial.number': 46, 'dt_min_samples_leaf': 45}",sweet-tree-390,DecisionTree,['pre-trained:microsoft/codebert-base']
940,"{'_timestamp': 1704273176.2134857, 'eval/accuracy': 0.28, 'eval/precision_macro': 0.20312499999999997, 'eval/precision_micro': 0.28, 'eval/loss': 1.7791070521412888, 'eval/f1_micro': 0.28, 'test/f1_weighted': 0.394526620333072, 'eval/recall_micro': 0.28, 'test/precision_macro': 0.30238095238095236, 'test/precision_weighted': 0.3983371126228269, 'test/precision_micro': 0.42857142857142855, 'eval/precision_weighted': 0.2383333333333333, 'split': 10, 'eval/f1_macro': 0.19716394716394717, 'test/accuracy': 0.42857142857142855, 'eval/f1_weighted': 0.24354312354312355, 'test/loss': 1.32614138813784, 'test/f1_micro': 0.42857142857142855, 'eval/recall_weighted': 0.28, '_step': 20, '_wandb': {'runtime': 1252}, '_runtime': 1253.743089675903, 'test/recall_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, 'test/f1_macro': 0.29498082562598693, 'eval/recall_macro': 0.21666666666666667, 'test/recall_macro': 0.3333333333333333}","{'dt_criterion': 'gini', 'dt_max_depth': 12, 'trial.number': 45, 'dt_min_samples_leaf': 29}",colorful-cosmos-389,DecisionTree,['pre-trained:microsoft/codebert-base']
941,"{'_step': 20, '_runtime': 1254.6053454875946, 'test/accuracy': 0.36507936507936506, 'eval/recall_weighted': 0.2, 'test/recall_weighted': 0.36507936507936506, 'test/precision_weighted': 0.322693179836037, 'eval/loss': 7.18056554494537, 'test/loss': 2.974267749077718, 'eval/f1_macro': 0.13636363636363635, 'eval/recall_micro': 0.2, 'test/recall_macro': 0.24166666666666667, 'eval/precision_macro': 0.125, 'test/precision_micro': 0.36507936507936506, 'test/f1_macro': 0.22862554112554115, 'test/f1_weighted': 0.34099498385212673, '_wandb': {'runtime': 1253}, 'eval/accuracy': 0.2, 'test/f1_micro': 0.36507936507936506, 'eval/precision_weighted': 0.16666666666666663, '_timestamp': 1704271918.0959425, 'eval/f1_weighted': 0.1818181818181818, 'eval/recall_macro': 0.15000000000000002, 'test/recall_micro': 0.36507936507936506, 'eval/precision_micro': 0.2, 'test/precision_macro': 0.21978021978021975, 'split': 10, 'eval/f1_micro': 0.20000000000000004}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 44, 'dt_min_samples_leaf': 21}",unique-night-388,DecisionTree,['pre-trained:microsoft/codebert-base']
942,"{'_runtime': 1252.8890795707705, 'eval/precision_weighted': 0.1955555555555555, 'test/precision_weighted': 0.31405895691609975, 'test/accuracy': 0.3968253968253968, 'test/f1_macro': 0.2607371794871795, 'test/f1_micro': 0.3968253968253968, 'eval/recall_weighted': 0.24, '_wandb': {'runtime': 1251}, 'test/loss': 1.7906017751272476, '_timestamp': 1704270659.417353, 'eval/recall_micro': 0.24, 'split': 10, 'eval/f1_macro': 0.18912337662337655, 'test/precision_micro': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, '_step': 20, 'eval/loss': 4.115607490893121, 'eval/accuracy': 0.24, 'eval/f1_micro': 0.24, 'eval/precision_macro': 0.1736111111111111, 'eval/recall_macro': 0.2125, 'test/recall_macro': 0.3145833333333333, 'eval/precision_micro': 0.24, 'test/precision_macro': 0.2294642857142857, 'eval/f1_weighted': 0.214025974025974, 'test/f1_weighted': 0.3471713471713472, 'test/recall_micro': 0.3968253968253968}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 43, 'dt_min_samples_leaf': 39}",sweet-eon-387,DecisionTree,['pre-trained:microsoft/codebert-base']
943,"{'eval/f1_micro': 0.20000000000000004, 'eval/precision_macro': 0.125, 'test/recall_macro': 0.24166666666666667, 'eval/recall_weighted': 0.2, 'test/precision_micro': 0.36507936507936506, 'eval/recall_micro': 0.2, 'eval/accuracy': 0.2, 'test/accuracy': 0.36507936507936506, 'test/f1_macro': 0.22862554112554115, 'test/f1_weighted': 0.34099498385212673, 'test/precision_weighted': 0.322693179836037, 'split': 10, '_wandb': {'runtime': 1252}, '_timestamp': 1704269401.0380735, 'test/precision_macro': 0.21978021978021975, '_step': 20, 'eval/precision_weighted': 0.16666666666666663, 'test/loss': 2.974267749077718, 'eval/f1_weighted': 0.1818181818181818, 'eval/precision_micro': 0.2, 'test/recall_weighted': 0.36507936507936506, 'eval/recall_macro': 0.15000000000000002, 'test/recall_micro': 0.36507936507936506, '_runtime': 1253.451770544052, 'eval/loss': 7.18056554494537, 'eval/f1_macro': 0.13636363636363635, 'test/f1_micro': 0.36507936507936506}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 42, 'dt_min_samples_leaf': 21}",woven-rain-386,DecisionTree,['pre-trained:microsoft/codebert-base']
944,"{'_wandb': {'runtime': 1251}, 'test/f1_micro': 0.42857142857142855, 'eval/f1_weighted': 0.24259740259740256, 'eval/precision_weighted': 0.2177777777777778, 'eval/accuracy': 0.28, 'eval/f1_micro': 0.28, 'eval/recall_micro': 0.28, 'test/recall_micro': 0.42857142857142855, 'test/accuracy': 0.42857142857142855, 'test/f1_weighted': 0.3746341841579937, 'eval/precision_micro': 0.28, 'test/precision_weighted': 0.3368102796674225, 'test/f1_macro': 0.30885225885225887, 'test/precision_macro': 0.26904761904761904, 'test/recall_weighted': 0.42857142857142855, '_timestamp': 1704268142.2020328, 'split': 10, 'eval/loss': 6.860243673865673, 'eval/f1_macro': 0.2248376623376623, '_runtime': 1252.5796127319336, 'test/recall_macro': 0.37083333333333335, 'eval/precision_macro': 0.20138888888888887, '_step': 20, 'test/loss': 3.9656082978384193, 'eval/recall_macro': 0.2625, 'eval/recall_weighted': 0.28, 'test/precision_micro': 0.42857142857142855}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 41, 'dt_min_samples_leaf': 29}",clear-waterfall-385,DecisionTree,['pre-trained:microsoft/codebert-base']
945,"{'eval/accuracy': 0.32, 'eval/f1_weighted': 0.3098181818181818, 'eval/loss': 7.083432274482229, 'eval/recall_weighted': 0.32, '_runtime': 1253.3029482364657, 'eval/f1_macro': 0.2761363636363636, 'eval/f1_micro': 0.32, 'test/f1_macro': 0.21038146441372252, 'eval/recall_micro': 0.32, 'eval/precision_micro': 0.32, '_step': 20, 'eval/precision_macro': 0.2791666666666667, 'split': 10, 'test/loss': 5.828670791675353, '_timestamp': 1704266883.9691403, 'test/precision_weighted': 0.3128815628815629, 'test/accuracy': 0.31746031746031744, 'test/f1_micro': 0.31746031746031744, 'eval/precision_weighted': 0.3066666666666667, '_wandb': {'runtime': 1251}, 'test/precision_macro': 0.2139423076923077, 'test/recall_weighted': 0.31746031746031744, 'test/f1_weighted': 0.3144328221133137, 'eval/recall_macro': 0.2791666666666667, 'test/recall_macro': 0.20833333333333337, 'test/recall_micro': 0.31746031746031744, 'test/precision_micro': 0.31746031746031744}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 40, 'dt_min_samples_leaf': 15}",expert-serenity-384,DecisionTree,['pre-trained:microsoft/codebert-base']
946,"{'eval/recall_macro': 0.31666666666666665, 'eval/recall_micro': 0.4, 'test/precision_micro': 0.3968253968253968, '_step': 20, '_timestamp': 1704265625.8159473, 'eval/f1_micro': 0.4000000000000001, 'split': 10, 'eval/loss': 3.0030399810369635, 'test/f1_weighted': 0.37291945126046505, 'test/f1_micro': 0.3968253968253968, 'test/precision_weighted': 0.3930461073318216, 'eval/recall_weighted': 0.4, '_wandb': {'runtime': 1250}, '_runtime': 1252.0316631793976, 'eval/accuracy': 0.4, 'test/recall_macro': 0.2833333333333333, 'test/precision_macro': 0.2926587301587301, 'test/recall_weighted': 0.3968253968253968, 'eval/f1_macro': 0.28044871794871795, 'test/accuracy': 0.3968253968253968, 'test/f1_macro': 0.26375506214215894, 'test/loss': 1.8746312523659312, 'eval/f1_weighted': 0.34205128205128205, 'eval/precision_micro': 0.4, 'test/recall_micro': 0.3968253968253968, 'eval/precision_macro': 0.3058035714285714, 'eval/precision_weighted': 0.35214285714285715}","{'dt_criterion': 'gini', 'dt_max_depth': 8, 'trial.number': 39, 'dt_min_samples_leaf': 26}",driven-cloud-383,DecisionTree,['pre-trained:microsoft/codebert-base']
947,"{'test/accuracy': 0.42857142857142855, 'eval/precision_micro': 0.28, 'test/precision_macro': 0.28862126245847175, 'eval/f1_weighted': 0.2471794871794872, 'eval/recall_macro': 0.21666666666666667, 'eval/recall_weighted': 0.28, 'test/recall_weighted': 0.42857142857142855, '_step': 20, 'eval/loss': 1.765472162077429, 'eval/f1_micro': 0.28, 'test/f1_micro': 0.42857142857142855, 'split': 10, 'test/loss': 1.3296695306514268, 'eval/f1_macro': 0.2003205128205128, 'eval/precision_weighted': 0.2735714285714286, 'test/precision_weighted': 0.38535569266466274, '_runtime': 1254.8706896305084, 'test/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.2388392857142857, 'test/precision_micro': 0.42857142857142855, '_timestamp': 1704264368.7570066, 'eval/recall_micro': 0.28, 'eval/accuracy': 0.28, 'test/f1_weighted': 0.3815011544952836, '_wandb': {'runtime': 1253}, 'test/f1_macro': 0.2637801696020874, 'test/recall_macro': 0.2833333333333333}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 38, 'dt_min_samples_leaf': 18}",super-serenity-382,DecisionTree,['pre-trained:microsoft/codebert-base']
948,"{'split': 10, 'eval/recall_micro': 0.24, 'test/recall_macro': 0.2916666666666667, 'eval/precision_weighted': 0.19466666666666668, 'eval/f1_weighted': 0.21163636363636365, 'eval/f1_macro': 0.17545454545454547, 'eval/precision_macro': 0.16666666666666669, '_timestamp': 1704263108.412913, 'test/f1_macro': 0.276048817696415, 'eval/recall_weighted': 0.24, 'test/precision_micro': 0.3968253968253968, '_step': 20, 'eval/accuracy': 0.24, 'test/accuracy': 0.3968253968253968, 'test/recall_micro': 0.3968253968253968, '_runtime': 1252.405490398407, 'eval/recall_macro': 0.19166666666666665, 'test/recall_weighted': 0.3968253968253968, 'test/precision_weighted': 0.33618233618233617, '_wandb': {'runtime': 1251}, 'eval/loss': 1.7254460051822684, 'test/loss': 1.4105774970582492, 'eval/f1_micro': 0.24, 'test/f1_micro': 0.3968253968253968, 'test/f1_weighted': 0.3620645817442156, 'eval/precision_micro': 0.24, 'test/precision_macro': 0.2653846153846154}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 37, 'dt_min_samples_leaf': 39}",lucky-silence-381,DecisionTree,['pre-trained:microsoft/codebert-base']
949,"{'eval/precision_weighted': 0.32285714285714284, '_step': 20, '_runtime': 1252.2728881835938, 'test/accuracy': 0.36507936507936506, 'test/f1_micro': 0.36507936507936506, 'eval/recall_micro': 0.32, 'eval/precision_macro': 0.3267857142857143, 'test/loss': 5.28953065227585, 'eval/f1_weighted': 0.308, 'test/precision_macro': 0.22088675213675213, 'test/precision_weighted': 0.32610907610907613, '_wandb': {'runtime': 1250}, 'eval/f1_macro': 0.2875, 'test/precision_micro': 0.36507936507936506, 'test/f1_macro': 0.22528860028860032, 'eval/recall_macro': 0.2791666666666667, 'test/recall_macro': 0.2333333333333333, 'test/recall_weighted': 0.36507936507936506, 'eval/loss': 7.075807460097883, 'eval/recall_weighted': 0.32, 'split': 10, 'eval/accuracy': 0.32, 'test/recall_micro': 0.36507936507936506, 'eval/precision_micro': 0.32, '_timestamp': 1704261849.3815153, 'eval/f1_micro': 0.32, 'test/f1_weighted': 0.34282736663689045}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 36, 'dt_min_samples_leaf': 14}",stellar-night-380,DecisionTree,['pre-trained:microsoft/codebert-base']
950,"{'split': 10, 'eval/accuracy': 0.28, 'test/f1_micro': 0.3968253968253968, 'eval/f1_weighted': 0.2533333333333333, 'eval/loss': 1.849080524088798, 'test/accuracy': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, 'test/f1_weighted': 0.37311894454751593, '_step': 20, '_runtime': 1252.8079493045807, 'eval/f1_micro': 0.28, 'test/f1_macro': 0.25649350649350644, 'eval/recall_macro': 0.23333333333333336, 'test/recall_macro': 0.275, 'test/precision_weighted': 0.35233285233285233, '_timestamp': 1704260592.9586682, 'eval/recall_micro': 0.28, 'test/recall_micro': 0.3968253968253968, 'eval/f1_macro': 0.21666666666666667, 'eval/precision_micro': 0.28, 'eval/recall_weighted': 0.28, 'test/precision_macro': 0.240530303030303, '_wandb': {'runtime': 1251}, 'test/loss': 1.4583807868708398, 'eval/precision_macro': 0.20476190476190476, 'test/precision_micro': 0.3968253968253968, 'eval/precision_weighted': 0.23428571428571424}","{'dt_criterion': 'gini', 'dt_max_depth': 8, 'trial.number': 35, 'dt_min_samples_leaf': 20}",driven-disco-379,DecisionTree,['pre-trained:microsoft/codebert-base']
951,"{'eval/precision_weighted': 0.35214285714285715, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.28044871794871795, '_step': 20, 'split': 10, '_timestamp': 1704259334.7966237, 'test/precision_macro': 0.2926587301587301, 'test/precision_weighted': 0.3930461073318216, '_wandb': {'runtime': 1252}, 'test/loss': 1.8746312523659312, 'eval/precision_macro': 0.3058035714285714, 'eval/loss': 3.0030399810369635, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.2833333333333333, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.3968253968253968, 'test/f1_micro': 0.3968253968253968, 'eval/recall_micro': 0.4, 'test/precision_micro': 0.3968253968253968, 'eval/f1_weighted': 0.34205128205128205, 'test/recall_micro': 0.3968253968253968, 'test/f1_macro': 0.26375506214215894, 'test/f1_weighted': 0.37291945126046505, 'eval/recall_macro': 0.31666666666666665, 'eval/recall_weighted': 0.4, '_runtime': 1253.582353591919, 'test/accuracy': 0.3968253968253968}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 34, 'dt_min_samples_leaf': 26}",avid-elevator-378,DecisionTree,['pre-trained:microsoft/codebert-base']
952,"{'eval/precision_weighted': 0.2509523809523809, '_wandb': {'runtime': 1250}, 'eval/recall_macro': 0.21666666666666667, 'test/recall_micro': 0.3968253968253968, 'eval/recall_weighted': 0.28, 'eval/f1_micro': 0.28, 'test/f1_micro': 0.3968253968253968, 'split': 10, 'eval/f1_macro': 0.20765345765345763, '_step': 20, 'eval/accuracy': 0.28, 'eval/recall_micro': 0.28, 'test/precision_macro': 0.27960526315789475, '_runtime': 1251.584323167801, 'test/loss': 4.7228203067187176, 'eval/precision_micro': 0.28, 'test/recall_weighted': 0.3968253968253968, '_timestamp': 1704258076.865729, 'test/f1_weighted': 0.3790883139396739, 'test/accuracy': 0.3968253968253968, 'eval/precision_macro': 0.2023809523809524, 'eval/f1_weighted': 0.26318570318570317, 'test/recall_macro': 0.3, 'test/precision_micro': 0.3968253968253968, 'test/precision_weighted': 0.3654970760233918, 'eval/loss': 4.444325242766112, 'test/f1_macro': 0.28752899009065996}","{'dt_criterion': 'gini', 'dt_max_depth': 9, 'trial.number': 33, 'dt_min_samples_leaf': 17}",pretty-terrain-377,DecisionTree,['pre-trained:microsoft/codebert-base']
953,"{'eval/f1_micro': 0.28, 'test/f1_micro': 0.42857142857142855, 'eval/f1_weighted': 0.2471794871794872, 'eval/recall_macro': 0.21666666666666667, 'test/recall_macro': 0.2833333333333333, 'test/loss': 1.878621827458272, 'eval/accuracy': 0.28, 'eval/recall_weighted': 0.28, 'eval/loss': 3.092916916476667, 'test/accuracy': 0.42857142857142855, 'eval/precision_micro': 0.28, 'test/precision_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, 'split': 10, 'test/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.2388392857142857, 'test/precision_macro': 0.28862126245847175, '_step': 20, 'eval/f1_macro': 0.2003205128205128, '_runtime': 1253.803424119949, '_timestamp': 1704256819.1008492, 'eval/recall_micro': 0.28, 'eval/precision_weighted': 0.2735714285714286, '_wandb': {'runtime': 1252}, 'test/f1_macro': 0.2637801696020874, 'test/f1_weighted': 0.3815011544952836, 'test/precision_weighted': 0.38535569266466274}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 32, 'dt_min_samples_leaf': 24}",woven-microwave-376,DecisionTree,['pre-trained:microsoft/codebert-base']
954,"{'test/f1_macro': 0.3060606060606061, 'test/recall_micro': 0.4444444444444444, 'eval/precision_macro': 0.23437499999999997, 'eval/f1_micro': 0.36, 'eval/f1_weighted': 0.30508158508158506, 'eval/precision_micro': 0.36, 'test/precision_micro': 0.4444444444444444, 'split': 10, 'eval/recall_macro': 0.26666666666666666, 'eval/recall_weighted': 0.36, 'test/precision_macro': 0.2902777777777778, 'test/precision_weighted': 0.38888888888888895, 'eval/precision_weighted': 0.28833333333333333, 'eval/f1_macro': 0.2356254856254856, 'test/f1_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, '_timestamp': 1704255559.1593547, 'eval/accuracy': 0.36, '_step': 20, '_wandb': {'runtime': 1252}, '_runtime': 1254.138623714447, 'eval/recall_micro': 0.36, 'test/recall_macro': 0.325, 'test/loss': 1.8927905872624295, 'test/accuracy': 0.4444444444444444, 'test/f1_weighted': 0.41414141414141414, 'eval/loss': 3.0294529378784487}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 31, 'dt_min_samples_leaf': 25}",prime-water-375,DecisionTree,['pre-trained:microsoft/codebert-base']
955,"{'split': 10, 'eval/f1_micro': 0.32, 'test/f1_macro': 0.23480568395822635, 'eval/recall_micro': 0.32, 'test/recall_macro': 0.24583333333333335, 'eval/precision_macro': 0.3125, 'eval/recall_weighted': 0.32, 'test/f1_micro': 0.31746031746031744, 'test/f1_weighted': 0.31192745317039106, 'test/recall_micro': 0.31746031746031744, 'test/recall_weighted': 0.31746031746031744, 'eval/precision_weighted': 0.32, '_wandb': {'runtime': 1253}, 'test/precision_weighted': 0.30819193577814274, '_step': 20, 'eval/loss': 4.404295085476793, 'test/loss': 2.067608531165856, '_timestamp': 1704254298.467266, 'eval/recall_macro': 0.29583333333333334, 'test/precision_macro': 0.22624521072796933, '_runtime': 1254.4445130825045, 'test/accuracy': 0.31746031746031744, 'eval/f1_weighted': 0.31545454545454543, 'eval/precision_micro': 0.32, 'eval/accuracy': 0.32, 'eval/f1_macro': 0.2992424242424242, 'test/precision_micro': 0.31746031746031744}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 30, 'dt_min_samples_leaf': 10}",clean-voice-374,DecisionTree,['pre-trained:microsoft/codebert-base']
956,"{'test/recall_macro': 0.3264285714285714, '_wandb': {'runtime': 1265}, '_runtime': 1266.3860836029053, 'test/precision_weighted': 0.4354497354497354, 'eval/f1_micro': 0.32, 'test/recall_micro': 0.47619047619047616, 'eval/precision_macro': 0.09090909090909093, 'test/precision_micro': 0.47619047619047616, '_timestamp': 1704253127.5360987, 'eval/accuracy': 0.32, 'eval/recall_micro': 0.32, 'test/recall_weighted': 0.47619047619047616, 'test/accuracy': 0.47619047619047616, 'test/f1_macro': 0.2885690653432589, 'eval/f1_weighted': 0.20000000000000004, 'eval/recall_macro': 0.2, 'split': 10, 'eval/loss': 1.3519183815620262, 'test/loss': 1.3293795402201043, 'eval/f1_macro': 0.12500000000000003, 'eval/precision_micro': 0.32, 'eval/recall_weighted': 0.32, 'test/precision_macro': 0.34833333333333333, 'eval/precision_weighted': 0.14545454545454548, '_step': 20, 'test/f1_micro': 0.47619047619047616, 'test/f1_weighted': 0.39683852587078383}","{'rf_max_depth': 4, 'trial.number': 29}",fresh-firebrand-373,RandomForest,['pre-trained:microsoft/codebert-base']
957,"{'eval/precision_micro': 0.28, 'test/precision_macro': 0.224025974025974, 'test/accuracy': 0.31746031746031744, 'eval/recall_micro': 0.28, 'test/f1_micro': 0.31746031746031744, 'test/f1_weighted': 0.30822540752538163, 'eval/loss': 5.6701401048873485, 'eval/f1_micro': 0.28, 'eval/recall_macro': 0.24583333333333335, 'test/recall_macro': 0.25416666666666665, 'test/recall_weighted': 0.31746031746031744, 'split': 10, '_runtime': 1266.5256531238556, '_step': 20, 'test/recall_micro': 0.31746031746031744, 'eval/recall_weighted': 0.28, 'test/precision_weighted': 0.30370026798598226, '_wandb': {'runtime': 1265}, 'eval/f1_macro': 0.21746031746031744, 'eval/precision_weighted': 0.2307878787878788, 'test/f1_macro': 0.23612911589318125, '_timestamp': 1704253038.626034, 'eval/accuracy': 0.28, 'eval/precision_macro': 0.19646464646464645, 'test/precision_micro': 0.31746031746031744, 'test/loss': 5.1518106373303345, 'eval/f1_weighted': 0.25193650793650796}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 29, 'dt_min_samples_leaf': 12}",light-leaf-372,DecisionTree,['pre-trained:microsoft/codebert-base']
958,"{'test/recall_macro': 0.20190476190476192, 'eval/recall_macro': 0.3666666666666667, 'test/recall_weighted': 0.31746031746031744, '_wandb': {'runtime': 1266}, 'eval/loss': 1.4234013978788216, 'eval/f1_macro': 0.29100529100529104, 'test/f1_micro': 0.31746031746031744, '_step': 20, 'eval/accuracy': 0.48, 'eval/precision_macro': 0.2426470588235294, 'test/precision_macro': 0.14693877551020407, 'test/loss': 1.4113285127668684, 'test/f1_weighted': 0.22941622941622936, 'eval/precision_weighted': 0.30823529411764705, '_timestamp': 1704251856.961712, 'eval/f1_micro': 0.48, 'test/accuracy': 0.31746031746031744, '_runtime': 1267.7708349227903, 'eval/recall_micro': 0.48, 'split': 10, 'test/recall_micro': 0.31746031746031744, 'eval/recall_weighted': 0.48, 'test/precision_weighted': 0.22053773890508588, 'test/f1_macro': 0.14760914760914762, 'eval/f1_weighted': 0.37417989417989417, 'eval/precision_micro': 0.48, 'test/precision_micro': 0.31746031746031744}","{'rf_max_depth': 5, 'trial.number': 28}",fearless-serenity-371,RandomForest,['pre-trained:microsoft/codebert-base']
959,"{'eval/f1_micro': 0.28, 'eval/f1_weighted': 0.2533333333333333, '_runtime': 1266.455809593201, 'eval/loss': 3.1476298130154903, 'eval/precision_macro': 0.20476190476190476, 'eval/recall_weighted': 0.28, 'test/precision_weighted': 0.3353563647681295, '_wandb': {'runtime': 1265}, 'test/loss': 2.491956299236284, 'eval/f1_macro': 0.21666666666666667, 'test/recall_micro': 0.380952380952381, 'eval/precision_micro': 0.28, '_timestamp': 1704251767.5549865, 'eval/accuracy': 0.28, 'test/f1_micro': 0.380952380952381, 'test/f1_weighted': 0.3566919191919192, 'eval/precision_weighted': 0.23428571428571424, 'eval/recall_macro': 0.23333333333333336, 'test/precision_micro': 0.380952380952381, 'split': 10, 'test/precision_macro': 0.2267156862745098, '_step': 20, 'test/accuracy': 0.380952380952381, 'test/f1_macro': 0.2414772727272727, 'eval/recall_micro': 0.28, 'test/recall_macro': 0.25833333333333336, 'test/recall_weighted': 0.380952380952381}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 28, 'dt_min_samples_leaf': 19}",proud-forest-370,DecisionTree,['pre-trained:microsoft/codebert-base']
960,"{'_wandb': {'runtime': 1266}, '_runtime': 1267.5084557533264, 'eval/accuracy': 0.36, '_step': 20, 'split': 10, 'test/recall_macro': 0.25261904761904763, 'eval/precision_macro': 0.22023809523809523, 'eval/precision_weighted': 0.2523809523809524, 'eval/loss': 1.344072557309433, '_timestamp': 1704250581.5838647, 'test/f1_micro': 0.3333333333333333, 'test/f1_weighted': 0.2578391626010673, 'eval/recall_weighted': 0.36, 'test/precision_macro': 0.3365384615384615, 'test/recall_weighted': 0.3333333333333333, 'eval/f1_macro': 0.2004608294930876, 'test/precision_micro': 0.3333333333333333, 'test/loss': 1.378744352908334, 'eval/f1_micro': 0.36, 'eval/precision_micro': 0.36, 'test/precision_weighted': 0.33048433048433046, 'test/accuracy': 0.3333333333333333, 'eval/f1_weighted': 0.26359447004608294, 'test/f1_macro': 0.2245220057720058, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.36, 'test/recall_micro': 0.3333333333333333}","{'rf_max_depth': 4, 'trial.number': 27}",celestial-wave-369,RandomForest,['pre-trained:microsoft/codebert-base']
961,"{'test/precision_macro': 0.28862126245847175, 'test/recall_weighted': 0.42857142857142855, 'test/f1_macro': 0.2637801696020874, 'test/f1_micro': 0.42857142857142855, 'eval/precision_macro': 0.2388392857142857, 'split': 10, 'eval/loss': 3.092916916476667, 'eval/precision_micro': 0.28, 'test/precision_weighted': 0.38535569266466274, 'eval/f1_micro': 0.28, 'test/recall_micro': 0.42857142857142855, '_timestamp': 1704250495.7758017, 'eval/f1_macro': 0.2003205128205128, 'eval/recall_weighted': 0.28, '_step': 20, '_runtime': 1266.5860035419464, 'test/loss': 1.878621827458272, 'eval/accuracy': 0.28, 'eval/precision_weighted': 0.2735714285714286, 'eval/f1_weighted': 0.2471794871794872, 'eval/recall_micro': 0.28, 'test/f1_weighted': 0.3815011544952836, 'eval/recall_macro': 0.21666666666666667, 'test/recall_macro': 0.2833333333333333, 'test/precision_micro': 0.42857142857142855, '_wandb': {'runtime': 1265}, 'test/accuracy': 0.42857142857142855}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 27, 'dt_min_samples_leaf': 24}",pleasant-firebrand-368,DecisionTree,['pre-trained:microsoft/codebert-base']
962,"{'split': 10, 'test/f1_weighted': 0.2189381499726327, 'eval/recall_macro': 0.25, 'test/precision_micro': 0.380952380952381, '_wandb': {'runtime': 1264}, '_runtime': 1265.951404094696, 'test/loss': 1.3914581370349468, 'eval/accuracy': 0.4, 'test/f1_micro': 0.380952380952381, 'test/precision_weighted': 0.15360983102918588, 'eval/f1_macro': 0.14285714285714288, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.0967741935483871, '_step': 20, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.380952380952381, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_micro': 0.380952380952381, 'eval/precision_micro': 0.4, 'eval/recall_micro': 0.4, 'test/recall_weighted': 0.380952380952381, 'eval/loss': 1.3201572542809314, '_timestamp': 1704249308.703241, 'test/f1_macro': 0.1379310344827586, 'test/recall_macro': 0.24, 'eval/precision_macro': 0.1, 'eval/precision_weighted': 0.16}","{'rf_max_depth': 2, 'trial.number': 26}",bumbling-grass-367,RandomForest,['pre-trained:microsoft/codebert-base']
963,"{'_step': 20, 'eval/recall_macro': 0.26666666666666666, 'eval/recall_weighted': 0.36, 'test/f1_micro': 0.4444444444444444, 'test/f1_weighted': 0.41414141414141414, 'eval/recall_micro': 0.36, '_wandb': {'runtime': 1264}, 'test/recall_macro': 0.325, 'eval/precision_macro': 0.23437499999999997, 'test/precision_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'split': 10, '_timestamp': 1704249224.0538526, 'eval/f1_micro': 0.36, 'test/accuracy': 0.4444444444444444, 'test/precision_weighted': 0.38888888888888895, '_runtime': 1266.0373575687408, 'test/loss': 1.8927905872624295, 'eval/precision_micro': 0.36, 'test/precision_macro': 0.2902777777777778, 'eval/loss': 3.0294529378784487, 'eval/accuracy': 0.36, 'test/f1_macro': 0.3060606060606061, 'test/recall_micro': 0.4444444444444444, 'eval/precision_weighted': 0.28833333333333333, 'eval/f1_macro': 0.2356254856254856, 'eval/f1_weighted': 0.30508158508158506}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 26, 'dt_min_samples_leaf': 25}",northern-waterfall-366,DecisionTree,['pre-trained:microsoft/codebert-base']
964,"{'eval/f1_weighted': 0.23529411764705885, 'test/recall_micro': 0.3492063492063492, 'eval/f1_macro': 0.14705882352941177, '_runtime': 1267.014010667801, 'test/precision_macro': 0.09322033898305083, 'split': 10, 'test/f1_micro': 0.3492063492063492, 'eval/recall_micro': 0.4, '_step': 20, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.20786092214663648, 'eval/precision_macro': 0.10416666666666669, '_wandb': {'runtime': 1265}, 'test/accuracy': 0.3492063492063492, 'test/f1_macro': 0.13095238095238096, 'eval/recall_macro': 0.25, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.14796879203658864, 'eval/loss': 1.3459722612597065, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.16666666666666669, 'test/loss': 1.3807216789264174, 'test/recall_macro': 0.22, 'test/precision_micro': 0.3492063492063492, '_timestamp': 1704248038.656175, 'test/recall_weighted': 0.3492063492063492, 'eval/f1_micro': 0.4000000000000001}","{'rf_max_depth': 3, 'trial.number': 25}",cosmic-donkey-365,RandomForest,['pre-trained:microsoft/codebert-base']
965,"{'eval/recall_micro': 0.36, 'test/precision_micro': 0.4444444444444444, 'split': 10, 'eval/loss': 3.0294529378784487, '_timestamp': 1704247953.1760316, 'eval/accuracy': 0.36, 'test/recall_macro': 0.325, 'test/precision_macro': 0.2902777777777778, 'eval/precision_weighted': 0.28833333333333333, 'test/precision_weighted': 0.38888888888888895, 'eval/f1_macro': 0.2356254856254856, 'test/accuracy': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, 'eval/recall_macro': 0.26666666666666666, 'eval/precision_macro': 0.23437499999999997, 'test/recall_weighted': 0.4444444444444444, '_runtime': 1266.0787556171415, 'test/loss': 1.8927905872624295, 'eval/f1_weighted': 0.30508158508158506, 'eval/recall_weighted': 0.36, '_step': 20, '_wandb': {'runtime': 1264}, 'test/f1_macro': 0.3060606060606061, 'test/f1_weighted': 0.41414141414141414, 'test/recall_micro': 0.4444444444444444, 'eval/f1_micro': 0.36, 'eval/precision_micro': 0.36}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 25, 'dt_min_samples_leaf': 25}",elated-gorge-364,DecisionTree,['pre-trained:microsoft/codebert-base']
966,"{'_timestamp': 1704246766.474789, 'test/f1_weighted': 0.2307124400147656, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.36, 'test/precision_micro': 0.3968253968253968, 'split': 10, '_wandb': {'runtime': 1264}, 'test/loss': 1.3703166008338523, 'test/f1_micro': 0.3968253968253968, 'eval/precision_macro': 0.09375, '_step': 20, 'eval/loss': 1.345112990741017, 'eval/recall_macro': 0.225, 'test/precision_macro': 0.10245901639344264, 'test/f1_macro': 0.1453488372093023, 'eval/precision_micro': 0.36, 'eval/precision_weighted': 0.15, '_runtime': 1265.6973078250885, 'eval/f1_micro': 0.36, 'test/accuracy': 0.3968253968253968, 'eval/f1_macro': 0.13235294117647062, 'test/recall_micro': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, 'test/precision_weighted': 0.16263335935467085, 'eval/accuracy': 0.36, 'eval/f1_weighted': 0.21176470588235297, 'eval/recall_micro': 0.36}","{'rf_max_depth': 2, 'trial.number': 24}",fearless-terrain-363,RandomForest,['pre-trained:microsoft/codebert-base']
967,"{'eval/precision_macro': 0.34226190476190477, 'test/precision_weighted': 0.3354341736694678, 'eval/loss': 7.204752227491018, '_timestamp': 1704246681.1906602, 'test/recall_micro': 0.36507936507936506, 'test/precision_micro': 0.36507936507936506, 'eval/accuracy': 0.32, 'test/recall_macro': 0.24166666666666667, 'eval/precision_weighted': 0.3376190476190476, 'eval/recall_micro': 0.32, 'eval/precision_micro': 0.32, 'eval/recall_weighted': 0.32, '_step': 20, '_runtime': 1266.0495202541351, 'eval/f1_micro': 0.32, 'eval/f1_weighted': 0.3194920634920635, 'eval/recall_macro': 0.29583333333333334, 'eval/f1_macro': 0.3103174603174604, 'test/accuracy': 0.36507936507936506, 'test/f1_micro': 0.36507936507936506, 'test/f1_weighted': 0.3489858906525573, 'test/recall_weighted': 0.36507936507936506, 'test/loss': 3.5678813482519796, 'test/precision_macro': 0.23026960784313727, 'split': 10, '_wandb': {'runtime': 1264}, 'test/f1_macro': 0.23506944444444444}","{'dt_criterion': 'gini', 'dt_max_depth': 13, 'trial.number': 24, 'dt_min_samples_leaf': 18}",stellar-salad-362,DecisionTree,['pre-trained:microsoft/codebert-base']
968,"{'test/loss': 1.342769350171377, 'eval/accuracy': 0.4, 'test/precision_weighted': 0.4934558618769145, 'test/precision_micro': 0.380952380952381, 'eval/loss': 1.3026769794552124, '_timestamp': 1704245496.4106026, 'eval/f1_macro': 0.15151515151515152, 'eval/f1_weighted': 0.24242424242424243, 'test/recall_micro': 0.380952380952381, 'eval/precision_weighted': 0.17391304347826086, 'split': 10, '_runtime': 1266.525966644287, 'test/f1_macro': 0.1629711751662971, 'test/f1_weighted': 0.25291239925386266, 'test/recall_macro': 0.2419047619047619, 'eval/precision_macro': 0.10869565217391304, 'eval/recall_weighted': 0.4, '_step': 20, 'test/f1_micro': 0.380952380952381, 'test/recall_weighted': 0.380952380952381, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.380952380952381, 'eval/recall_macro': 0.25, 'test/precision_macro': 0.3508771929824561, '_wandb': {'runtime': 1265}, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4}","{'rf_max_depth': 3, 'trial.number': 23}",zesty-gorge-361,RandomForest,['pre-trained:microsoft/codebert-base']
969,"{'eval/f1_micro': 0.28, 'test/accuracy': 0.42857142857142855, 'test/f1_micro': 0.42857142857142855, 'eval/recall_macro': 0.21666666666666667, 'eval/loss': 1.7408499980300507, 'eval/accuracy': 0.28, 'eval/f1_macro': 0.2003205128205128, 'test/f1_macro': 0.2637801696020874, 'split': 10, 'test/recall_micro': 0.42857142857142855, '_wandb': {'runtime': 1263}, '_timestamp': 1704245409.5163298, 'test/f1_weighted': 0.3815011544952836, 'eval/precision_macro': 0.2388392857142857, 'test/precision_macro': 0.28862126245847175, '_step': 20, 'eval/f1_weighted': 0.2471794871794872, 'test/recall_macro': 0.2833333333333333, 'test/recall_weighted': 0.42857142857142855, 'test/precision_weighted': 0.38535569266466274, 'eval/recall_micro': 0.28, 'eval/precision_micro': 0.28, 'eval/recall_weighted': 0.28, 'test/precision_micro': 0.42857142857142855, '_runtime': 1265.2904317378998, 'test/loss': 1.3760304434705677, 'eval/precision_weighted': 0.2735714285714286}","{'dt_criterion': 'gini', 'dt_max_depth': 16, 'trial.number': 23, 'dt_min_samples_leaf': 23}",sunny-durian-360,DecisionTree,['pre-trained:microsoft/codebert-base']
970,"{'_step': 20, '_wandb': {'runtime': 1263}, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.3968253968253968, '_timestamp': 1704244226.100104, 'test/recall_micro': 0.3968253968253968, 'eval/precision_macro': 0.22282608695652173, 'eval/precision_micro': 0.4, 'test/recall_macro': 0.2519047619047619, 'test/recall_weighted': 0.3968253968253968, 'eval/f1_weighted': 0.27818181818181814, 'eval/recall_micro': 0.4, 'eval/precision_weighted': 0.27652173913043476, 'test/f1_weighted': 0.2600658149438637, 'eval/recall_macro': 0.26666666666666666, 'eval/loss': 1.3023060721121298, 'test/loss': 1.330838862594145, 'eval/accuracy': 0.4, 'test/accuracy': 0.3968253968253968, 'test/f1_macro': 0.16717479674796748, 'test/precision_micro': 0.3968253968253968, 'test/precision_weighted': 0.2781954887218045, 'split': 10, '_runtime': 1265.2015788555143, 'eval/f1_macro': 0.19886363636363635, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.18859649122807015}","{'rf_max_depth': 2, 'trial.number': 22}",fresh-vortex-359,RandomForest,['pre-trained:microsoft/codebert-base']
971,"{'eval/recall_weighted': 0.36, 'test/precision_weighted': 0.38888888888888895, 'test/f1_macro': 0.3060606060606061, 'eval/f1_micro': 0.36, 'eval/precision_weighted': 0.28833333333333333, '_runtime': 1265.2054452896118, '_timestamp': 1704244140.4275403, 'eval/recall_micro': 0.36, 'test/precision_macro': 0.2902777777777778, 'test/precision_micro': 0.4444444444444444, 'test/loss': 1.8927905872624295, 'eval/f1_macro': 0.2356254856254856, 'eval/f1_weighted': 0.30508158508158506, 'test/recall_macro': 0.325, '_step': 20, 'eval/recall_macro': 0.26666666666666666, 'eval/precision_macro': 0.23437499999999997, 'eval/precision_micro': 0.36, 'test/recall_weighted': 0.4444444444444444, '_wandb': {'runtime': 1263}, 'test/f1_micro': 0.4444444444444444, 'test/f1_weighted': 0.41414141414141414, 'test/recall_micro': 0.4444444444444444, 'eval/accuracy': 0.36, 'eval/loss': 3.0294529378784487, 'test/accuracy': 0.4444444444444444, 'split': 10}","{'dt_criterion': 'gini', 'dt_max_depth': 12, 'trial.number': 22, 'dt_min_samples_leaf': 25}",fresh-wind-358,DecisionTree,['pre-trained:microsoft/codebert-base']
972,"{'_wandb': {'runtime': 1264}, '_runtime': 1266.027976512909, 'split': 10, 'eval/recall_micro': 0.4, 'test/recall_weighted': 0.3968253968253968, 'test/f1_macro': 0.14367816091954022, 'test/f1_weighted': 0.2280605728881591, 'eval/f1_macro': 0.14705882352941177, 'test/loss': 1.3793617694930842, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.25, 'eval/loss': 1.3127577632068068, '_timestamp': 1704242952.8526163, 'eval/f1_weighted': 0.23529411764705885, 'eval/precision_macro': 0.10416666666666669, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.10080645161290322, 'test/precision_weighted': 0.16001024065540193, '_step': 20, 'test/f1_micro': 0.3968253968253968, 'test/recall_macro': 0.25, 'test/recall_micro': 0.3968253968253968, 'eval/precision_weighted': 0.16666666666666669, 'test/accuracy': 0.3968253968253968, 'test/precision_micro': 0.3968253968253968, 'eval/precision_micro': 0.4, 'eval/accuracy': 0.4}","{'rf_max_depth': 2, 'trial.number': 21}",curious-totem-357,RandomForest,['pre-trained:microsoft/codebert-base']
973,"{'eval/f1_micro': 0.28, 'test/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.20312499999999997, 'eval/loss': 1.5620469099382857, 'test/loss': 1.3400354753567267, 'eval/accuracy': 0.28, 'eval/f1_macro': 0.19716394716394717, 'eval/recall_weighted': 0.28, '_timestamp': 1704242867.2463005, 'test/f1_weighted': 0.394526620333072, 'test/recall_macro': 0.3333333333333333, 'test/precision_micro': 0.42857142857142855, 'test/accuracy': 0.42857142857142855, 'test/f1_micro': 0.42857142857142855, 'eval/recall_micro': 0.28, 'test/precision_weighted': 0.3983371126228269, 'eval/f1_weighted': 0.24354312354312355, 'test/precision_macro': 0.30238095238095236, 'split': 10, 'test/f1_macro': 0.29498082562598693, 'eval/precision_weighted': 0.2383333333333333, '_step': 20, '_wandb': {'runtime': 1265}, '_runtime': 1266.3918163776398, 'eval/recall_macro': 0.21666666666666667, 'eval/precision_micro': 0.28, 'test/recall_weighted': 0.42857142857142855}","{'dt_criterion': 'gini', 'dt_max_depth': 11, 'trial.number': 21, 'dt_min_samples_leaf': 32}",glowing-morning-356,DecisionTree,['pre-trained:microsoft/codebert-base']
974,"{'eval/precision_micro': 0.28, '_wandb': {'runtime': 1263}, 'eval/f1_macro': 0.125, 'test/f1_macro': 0.2370533695160561, 'test/f1_weighted': 0.23269654612938195, 'eval/accuracy': 0.28, 'test/recall_micro': 0.2857142857142857, 'eval/precision_macro': 0.09722222222222222, 'test/recall_weighted': 0.2857142857142857, 'test/precision_weighted': 0.21050642479213907, 'split': 10, 'eval/recall_micro': 0.28, 'test/recall_macro': 0.26142857142857145, 'test/precision_micro': 0.2857142857142857, 'eval/recall_macro': 0.175, 'eval/precision_weighted': 0.15555555555555556, 'eval/loss': 3.030264334236574, 'test/loss': 2.08112195811556, 'test/f1_micro': 0.2857142857142857, 'eval/f1_weighted': 0.2, 'eval/recall_weighted': 0.28, '_runtime': 1264.714162349701, 'eval/f1_micro': 0.28, '_step': 20, '_timestamp': 1704241681.5414293, 'test/accuracy': 0.2857142857142857, 'test/precision_macro': 0.24404761904761904}","{'rf_max_depth': 11, 'trial.number': 20}",earnest-darkness-355,RandomForest,['pre-trained:microsoft/codebert-base']
975,"{'eval/recall_weighted': 0.24, 'test/precision_weighted': 0.31405895691609975, 'test/loss': 1.7906017751272476, 'eval/accuracy': 0.24, 'test/f1_weighted': 0.3471713471713472, 'eval/precision_micro': 0.24, 'test/recall_macro': 0.3145833333333333, 'eval/precision_macro': 0.1736111111111111, 'test/recall_weighted': 0.3968253968253968, '_runtime': 1265.3941733837128, 'test/f1_micro': 0.3968253968253968, '_timestamp': 1704241597.323661, 'test/f1_macro': 0.2607371794871795, '_step': 20, 'eval/loss': 4.115607490893121, 'eval/recall_micro': 0.24, 'test/recall_micro': 0.3968253968253968, 'test/precision_macro': 0.2294642857142857, 'eval/precision_weighted': 0.1955555555555555, 'eval/f1_macro': 0.18912337662337655, 'test/accuracy': 0.3968253968253968, 'test/precision_micro': 0.3968253968253968, 'eval/f1_micro': 0.24, 'eval/recall_macro': 0.2125, 'eval/f1_weighted': 0.214025974025974, 'split': 10, '_wandb': {'runtime': 1264}}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 20, 'dt_min_samples_leaf': 37}",gentle-dragon-354,DecisionTree,['pre-trained:microsoft/codebert-base']
976,"{'_timestamp': 1704240411.992071, 'eval/f1_micro': 0.36, 'test/loss': 1.479567733531788, 'eval/f1_weighted': 0.3396273291925466, 'test/f1_weighted': 0.32614004353134785, 'test/precision_macro': 0.41227106227106225, 'eval/precision_weighted': 0.32717948717948725, '_step': 20, 'eval/f1_macro': 0.3051242236024845, 'eval/recall_macro': 0.3125, 'eval/recall_micro': 0.36, 'test/recall_macro': 0.340952380952381, 'eval/precision_macro': 0.30448717948717946, 'eval/recall_weighted': 0.36, 'test/recall_weighted': 0.36507936507936506, 'eval/accuracy': 0.36, '_runtime': 1265.79811501503, 'test/precision_weighted': 0.452991452991453, 'split': 10, 'test/accuracy': 0.36507936507936506, 'test/precision_micro': 0.36507936507936506, 'test/recall_micro': 0.36507936507936506, 'eval/precision_micro': 0.36, '_wandb': {'runtime': 1264}, 'test/f1_macro': 0.3153647077560121, 'test/f1_micro': 0.36507936507936506, 'eval/loss': 1.5081129177325523}","{'rf_max_depth': 6, 'trial.number': 19}",wobbly-voice-353,RandomForest,['pre-trained:microsoft/codebert-base']
977,"{'test/recall_weighted': 0.3968253968253968, 'test/loss': 4.93811809863862, 'eval/f1_micro': 0.20000000000000004, 'eval/precision_micro': 0.2, 'test/f1_micro': 0.3968253968253968, 'eval/recall_weighted': 0.2, 'test/precision_micro': 0.3968253968253968, 'eval/f1_macro': 0.18656015037593984, 'test/accuracy': 0.3968253968253968, 'eval/recall_micro': 0.2, 'eval/accuracy': 0.2, 'test/f1_macro': 0.3501984126984127, 'eval/f1_weighted': 0.1813533834586466, 'test/f1_weighted': 0.393864953388763, 'test/precision_macro': 0.35128205128205126, 'test/precision_weighted': 0.4140822140822141, 'test/recall_macro': 0.37916666666666665, 'eval/precision_macro': 0.1736111111111111, 'eval/precision_weighted': 0.17333333333333337, '_step': 20, '_wandb': {'runtime': 1263}, 'eval/loss': 10.975773977696916, 'eval/recall_macro': 0.2125, 'test/recall_micro': 0.3968253968253968, 'split': 10, '_runtime': 1264.7081763744354, '_timestamp': 1704240327.2026353}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 19, 'dt_min_samples_leaf': 23}",stilted-shape-352,DecisionTree,['pre-trained:microsoft/codebert-base']
978,"{'eval/recall_weighted': 0.36, 'eval/precision_weighted': 0.15, '_timestamp': 1704239141.4865634, 'test/f1_macro': 0.1419753086419753, 'eval/recall_macro': 0.225, 'eval/recall_micro': 0.36, 'split': 10, 'eval/loss': 1.37104126027397, 'test/f1_weighted': 0.22535763276504017, 'test/f1_micro': 0.36507936507936506, '_runtime': 1267.1532814502716, 'test/loss': 1.3746174032821683, 'eval/accuracy': 0.36, 'eval/precision_micro': 0.36, 'test/precision_macro': 0.10267857142857142, 'test/precision_micro': 0.36507936507936506, '_step': 20, '_wandb': {'runtime': 1265}, 'eval/precision_macro': 0.09375, 'eval/f1_micro': 0.36, 'test/precision_weighted': 0.16298185941043083, 'eval/f1_weighted': 0.21176470588235297, 'test/recall_weighted': 0.36507936507936506, 'test/recall_macro': 0.23, 'eval/f1_macro': 0.13235294117647062, 'test/accuracy': 0.36507936507936506, 'test/recall_micro': 0.36507936507936506}","{'rf_max_depth': 3, 'trial.number': 18}",ethereal-butterfly-351,RandomForest,['pre-trained:microsoft/codebert-base']
979,"{'test/f1_macro': 0.1960393407761829, 'eval/recall_micro': 0.36, 'test/recall_weighted': 0.2857142857142857, 'eval/precision_weighted': 0.3652380952380953, 'eval/precision_micro': 0.36, 'test/precision_macro': 0.20254629629629628, 'test/precision_weighted': 0.30643738977072316, 'test/loss': 4.702661652795524, 'test/f1_micro': 0.2857142857142857, 'test/f1_weighted': 0.29484485624836504, 'test/recall_micro': 0.2857142857142857, '_wandb': {'runtime': 1264}, 'eval/f1_macro': 0.32944832944832947, 'eval/loss': 7.108424147709593, 'eval/recall_macro': 0.3208333333333333, '_runtime': 1265.5878021717072, '_timestamp': 1704239058.118662, 'eval/accuracy': 0.36, 'test/accuracy': 0.2857142857142857, '_step': 20, 'eval/f1_micro': 0.36, 'eval/f1_weighted': 0.3534421134421134, 'test/recall_macro': 0.19166666666666668, 'eval/precision_macro': 0.3630952380952381, 'eval/recall_weighted': 0.36, 'test/precision_micro': 0.2857142857142857, 'split': 10}","{'dt_criterion': 'gini', 'dt_max_depth': 14, 'trial.number': 18, 'dt_min_samples_leaf': 13}",ethereal-glade-350,DecisionTree,['pre-trained:microsoft/codebert-base']
980,"{'eval/loss': 1.3801251782367183, 'test/accuracy': 0.36507936507936506, 'test/precision_weighted': 0.19293272864701436, '_wandb': {'runtime': 1264}, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.36507936507936506, 'eval/f1_macro': 0.2077922077922078, 'test/f1_weighted': 0.2377816970409563, 'eval/precision_micro': 0.4, '_runtime': 1265.6797885894775, 'eval/accuracy': 0.4, 'test/recall_macro': 0.2557142857142857, 'test/recall_micro': 0.36507936507936506, 'test/precision_macro': 0.18154761904761904, 'test/recall_weighted': 0.36507936507936506, 'eval/precision_weighted': 0.25652173913043474, '_timestamp': 1704237871.0167696, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.275, 'eval/precision_macro': 0.22282608695652173, 'split': 10, 'test/f1_micro': 0.36507936507936506, 'eval/recall_micro': 0.4, 'eval/f1_weighted': 0.2753246753246753, 'test/loss': 1.3763531371073594, 'test/f1_macro': 0.18580246913580245, '_step': 20}","{'rf_max_depth': 4, 'trial.number': 17}",brisk-sponge-349,RandomForest,['pre-trained:microsoft/codebert-base']
981,"{'eval/accuracy': 0.24, 'eval/recall_macro': 0.2125, 'test/precision_micro': 0.3968253968253968, 'eval/loss': 4.1293000234238955, 'eval/recall_micro': 0.24, 'eval/recall_weighted': 0.24, 'test/recall_micro': 0.3968253968253968, 'split': 10, 'test/accuracy': 0.3968253968253968, 'test/f1_macro': 0.2768356643356643, 'test/precision_macro': 0.24285714285714283, 'test/loss': 1.7531219919259755, 'eval/f1_weighted': 0.214025974025974, 'test/recall_macro': 0.32708333333333334, 'test/precision_weighted': 0.31972789115646255, '_step': 20, '_timestamp': 1704237788.788348, 'test/f1_weighted': 0.3527028527028527, 'eval/precision_macro': 0.1736111111111111, 'test/recall_weighted': 0.3968253968253968, '_runtime': 1265.1380789279938, 'eval/f1_micro': 0.24, 'test/f1_micro': 0.3968253968253968, 'eval/precision_micro': 0.24, '_wandb': {'runtime': 1263}, 'eval/f1_macro': 0.18912337662337655, 'eval/precision_weighted': 0.1955555555555555}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 17, 'dt_min_samples_leaf': 47}",avid-snowflake-348,DecisionTree,['pre-trained:microsoft/codebert-base']
982,"{'eval/recall_micro': 0.36, 'eval/recall_weighted': 0.36, 'test/precision_macro': 0.09913793103448276, '_step': 20, 'test/precision_micro': 0.36507936507936506, 'eval/f1_micro': 0.36, 'test/f1_macro': 0.1385542168674699, 'eval/f1_weighted': 0.21176470588235297, 'test/precision_weighted': 0.1573617952928298, 'eval/accuracy': 0.36, 'eval/recall_macro': 0.225, 'test/recall_macro': 0.23, 'split': 10, 'test/accuracy': 0.36507936507936506, 'eval/precision_micro': 0.36, 'eval/precision_weighted': 0.15, '_wandb': {'runtime': 1266}, 'eval/loss': 1.3262132360664394, 'test/recall_weighted': 0.36507936507936506, 'test/f1_micro': 0.36507936507936506, 'eval/precision_macro': 0.09375, 'eval/f1_macro': 0.13235294117647062, 'test/f1_weighted': 0.21992732836106335, 'test/recall_micro': 0.36507936507936506, '_runtime': 1268.149927854538, 'test/loss': 1.3401914395330166, '_timestamp': 1704236600.626345}","{'rf_max_depth': 2, 'trial.number': 16}",unique-planet-347,RandomForest,['pre-trained:microsoft/codebert-base']
983,"{'eval/precision_micro': 0.28, 'test/precision_macro': 0.31646825396825395, 'eval/recall_micro': 0.28, 'eval/loss': 3.1110615714852554, '_timestamp': 1704236518.4725845, 'eval/f1_macro': 0.20054713804713803, 'test/recall_weighted': 0.42857142857142855, '_runtime': 1265.7305285930634, 'eval/accuracy': 0.28, 'eval/f1_micro': 0.28, 'test/f1_macro': 0.29601312665828794, 'eval/f1_weighted': 0.24451178451178449, 'eval/recall_macro': 0.21666666666666667, 'split': 10, 'test/f1_micro': 0.42857142857142855, 'eval/precision_weighted': 0.27098039215686276, '_wandb': {'runtime': 1264}, 'test/accuracy': 0.42857142857142855, 'eval/precision_macro': 0.24019607843137256, 'eval/recall_weighted': 0.28, 'test/precision_micro': 0.42857142857142855, 'test/recall_macro': 0.3333333333333333, 'test/loss': 1.898910952643904, 'test/f1_weighted': 0.39340076206435654, 'test/recall_micro': 0.42857142857142855, 'test/precision_weighted': 0.40816326530612246, '_step': 20}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 16, 'dt_min_samples_leaf': 27}",apricot-glade-346,DecisionTree,['pre-trained:microsoft/codebert-base']
984,"{'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.36507936507936506, 'test/f1_macro': 0.2863562091503268, 'eval/f1_weighted': 0.2855913978494623, 'eval/recall_micro': 0.4, 'test/precision_macro': 0.4621848739495798, '_step': 20, 'test/precision_micro': 0.36507936507936506, '_timestamp': 1704235326.7526586, 'test/recall_macro': 0.29833333333333334, 'eval/recall_weighted': 0.4, 'eval/recall_macro': 0.26666666666666666, 'test/recall_micro': 0.36507936507936506, 'test/recall_weighted': 0.36507936507936506, 'test/f1_weighted': 0.294247328561054, '_wandb': {'runtime': 1265}, 'eval/f1_macro': 0.20071684587813615, 'test/f1_micro': 0.36507936507936506, 'eval/precision_micro': 0.4, 'eval/precision_weighted': 0.25142857142857145, 'split': 10, 'test/loss': 1.4196228410624605, 'eval/precision_macro': 0.1904761904761905, '_runtime': 1266.515323638916, 'eval/loss': 1.324294849139625, 'test/precision_weighted': 0.3927348717264684}","{'rf_max_depth': 6, 'trial.number': 15}",classic-meadow-345,RandomForest,['pre-trained:microsoft/codebert-base']
985,"{'_wandb': {'runtime': 1263}, 'test/f1_macro': 0.21038146441372252, 'test/precision_macro': 0.2139423076923077, 'test/f1_micro': 0.31746031746031744, 'test/f1_weighted': 0.3144328221133137, 'test/precision_micro': 0.31746031746031744, 'test/recall_weighted': 0.31746031746031744, 'test/precision_weighted': 0.3128815628815629, '_timestamp': 1704235247.9811652, 'eval/recall_micro': 0.32, 'test/recall_micro': 0.31746031746031744, 'eval/precision_weighted': 0.3066666666666667, '_step': 20, 'eval/f1_weighted': 0.3098181818181818, 'eval/precision_macro': 0.2791666666666667, 'split': 10, '_runtime': 1265.21373128891, 'test/accuracy': 0.31746031746031744, 'test/recall_macro': 0.20833333333333337, 'eval/precision_micro': 0.32, 'eval/loss': 7.083432274482229, 'test/loss': 5.828670791675353, 'eval/accuracy': 0.32, 'eval/f1_micro': 0.32, 'eval/recall_weighted': 0.32, 'eval/f1_macro': 0.2761363636363636, 'eval/recall_macro': 0.2791666666666667}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 15, 'dt_min_samples_leaf': 16}",fanciful-jazz-344,DecisionTree,['pre-trained:microsoft/codebert-base']
986,"{'eval/loss': 1.2580586832890366, 'eval/f1_macro': 0.14285714285714288, 'test/f1_weighted': 0.25716746646979205, 'eval/precision_micro': 0.4, 'eval/recall_micro': 0.4, 'split': 10, '_runtime': 1266.3495659828186, 'test/precision_macro': 0.22745901639344265, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.4126984126984127, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_macro': 0.25, 'test/precision_weighted': 0.2419984387197502, 'test/f1_macro': 0.187015503875969, 'test/recall_macro': 0.275, 'test/precision_micro': 0.4126984126984127, 'test/recall_weighted': 0.4126984126984127, '_step': 20, '_wandb': {'runtime': 1265}, 'test/loss': 1.3304355584303749, 'test/f1_micro': 0.4126984126984127, 'test/recall_micro': 0.4126984126984127, 'eval/precision_weighted': 0.16, 'eval/precision_macro': 0.1, '_timestamp': 1704234055.998274, 'eval/accuracy': 0.4, 'eval/recall_weighted': 0.4}","{'rf_max_depth': 2, 'trial.number': 14}",smooth-cosmos-343,RandomForest,['pre-trained:microsoft/codebert-base']
987,"{'test/precision_weighted': 0.3368102796674225, 'eval/precision_macro': 0.20138888888888887, 'eval/f1_micro': 0.28, 'test/loss': 3.9656082978384193, 'eval/f1_weighted': 0.24259740259740256, 'eval/precision_micro': 0.28, '_timestamp': 1704233979.5911355, 'test/f1_weighted': 0.3746341841579937, 'eval/recall_macro': 0.2625, 'eval/recall_micro': 0.28, 'test/f1_macro': 0.30885225885225887, 'eval/recall_weighted': 0.28, 'test/precision_macro': 0.26904761904761904, 'eval/precision_weighted': 0.2177777777777778, '_runtime': 1265.7690267562866, 'eval/f1_macro': 0.2248376623376623, 'test/recall_macro': 0.37083333333333335, 'eval/loss': 6.860243673865673, 'test/accuracy': 0.42857142857142855, 'test/precision_micro': 0.42857142857142855, '_step': 20, '_wandb': {'runtime': 1264}, 'eval/accuracy': 0.28, 'test/f1_micro': 0.42857142857142855, 'test/recall_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 14, 'dt_min_samples_leaf': 29}",copper-sponge-342,DecisionTree,['pre-trained:microsoft/codebert-base']
988,"{'split': 10, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.2557142857142857, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.22149122807017543, 'eval/loss': 1.3545039079747423, 'test/accuracy': 0.36507936507936506, 'eval/recall_weighted': 0.44, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.36507936507936506, 'test/f1_weighted': 0.23762205876027015, '_timestamp': 1704232785.9011223, 'test/f1_macro': 0.1897018970189702, '_wandb': {'runtime': 1263}, 'eval/f1_macro': 0.2184873949579832, 'test/recall_weighted': 0.36507936507936506, 'eval/precision_weighted': 0.40666666666666673, 'test/loss': 1.4043438641688466, '_runtime': 1265.1853513717651, 'eval/recall_macro': 0.2916666666666667, 'test/precision_weighted': 0.2087162350320245, '_step': 20, 'eval/f1_weighted': 0.30386554621848744, 'test/recall_micro': 0.36507936507936506, 'eval/precision_macro': 0.3541666666666667, 'test/precision_micro': 0.36507936507936506}","{'rf_max_depth': 4, 'trial.number': 13}",hopeful-haze-341,RandomForest,['pre-trained:microsoft/codebert-base']
989,"{'eval/accuracy': 0.24, 'test/accuracy': 0.3968253968253968, 'eval/precision_micro': 0.24, 'test/recall_weighted': 0.3968253968253968, 'eval/loss': 1.4458082322379109, '_timestamp': 1704232710.3165083, 'eval/recall_micro': 0.24, 'test/recall_micro': 0.3968253968253968, 'eval/precision_weighted': 0.16410256410256407, 'split': 10, '_wandb': {'runtime': 1264}, 'eval/f1_micro': 0.24, 'test/f1_micro': 0.3968253968253968, 'test/recall_macro': 0.30833333333333335, '_runtime': 1265.411224603653, 'test/precision_micro': 0.3968253968253968, 'test/precision_weighted': 0.2925170068027211, '_step': 20, 'test/f1_macro': 0.2251012145748988, 'test/f1_weighted': 0.32851359167148647, 'test/loss': 1.2692118188646868, 'eval/recall_macro': 0.2, 'test/precision_macro': 0.18928571428571428, 'eval/f1_weighted': 0.1898989898989899, 'eval/precision_macro': 0.1217948717948718, 'eval/f1_macro': 0.14646464646464646, 'eval/recall_weighted': 0.24}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 13, 'dt_min_samples_leaf': 99}",still-star-340,DecisionTree,['pre-trained:microsoft/codebert-base']
990,"{'_runtime': 1265.1990070343018, 'test/precision_weighted': 0.15747039556563366, 'test/recall_macro': 0.25, 'test/recall_weighted': 0.3968253968253968, '_timestamp': 1704231517.2567492, 'eval/f1_micro': 0.36, 'test/recall_micro': 0.3968253968253968, '_wandb': {'runtime': 1263}, 'eval/f1_macro': 0.13235294117647062, 'test/precision_micro': 0.3968253968253968, 'eval/recall_micro': 0.36, 'eval/precision_micro': 0.36, 'eval/f1_weighted': 0.21176470588235297, 'eval/precision_weighted': 0.15, 'eval/precision_macro': 0.09375, 'test/precision_macro': 0.0992063492063492, 'test/loss': 1.3848903366065242, 'eval/accuracy': 0.36, 'test/accuracy': 0.3968253968253968, 'test/f1_macro': 0.14204545454545456, 'test/f1_weighted': 0.22546897546897549, 'eval/recall_weighted': 0.36, '_step': 20, 'split': 10, 'eval/recall_macro': 0.225, 'eval/loss': 1.3510827335451203, 'test/f1_micro': 0.3968253968253968}","{'rf_max_depth': 2, 'trial.number': 12}",pretty-cosmos-339,RandomForest,['pre-trained:microsoft/codebert-base']
991,"{'test/precision_micro': 0.42857142857142855, '_wandb': {'runtime': 1264}, 'eval/f1_weighted': 0.24354312354312355, 'test/recall_macro': 0.3333333333333333, 'test/accuracy': 0.42857142857142855, 'eval/recall_weighted': 0.28, 'eval/loss': 1.5609715043432888, 'test/recall_micro': 0.42857142857142855, 'test/precision_weighted': 0.3983371126228269, 'eval/f1_micro': 0.28, 'eval/recall_macro': 0.21666666666666667, 'eval/precision_macro': 0.20312499999999997, 'eval/recall_micro': 0.28, 'eval/precision_weighted': 0.2383333333333333, 'split': 10, 'eval/accuracy': 0.28, 'eval/precision_micro': 0.28, 'test/f1_weighted': 0.394526620333072, 'test/precision_macro': 0.30238095238095236, 'test/recall_weighted': 0.42857142857142855, '_step': 20, '_timestamp': 1704231439.8187978, 'test/f1_macro': 0.29498082562598693, 'test/f1_micro': 0.42857142857142855, '_runtime': 1265.8749487400055, 'test/loss': 1.337114875930426, 'eval/f1_macro': 0.19716394716394717}","{'dt_criterion': 'gini', 'dt_max_depth': 11, 'trial.number': 12, 'dt_min_samples_leaf': 33}",tough-snowball-338,DecisionTree,['pre-trained:microsoft/codebert-base']
992,"{'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.36507936507936506, '_timestamp': 1704230246.778756, 'eval/f1_macro': 0.2077922077922078, 'test/f1_micro': 0.36507936507936506, 'eval/recall_macro': 0.275, 'eval/precision_micro': 0.4, 'eval/precision_macro': 0.22282608695652173, '_wandb': {'runtime': 1264}, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.2753246753246753, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.23, '_step': 20, 'test/loss': 1.3933437383556355, 'test/f1_weighted': 0.22535763276504017, 'eval/precision_weighted': 0.25652173913043474, 'eval/accuracy': 0.4, 'test/recall_micro': 0.36507936507936506, 'test/precision_weighted': 0.16298185941043083, 'test/precision_micro': 0.36507936507936506, 'split': 10, 'test/accuracy': 0.36507936507936506, 'test/precision_macro': 0.10267857142857142, '_runtime': 1265.4337849617004, 'eval/loss': 1.34344812060978, 'test/f1_macro': 0.1419753086419753}","{'rf_max_depth': 2, 'trial.number': 11}",expert-meadow-337,RandomForest,['pre-trained:microsoft/codebert-base']
993,"{'test/precision_weighted': 0.33618233618233617, 'test/f1_weighted': 0.3620645817442156, 'eval/recall_macro': 0.19166666666666665, 'eval/recall_micro': 0.24, '_wandb': {'runtime': 1263}, 'test/f1_micro': 0.3968253968253968, 'test/accuracy': 0.3968253968253968, 'test/recall_macro': 0.2916666666666667, 'eval/precision_macro': 0.16666666666666669, 'eval/accuracy': 0.24, 'eval/f1_micro': 0.24, 'eval/f1_weighted': 0.21163636363636365, 'test/recall_micro': 0.3968253968253968, 'test/precision_micro': 0.3968253968253968, '_runtime': 1264.7908191680908, 'test/loss': 1.4463200005947086, 'eval/recall_weighted': 0.24, 'eval/precision_weighted': 0.19466666666666668, 'split': 10, '_timestamp': 1704230169.818618, '_step': 20, 'eval/loss': 1.749520572735801, 'test/precision_macro': 0.2653846153846154, 'test/recall_weighted': 0.3968253968253968, 'eval/f1_macro': 0.17545454545454547, 'test/f1_macro': 0.276048817696415, 'eval/precision_micro': 0.24}","{'dt_criterion': 'gini', 'dt_max_depth': 20, 'trial.number': 11, 'dt_min_samples_leaf': 34}",fresh-donkey-336,DecisionTree,['pre-trained:microsoft/codebert-base']
994,"{'test/precision_weighted': 0.150519978106185, 'split': 10, '_timestamp': 1704228977.213204, 'eval/f1_micro': 0.4000000000000001, 'test/precision_macro': 0.09482758620689656, 'test/precision_micro': 0.3492063492063492, 'test/f1_micro': 0.3492063492063492, 'test/f1_weighted': 0.2103652706062344, 'eval/recall_micro': 0.4, 'eval/recall_weighted': 0.4, 'eval/precision_micro': 0.4, '_runtime': 1266.5419561862946, 'eval/loss': 1.3264811802905043, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_macro': 0.22, 'eval/precision_macro': 0.1, 'test/loss': 1.3506788776604397, 'test/recall_micro': 0.3492063492063492, '_step': 20, 'test/accuracy': 0.3492063492063492, 'test/f1_macro': 0.1325301204819277, 'eval/recall_macro': 0.25, '_wandb': {'runtime': 1265}, 'eval/f1_macro': 0.14285714285714288, 'eval/accuracy': 0.4, 'test/recall_weighted': 0.3492063492063492, 'eval/precision_weighted': 0.16}","{'rf_max_depth': 2, 'trial.number': 10}",jumping-sound-335,RandomForest,['pre-trained:microsoft/codebert-base']
995,"{'_timestamp': 1704228900.9742093, 'test/recall_macro': 0.3333333333333333, 'eval/loss': 1.5620469099382857, '_wandb': {'runtime': 1265}, 'test/accuracy': 0.42857142857142855, 'eval/recall_macro': 0.21666666666666667, 'eval/recall_micro': 0.28, 'eval/accuracy': 0.28, 'test/f1_weighted': 0.394526620333072, 'eval/recall_weighted': 0.28, 'eval/precision_weighted': 0.2383333333333333, 'test/precision_weighted': 0.3983371126228269, 'test/precision_micro': 0.42857142857142855, '_runtime': 1267.038502216339, 'test/loss': 1.3400354753567267, 'eval/f1_micro': 0.28, 'test/precision_macro': 0.30238095238095236, 'eval/precision_micro': 0.28, 'eval/f1_macro': 0.19716394716394717, 'test/f1_macro': 0.29498082562598693, 'eval/f1_weighted': 0.24354312354312355, 'eval/precision_macro': 0.20312499999999997, 'test/recall_weighted': 0.42857142857142855, '_step': 20, 'split': 10, 'test/f1_micro': 0.42857142857142855, 'test/recall_micro': 0.42857142857142855}","{'dt_criterion': 'gini', 'dt_max_depth': 19, 'trial.number': 10, 'dt_min_samples_leaf': 32}",ruby-field-334,DecisionTree,['pre-trained:microsoft/codebert-base']
996,"{'_timestamp': 1704227707.0192392, 'test/accuracy': 0.3968253968253968, 'test/f1_micro': 0.3968253968253968, 'test/recall_micro': 0.3968253968253968, '_step': 20, 'split': 10, 'test/precision_micro': 0.3968253968253968, 'eval/loss': 1.267158860410919, 'eval/precision_macro': 0.09782608695652174, 'eval/f1_weighted': 0.21818181818181817, 'eval/recall_micro': 0.36, 'test/precision_weighted': 0.38816738816738816, '_wandb': {'runtime': 1271}, 'eval/f1_macro': 0.13636363636363635, 'test/f1_weighted': 0.2818514684456713, 'test/precision_macro': 0.35454545454545455, 'eval/precision_weighted': 0.1565217391304348, '_runtime': 1273.21289229393, 'test/f1_macro': 0.22104468599033816, 'eval/recall_macro': 0.225, 'test/recall_macro': 0.27761904761904765, 'eval/precision_micro': 0.36, 'test/loss': 1.314365509378067, 'eval/f1_micro': 0.36, 'test/recall_weighted': 0.3968253968253968, 'eval/accuracy': 0.36, 'eval/recall_weighted': 0.36}","{'rf_max_depth': 3, 'trial.number': 9}",rural-hill-333,RandomForest,['pre-trained:microsoft/codebert-base']
997,"{'test/f1_micro': 0.36507936507936506, '_runtime': 1273.2573606967926, 'eval/f1_macro': 0.13636363636363635, 'test/recall_micro': 0.36507936507936506, 'test/precision_micro': 0.36507936507936506, 'test/loss': 2.974267749077718, 'eval/accuracy': 0.2, 'eval/precision_macro': 0.125, 'test/recall_weighted': 0.36507936507936506, '_step': 20, '_timestamp': 1704227629.2334416, 'eval/precision_weighted': 0.16666666666666663, 'eval/loss': 7.18056554494537, 'eval/f1_weighted': 0.1818181818181818, 'test/recall_macro': 0.24166666666666667, 'split': 10, 'eval/recall_macro': 0.15000000000000002, 'test/precision_macro': 0.21978021978021975, 'test/f1_macro': 0.22862554112554115, 'eval/recall_micro': 0.2, 'test/accuracy': 0.36507936507936506, 'eval/precision_micro': 0.2, 'eval/recall_weighted': 0.2, '_wandb': {'runtime': 1271}, 'eval/f1_micro': 0.20000000000000004, 'test/f1_weighted': 0.34099498385212673, 'test/precision_weighted': 0.322693179836037}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 9, 'dt_min_samples_leaf': 21}",glad-sun-332,DecisionTree,['pre-trained:microsoft/codebert-base']
998,"{'eval/recall_micro': 0.4, '_runtime': 1235.0270359516144, 'test/loss': 24.60122374177838, 'test/precision_macro': 0.30573152337858217, 'test/recall_weighted': 0.31746031746031744, 'split': 10, 'eval/loss': 21.626192033470293, 'test/f1_micro': 0.31746031746031744, 'eval/recall_macro': 0.31666666666666665, 'test/precision_micro': 0.31746031746031744, 'eval/f1_macro': 0.2976284584980237, 'eval/f1_weighted': 0.36711462450592885, 'test/precision_weighted': 0.4265124853360148, '_step': 20, 'test/f1_macro': 0.2826341647770219, 'eval/precision_micro': 0.4, '_wandb': {'runtime': 1233}, 'test/accuracy': 0.31746031746031744, 'test/f1_weighted': 0.34959387635124595, 'eval/recall_weighted': 0.4, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.2955837173579109, 'test/recall_micro': 0.31746031746031744, 'eval/precision_macro': 0.2846153846153846, 'eval/precision_weighted': 0.3433846153846154, '_timestamp': 1704227278.093339}","{'n_neighbours': 1, 'trial.number': 9}",skilled-durian-331,KNeighbours,['pre-trained:microsoft/codebert-base']
999,"{'test/recall_weighted': 0.3968253968253968, 'test/precision_weighted': 0.43461829176114886, 'eval/precision_macro': 0.22619047619047616, 'eval/precision_weighted': 0.2704761904761904, '_timestamp': 1704226430.868356, 'eval/f1_macro': 0.25384615384615383, 'eval/recall_macro': 0.29166666666666663, 'eval/recall_micro': 0.36, 'test/recall_macro': 0.33952380952380956, 'test/recall_micro': 0.3968253968253968, 'test/accuracy': 0.3968253968253968, 'eval/f1_weighted': 0.30769230769230765, 'eval/loss': 1.3418522517177005, 'test/precision_micro': 0.3968253968253968, 'eval/f1_micro': 0.36, 'eval/precision_micro': 0.36, 'eval/accuracy': 0.36, 'test/f1_weighted': 0.34203795835636636, 'split': 10, '_runtime': 1276.9134318828585, 'test/precision_macro': 0.4238095238095238, '_step': 20, 'test/f1_micro': 0.3968253968253968, 'test/f1_macro': 0.3098839137645108, 'eval/recall_weighted': 0.36, '_wandb': {'runtime': 1275}, 'test/loss': 1.4297296913730826}","{'rf_max_depth': 7, 'trial.number': 8}",snowy-energy-330,RandomForest,['pre-trained:microsoft/codebert-base']
1000,"{'eval/recall_macro': 0.22916666666666669, 'eval/precision_macro': 0.22708333333333333, 'test/f1_weighted': 0.3218504793221636, '_wandb': {'runtime': 1274}, '_step': 20, 'eval/f1_macro': 0.22601010101010097, 'eval/f1_weighted': 0.2452525252525252, 'test/recall_micro': 0.31746031746031744, 'split': 10, 'test/precision_macro': 0.2700854700854701, 'test/recall_macro': 0.28125, 'test/f1_micro': 0.31746031746031744, 'test/recall_weighted': 0.31746031746031744, 'eval/precision_weighted': 0.2553333333333333, '_timestamp': 1704226351.1031103, 'test/accuracy': 0.31746031746031744, 'eval/precision_micro': 0.24, 'test/precision_weighted': 0.330348663681997, 'eval/accuracy': 0.24, 'eval/loss': 20.48167689091328, 'eval/f1_micro': 0.24, 'test/f1_macro': 0.27351114358786993, 'test/precision_micro': 0.31746031746031744, '_runtime': 1276.0982222557068, 'eval/recall_micro': 0.24, 'eval/recall_weighted': 0.24, 'test/loss': 15.44447461023088}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 8, 'dt_min_samples_leaf': 6}",distinctive-leaf-329,DecisionTree,['pre-trained:microsoft/codebert-base']
1001,"{'_runtime': 1234.5149445533752, 'eval/f1_micro': 0.36, 'eval/precision_macro': 0.23026315789473684, 'test/f1_micro': 0.3492063492063492, 'split': 10, 'eval/accuracy': 0.36, 'eval/f1_macro': 0.20935960591133007, 'eval/precision_weighted': 0.26842105263157895, 'test/precision_weighted': 0.3055555555555556, '_step': 20, 'test/recall_micro': 0.3492063492063492, 'test/precision_macro': 0.2169642857142857, 'eval/recall_macro': 0.25, 'test/precision_micro': 0.3492063492063492, 'eval/loss': 14.82238442241989, 'test/accuracy': 0.3492063492063492, 'test/f1_macro': 0.2211732229123534, 'eval/recall_weighted': 0.36, 'test/recall_weighted': 0.3492063492063492, '_timestamp': 1704226038.6835816, 'eval/recall_micro': 0.36, 'test/recall_macro': 0.2306067588325653, 'test/loss': 13.722428099905448, 'eval/f1_weighted': 0.27783251231527095, 'eval/precision_micro': 0.36, '_wandb': {'runtime': 1233}, 'test/f1_weighted': 0.3235488076067787}","{'n_neighbours': 3, 'trial.number': 8}",lyric-durian-328,KNeighbours,['pre-trained:microsoft/codebert-base']
1002,"{'eval/f1_macro': 0.12500000000000003, 'eval/f1_micro': 0.32, 'eval/recall_macro': 0.2, 'eval/recall_micro': 0.32, 'eval/recall_weighted': 0.32, 'eval/accuracy': 0.32, 'test/f1_micro': 0.4126984126984127, 'eval/precision_macro': 0.09090909090909093, '_step': 20, '_runtime': 1276.4695465564728, '_timestamp': 1704225149.4501426, 'test/recall_micro': 0.4126984126984127, 'test/recall_weighted': 0.4126984126984127, 'eval/loss': 1.2888638507788734, 'eval/f1_weighted': 0.20000000000000004, 'eval/precision_micro': 0.32, 'eval/precision_weighted': 0.14545454545454548, '_wandb': {'runtime': 1275}, 'test/f1_weighted': 0.25583835066593685, 'test/precision_macro': 0.35080645161290325, 'split': 10, 'test/f1_macro': 0.20617816091954025, 'test/accuracy': 0.4126984126984127, 'test/recall_macro': 0.2857142857142857, 'test/precision_micro': 0.4126984126984127, 'test/precision_weighted': 0.27112135176651303, 'test/loss': 1.2844060708871845}","{'rf_max_depth': 2, 'trial.number': 7}",likely-eon-327,RandomForest,['pre-trained:microsoft/codebert-base']
1003,"{'eval/f1_weighted': 0.22683982683982684, 'test/f1_weighted': 0.4030116421420769, 'eval/recall_macro': 0.175, 'test/recall_macro': 0.3041666666666667, 'test/precision_weighted': 0.41596749811035527, 'eval/f1_macro': 0.16450216450216448, 'test/accuracy': 0.4126984126984127, 'eval/recall_micro': 0.24, 'eval/precision_weighted': 0.21515151515151512, 'eval/precision_micro': 0.24, 'test/f1_micro': 0.4126984126984127, 'test/precision_micro': 0.4126984126984127, 'test/precision_macro': 0.3504960317460318, '_wandb': {'runtime': 1275}, 'test/f1_macro': 0.31448895307590957, 'test/loss': 4.533105023644108, 'eval/accuracy': 0.24, 'test/recall_micro': 0.4126984126984127, 'eval/precision_macro': 0.1553030303030303, 'test/recall_weighted': 0.4126984126984127, 'split': 10, 'eval/loss': 12.64633374355964, '_timestamp': 1704225070.5864935, 'eval/recall_weighted': 0.24, 'eval/f1_micro': 0.24, '_step': 20, '_runtime': 1276.4791605472565}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 7, 'dt_min_samples_leaf': 15}",deep-sunset-326,DecisionTree,['pre-trained:microsoft/codebert-base']
1004,"{'eval/loss': 12.134515960557732, 'eval/precision_micro': 0.36, 'test/accuracy': 0.2857142857142857, 'test/f1_macro': 0.22615132182684472, 'eval/recall_macro': 0.25, '_step': 20, 'test/f1_weighted': 0.28846161689576044, 'test/recall_micro': 0.2857142857142857, 'eval/recall_weighted': 0.36, '_runtime': 1234.773922920227, '_timestamp': 1704224797.996795, 'eval/f1_weighted': 0.27068965517241383, 'test/recall_macro': 0.2259984639016897, 'test/recall_weighted': 0.2857142857142857, 'eval/precision_weighted': 0.2350877192982456, '_wandb': {'runtime': 1233}, 'test/loss': 9.427132550860582, 'eval/precision_macro': 0.18859649122807015, 'test/precision_weighted': 0.2916099773242631, 'eval/accuracy': 0.36, 'test/f1_micro': 0.2857142857142857, 'eval/recall_micro': 0.36, 'test/precision_macro': 0.22678571428571428, 'split': 10, 'eval/f1_macro': 0.20043103448275865, 'eval/f1_micro': 0.36, 'test/precision_micro': 0.2857142857142857}","{'n_neighbours': 4, 'trial.number': 7}",splendid-donkey-325,KNeighbours,['pre-trained:microsoft/codebert-base']
1005,"{'test/precision_macro': 0.47132867132867134, 'test/f1_micro': 0.3968253968253968, 'test/recall_macro': 0.32261904761904764, 'eval/precision_macro': 0.31875, 'eval/recall_weighted': 0.4, 'split': 10, '_timestamp': 1704223868.8568814, 'eval/f1_macro': 0.2985714285714286, 'eval/accuracy': 0.4, 'eval/precision_weighted': 0.35, 'test/f1_weighted': 0.32027312462095076, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.35200000000000004, '_step': 20, '_wandb': {'runtime': 1274}, 'test/loss': 5.057853799086226, 'eval/loss': 2.724718177564494, 'eval/recall_macro': 0.325, 'test/accuracy': 0.3968253968253968, 'test/f1_macro': 0.27453886693017127, 'test/precision_weighted': 0.5725607725607725, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, '_runtime': 1275.8235754966736, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.3968253968253968}","{'rf_max_depth': 25, 'trial.number': 6}",rural-pyramid-324,RandomForest,['pre-trained:microsoft/codebert-base']
1006,"{'eval/loss': 1.4458082322379109, 'eval/f1_weighted': 0.1898989898989899, 'eval/recall_macro': 0.2, 'eval/recall_micro': 0.24, 'test/recall_macro': 0.30833333333333335, 'eval/recall_weighted': 0.24, '_timestamp': 1704223790.5393257, 'test/f1_micro': 0.3968253968253968, 'test/precision_weighted': 0.2925170068027211, '_wandb': {'runtime': 1275}, 'eval/accuracy': 0.24, 'eval/f1_macro': 0.14646464646464646, 'test/accuracy': 0.3968253968253968, 'test/f1_weighted': 0.32851359167148647, 'test/precision_micro': 0.3968253968253968, 'eval/precision_weighted': 0.16410256410256407, '_runtime': 1276.3840515613556, 'test/loss': 1.2692118188646868, 'eval/f1_micro': 0.24, 'test/f1_macro': 0.2251012145748988, 'test/precision_macro': 0.18928571428571428, 'test/recall_weighted': 0.3968253968253968, 'split': 10, 'eval/precision_micro': 0.24, '_step': 20, 'eval/precision_macro': 0.1217948717948718, 'test/recall_micro': 0.3968253968253968}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 6, 'dt_min_samples_leaf': 67}",colorful-glitter-323,DecisionTree,['pre-trained:microsoft/codebert-base']
1007,"{'_runtime': 1236.7029793262482, 'test/f1_micro': 0.31746031746031744, 'eval/precision_weighted': 0.3433846153846154, 'eval/accuracy': 0.4, 'eval/precision_micro': 0.4, 'split': 10, '_timestamp': 1704223557.1930234, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.31746031746031744, 'test/recall_macro': 0.2955837173579109, 'eval/loss': 21.626192033470293, 'test/f1_weighted': 0.34959387635124595, 'test/precision_micro': 0.31746031746031744, 'test/recall_weighted': 0.31746031746031744, 'eval/f1_macro': 0.2976284584980237, 'eval/recall_macro': 0.31666666666666665, 'eval/recall_weighted': 0.4, '_wandb': {'runtime': 1233}, 'test/f1_macro': 0.2826341647770219, 'test/recall_micro': 0.31746031746031744, 'test/precision_macro': 0.30573152337858217, 'test/precision_weighted': 0.4265124853360148, '_step': 20, 'test/loss': 24.60122374177838, 'eval/f1_weighted': 0.36711462450592885, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.2846153846153846}","{'n_neighbours': 1, 'trial.number': 6}",breezy-capybara-322,KNeighbours,['pre-trained:microsoft/codebert-base']
1008,"{'split': 10, 'test/f1_macro': 0.15208333333333338, 'test/recall_weighted': 0.3492063492063492, '_step': 20, 'eval/recall_macro': 0.26666666666666666, 'eval/precision_micro': 0.4, 'test/f1_micro': 0.3492063492063492, 'test/recall_micro': 0.3492063492063492, 'test/precision_macro': 0.17878787878787877, 'eval/precision_weighted': 0.27652173913043476, 'test/precision_weighted': 0.26262626262626265, 'test/accuracy': 0.3492063492063492, 'test/f1_weighted': 0.23611111111111116, '_wandb': {'runtime': 1274}, '_runtime': 1275.8891735076904, '_timestamp': 1704222589.0397384, 'eval/recall_micro': 0.4, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.19886363636363635, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.3492063492063492, 'test/loss': 1.3398321009476866, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_macro': 0.22282608695652173, 'eval/loss': 1.2931884793294566, 'eval/f1_weighted': 0.27818181818181814, 'test/recall_macro': 0.22190476190476188}","{'rf_max_depth': 3, 'trial.number': 5}",floral-grass-321,RandomForest,['pre-trained:microsoft/codebert-base']
1009,"{'test/loss': 9.500360878194908, 'test/precision_weighted': 0.3713873428159143, 'test/f1_macro': 0.24965034965034968, 'test/f1_micro': 0.31746031746031744, 'test/f1_weighted': 0.33877233877233875, 'eval/precision_weighted': 0.22285714285714284, '_runtime': 1276.5595128536224, 'eval/f1_macro': 0.20795454545454545, 'test/recall_macro': 0.24583333333333335, 'test/recall_micro': 0.31746031746031744, 'test/precision_macro': 0.26662337662337665, '_step': 20, 'eval/recall_macro': 0.2375, 'test/precision_micro': 0.31746031746031744, '_wandb': {'runtime': 1275}, 'eval/f1_weighted': 0.2390909090909091, 'split': 10, 'test/recall_weighted': 0.31746031746031744, '_timestamp': 1704222508.8023047, 'eval/accuracy': 0.28, 'eval/precision_macro': 0.2023809523809524, 'eval/recall_weighted': 0.28, 'eval/loss': 16.53987949241523, 'eval/f1_micro': 0.28, 'test/accuracy': 0.31746031746031744, 'eval/recall_micro': 0.28, 'eval/precision_micro': 0.28}","{'dt_criterion': 'gini', 'dt_max_depth': 14, 'trial.number': 5, 'dt_min_samples_leaf': 8}",fast-frost-320,DecisionTree,['pre-trained:microsoft/codebert-base']
1010,"{'eval/loss': 21.626192033470293, 'eval/precision_macro': 0.2846153846153846, 'eval/precision_micro': 0.4, '_step': 20, '_timestamp': 1704222314.6986372, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.31746031746031744, 'test/f1_weighted': 0.34959387635124595, 'test/recall_macro': 0.2955837173579109, 'test/precision_weighted': 0.4265124853360148, 'split': 10, '_wandb': {'runtime': 1233}, 'test/recall_micro': 0.31746031746031744, 'test/recall_weighted': 0.31746031746031744, 'eval/accuracy': 0.4, 'test/precision_macro': 0.30573152337858217, 'test/precision_micro': 0.31746031746031744, '_runtime': 1235.256058216095, 'test/accuracy': 0.31746031746031744, 'test/loss': 24.60122374177838, 'eval/f1_macro': 0.2976284584980237, 'test/f1_macro': 0.2826341647770219, 'eval/f1_weighted': 0.36711462450592885, 'eval/recall_macro': 0.31666666666666665, 'eval/recall_micro': 0.4, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.3433846153846154}","{'n_neighbours': 1, 'trial.number': 5}",gallant-bird-319,KNeighbours,['pre-trained:microsoft/codebert-base']
1011,"{'eval/accuracy': 0.48, 'test/accuracy': 0.36507936507936506, 'eval/precision_micro': 0.48, 'eval/precision_weighted': 0.5977777777777777, 'split': 10, '_runtime': 1282.1777443885803, 'test/f1_macro': 0.25735294117647056, 'test/f1_weighted': 0.2908496732026144, 'test/recall_micro': 0.36507936507936506, 'test/recall_weighted': 0.36507936507936506, 'eval/f1_micro': 0.48, 'eval/recall_micro': 0.48, 'eval/precision_macro': 0.6736111111111112, 'test/loss': 3.0497707322879135, 'eval/recall_macro': 0.4166666666666667, 'test/recall_macro': 0.3007142857142857, 'test/precision_macro': 0.2426079734219269, '_timestamp': 1704221308.3795953, 'test/precision_weighted': 0.2544797764066867, '_wandb': {'runtime': 1280}, 'test/precision_micro': 0.36507936507936506, '_step': 20, 'eval/loss': 1.268705044242259, 'eval/f1_weighted': 0.44990476190476186, 'eval/f1_macro': 0.4428571428571429, 'test/f1_micro': 0.36507936507936506, 'eval/recall_weighted': 0.48}","{'rf_max_depth': 26, 'trial.number': 4}",hopeful-universe-318,RandomForest,['pre-trained:microsoft/codebert-base']
1012,"{'test/loss': 3.9656082978384193, 'eval/f1_micro': 0.28, 'eval/recall_macro': 0.2625, 'test/recall_micro': 0.42857142857142855, 'test/precision_macro': 0.26904761904761904, 'eval/loss': 6.860243673865673, '_timestamp': 1704221229.0775187, 'test/f1_macro': 0.30885225885225887, 'test/recall_macro': 0.37083333333333335, 'eval/precision_micro': 0.28, '_step': 20, 'split': 10, 'eval/f1_macro': 0.2248376623376623, 'test/precision_weighted': 0.3368102796674225, 'test/precision_micro': 0.42857142857142855, 'eval/precision_weighted': 0.2177777777777778, '_runtime': 1282.7743916511536, 'test/accuracy': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, 'eval/accuracy': 0.28, 'test/f1_micro': 0.42857142857142855, 'eval/recall_micro': 0.28, 'eval/precision_macro': 0.20138888888888887, 'eval/recall_weighted': 0.28, '_wandb': {'runtime': 1281}, 'eval/f1_weighted': 0.24259740259740256, 'test/f1_weighted': 0.3746341841579937}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 4, 'dt_min_samples_leaf': 32}",frosty-valley-317,DecisionTree,['pre-trained:microsoft/codebert-base']
1013,"{'split': 10, '_runtime': 1243.583645105362, 'test/f1_weighted': 0.34959387635124595, 'test/precision_micro': 0.31746031746031744, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.31746031746031744, 'test/recall_macro': 0.2955837173579109, 'test/precision_weighted': 0.4265124853360148, 'eval/loss': 21.626192033470293, '_timestamp': 1704221074.911225, 'eval/recall_macro': 0.31666666666666665, '_step': 20, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.2976284584980237, 'test/precision_macro': 0.30573152337858217, 'test/recall_micro': 0.31746031746031744, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.31746031746031744, '_wandb': {'runtime': 1241}, 'test/f1_macro': 0.2826341647770219, 'eval/recall_micro': 0.4, 'test/loss': 24.60122374177838, 'eval/f1_weighted': 0.36711462450592885, 'test/accuracy': 0.31746031746031744, 'eval/precision_macro': 0.2846153846153846, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.3433846153846154}","{'n_neighbours': 1, 'trial.number': 4}",woven-spaceship-316,KNeighbours,['pre-trained:microsoft/codebert-base']
1014,"{'eval/precision_micro': 0.48, 'test/precision_macro': 0.11611807732497388, 'test/recall_weighted': 0.14285714285714285, 'test/accuracy': 0.14285714285714285, 'test/loss': 20.68103035377725, 'eval/recall_macro': 0.4833333333333333, 'eval/recall_weighted': 0.48, 'eval/loss': 13.643475153842168, '_runtime': 1258.0903315544128, 'test/recall_macro': 0.1699660633484163, 'eval/f1_micro': 0.48, 'test/f1_micro': 0.14285714285714285, 'eval/recall_micro': 0.48, 'test/recall_micro': 0.14285714285714285, 'test/precision_weighted': 0.10176477417856727, 'split': 10, 'test/f1_macro': 0.12486651411136536, 'eval/f1_weighted': 0.4957142857142857, 'eval/precision_macro': 0.5, 'test/precision_micro': 0.14285714285714285, 'eval/accuracy': 0.48, 'eval/precision_weighted': 0.5733333333333334, '_step': 20, '_timestamp': 1704220892.5220656, 'eval/f1_macro': 0.4633928571428571, 'test/f1_weighted': 0.1090455607618079, '_wandb': {'runtime': 1256}}","{'smoothing': 0.6445866174935868, 'trial.number': 4}",vibrant-yogurt-315,Bernolli,['pre-trained:microsoft/codebert-base']
1015,"{'test/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.09782608695652174, '_step': 20, '_runtime': 1286.5918979644775, 'test/recall_macro': 0.31261904761904763, 'eval/recall_macro': 0.225, '_wandb': {'runtime': 1285}, 'eval/loss': 1.346987006976896, 'test/precision_macro': 0.6867816091954023, 'eval/precision_weighted': 0.1565217391304348, 'eval/f1_weighted': 0.21818181818181817, 'test/precision_micro': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, 'test/loss': 1.3300053488229304, 'eval/f1_micro': 0.36, 'test/accuracy': 0.42857142857142855, 'test/precision_weighted': 0.6615581098339719, 'split': 10, 'eval/f1_macro': 0.13636363636363635, 'eval/recall_micro': 0.36, 'test/f1_weighted': 0.3119902186167246, 'eval/recall_weighted': 0.36, '_timestamp': 1704220020.648972, 'test/f1_macro': 0.2682671244418232, 'test/f1_micro': 0.42857142857142855, 'eval/accuracy': 0.36, 'eval/precision_micro': 0.36}","{'rf_max_depth': 3, 'trial.number': 3}",sunny-snowball-314,RandomForest,['pre-trained:microsoft/codebert-base']
1016,"{'_timestamp': 1704219942.1763222, 'eval/f1_macro': 0.20655270655270655, 'test/f1_micro': 0.4126984126984127, 'test/precision_micro': 0.4126984126984127, 'test/recall_weighted': 0.4126984126984127, 'test/precision_weighted': 0.2630023640661938, 'eval/accuracy': 0.36, 'test/f1_weighted': 0.3212660355517498, 'eval/precision_micro': 0.36, '_wandb': {'runtime': 1285}, 'eval/recall_macro': 0.275, '_step': 20, 'test/accuracy': 0.4126984126984127, 'test/f1_macro': 0.19430569430569428, 'eval/precision_macro': 0.16544117647058823, 'eval/loss': 1.496078348360896, 'test/recall_micro': 0.4126984126984127, 'split': 10, 'test/loss': 1.3706803808059724, 'eval/f1_micro': 0.36, 'test/recall_macro': 0.25, 'eval/precision_weighted': 0.21470588235294116, '_runtime': 1286.8690512180328, 'eval/recall_micro': 0.36, 'eval/recall_weighted': 0.36, 'test/precision_macro': 0.1589095744680851, 'eval/f1_weighted': 0.2689458689458689}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 3, 'dt_min_samples_leaf': 46}",laced-moon-313,DecisionTree,['pre-trained:microsoft/codebert-base']
1017,"{'eval/f1_macro': 0.17959770114942528, 'test/f1_macro': 0.22330447330447328, 'eval/recall_macro': 0.24166666666666667, 'test/loss': 17.460707548391003, 'eval/f1_micro': 0.36, 'eval/recall_micro': 0.36, 'eval/accuracy': 0.36, 'eval/f1_weighted': 0.2606896551724138, 'test/precision_macro': 0.2214985994397759, 'eval/loss': 18.909055085675305, 'test/precision_micro': 0.36507936507936506, 'test/accuracy': 0.36507936507936506, 'split': 10, '_runtime': 1244.1219809055328, 'test/recall_micro': 0.36507936507936506, 'test/recall_weighted': 0.36507936507936506, 'eval/precision_weighted': 0.20842105263157895, '_step': 20, 'test/recall_macro': 0.24489247311827955, 'eval/precision_micro': 0.36, '_timestamp': 1704219826.5428288, 'test/f1_micro': 0.36507936507936506, 'test/f1_weighted': 0.3412583888774364, 'eval/precision_macro': 0.1469298245614035, 'eval/recall_weighted': 0.36, 'test/precision_weighted': 0.33481392557022804, '_wandb': {'runtime': 1242}}","{'n_neighbours': 2, 'trial.number': 3}",dulcet-bush-312,KNeighbours,['pre-trained:microsoft/codebert-base']
1018,"{'test/f1_micro': 0.14285714285714285, 'eval/recall_micro': 0.44, 'test/precision_micro': 0.14285714285714285, 'test/recall_micro': 0.14285714285714285, 'eval/precision_weighted': 0.5523809523809523, 'eval/loss': 13.871668820584144, '_timestamp': 1704219629.4117153, 'test/recall_macro': 0.1699660633484163, 'eval/recall_macro': 0.45833333333333337, 'eval/precision_micro': 0.44, 'test/loss': 21.159912700055937, 'eval/f1_macro': 0.43138528138528137, 'test/accuracy': 0.14285714285714285, 'test/f1_weighted': 0.1090455607618079, '_runtime': 1258.6621403694153, 'eval/accuracy': 0.44, 'test/f1_macro': 0.12486651411136536, 'eval/f1_weighted': 0.4532294372294372, 'eval/precision_macro': 0.4797619047619048, 'split': 10, '_wandb': {'runtime': 1257}, 'eval/f1_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.11611807732497388, 'test/recall_weighted': 0.14285714285714285, 'test/precision_weighted': 0.10176477417856727, '_step': 20}","{'smoothing': 0.29896887307963693, 'trial.number': 3}",peach-vortex-311,Bernolli,['pre-trained:microsoft/codebert-base']
1019,"{'_step': 20, 'test/precision_micro': 0.31746031746031744, 'eval/precision_macro': 0.2222222222222222, 'eval/recall_weighted': 0.32, 'eval/loss': 2.819016767683562, 'test/precision_weighted': 0.18896447467876035, 'test/f1_weighted': 0.23691068467187873, 'test/recall_micro': 0.31746031746031744, 'test/recall_weighted': 0.31746031746031744, '_wandb': {'runtime': 1284}, 'test/loss': 2.038233244145116, 'eval/accuracy': 0.32, 'eval/f1_macro': 0.19642857142857145, 'test/f1_macro': 0.1492537313432836, '_timestamp': 1704218730.4512794, 'eval/f1_weighted': 0.2571428571428572, 'eval/recall_micro': 0.32, 'test/recall_macro': 0.2, 'eval/precision_weighted': 0.2555555555555556, 'split': 10, 'eval/f1_micro': 0.32, 'test/accuracy': 0.31746031746031744, 'eval/recall_macro': 0.225, 'eval/precision_micro': 0.32, '_runtime': 1285.357660293579, 'test/f1_micro': 0.31746031746031744, 'test/precision_macro': 0.11904761904761904}","{'rf_max_depth': 10, 'trial.number': 2}",tough-oath-310,RandomForest,['pre-trained:microsoft/codebert-base']
1020,"{'eval/accuracy': 0.2, 'test/recall_micro': 0.36507936507936506, 'test/recall_weighted': 0.36507936507936506, 'test/precision_weighted': 0.322693179836037, '_step': 20, 'test/precision_macro': 0.21978021978021975, 'test/f1_micro': 0.36507936507936506, 'test/recall_macro': 0.24166666666666667, '_runtime': 1285.6224129199982, 'test/accuracy': 0.36507936507936506, 'test/f1_macro': 0.22862554112554115, 'eval/recall_macro': 0.15000000000000002, 'eval/f1_weighted': 0.1818181818181818, 'eval/precision_macro': 0.125, 'split': 10, 'eval/f1_macro': 0.13636363636363635, 'test/f1_weighted': 0.34099498385212673, 'eval/recall_weighted': 0.2, 'eval/precision_weighted': 0.16666666666666663, 'eval/f1_micro': 0.20000000000000004, 'test/precision_micro': 0.36507936507936506, '_wandb': {'runtime': 1284}, 'eval/loss': 8.568527151244872, 'test/loss': 2.961593765778107, '_timestamp': 1704218649.9348638, 'eval/recall_micro': 0.2, 'eval/precision_micro': 0.2}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 2, 'dt_min_samples_leaf': 20}",ancient-water-309,DecisionTree,['pre-trained:microsoft/codebert-base']
1021,"{'test/recall_macro': 0.2955837173579109, 'eval/loss': 21.626192033470293, 'test/f1_macro': 0.2826341647770219, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.31746031746031744, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.31746031746031744, 'eval/f1_weighted': 0.36711462450592885, '_timestamp': 1704218577.6721375, 'eval/f1_macro': 0.2976284584980237, 'eval/precision_macro': 0.2846153846153846, 'test/precision_macro': 0.30573152337858217, '_step': 20, '_runtime': 1244.2727437019348, 'test/loss': 24.60122374177838, 'split': 10, 'test/accuracy': 0.31746031746031744, 'eval/recall_weighted': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_weighted': 0.34959387635124595, 'test/recall_weighted': 0.31746031746031744, 'test/precision_weighted': 0.4265124853360148, '_wandb': {'runtime': 1242}, 'eval/accuracy': 0.4, 'test/f1_micro': 0.31746031746031744, 'eval/recall_macro': 0.31666666666666665, 'eval/precision_weighted': 0.3433846153846154}","{'n_neighbours': 1, 'trial.number': 2}",light-donkey-308,KNeighbours,['pre-trained:microsoft/codebert-base']
1022,"{'test/loss': 21.35800817449475, 'test/precision_weighted': 0.10126286063317548, 'eval/accuracy': 0.44, 'test/accuracy': 0.14285714285714285, 'eval/precision_micro': 0.44, 'test/recall_weighted': 0.14285714285714285, 'eval/precision_weighted': 0.5523809523809523, 'eval/f1_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_micro': 0.14285714285714285, '_wandb': {'runtime': 1255}, 'eval/loss': 13.978323773076673, 'test/recall_micro': 0.14285714285714285, 'eval/f1_weighted': 0.4532294372294372, 'eval/recall_micro': 0.44, 'test/f1_micro': 0.14285714285714285, 'eval/recall_macro': 0.45833333333333337, 'test/recall_macro': 0.1699660633484163, 'eval/precision_macro': 0.4797619047619048, '_step': 20, 'split': 10, '_timestamp': 1704218364.4209151, 'test/f1_macro': 0.12379124529416106, 'test/f1_weighted': 0.10849939247370412, 'test/precision_macro': 0.11512993503248375, '_runtime': 1256.7660851478577, 'eval/f1_macro': 0.43138528138528137}","{'smoothing': 0.16082269280631656, 'trial.number': 2}",rare-dawn-307,Bernolli,['pre-trained:microsoft/codebert-base']
1023,"{'_wandb': {'runtime': 1285}, 'eval/loss': 1.375783876589267, 'eval/recall_macro': 0.225, 'eval/recall_micro': 0.36, 'test/precision_macro': 0.13712121212121212, '_runtime': 1287.059165239334, 'test/f1_micro': 0.3492063492063492, 'eval/f1_weighted': 0.21818181818181817, 'test/loss': 1.4073901695045916, '_timestamp': 1704217441.0865333, 'eval/f1_macro': 0.13636363636363635, 'test/f1_macro': 0.16250000000000003, 'eval/precision_macro': 0.09782608695652174, 'test/precision_weighted': 0.17797017797017797, 'eval/f1_micro': 0.36, 'test/f1_weighted': 0.2281746031746032, 'test/recall_micro': 0.3492063492063492, 'test/precision_micro': 0.3492063492063492, 'split': 10, 'eval/accuracy': 0.36, 'eval/precision_weighted': 0.1565217391304348, '_step': 20, 'test/accuracy': 0.3492063492063492, 'test/recall_macro': 0.235, 'eval/recall_weighted': 0.36, 'eval/precision_micro': 0.36, 'test/recall_weighted': 0.3492063492063492}","{'rf_max_depth': 3, 'trial.number': 1}",wandering-wood-306,RandomForest,['pre-trained:microsoft/codebert-base']
1024,"{'_runtime': 1243.8715891838074, 'eval/f1_micro': 0.36, 'test/f1_weighted': 0.28846161689576044, 'eval/recall_micro': 0.36, 'eval/precision_macro': 0.18859649122807015, 'test/precision_macro': 0.22678571428571428, 'test/f1_macro': 0.22615132182684472, 'eval/recall_weighted': 0.36, 'eval/precision_weighted': 0.2350877192982456, 'test/f1_micro': 0.2857142857142857, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.2259984639016897, 'eval/f1_macro': 0.20043103448275865, 'eval/f1_weighted': 0.27068965517241383, 'split': 10, 'eval/accuracy': 0.36, 'test/accuracy': 0.2857142857142857, 'test/recall_micro': 0.2857142857142857, 'test/precision_weighted': 0.2916099773242631, 'eval/loss': 12.134515960557732, 'test/loss': 9.427132550860582, '_timestamp': 1704217328.412573, 'eval/precision_micro': 0.36, 'test/precision_micro': 0.2857142857142857, '_step': 20, '_wandb': {'runtime': 1242}, 'test/recall_weighted': 0.2857142857142857}","{'n_neighbours': 4, 'trial.number': 1}",fanciful-waterfall-305,KNeighbours,['pre-trained:microsoft/codebert-base']
1025,"{'_wandb': {'runtime': 1283}, 'test/loss': 1.2692118188646868, 'test/accuracy': 0.3968253968253968, 'test/precision_macro': 0.18928571428571428, 'eval/precision_weighted': 0.16410256410256407, 'eval/f1_micro': 0.24, 'eval/recall_micro': 0.24, 'eval/precision_macro': 0.1217948717948718, 'eval/recall_macro': 0.2, 'test/precision_weighted': 0.2925170068027211, 'split': 10, 'eval/loss': 1.4458082322379109, 'test/f1_macro': 0.2251012145748988, 'eval/precision_micro': 0.24, 'eval/recall_weighted': 0.24, '_runtime': 1284.9102547168732, 'test/f1_micro': 0.3968253968253968, 'eval/f1_weighted': 0.1898989898989899, '_step': 20, 'eval/f1_macro': 0.14646464646464646, 'test/recall_micro': 0.3968253968253968, 'test/f1_weighted': 0.32851359167148647, 'test/recall_macro': 0.30833333333333335, 'test/precision_micro': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, '_timestamp': 1704217359.6315646, 'eval/accuracy': 0.24}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 1, 'dt_min_samples_leaf': 66}",fallen-breeze-304,DecisionTree,['pre-trained:microsoft/codebert-base']
1026,"{'test/recall_micro': 0.14285714285714285, 'eval/precision_macro': 0.4797619047619048, 'split': 10, '_runtime': 1256.1186482906342, 'test/loss': 21.391147404787866, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.43138528138528137, 'eval/recall_macro': 0.45833333333333337, '_timestamp': 1704217103.8754332, 'eval/f1_weighted': 0.4532294372294372, 'test/recall_macro': 0.1699660633484163, 'test/precision_micro': 0.14285714285714285, 'eval/precision_weighted': 0.5523809523809523, 'eval/loss': 13.996701189964757, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.10126286063317548, '_step': 20, 'test/f1_micro': 0.14285714285714285, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.14285714285714285, '_wandb': {'runtime': 1254}, 'eval/f1_micro': 0.44, 'test/accuracy': 0.14285714285714285, 'test/f1_macro': 0.12379124529416106, 'eval/recall_micro': 0.44, 'test/f1_weighted': 0.10849939247370412, 'test/precision_macro': 0.11512993503248375}","{'smoothing': 0.138106333437943, 'trial.number': 1}",tough-yogurt-303,Bernolli,['pre-trained:microsoft/codebert-base']
1027,"{'eval/recall_micro': 0.52, '_timestamp': 1704215564.619565, 'test/f1_micro': 0.5079365079365079, 'eval/accuracy': 0.52, 'test/f1_macro': 0.26942567567567566, 'test/f1_weighted': 0.4276061776061776, 'eval/precision_weighted': 0.3317647058823529, 'split': 10, 'test/recall_weighted': 0.5079365079365079, 'eval/loss': 1.2356044350073252, 'eval/f1_micro': 0.52, 'eval/f1_weighted': 0.40380952380952384, 'eval/precision_micro': 0.52, 'test/precision_weighted': 0.37546193643754616, '_step': 20, 'eval/f1_macro': 0.30952380952380953, 'test/recall_micro': 0.5079365079365079, 'eval/recall_weighted': 0.52, 'test/precision_micro': 0.5079365079365079, 'eval/recall_macro': 0.39166666666666666, 'test/recall_macro': 0.34696969696969693, 'test/precision_macro': 0.22671840354767184, '_wandb': {'runtime': 1}, '_runtime': 2.636554002761841, 'test/loss': 1.2621760222008382, 'test/accuracy': 0.5079365079365079, 'eval/precision_macro': 0.25735294117647056}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 99, 'dt_min_samples_leaf': 71}",curious-haze-302,DecisionTree,['TfIdf']
1028,"{'_step': 20, 'split': 10, 'eval/loss': 1.2968738573520882, 'eval/accuracy': 0.44, 'test/recall_weighted': 0.47619047619047616, 'eval/recall_micro': 0.44, 'test/precision_weighted': 0.3620268620268621, '_runtime': 3.40765118598938, 'eval/f1_macro': 0.2632850241545893, 'test/accuracy': 0.47619047619047616, 'eval/f1_weighted': 0.3501449275362319, 'test/recall_macro': 0.3318181818181818, 'eval/precision_macro': 0.21794871794871795, 'eval/recall_macro': 0.3416666666666667, 'eval/recall_weighted': 0.44, 'test/f1_macro': 0.25490196078431376, 'test/f1_micro': 0.47619047619047616, 'test/f1_weighted': 0.4052287581699347, 'test/recall_micro': 0.47619047619047616, 'eval/precision_micro': 0.44, '_timestamp': 1704215556.9907691, 'test/precision_macro': 0.21634615384615383, 'eval/precision_weighted': 0.29538461538461536, '_wandb': {'runtime': 1}, 'test/loss': 1.226718025174548, 'eval/f1_micro': 0.44, 'test/precision_micro': 0.47619047619047616}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 98, 'dt_min_samples_leaf': 82}",vague-paper-301,DecisionTree,['TfIdf']
1029,"{'test/f1_macro': 0.17187500000000003, 'test/recall_micro': 0.5238095238095238, '_step': 20, 'split': 10, '_wandb': {'runtime': 1}, '_runtime': 3.205087184906006, 'eval/loss': 1.3126565071353458, 'eval/f1_macro': 0.14285714285714288, 'test/precision_weighted': 0.27437641723356015, 'test/accuracy': 0.5238095238095238, 'test/f1_micro': 0.5238095238095238, 'test/f1_weighted': 0.36011904761904767, 'test/precision_macro': 0.13095238095238096, 'eval/precision_weighted': 0.16, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_weighted': 0.4, 'test/loss': 1.2588970748241275, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.1, 'eval/f1_weighted': 0.22857142857142865, '_timestamp': 1704215548.4986942, 'eval/accuracy': 0.4, 'eval/recall_macro': 0.25, 'test/precision_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 97, 'dt_min_samples_leaf': 93}",vocal-smoke-300,DecisionTree,['TfIdf']
1030,"{'_timestamp': 1704215540.1511734, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.492063492063492, 'eval/recall_weighted': 0.44, '_wandb': {'runtime': 1}, '_runtime': 3.038912296295166, 'eval/f1_weighted': 0.3440000000000001, 'test/recall_macro': 0.33939393939393936, 'test/precision_weighted': 0.3687888198757764, 'split': 10, 'eval/loss': 1.2871543048462406, 'eval/accuracy': 0.44, 'test/f1_macro': 0.2621419676214197, 'test/recall_weighted': 0.492063492063492, 'test/loss': 1.2234015778747367, 'test/f1_micro': 0.492063492063492, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.22146739130434784, '_step': 20, 'test/accuracy': 0.492063492063492, 'eval/recall_macro': 0.3416666666666667, 'eval/f1_macro': 0.265, 'test/f1_weighted': 0.41649370416493714, 'eval/precision_weighted': 0.2826666666666667, 'eval/f1_micro': 0.44, 'eval/precision_macro': 0.21666666666666667, 'test/precision_micro': 0.492063492063492}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 96, 'dt_min_samples_leaf': 78}",dainty-dragon-299,DecisionTree,['TfIdf']
1031,"{'test/accuracy': 0.5238095238095238, 'eval/f1_weighted': 0.22857142857142865, 'test/precision_weighted': 0.27437641723356015, 'test/f1_micro': 0.5238095238095238, 'eval/precision_macro': 0.1, 'split': 10, '_runtime': 3.2613959312438965, 'eval/loss': 1.3126565071353458, '_timestamp': 1704215532.163091, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.25, 'test/recall_micro': 0.5238095238095238, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.13095238095238096, 'test/loss': 1.2588970748241275, 'test/recall_weighted': 0.5238095238095238, 'test/f1_macro': 0.17187500000000003, 'eval/precision_weighted': 0.16, 'eval/f1_macro': 0.14285714285714288, 'eval/recall_macro': 0.25, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.5238095238095238, '_step': 20, '_wandb': {'runtime': 1}, 'test/f1_weighted': 0.36011904761904767, 'eval/recall_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 95, 'dt_min_samples_leaf': 88}",warm-monkey-298,DecisionTree,['TfIdf']
1032,"{'test/recall_macro': 0.25, 'eval/f1_weighted': 0.22857142857142865, 'eval/loss': 1.3126565071353458, '_timestamp': 1704215523.8528092, 'test/accuracy': 0.5238095238095238, 'test/precision_macro': 0.13095238095238096, 'eval/precision_weighted': 0.16, '_wandb': {'runtime': 1}, 'split': 10, 'eval/f1_macro': 0.14285714285714288, 'test/f1_macro': 0.17187500000000003, '_step': 20, 'test/recall_micro': 0.5238095238095238, 'eval/precision_macro': 0.1, 'test/f1_weighted': 0.36011904761904767, 'test/loss': 1.2588970748241275, 'eval/recall_macro': 0.25, 'eval/recall_weighted': 0.4, '_runtime': 3.1516222953796387, 'eval/recall_micro': 0.4, 'test/precision_micro': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015, 'eval/accuracy': 0.4, 'test/f1_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 94, 'dt_min_samples_leaf': 100}",stilted-meadow-297,DecisionTree,['TfIdf']
1033,"{'_step': 20, 'test/f1_micro': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.29538461538461536, 'test/recall_macro': 0.3242424242424242, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.2632850241545893, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.24761904761904763, 'eval/recall_micro': 0.44, 'split': 10, '_runtime': 3.261845588684082, 'test/f1_weighted': 0.3971277399848828, 'eval/precision_macro': 0.21794871794871795, 'test/precision_macro': 0.21309771309771308, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/loss': 1.2327203320020346, 'test/precision_weighted': 0.3622413622413622, 'eval/loss': 1.2953973805099952, '_timestamp': 1704215515.7462215, 'eval/f1_weighted': 0.3501449275362319, 'eval/recall_macro': 0.3416666666666667, 'eval/precision_micro': 0.44, 'test/precision_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 93, 'dt_min_samples_leaf': 86}",lilac-sky-296,DecisionTree,['TfIdf']
1034,"{'_step': 20, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.4, 'test/accuracy': 0.5238095238095238, 'eval/precision_micro': 0.4, 'eval/precision_weighted': 0.16, 'test/f1_macro': 0.17187500000000003, 'eval/precision_macro': 0.1, 'test/recall_weighted': 0.5238095238095238, 'eval/loss': 1.3126565071353458, '_timestamp': 1704215507.5228543, 'test/recall_micro': 0.5238095238095238, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.13095238095238096, 'test/loss': 1.2588970748241275, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.5238095238095238, 'eval/recall_macro': 0.25, 'test/precision_micro': 0.5238095238095238, 'split': 10, 'eval/f1_macro': 0.14285714285714288, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.36011904761904767, 'test/precision_weighted': 0.27437641723356015, '_runtime': 3.260838270187378, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 92, 'dt_min_samples_leaf': 94}",easy-sun-295,DecisionTree,['TfIdf']
1035,"{'eval/recall_micro': 0.4, 'test/precision_macro': 0.13095238095238096, '_timestamp': 1704215498.8433745, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.36011904761904767, 'test/accuracy': 0.5238095238095238, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'test/precision_micro': 0.5238095238095238, 'split': 10, '_wandb': {'runtime': 1}, 'test/f1_macro': 0.17187500000000003, 'test/f1_micro': 0.5238095238095238, 'eval/f1_macro': 0.14285714285714288, 'test/loss': 1.2588970748241275, 'eval/precision_macro': 0.1, 'eval/precision_weighted': 0.16, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.5238095238095238, '_runtime': 2.7860944271087646, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_micro': 0.5238095238095238, '_step': 20, 'eval/loss': 1.3126565071353458, 'eval/recall_weighted': 0.4, 'test/precision_weighted': 0.27437641723356015}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 91, 'dt_min_samples_leaf': 100}",lyric-gorge-294,DecisionTree,['TfIdf']
1036,"{'_runtime': 3.3017852306365967, 'eval/recall_macro': 0.39166666666666666, 'eval/precision_micro': 0.52, 'test/recall_weighted': 0.5079365079365079, '_step': 20, 'eval/f1_macro': 0.30952380952380953, 'eval/loss': 1.2313815870999172, 'eval/f1_weighted': 0.40380952380952384, 'eval/precision_macro': 0.25735294117647056, 'test/precision_weighted': 0.37546193643754616, 'eval/accuracy': 0.52, 'eval/f1_micro': 0.52, 'test/accuracy': 0.5079365079365079, 'eval/recall_weighted': 0.52, 'split': 10, 'test/loss': 1.2744781026777987, 'test/precision_micro': 0.5079365079365079, 'test/f1_weighted': 0.4276061776061776, 'eval/recall_micro': 0.52, 'test/recall_macro': 0.34696969696969693, '_timestamp': 1704215491.1392353, 'test/f1_macro': 0.26942567567567566, 'test/f1_micro': 0.5079365079365079, 'test/precision_macro': 0.22671840354767184, '_wandb': {'runtime': 1}, 'test/recall_micro': 0.5079365079365079, 'eval/precision_weighted': 0.3317647058823529}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 90, 'dt_min_samples_leaf': 75}",cosmic-puddle-293,DecisionTree,['TfIdf']
1037,"{'eval/loss': 1.2968738573520882, 'test/precision_macro': 0.21634615384615383, 'test/f1_micro': 0.47619047619047616, 'eval/recall_weighted': 0.44, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.25490196078431376, 'eval/precision_micro': 0.44, 'eval/accuracy': 0.44, 'test/accuracy': 0.47619047619047616, 'eval/precision_weighted': 0.29538461538461536, 'test/loss': 1.226718025174548, 'test/precision_micro': 0.47619047619047616, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.2632850241545893, 'eval/f1_weighted': 0.3501449275362319, 'test/f1_weighted': 0.4052287581699347, 'test/recall_weighted': 0.47619047619047616, 'test/recall_micro': 0.47619047619047616, 'eval/precision_macro': 0.21794871794871795, '_step': 20, '_runtime': 3.2929563522338867, 'eval/recall_macro': 0.3416666666666667, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.3318181818181818, 'split': 10, '_timestamp': 1704215482.9015293, 'test/precision_weighted': 0.3620268620268621}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 89, 'dt_min_samples_leaf': 83}",eager-totem-292,DecisionTree,['TfIdf']
1038,"{'eval/loss': 1.3088549567407273, '_runtime': 2.7131850719451904, 'eval/recall_macro': 0.35, 'eval/f1_micro': 0.48, 'eval/f1_weighted': 0.3679120879120879, 'test/precision_macro': 0.21944444444444444, 'test/precision_micro': 0.5079365079365079, 'test/loss': 1.2689644340816222, 'test/f1_macro': 0.2623626373626374, 'test/recall_micro': 0.5079365079365079, 'eval/precision_weighted': 0.3028571428571428, 'test/accuracy': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, 'test/precision_weighted': 0.35837742504409176, '_wandb': {'runtime': 1}, 'split': 10, 'eval/accuracy': 0.48, 'eval/f1_macro': 0.2760989010989011, 'test/f1_micro': 0.5079365079365079, 'test/f1_weighted': 0.4193267050409908, 'eval/recall_micro': 0.48, 'eval/precision_macro': 0.23214285714285715, '_step': 20, 'eval/precision_micro': 0.48, 'test/recall_macro': 0.3295454545454546, 'eval/recall_weighted': 0.48, '_timestamp': 1704215474.076893}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 88, 'dt_min_samples_leaf': 67}",likely-wave-291,DecisionTree,['TfIdf']
1039,"{'eval/loss': 1.3126565071353458, 'test/f1_macro': 0.17187500000000003, 'test/f1_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, '_step': 20, '_runtime': 3.2419252395629883, 'split': 10, 'eval/f1_macro': 0.14285714285714288, 'test/recall_macro': 0.25, 'test/recall_micro': 0.5238095238095238, 'eval/precision_macro': 0.1, '_timestamp': 1704215466.4400992, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.13095238095238096, 'eval/precision_weighted': 0.16, 'test/loss': 1.2588970748241275, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.5238095238095238, 'test/f1_weighted': 0.36011904761904767, 'eval/accuracy': 0.4, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.4, 'test/precision_micro': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015, '_wandb': {'runtime': 1}, 'eval/precision_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 87, 'dt_min_samples_leaf': 95}",clear-butterfly-290,DecisionTree,['TfIdf']
1040,"{'test/accuracy': 0.5238095238095238, 'eval/precision_micro': 0.4, 'test/f1_micro': 0.5238095238095238, '_wandb': {'runtime': 1}, '_timestamp': 1704215458.2463, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/recall_weighted': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015, 'eval/f1_macro': 0.14285714285714288, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.16, '_step': 20, 'test/recall_micro': 0.5238095238095238, 'split': 10, 'test/f1_macro': 0.17187500000000003, 'test/f1_weighted': 0.36011904761904767, 'eval/precision_macro': 0.1, '_runtime': 3.232150077819824, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.4, 'test/precision_macro': 0.13095238095238096, 'eval/loss': 1.3283242560896509, 'test/loss': 1.2585682660123374, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_macro': 0.25, 'test/precision_micro': 0.5238095238095238}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 86, 'dt_min_samples_leaf': 92}",cerulean-firefly-289,DecisionTree,['TfIdf']
1041,"{'test/loss': 1.2288563318331762, 'test/f1_macro': 0.2621419676214197, 'test/f1_weighted': 0.41649370416493714, '_runtime': 2.667877435684204, 'eval/loss': 1.2770549243653675, '_wandb': {'runtime': 1}, 'eval/recall_weighted': 0.48, 'eval/f1_macro': 0.28717948717948716, 'test/recall_micro': 0.492063492063492, 'eval/precision_macro': 0.2361111111111111, 'eval/precision_micro': 0.48, 'test/recall_weighted': 0.492063492063492, '_step': 20, 'eval/recall_micro': 0.48, 'test/precision_macro': 0.22146739130434784, 'test/precision_micro': 0.492063492063492, '_timestamp': 1704215449.3872163, 'test/recall_macro': 0.33939393939393936, 'eval/recall_macro': 0.3666666666666667, 'eval/precision_weighted': 0.30666666666666664, 'split': 10, 'eval/f1_weighted': 0.37415384615384617, 'test/f1_micro': 0.492063492063492, 'test/precision_weighted': 0.3687888198757764, 'test/accuracy': 0.492063492063492, 'eval/accuracy': 0.48, 'eval/f1_micro': 0.48}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 85, 'dt_min_samples_leaf': 76}",distinctive-voice-288,DecisionTree,['TfIdf']
1042,"{'eval/f1_macro': 0.2632850241545893, 'test/precision_macro': 0.21634615384615383, 'test/f1_macro': 0.25490196078431376, 'eval/precision_weighted': 0.29538461538461536, 'test/precision_weighted': 0.3620268620268621, '_step': 20, 'split': 10, 'eval/loss': 1.2968738573520882, 'test/f1_weighted': 0.4052287581699347, 'eval/precision_macro': 0.21794871794871795, 'eval/accuracy': 0.44, 'test/recall_macro': 0.3318181818181818, '_runtime': 3.298996686935425, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.47619047619047616, 'test/recall_weighted': 0.47619047619047616, 'test/loss': 1.226718025174548, 'test/accuracy': 0.47619047619047616, 'eval/f1_weighted': 0.3501449275362319, 'test/recall_micro': 0.47619047619047616, 'eval/precision_micro': 0.44, '_wandb': {'runtime': 1}, '_timestamp': 1704215441.7794576, 'eval/recall_micro': 0.44, 'eval/recall_weighted': 0.44, 'eval/recall_macro': 0.3416666666666667, 'test/precision_micro': 0.47619047619047616}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 84, 'dt_min_samples_leaf': 83}",lunar-grass-287,DecisionTree,['TfIdf']
1043,"{'test/recall_weighted': 0.5238095238095238, '_step': 20, 'eval/loss': 1.3126565071353458, 'eval/f1_macro': 0.14285714285714288, 'eval/recall_macro': 0.25, 'test/precision_weighted': 0.27437641723356015, 'test/f1_macro': 0.17187500000000003, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1, 'test/precision_macro': 0.13095238095238096, 'test/f1_micro': 0.5238095238095238, 'test/f1_weighted': 0.36011904761904767, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.5238095238095238, 'test/loss': 1.2588970748241275, 'eval/accuracy': 0.4, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_macro': 0.25, 'split': 10, '_runtime': 2.6785318851470947, '_timestamp': 1704215434.5694728, 'test/recall_micro': 0.5238095238095238, '_wandb': {'runtime': 1}, 'eval/recall_weighted': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.5238095238095238, 'eval/precision_weighted': 0.16}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 83, 'dt_min_samples_leaf': 88}",honest-brook-286,DecisionTree,['TfIdf']
1044,"{'test/precision_weighted': 0.3620268620268621, '_step': 20, 'test/f1_weighted': 0.4052287581699347, 'eval/recall_macro': 0.3416666666666667, 'eval/precision_macro': 0.21794871794871795, 'eval/recall_weighted': 0.44, '_runtime': 3.299224853515625, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.2632850241545893, 'test/f1_macro': 0.25490196078431376, '_timestamp': 1704215426.974356, 'eval/f1_micro': 0.44, 'eval/f1_weighted': 0.3501449275362319, 'eval/recall_micro': 0.44, 'eval/loss': 1.2968738573520882, 'test/recall_micro': 0.47619047619047616, 'test/precision_micro': 0.47619047619047616, 'test/recall_weighted': 0.47619047619047616, 'test/loss': 1.226718025174548, 'eval/precision_micro': 0.44, '_wandb': {'runtime': 1}, 'split': 10, 'eval/precision_weighted': 0.29538461538461536, 'test/accuracy': 0.47619047619047616, 'test/f1_micro': 0.47619047619047616, 'test/recall_macro': 0.3318181818181818, 'test/precision_macro': 0.21634615384615383}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 82, 'dt_min_samples_leaf': 80}",cerulean-monkey-285,DecisionTree,['TfIdf']
1045,"{'_wandb': {'runtime': 1}, '_timestamp': 1704215418.7248635, 'eval/recall_weighted': 0.4, 'test/accuracy': 0.5238095238095238, 'test/f1_weighted': 0.36011904761904767, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.5238095238095238, 'eval/loss': 1.3126565071353458, 'eval/accuracy': 0.4, 'test/recall_macro': 0.25, 'test/recall_weighted': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015, 'eval/f1_macro': 0.14285714285714288, 'eval/precision_weighted': 0.16, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.17187500000000003, 'eval/f1_weighted': 0.22857142857142865, 'split': 10, 'test/loss': 1.2588970748241275, 'test/f1_micro': 0.5238095238095238, 'eval/recall_macro': 0.25, 'eval/precision_macro': 0.1, 'test/precision_macro': 0.13095238095238096, '_step': 20, '_runtime': 3.2952144145965576, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.5238095238095238}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 81, 'dt_min_samples_leaf': 93}",copper-blaze-284,DecisionTree,['TfIdf']
1046,"{'eval/loss': 1.2356044350073252, 'eval/accuracy': 0.52, 'eval/f1_weighted': 0.40380952380952384, 'eval/recall_micro': 0.52, 'eval/precision_weighted': 0.3317647058823529, '_step': 20, 'split': 10, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.30952380952380953, 'test/recall_micro': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, 'test/precision_weighted': 0.37546193643754616, 'test/loss': 1.2621760222008382, 'eval/f1_micro': 0.52, 'test/f1_macro': 0.26942567567567566, 'test/f1_micro': 0.5079365079365079, 'eval/recall_macro': 0.39166666666666666, 'eval/precision_micro': 0.52, 'eval/recall_weighted': 0.52, 'eval/precision_macro': 0.25735294117647056, '_runtime': 3.111166715621948, '_timestamp': 1704215410.2716775, 'test/accuracy': 0.5079365079365079, 'test/recall_macro': 0.34696969696969693, 'test/precision_macro': 0.22671840354767184, 'test/f1_weighted': 0.4276061776061776, 'test/precision_micro': 0.5079365079365079}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 80, 'dt_min_samples_leaf': 70}",mild-frost-283,DecisionTree,['TfIdf']
1047,"{'eval/accuracy': 0.4, 'eval/precision_weighted': 0.16, 'split': 10, '_runtime': 3.2405083179473877, '_timestamp': 1704215402.2150905, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015, 'eval/precision_macro': 0.1, 'test/precision_macro': 0.13095238095238096, 'test/f1_weighted': 0.36011904761904767, 'eval/loss': 1.3126565071353458, 'test/loss': 1.2588970748241275, 'eval/f1_macro': 0.14285714285714288, 'test/f1_macro': 0.17187500000000003, 'test/accuracy': 0.5238095238095238, 'eval/f1_weighted': 0.22857142857142865, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.5238095238095238, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'test/recall_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, '_step': 20, '_wandb': {'runtime': 1}, 'eval/recall_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 79, 'dt_min_samples_leaf': 91}",bright-sun-282,DecisionTree,['TfIdf']
1048,"{'test/f1_macro': 0.17187500000000003, 'eval/recall_macro': 0.25, 'test/loss': 1.2588970748241275, 'eval/recall_weighted': 0.4, 'test/accuracy': 0.5238095238095238, 'eval/f1_weighted': 0.22857142857142865, 'test/precision_weighted': 0.27437641723356015, 'eval/f1_macro': 0.14285714285714288, 'test/f1_weighted': 0.36011904761904767, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1, '_timestamp': 1704215393.8139596, 'eval/accuracy': 0.4, 'test/recall_macro': 0.25, 'test/precision_micro': 0.5238095238095238, 'split': 10, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.5238095238095238, 'test/recall_micro': 0.5238095238095238, 'test/f1_micro': 0.5238095238095238, 'test/precision_macro': 0.13095238095238096, 'eval/precision_weighted': 0.16, '_wandb': {'runtime': 1}, '_runtime': 3.052987575531006, 'eval/loss': 1.3126565071353458, 'eval/f1_micro': 0.4000000000000001, '_step': 20}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 78, 'dt_min_samples_leaf': 100}",solar-river-281,DecisionTree,['TfIdf']
1049,"{'split': 10, 'eval/f1_macro': 0.30952380952380953, 'eval/f1_micro': 0.52, 'eval/recall_micro': 0.52, 'test/loss': 1.2763908365658756, 'test/f1_macro': 0.26942567567567566, 'test/f1_weighted': 0.4276061776061776, 'test/recall_macro': 0.34696969696969693, 'eval/precision_micro': 0.52, '_runtime': 3.2576072216033936, 'eval/f1_weighted': 0.40380952380952384, 'test/recall_micro': 0.5079365079365079, 'test/precision_macro': 0.22671840354767184, '_step': 20, '_wandb': {'runtime': 1}, 'eval/loss': 1.2372996440079445, 'test/f1_micro': 0.5079365079365079, '_timestamp': 1704215385.7407732, 'eval/precision_weighted': 0.3317647058823529, 'test/precision_weighted': 0.37546193643754616, 'eval/recall_macro': 0.39166666666666666, 'eval/recall_weighted': 0.52, 'test/precision_micro': 0.5079365079365079, 'test/accuracy': 0.5079365079365079, 'eval/precision_macro': 0.25735294117647056, 'test/recall_weighted': 0.5079365079365079, 'eval/accuracy': 0.52}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 77, 'dt_min_samples_leaf': 74}",major-bee-280,DecisionTree,['TfIdf']
1050,"{'eval/recall_macro': 0.3416666666666667, 'eval/precision_weighted': 0.29538461538461536, '_step': 20, 'test/recall_micro': 0.47619047619047616, 'test/precision_weighted': 0.3620268620268621, 'test/precision_micro': 0.47619047619047616, 'split': 10, '_wandb': {'runtime': 1}, '_runtime': 3.201601266860962, 'eval/f1_weighted': 0.3501449275362319, 'test/recall_macro': 0.3318181818181818, 'eval/precision_macro': 0.21794871794871795, '_timestamp': 1704215377.4934523, 'test/accuracy': 0.47619047619047616, 'test/f1_weighted': 0.4052287581699347, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.21634615384615383, 'eval/loss': 1.2968738573520882, 'eval/accuracy': 0.44, 'test/f1_macro': 0.25490196078431376, 'test/f1_micro': 0.47619047619047616, 'eval/recall_micro': 0.44, 'test/recall_weighted': 0.47619047619047616, 'test/loss': 1.226718025174548, 'eval/f1_macro': 0.2632850241545893, 'eval/f1_micro': 0.44}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 76, 'dt_min_samples_leaf': 83}",worthy-rain-279,DecisionTree,['TfIdf']
1051,"{'eval/recall_macro': 0.35, 'eval/recall_micro': 0.48, 'test/recall_weighted': 0.5079365079365079, 'test/precision_weighted': 0.35837742504409176, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.48, 'test/accuracy': 0.5079365079365079, 'eval/f1_weighted': 0.3679120879120879, 'test/loss': 1.2689644340816222, 'test/f1_macro': 0.2623626373626374, 'test/f1_micro': 0.5079365079365079, '_step': 20, 'eval/recall_weighted': 0.48, 'eval/precision_weighted': 0.3028571428571428, '_timestamp': 1704215368.85327, 'test/recall_micro': 0.5079365079365079, 'eval/f1_macro': 0.2760989010989011, 'test/f1_weighted': 0.4193267050409908, 'split': 10, '_runtime': 2.786405086517334, 'eval/precision_micro': 0.48, 'test/precision_micro': 0.5079365079365079, 'test/precision_macro': 0.21944444444444444, 'eval/loss': 1.3088549567407273, 'eval/f1_micro': 0.48, 'test/recall_macro': 0.3295454545454546, 'eval/precision_macro': 0.23214285714285715}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 75, 'dt_min_samples_leaf': 62}",flowing-fog-278,DecisionTree,['TfIdf']
1052,"{'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'test/precision_weighted': 0.27437641723356015, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.5238095238095238, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.5238095238095238, 'test/f1_macro': 0.17187500000000003, '_step': 20, 'test/f1_micro': 0.5238095238095238, 'eval/f1_macro': 0.14285714285714288, '_wandb': {'runtime': 1}, 'eval/loss': 1.3126565071353458, '_timestamp': 1704215361.1114972, 'eval/accuracy': 0.4, 'eval/f1_weighted': 0.22857142857142865, 'test/precision_macro': 0.13095238095238096, 'eval/precision_weighted': 0.16, '_runtime': 3.259848117828369, 'test/loss': 1.2588970748241275, 'test/f1_weighted': 0.36011904761904767, 'split': 10, 'eval/precision_macro': 0.1, 'test/recall_weighted': 0.5238095238095238, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.5238095238095238, 'eval/precision_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 74, 'dt_min_samples_leaf': 91}",eager-capybara-277,DecisionTree,['TfIdf']
1053,"{'_timestamp': 1704215352.9387188, 'eval/recall_weighted': 0.44, 'test/f1_macro': 0.254728370221328, 'test/f1_micro': 0.47619047619047616, 'eval/recall_micro': 0.44, 'eval/precision_macro': 0.21794871794871795, 'test/recall_weighted': 0.47619047619047616, 'split': 10, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.44, 'test/precision_weighted': 0.368922305764411, '_step': 20, '_runtime': 3.318941831588745, 'eval/f1_weighted': 0.3501449275362319, 'eval/recall_macro': 0.3416666666666667, 'test/recall_micro': 0.47619047619047616, 'eval/precision_micro': 0.44, 'test/recall_macro': 0.3318181818181818, 'test/accuracy': 0.47619047619047616, 'test/precision_macro': 0.21789473684210525, 'eval/f1_micro': 0.44, 'test/f1_weighted': 0.40854651719842866, 'eval/loss': 1.2963054839878876, 'test/loss': 1.2282945877476723, 'eval/f1_macro': 0.2632850241545893, 'test/precision_micro': 0.47619047619047616, 'eval/precision_weighted': 0.29538461538461536}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 73, 'dt_min_samples_leaf': 85}",sage-oath-276,DecisionTree,['TfIdf']
1054,"{'test/recall_micro': 0.5238095238095238, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.5238095238095238, '_runtime': 2.6403543949127197, 'eval/accuracy': 0.4, 'test/accuracy': 0.5238095238095238, 'eval/f1_weighted': 0.22857142857142865, 'test/precision_weighted': 0.27437641723356015, 'split': 10, 'test/loss': 1.2588970748241275, 'test/precision_micro': 0.5238095238095238, 'eval/f1_macro': 0.14285714285714288, 'eval/f1_micro': 0.4000000000000001, 'test/f1_weighted': 0.36011904761904767, 'eval/recall_micro': 0.4, 'eval/loss': 1.3126565071353458, 'test/f1_macro': 0.17187500000000003, 'test/recall_macro': 0.25, 'test/precision_macro': 0.13095238095238096, 'test/f1_micro': 0.5238095238095238, 'eval/recall_macro': 0.25, 'eval/precision_weighted': 0.16, '_step': 20, '_wandb': {'runtime': 1}, '_timestamp': 1704215343.9156923, 'eval/precision_macro': 0.1}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 72, 'dt_min_samples_leaf': 100}",dulcet-leaf-275,DecisionTree,['TfIdf']
1055,"{'test/loss': 1.2588970748241275, '_wandb': {'runtime': 1}, 'test/accuracy': 0.5238095238095238, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.14285714285714288, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.13095238095238096, 'test/precision_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, '_step': 20, 'split': 10, '_timestamp': 1704215336.3411362, 'test/f1_weighted': 0.36011904761904767, '_runtime': 3.295250177383423, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.25, 'eval/precision_macro': 0.1, 'eval/precision_micro': 0.4, 'eval/loss': 1.3126565071353458, 'test/f1_macro': 0.17187500000000003, 'eval/recall_micro': 0.4, 'eval/precision_weighted': 0.16, 'test/f1_micro': 0.5238095238095238, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_micro': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 71, 'dt_min_samples_leaf': 97}",resilient-moon-274,DecisionTree,['TfIdf']
1056,"{'_runtime': 3.3058645725250244, 'eval/accuracy': 0.44, 'test/f1_macro': 0.25490196078431376, 'eval/recall_macro': 0.3416666666666667, 'eval/precision_macro': 0.21794871794871795, '_step': 20, 'split': 10, 'test/loss': 1.226718025174548, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.2632850241545893, 'eval/recall_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_micro': 0.47619047619047616, 'test/recall_weighted': 0.47619047619047616, 'eval/precision_micro': 0.44, '_timestamp': 1704215328.1039417, 'test/accuracy': 0.47619047619047616, 'test/recall_micro': 0.47619047619047616, 'eval/precision_weighted': 0.29538461538461536, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.47619047619047616, 'test/f1_weighted': 0.4052287581699347, 'eval/loss': 1.2968738573520882, 'test/precision_macro': 0.21634615384615383, 'test/precision_weighted': 0.3620268620268621, 'eval/f1_weighted': 0.3501449275362319, 'test/recall_macro': 0.3318181818181818}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 70, 'dt_min_samples_leaf': 80}",leafy-salad-273,DecisionTree,['TfIdf']
1057,"{'test/recall_weighted': 0.5079365079365079, 'eval/precision_weighted': 0.3317647058823529, 'test/f1_micro': 0.5079365079365079, 'eval/recall_macro': 0.39166666666666666, 'test/recall_macro': 0.34696969696969693, 'test/recall_micro': 0.5079365079365079, '_timestamp': 1704215319.2960334, 'eval/recall_weighted': 0.52, 'eval/accuracy': 0.52, 'eval/f1_macro': 0.30952380952380953, 'test/precision_macro': 0.22671840354767184, 'test/precision_weighted': 0.37546193643754616, '_step': 20, 'eval/f1_weighted': 0.40380952380952384, 'eval/precision_macro': 0.25735294117647056, 'split': 10, '_wandb': {'runtime': 1}, 'test/accuracy': 0.5079365079365079, 'test/f1_macro': 0.26942567567567566, 'eval/loss': 1.2372996440079445, 'eval/f1_micro': 0.52, 'eval/precision_micro': 0.52, 'test/precision_micro': 0.5079365079365079, '_runtime': 2.6854324340820312, 'test/loss': 1.2763908365658756, 'test/f1_weighted': 0.4276061776061776, 'eval/recall_micro': 0.52}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 69, 'dt_min_samples_leaf': 72}",electric-shadow-272,DecisionTree,['TfIdf']
1058,"{'test/recall_weighted': 0.5238095238095238, '_step': 20, '_wandb': {'runtime': 1}, '_runtime': 3.274559259414673, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'test/precision_macro': 0.13095238095238096, 'eval/precision_weighted': 0.16, '_timestamp': 1704215311.6833162, 'test/accuracy': 0.5238095238095238, 'test/f1_micro': 0.5238095238095238, 'eval/precision_macro': 0.1, 'eval/recall_weighted': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.17187500000000003, 'eval/precision_micro': 0.4, 'split': 10, 'test/loss': 1.2588970748241275, 'test/recall_micro': 0.5238095238095238, 'test/precision_micro': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015, 'eval/accuracy': 0.4, 'eval/recall_micro': 0.4, 'eval/loss': 1.3126565071353458, 'eval/f1_macro': 0.14285714285714288, 'test/f1_weighted': 0.36011904761904767}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 68, 'dt_min_samples_leaf': 90}",helpful-dream-271,DecisionTree,['TfIdf']
1059,"{'test/f1_micro': 0.5079365079365079, 'eval/precision_macro': 0.23214285714285715, 'eval/precision_weighted': 0.3028571428571428, 'eval/loss': 1.3088549567407273, 'test/f1_macro': 0.2623626373626374, 'eval/recall_macro': 0.35, 'test/recall_micro': 0.5079365079365079, 'test/precision_weighted': 0.35837742504409176, 'split': 10, '_wandb': {'runtime': 1}, '_runtime': 3.3102035522460938, '_step': 20, 'eval/accuracy': 0.48, 'eval/f1_macro': 0.2760989010989011, 'test/loss': 1.2689644340816222, 'test/f1_weighted': 0.4193267050409908, 'test/precision_macro': 0.21944444444444444, 'eval/recall_micro': 0.48, 'eval/recall_weighted': 0.48, 'test/recall_weighted': 0.5079365079365079, '_timestamp': 1704215303.4974525, 'eval/f1_micro': 0.48, 'test/precision_micro': 0.5079365079365079, 'test/accuracy': 0.5079365079365079, 'test/recall_macro': 0.3295454545454546, 'eval/precision_micro': 0.48, 'eval/f1_weighted': 0.3679120879120879}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 67, 'dt_min_samples_leaf': 51}",fresh-smoke-270,DecisionTree,['TfIdf']
1060,"{'test/recall_weighted': 0.5079365079365079, 'eval/precision_micro': 0.48, 'test/precision_micro': 0.5079365079365079, 'eval/f1_macro': 0.2760989010989011, 'eval/precision_weighted': 0.3028571428571428, '_step': 20, 'eval/accuracy': 0.48, 'eval/recall_macro': 0.35, 'test/accuracy': 0.5079365079365079, 'test/f1_micro': 0.5079365079365079, 'eval/f1_weighted': 0.3679120879120879, 'eval/recall_weighted': 0.48, '_runtime': 2.7206621170043945, 'test/loss': 1.2689644340816222, '_timestamp': 1704215294.6645882, 'split': 10, '_wandb': {'runtime': 1}, 'eval/precision_macro': 0.23214285714285715, 'test/precision_macro': 0.21944444444444444, 'eval/loss': 1.3088549567407273, 'test/recall_macro': 0.3295454545454546, 'test/f1_weighted': 0.4193267050409908, 'eval/recall_micro': 0.48, 'test/recall_micro': 0.5079365079365079, 'test/precision_weighted': 0.35837742504409176, 'eval/f1_micro': 0.48, 'test/f1_macro': 0.2623626373626374}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 66, 'dt_min_samples_leaf': 63}",fragrant-voice-269,DecisionTree,['TfIdf']
1061,"{'test/recall_micro': 0.47619047619047616, 'test/precision_micro': 0.47619047619047616, 'test/precision_weighted': 0.3620268620268621, 'test/f1_weighted': 0.4052287581699347, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.3318181818181818, 'eval/loss': 1.2968738573520882, 'test/accuracy': 0.47619047619047616, 'eval/f1_micro': 0.44, 'eval/precision_micro': 0.44, 'test/recall_weighted': 0.47619047619047616, 'eval/precision_weighted': 0.29538461538461536, '_wandb': {'runtime': 1}, 'eval/f1_weighted': 0.3501449275362319, 'test/f1_micro': 0.47619047619047616, 'test/precision_macro': 0.21634615384615383, 'eval/recall_weighted': 0.44, 'test/loss': 1.226718025174548, '_timestamp': 1704215286.9908788, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.2632850241545893, 'eval/recall_macro': 0.3416666666666667, 'eval/precision_macro': 0.21794871794871795, 'split': 10, '_runtime': 3.3002727031707764, '_step': 20, 'test/f1_macro': 0.25490196078431376}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 65, 'dt_min_samples_leaf': 80}",stellar-pond-268,DecisionTree,['TfIdf']
1062,"{'test/f1_weighted': 0.4276061776061776, 'test/precision_macro': 0.22671840354767184, 'test/loss': 1.2621760222008382, 'test/f1_macro': 0.26942567567567566, 'eval/f1_micro': 0.52, 'eval/precision_micro': 0.52, 'test/recall_weighted': 0.5079365079365079, 'eval/loss': 1.2356044350073252, '_timestamp': 1704215278.760569, 'eval/precision_macro': 0.25735294117647056, 'test/recall_micro': 0.5079365079365079, 'eval/accuracy': 0.52, 'test/f1_micro': 0.5079365079365079, 'test/precision_micro': 0.5079365079365079, 'test/precision_weighted': 0.37546193643754616, '_wandb': {'runtime': 1}, '_runtime': 3.2718653678894043, 'eval/f1_weighted': 0.40380952380952384, 'eval/recall_micro': 0.52, 'eval/recall_macro': 0.39166666666666666, 'test/recall_macro': 0.34696969696969693, 'eval/recall_weighted': 0.52, 'eval/precision_weighted': 0.3317647058823529, '_step': 20, 'split': 10, 'eval/f1_macro': 0.30952380952380953, 'test/accuracy': 0.5079365079365079}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 64, 'dt_min_samples_leaf': 70}",balmy-cloud-267,DecisionTree,['TfIdf']
1063,"{'test/accuracy': 0.5238095238095238, 'test/f1_weighted': 0.36011904761904767, 'test/recall_macro': 0.25, '_step': 20, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015, 'split': 10, 'eval/f1_micro': 0.4000000000000001, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.14285714285714288, 'test/f1_micro': 0.5238095238095238, 'test/precision_macro': 0.13095238095238096, '_wandb': {'runtime': 1}, '_runtime': 3.269841432571411, 'eval/loss': 1.3126565071353458, 'test/loss': 1.2588970748241275, 'eval/precision_micro': 0.4, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_macro': 0.25, '_timestamp': 1704215270.5300984, 'eval/precision_macro': 0.1, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.5238095238095238, 'test/f1_macro': 0.17187500000000003, 'test/recall_weighted': 0.5238095238095238, 'eval/precision_weighted': 0.16}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 63, 'dt_min_samples_leaf': 100}",light-capybara-266,DecisionTree,['TfIdf']
1064,"{'eval/f1_macro': 0.14285714285714288, 'test/f1_micro': 0.5238095238095238, 'eval/recall_macro': 0.25, 'test/accuracy': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015, '_step': 20, '_wandb': {'runtime': 1}, '_timestamp': 1704215262.3259623, 'test/f1_macro': 0.17187500000000003, 'test/recall_macro': 0.25, 'test/precision_macro': 0.13095238095238096, 'test/precision_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, 'eval/loss': 1.3126565071353458, 'split': 10, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1, 'eval/precision_micro': 0.4, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/recall_micro': 0.5238095238095238, '_runtime': 3.2549774646759033, 'test/loss': 1.2588970748241275, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.36011904761904767, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.16}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 62, 'dt_min_samples_leaf': 94}",graceful-spaceship-265,DecisionTree,['TfIdf']
1065,"{'_wandb': {'runtime': 1}, 'test/loss': 1.2588970748241275, 'test/f1_micro': 0.5238095238095238, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_micro': 0.5238095238095238, 'eval/recall_weighted': 0.4, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.1, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.13095238095238096, 'test/precision_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, 'eval/accuracy': 0.4, 'test/accuracy': 0.5238095238095238, 'split': 10, 'test/f1_weighted': 0.36011904761904767, 'test/precision_weighted': 0.27437641723356015, 'eval/precision_weighted': 0.16, '_runtime': 3.014620542526245, 'test/f1_macro': 0.17187500000000003, '_timestamp': 1704215253.8381686, 'eval/f1_macro': 0.14285714285714288, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.25, '_step': 20, 'eval/loss': 1.3126565071353458, 'eval/recall_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 61, 'dt_min_samples_leaf': 92}",decent-paper-264,DecisionTree,['TfIdf']
1066,"{'_wandb': {'runtime': 2}, 'eval/f1_macro': 0.265, 'test/f1_weighted': 0.41649370416493714, 'eval/recall_macro': 0.3416666666666667, 'split': 10, 'test/accuracy': 0.492063492063492, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.33939393939393936, 'test/precision_micro': 0.492063492063492, 'test/recall_weighted': 0.492063492063492, 'test/f1_macro': 0.2621419676214197, 'test/recall_micro': 0.492063492063492, 'eval/precision_macro': 0.21666666666666667, '_runtime': 3.2776801586151123, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.492063492063492, '_timestamp': 1704215245.877808, 'eval/f1_weighted': 0.3440000000000001, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_weighted': 0.3687888198757764, '_step': 20, 'eval/loss': 1.28840870715292, 'test/loss': 1.2259395565068183, 'test/precision_macro': 0.22146739130434784, 'eval/precision_weighted': 0.2826666666666667}","{'dt_criterion': 'gini', 'dt_max_depth': 12, 'trial.number': 60, 'dt_min_samples_leaf': 77}",lyric-surf-263,DecisionTree,['TfIdf']
1067,"{'test/precision_macro': 0.13095238095238096, 'test/loss': 1.2588970748241275, 'eval/accuracy': 0.4, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.4, '_runtime': 3.320817708969116, 'test/recall_micro': 0.5238095238095238, 'eval/precision_macro': 0.1, 'test/precision_weighted': 0.27437641723356015, 'split': 10, 'eval/f1_macro': 0.14285714285714288, 'test/f1_macro': 0.17187500000000003, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'eval/loss': 1.3126565071353458, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.5238095238095238, 'test/f1_weighted': 0.36011904761904767, 'test/accuracy': 0.5238095238095238, 'eval/f1_weighted': 0.22857142857142865, '_step': 20, '_wandb': {'runtime': 1}, 'eval/precision_weighted': 0.16, '_timestamp': 1704215237.7163718, 'test/recall_macro': 0.25, 'test/precision_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 59, 'dt_min_samples_leaf': 91}",wandering-dream-262,DecisionTree,['TfIdf']
1068,"{'test/f1_weighted': 0.4193267050409908, 'eval/precision_micro': 0.48, 'eval/f1_weighted': 0.3679120879120879, 'eval/recall_micro': 0.48, 'test/recall_macro': 0.3295454545454546, 'test/precision_micro': 0.5079365079365079, 'eval/precision_weighted': 0.3028571428571428, '_step': 20, '_timestamp': 1704215228.8687077, 'eval/precision_macro': 0.23214285714285715, 'eval/recall_weighted': 0.48, 'test/accuracy': 0.5079365079365079, 'test/f1_macro': 0.2623626373626374, 'test/f1_micro': 0.5079365079365079, 'test/recall_micro': 0.5079365079365079, 'eval/loss': 1.3088549567407273, 'eval/f1_micro': 0.48, '_runtime': 2.71346664428711, 'eval/accuracy': 0.48, 'test/loss': 1.2689644340816222, 'eval/recall_macro': 0.35, 'test/precision_weighted': 0.35837742504409176, 'split': 10, 'eval/f1_macro': 0.2760989010989011, 'test/recall_weighted': 0.5079365079365079, '_wandb': {'runtime': 1}, 'test/precision_macro': 0.21944444444444444}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 58, 'dt_min_samples_leaf': 44}",dry-voice-261,DecisionTree,['TfIdf']
1069,"{'test/f1_micro': 0.5079365079365079, 'eval/f1_weighted': 0.3679120879120879, 'test/precision_micro': 0.5079365079365079, '_runtime': 3.2659077644348145, 'eval/recall_micro': 0.48, '_timestamp': 1704215221.1852908, 'eval/loss': 1.3088549567407273, 'test/accuracy': 0.5079365079365079, 'test/f1_weighted': 0.4193267050409908, 'test/loss': 1.2689644340816222, 'test/precision_weighted': 0.35837742504409176, 'eval/precision_weighted': 0.3028571428571428, 'eval/f1_macro': 0.2760989010989011, 'eval/recall_macro': 0.35, 'test/recall_macro': 0.3295454545454546, 'test/recall_micro': 0.5079365079365079, 'eval/precision_macro': 0.23214285714285715, '_step': 20, '_wandb': {'runtime': 1}, 'eval/recall_weighted': 0.48, 'test/precision_macro': 0.21944444444444444, 'split': 10, 'eval/f1_micro': 0.48, 'test/f1_macro': 0.2623626373626374, 'eval/precision_micro': 0.48, 'test/recall_weighted': 0.5079365079365079, 'eval/accuracy': 0.48}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 57, 'dt_min_samples_leaf': 58}",leafy-lake-260,DecisionTree,['TfIdf']
1070,"{'eval/f1_macro': 0.14285714285714288, 'eval/f1_micro': 0.4000000000000001, '_step': 20, 'test/f1_micro': 0.5238095238095238, 'test/f1_weighted': 0.36011904761904767, 'eval/precision_weighted': 0.16, 'split': 10, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.4, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.5238095238095238, 'eval/precision_macro': 0.1, '_runtime': 3.27913761138916, 'test/precision_micro': 0.5238095238095238, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.13095238095238096, '_timestamp': 1704215212.9662695, 'test/accuracy': 0.5238095238095238, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015, 'test/f1_macro': 0.17187500000000003, 'test/recall_macro': 0.25, 'eval/loss': 1.3126565071353458, 'test/loss': 1.2588970748241275, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 56, 'dt_min_samples_leaf': 88}",olive-music-259,DecisionTree,['TfIdf']
1071,"{'test/recall_macro': 0.25, 'eval/precision_weighted': 0.1936, 'eval/f1_weighted': 0.26888888888888896, 'test/precision_weighted': 0.21189216427311663, 'test/f1_macro': 0.15760869565217392, 'test/loss': 1.3302066853563077, 'test/recall_weighted': 0.4603174603174603, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_micro': 0.4603174603174603, 'eval/loss': 1.2885286144160266, '_timestamp': 1704215209.4957569, 'test/f1_micro': 0.4603174603174603, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.44, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'test/precision_macro': 0.11507936507936509, '_step': 20, 'eval/recall_macro': 0.25, 'test/f1_weighted': 0.290200138026225, 'eval/recall_micro': 0.44, 'split': 10, '_runtime': 2.6731178760528564}","{'dt_criterion': 'gini', 'dt_max_depth': 14, 'trial.number': 99, 'dt_min_samples_leaf': 89}",magic-bee-258,DecisionTree,['BoW']
1072,"{'test/recall_macro': 0.34696969696969693, 'eval/precision_micro': 0.52, 'eval/precision_weighted': 0.3317647058823529, 'eval/loss': 1.2313815870999172, 'eval/f1_macro': 0.30952380952380953, 'test/loss': 1.2744781026777987, 'eval/f1_micro': 0.52, 'eval/recall_micro': 0.52, 'test/precision_macro': 0.22671840354767184, '_step': 20, '_wandb': {'runtime': 1}, 'test/precision_micro': 0.5079365079365079, 'split': 10, 'test/f1_weighted': 0.4276061776061776, 'eval/recall_macro': 0.39166666666666666, 'eval/recall_weighted': 0.52, 'test/precision_weighted': 0.37546193643754616, '_runtime': 2.713797092437744, 'eval/f1_weighted': 0.40380952380952384, 'eval/precision_macro': 0.25735294117647056, 'test/recall_weighted': 0.5079365079365079, '_timestamp': 1704215204.139153, 'test/accuracy': 0.5079365079365079, 'test/recall_micro': 0.5079365079365079, 'eval/accuracy': 0.52, 'test/f1_macro': 0.26942567567567566, 'test/f1_micro': 0.5079365079365079}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 55, 'dt_min_samples_leaf': 75}",upbeat-donkey-257,DecisionTree,['TfIdf']
1073,"{'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'eval/precision_micro': 0.44, 'eval/f1_micro': 0.44, 'eval/recall_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'eval/recall_macro': 0.25, 'eval/precision_weighted': 0.1936, 'test/precision_weighted': 0.21189216427311663, 'test/f1_micro': 0.4603174603174603, '_wandb': {'runtime': 1}, 'test/loss': 1.3302066853563077, '_timestamp': 1704215201.872121, 'eval/precision_macro': 0.11, '_runtime': 3.2836833000183105, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_macro': 0.25, 'test/precision_macro': 0.11507936507936509, 'split': 10, 'eval/accuracy': 0.44, '_step': 20, 'eval/loss': 1.2885286144160266, 'test/f1_weighted': 0.290200138026225, 'test/recall_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 98, 'dt_min_samples_leaf': 77}",feasible-valley-256,DecisionTree,['BoW']
1074,"{'split': 10, 'test/f1_macro': 0.2623626373626374, 'eval/recall_weighted': 0.48, 'eval/loss': 1.3088549567407273, 'test/f1_micro': 0.5079365079365079, 'eval/recall_macro': 0.35, 'eval/precision_micro': 0.48, 'test/accuracy': 0.5079365079365079, 'eval/recall_micro': 0.48, 'test/precision_micro': 0.5079365079365079, '_wandb': {'runtime': 1}, 'test/loss': 1.2689644340816222, 'eval/accuracy': 0.48, 'eval/f1_weighted': 0.3679120879120879, 'test/f1_weighted': 0.4193267050409908, 'test/recall_macro': 0.3295454545454546, 'test/recall_weighted': 0.5079365079365079, '_timestamp': 1704215196.4329193, 'test/precision_macro': 0.21944444444444444, 'test/recall_micro': 0.5079365079365079, '_runtime': 3.2450191974639893, '_step': 20, 'eval/f1_macro': 0.2760989010989011, 'eval/f1_micro': 0.48, 'eval/precision_macro': 0.23214285714285715, 'eval/precision_weighted': 0.3028571428571428, 'test/precision_weighted': 0.35837742504409176}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 54, 'dt_min_samples_leaf': 68}",comfy-forest-255,DecisionTree,['TfIdf']
1075,"{'eval/accuracy': 0.44, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.4603174603174603, 'eval/precision_weighted': 0.1936, 'split': 10, '_runtime': 3.227440357208252, '_timestamp': 1704215193.6301763, 'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, '_wandb': {'runtime': 1}, 'test/f1_weighted': 0.290200138026225, 'test/recall_macro': 0.25, 'test/precision_micro': 0.4603174603174603, 'test/loss': 1.3302066853563077, 'eval/f1_micro': 0.44, 'eval/recall_macro': 0.25, 'eval/precision_macro': 0.11, 'test/precision_weighted': 0.21189216427311663, '_step': 20, 'eval/loss': 1.2885286144160266, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_weighted': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.11507936507936509, 'test/f1_micro': 0.4603174603174603, 'eval/precision_micro': 0.44}","{'dt_criterion': 'gini', 'dt_max_depth': 12, 'trial.number': 97, 'dt_min_samples_leaf': 70}",sparkling-capybara-254,DecisionTree,['BoW']
1076,"{'eval/f1_micro': 0.44, 'test/accuracy': 0.492063492063492, 'test/f1_micro': 0.492063492063492, 'eval/precision_weighted': 0.2826666666666667, 'split': 10, 'eval/loss': 1.2871543048462406, 'test/f1_weighted': 0.41649370416493714, '_wandb': {'runtime': 1}, '_timestamp': 1704215188.2915244, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.22146739130434784, 'test/recall_micro': 0.492063492063492, 'eval/precision_micro': 0.44, 'eval/f1_weighted': 0.3440000000000001, '_runtime': 3.2494335174560547, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.265, 'test/f1_macro': 0.2621419676214197, 'test/precision_weighted': 0.3687888198757764, '_step': 20, 'test/loss': 1.2234015778747367, 'test/precision_micro': 0.492063492063492, 'eval/recall_micro': 0.44, 'eval/precision_macro': 0.21666666666666667, 'eval/recall_macro': 0.3416666666666667, 'test/recall_macro': 0.33939393939393936, 'test/recall_weighted': 0.492063492063492}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 53, 'dt_min_samples_leaf': 78}",devoted-totem-253,DecisionTree,['TfIdf']
1077,"{'_runtime': 5.2995765209198, 'eval/loss': 1.2885286144160266, 'eval/recall_micro': 0.44, 'test/f1_weighted': 0.290200138026225, 'eval/precision_macro': 0.11, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.21189216427311663, '_step': 20, 'split': 10, '_wandb': {'runtime': 2}, 'test/loss': 1.3302066853563077, '_timestamp': 1704215185.4448445, 'test/recall_weighted': 0.4603174603174603, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.1936, 'eval/f1_micro': 0.44, 'test/precision_macro': 0.11507936507936509, 'test/precision_micro': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603, 'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, 'test/f1_micro': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'eval/accuracy': 0.44, 'eval/f1_weighted': 0.26888888888888896}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 96, 'dt_min_samples_leaf': 84}",fallen-glade-252,DecisionTree,['BoW']
1078,"{'eval/recall_macro': 0.25, 'test/recall_micro': 0.5238095238095238, 'test/precision_micro': 0.5238095238095238, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.36011904761904767, 'eval/precision_weighted': 0.16, '_step': 20, 'split': 10, '_runtime': 2.737560510635376, 'eval/accuracy': 0.4, 'test/f1_macro': 0.17187500000000003, 'test/precision_weighted': 0.27437641723356015, 'test/loss': 1.2588970748241275, 'eval/recall_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/accuracy': 0.5238095238095238, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.13095238095238096, 'test/recall_weighted': 0.5238095238095238, 'eval/f1_macro': 0.14285714285714288, '_timestamp': 1704215178.8396215, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.5238095238095238, 'test/recall_macro': 0.25, '_wandb': {'runtime': 1}, 'eval/loss': 1.3126565071353458, 'eval/precision_macro': 0.1}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 52, 'dt_min_samples_leaf': 87}",radiant-bee-251,DecisionTree,['TfIdf']
1079,"{'eval/accuracy': 0.44, 'eval/precision_macro': 0.11, 'eval/precision_weighted': 0.1936, '_step': 20, 'eval/loss': 1.290462308510823, 'test/recall_weighted': 0.4603174603174603, 'split': 10, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.4603174603174603, 'eval/recall_weighted': 0.44, 'test/accuracy': 0.4603174603174603, 'eval/recall_macro': 0.25, 'test/precision_macro': 0.11507936507936509, 'test/f1_macro': 0.15760869565217392, '_wandb': {'runtime': 1}, 'test/loss': 1.2854266288838343, 'eval/precision_micro': 0.44, '_runtime': 2.6177496910095215, 'test/f1_weighted': 0.290200138026225, 'test/precision_micro': 0.4603174603174603, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_macro': 0.25, 'test/precision_weighted': 0.21189216427311663, '_timestamp': 1704215174.534175, 'eval/f1_macro': 0.1527777777777778}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 95, 'dt_min_samples_leaf': 100}",radiant-elevator-250,DecisionTree,['BoW']
1080,"{'test/recall_weighted': 0.5238095238095238, 'test/f1_micro': 0.5238095238095238, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1, 'test/precision_weighted': 0.27437641723356015, 'test/accuracy': 0.5238095238095238, 'eval/f1_macro': 0.14285714285714288, 'test/f1_weighted': 0.36011904761904767, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.5238095238095238, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.5238095238095238, 'split': 10, 'eval/f1_weighted': 0.22857142857142865, '_runtime': 3.25588059425354, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.17187500000000003, '_timestamp': 1704215171.1158843, 'test/precision_macro': 0.13095238095238096, 'eval/precision_weighted': 0.16, '_step': 20, 'eval/loss': 1.3126565071353458, 'test/loss': 1.2588970748241275, 'eval/precision_micro': 0.4, '_wandb': {'runtime': 1}, 'test/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 51, 'dt_min_samples_leaf': 100}",giddy-resonance-249,DecisionTree,['TfIdf']
1081,"{'test/precision_macro': 0.11507936507936509, '_runtime': 3.3314480781555176, 'test/f1_micro': 0.4603174603174603, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.11, 'eval/precision_micro': 0.44, 'test/precision_micro': 0.4603174603174603, 'eval/precision_weighted': 0.1936, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.15760869565217392, 'test/recall_micro': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_weighted': 0.4603174603174603, 'split': 10, '_wandb': {'runtime': 2}, '_timestamp': 1704215167.07127, 'eval/f1_macro': 0.1527777777777778, 'eval/recall_micro': 0.44, 'eval/recall_weighted': 0.44, 'eval/loss': 1.290462308510823, 'test/loss': 1.2854266288838343, 'test/accuracy': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'eval/recall_macro': 0.25, '_step': 20, 'test/precision_weighted': 0.21189216427311663}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 94, 'dt_min_samples_leaf': 93}",feasible-tree-248,DecisionTree,['BoW']
1082,"{'_wandb': {'runtime': 1}, 'eval/accuracy': 0.44, 'test/recall_weighted': 0.47619047619047616, 'split': 10, 'test/f1_macro': 0.254728370221328, 'test/f1_micro': 0.47619047619047616, 'eval/recall_macro': 0.3416666666666667, '_runtime': 3.312640905380249, 'eval/f1_weighted': 0.3501449275362319, 'test/recall_macro': 0.3318181818181818, 'eval/loss': 1.2963054839878876, '_timestamp': 1704215162.8963828, 'eval/f1_macro': 0.2632850241545893, 'test/f1_weighted': 0.40854651719842866, 'eval/recall_micro': 0.44, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.29538461538461536, 'eval/f1_micro': 0.44, 'test/loss': 1.2282945877476723, 'test/recall_micro': 0.47619047619047616, 'eval/precision_macro': 0.21794871794871795, 'test/precision_micro': 0.47619047619047616, '_step': 20, 'test/accuracy': 0.47619047619047616, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.21789473684210525, 'test/precision_weighted': 0.368922305764411}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 50, 'dt_min_samples_leaf': 85}",brisk-durian-247,DecisionTree,['TfIdf']
1083,"{'test/f1_macro': 0.15760869565217392, 'eval/precision_macro': 0.11, 'eval/precision_micro': 0.44, 'test/f1_micro': 0.4603174603174603, 'eval/recall_weighted': 0.44, 'test/precision_weighted': 0.21189216427311663, 'eval/accuracy': 0.44, 'test/recall_micro': 0.4603174603174603, 'test/accuracy': 0.4603174603174603, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.25, 'eval/f1_macro': 0.1527777777777778, 'eval/f1_weighted': 0.26888888888888896, '_wandb': {'runtime': 1}, '_timestamp': 1704215158.8597145, '_step': 20, 'split': 10, 'eval/f1_micro': 0.44, 'test/f1_weighted': 0.290200138026225, 'eval/recall_macro': 0.25, 'eval/precision_weighted': 0.1936, '_runtime': 3.352042436599731, 'eval/loss': 1.2885286144160266, 'test/loss': 1.3302066853563077, 'test/precision_macro': 0.11507936507936509, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 93, 'dt_min_samples_leaf': 77}",cool-gorge-246,DecisionTree,['BoW']
1084,"{'test/precision_micro': 0.3968253968253968, 'eval/recall_micro': 0.36, 'test/recall_micro': 0.3968253968253968, 'split': 10, 'test/accuracy': 0.3968253968253968, 'eval/recall_macro': 0.325, 'eval/recall_weighted': 0.36, '_step': 20, 'eval/precision_macro': 0.29545454545454547, 'test/recall_macro': 0.3068181818181818, 'test/precision_macro': 0.2702777777777778, 'eval/precision_weighted': 0.3677922077922078, 'eval/loss': 1.320691757922265, 'eval/accuracy': 0.36, 'test/f1_micro': 0.3968253968253968, 'eval/f1_micro': 0.36, 'test/f1_macro': 0.2729885057471264, 'test/precision_weighted': 0.4362257495590828, 'eval/f1_weighted': 0.34900452488687783, 'test/recall_weighted': 0.3968253968253968, '_wandb': {'runtime': 1}, '_runtime': 2.746469020843506, '_timestamp': 1704215154.130883, 'eval/precision_micro': 0.36, 'test/loss': 1.2422969218318398, 'eval/f1_macro': 0.2955316742081448, 'test/f1_weighted': 0.4021164021164021}","{'dt_criterion': 'gini', 'dt_max_depth': 17, 'trial.number': 49, 'dt_min_samples_leaf': 66}",clear-elevator-245,DecisionTree,['TfIdf']
1085,"{'test/accuracy': 0.4603174603174603, 'eval/recall_weighted': 0.44, '_wandb': {'runtime': 1}, 'eval/precision_micro': 0.44, 'test/recall_weighted': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603, 'eval/f1_micro': 0.44, 'eval/recall_macro': 0.25, '_timestamp': 1704215150.5971148, 'test/loss': 1.3302066853563077, 'eval/f1_macro': 0.1527777777777778, 'eval/precision_weighted': 0.1936, 'eval/loss': 1.2885286144160266, 'test/f1_micro': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, 'split': 10, 'test/f1_weighted': 0.290200138026225, 'eval/recall_micro': 0.44, 'test/precision_weighted': 0.21189216427311663, '_step': 20, 'eval/accuracy': 0.44, 'test/f1_macro': 0.15760869565217392, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.11, '_runtime': 3.2979848384857178, 'test/precision_macro': 0.11507936507936509}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 92, 'dt_min_samples_leaf': 88}",morning-rain-244,DecisionTree,['BoW']
1086,"{'test/loss': 1.2588970748241275, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1, '_step': 20, '_runtime': 3.2905335426330566, 'eval/loss': 1.3126565071353458, 'test/accuracy': 0.5238095238095238, 'test/recall_macro': 0.25, 'split': 10, 'eval/recall_macro': 0.25, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.27437641723356015, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.36011904761904767, 'test/recall_weighted': 0.5238095238095238, '_wandb': {'runtime': 1}, 'test/f1_macro': 0.17187500000000003, 'test/f1_micro': 0.5238095238095238, 'test/recall_micro': 0.5238095238095238, 'test/precision_micro': 0.5238095238095238, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_weighted': 0.4, '_timestamp': 1704215146.4302745, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.14285714285714288, 'test/precision_macro': 0.13095238095238096, 'eval/precision_weighted': 0.16}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 48, 'dt_min_samples_leaf': 99}",glad-darkness-243,DecisionTree,['TfIdf']
1087,"{'test/f1_weighted': 0.290200138026225, 'eval/precision_macro': 0.11, '_timestamp': 1704215142.5439403, 'eval/f1_macro': 0.1527777777777778, 'test/f1_micro': 0.4603174603174603, 'eval/recall_weighted': 0.44, '_runtime': 3.4299392700195312, 'test/accuracy': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, 'eval/f1_micro': 0.44, 'eval/f1_weighted': 0.26888888888888896, 'eval/recall_micro': 0.44, 'eval/precision_micro': 0.44, 'eval/precision_weighted': 0.1936, 'test/precision_weighted': 0.21189216427311663, 'split': 10, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.25, 'test/precision_macro': 0.11507936507936509, 'test/loss': 1.2854266288838343, 'test/f1_macro': 0.15760869565217392, 'eval/loss': 1.290462308510823, 'test/recall_macro': 0.25, 'test/recall_weighted': 0.4603174603174603, '_step': 20, 'test/recall_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 91, 'dt_min_samples_leaf': 99}",blooming-smoke-242,DecisionTree,['BoW']
1088,"{'_runtime': 3.365701675415039, '_timestamp': 1704215137.3282866, 'test/recall_weighted': 0.5079365079365079, 'test/f1_micro': 0.5079365079365079, 'test/recall_micro': 0.5079365079365079, 'test/loss': 1.2689644340816222, 'eval/f1_macro': 0.2760989010989011, 'test/accuracy': 0.5079365079365079, 'test/f1_macro': 0.2623626373626374, 'split': 10, 'eval/f1_micro': 0.48, 'eval/precision_micro': 0.48, 'test/precision_micro': 0.5079365079365079, 'eval/precision_weighted': 0.3028571428571428, 'eval/f1_weighted': 0.3679120879120879, 'eval/recall_macro': 0.35, 'eval/recall_micro': 0.48, 'eval/recall_weighted': 0.48, '_step': 20, 'eval/loss': 1.3088549567407273, 'eval/accuracy': 0.48, 'test/f1_weighted': 0.4193267050409908, 'eval/precision_macro': 0.23214285714285715, 'test/precision_macro': 0.21944444444444444, 'test/precision_weighted': 0.35837742504409176, '_wandb': {'runtime': 1}, 'test/recall_macro': 0.3295454545454546}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 47, 'dt_min_samples_leaf': 59}",logical-thunder-241,DecisionTree,['TfIdf']
1089,"{'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, '_runtime': 2.8649039268493652, 'eval/precision_macro': 0.11, 'eval/precision_micro': 0.44, 'eval/f1_micro': 0.44, 'eval/recall_macro': 0.25, 'eval/recall_weighted': 0.44, '_step': 20, 'test/precision_macro': 0.11507936507936509, 'test/precision_micro': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'eval/loss': 1.2885286144160266, 'test/loss': 1.3302066853563077, '_timestamp': 1704215133.8002388, 'test/f1_weighted': 0.290200138026225, 'eval/recall_micro': 0.44, 'test/recall_weighted': 0.4603174603174603, '_wandb': {'runtime': 1}, 'split': 10, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.1527777777777778, 'test/f1_micro': 0.4603174603174603, 'eval/precision_weighted': 0.1936, 'test/precision_weighted': 0.21189216427311663}","{'dt_criterion': 'gini', 'dt_max_depth': 11, 'trial.number': 90, 'dt_min_samples_leaf': 83}",lemon-darkness-240,DecisionTree,['BoW']
1090,"{'test/recall_macro': 0.33939393939393936, 'eval/accuracy': 0.48, 'eval/recall_micro': 0.48, 'eval/f1_macro': 0.28717948717948716, 'eval/precision_macro': 0.2361111111111111, '_runtime': 3.10335111618042, 'eval/loss': 1.2770549243653675, 'eval/recall_weighted': 0.48, 'test/precision_weighted': 0.3687888198757764, 'eval/precision_micro': 0.48, 'split': 10, 'eval/recall_macro': 0.3666666666666667, '_wandb': {'runtime': 1}, 'test/recall_weighted': 0.492063492063492, 'test/f1_micro': 0.492063492063492, 'test/precision_micro': 0.492063492063492, '_step': 20, 'test/f1_macro': 0.2621419676214197, 'test/accuracy': 0.492063492063492, 'test/f1_weighted': 0.41649370416493714, 'eval/precision_weighted': 0.30666666666666664, '_timestamp': 1704215128.8237112, 'eval/f1_micro': 0.48, 'test/recall_micro': 0.492063492063492, 'test/precision_macro': 0.22146739130434784, 'test/loss': 1.2288563318331762, 'eval/f1_weighted': 0.37415384615384617}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 46, 'dt_min_samples_leaf': 76}",sunny-pine-239,DecisionTree,['TfIdf']
1091,"{'eval/f1_micro': 0.44, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'test/precision_micro': 0.4603174603174603, 'eval/recall_micro': 0.44, 'test/precision_weighted': 0.21189216427311663, 'split': 10, '_runtime': 3.289525270462036, 'test/f1_weighted': 0.290200138026225, 'eval/precision_weighted': 0.1936, 'test/f1_macro': 0.15760869565217392, 'eval/recall_macro': 0.25, 'eval/precision_micro': 0.44, '_step': 20, '_wandb': {'runtime': 1}, 'eval/loss': 1.290462308510823, '_timestamp': 1704215126.0387292, 'test/precision_macro': 0.11507936507936509, 'eval/accuracy': 0.44, 'test/accuracy': 0.4603174603174603, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.44, 'test/f1_micro': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/loss': 1.2854266288838343, 'eval/f1_macro': 0.1527777777777778, 'test/recall_weighted': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 89, 'dt_min_samples_leaf': 95}",sleek-frog-238,DecisionTree,['BoW']
1092,"{'eval/recall_macro': 0.25, 'eval/recall_weighted': 0.4, 'test/precision_weighted': 0.27437641723356015, '_step': 20, 'split': 10, 'test/loss': 1.2588970748241275, '_runtime': 3.2480597496032715, 'eval/loss': 1.3126565071353458, 'test/f1_weighted': 0.36011904761904767, 'test/f1_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, 'eval/recall_micro': 0.4, 'eval/precision_weighted': 0.16, '_timestamp': 1704215120.7598708, 'eval/f1_macro': 0.14285714285714288, 'eval/f1_weighted': 0.22857142857142865, 'eval/accuracy': 0.4, 'test/accuracy': 0.5238095238095238, 'test/recall_micro': 0.5238095238095238, 'eval/precision_micro': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.17187500000000003, 'eval/precision_macro': 0.1, '_wandb': {'runtime': 1}, 'test/precision_macro': 0.13095238095238096, 'test/precision_micro': 0.5238095238095238, 'test/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 45, 'dt_min_samples_leaf': 87}",breezy-frost-237,DecisionTree,['TfIdf']
1093,"{'_step': 20, 'split': 10, '_wandb': {'runtime': 2}, 'eval/loss': 1.2885286144160266, 'eval/precision_micro': 0.44, 'eval/precision_weighted': 0.1936, 'eval/f1_macro': 0.1527777777777778, 'eval/f1_weighted': 0.26888888888888896, 'test/precision_macro': 0.11507936507936509, 'test/precision_weighted': 0.21189216427311663, 'test/loss': 1.3302066853563077, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.25, '_runtime': 3.369973659515381, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.4603174603174603, 'eval/recall_micro': 0.44, 'test/precision_micro': 0.4603174603174603, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'test/f1_weighted': 0.290200138026225, 'test/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_macro': 0.11, 'eval/recall_weighted': 0.44, '_timestamp': 1704215117.8998487}","{'dt_criterion': 'gini', 'dt_max_depth': 12, 'trial.number': 88, 'dt_min_samples_leaf': 69}",wobbly-snow-236,DecisionTree,['BoW']
1094,"{'test/f1_micro': 0.5238095238095238, 'test/f1_weighted': 0.36011904761904767, 'test/recall_macro': 0.25, 'test/precision_weighted': 0.27437641723356015, '_runtime': 2.8964364528656006, 'eval/loss': 1.3126565071353458, 'eval/f1_macro': 0.14285714285714288, 'test/recall_weighted': 0.5238095238095238, 'eval/precision_weighted': 0.16, 'split': 10, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1, 'test/loss': 1.2588970748241275, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_weighted': 0.4, 'eval/precision_micro': 0.4, '_step': 20, 'eval/accuracy': 0.4, 'eval/f1_weighted': 0.22857142857142865, 'test/precision_macro': 0.13095238095238096, '_timestamp': 1704215113.8100405, 'test/f1_macro': 0.17187500000000003, 'eval/recall_macro': 0.25, 'test/accuracy': 0.5238095238095238, 'test/recall_micro': 0.5238095238095238, 'test/precision_micro': 0.5238095238095238, '_wandb': {'runtime': 1}}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 44, 'dt_min_samples_leaf': 98}",toasty-smoke-235,DecisionTree,['TfIdf']
1095,"{'_step': 20, 'split': 10, 'test/recall_weighted': 0.4444444444444444, 'eval/loss': 1.312828991102543, 'eval/precision_weighted': 0.25269841269841264, 'test/precision_weighted': 0.2748210395269219, 'eval/f1_macro': 0.22126436781609193, 'test/f1_macro': 0.23695652173913043, 'eval/f1_weighted': 0.3094252873563218, 'test/loss': 1.3138032633831536, 'test/accuracy': 0.4444444444444444, 'eval/recall_macro': 0.28181818181818186, '_wandb': {'runtime': 1}, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.4444444444444444, 'test/precision_macro': 0.20098039215686275, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.4444444444444444, '_runtime': 2.6604695320129395, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.4444444444444444, 'eval/precision_macro': 0.18253968253968253, '_timestamp': 1704215108.9906485, 'test/f1_weighted': 0.3369220151828847, 'test/recall_macro': 0.29780564263322884, 'eval/precision_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 87, 'dt_min_samples_leaf': 63}",fresh-donkey-234,DecisionTree,['BoW']
1096,"{'test/precision_micro': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, '_runtime': 3.2987546920776367, 'eval/f1_macro': 0.30952380952380953, 'eval/f1_micro': 0.52, 'test/f1_macro': 0.26942567567567566, 'test/f1_micro': 0.5079365079365079, 'test/loss': 1.2763908365658756, 'eval/accuracy': 0.52, 'eval/recall_macro': 0.39166666666666666, 'test/precision_macro': 0.22671840354767184, 'split': 10, 'test/accuracy': 0.5079365079365079, 'eval/f1_weighted': 0.40380952380952384, 'test/f1_weighted': 0.4276061776061776, 'eval/recall_micro': 0.52, 'test/recall_macro': 0.34696969696969693, 'test/recall_micro': 0.5079365079365079, 'eval/precision_macro': 0.25735294117647056, 'eval/recall_weighted': 0.52, 'test/precision_weighted': 0.37546193643754616, '_step': 20, 'eval/precision_weighted': 0.3317647058823529, '_wandb': {'runtime': 1}, 'eval/loss': 1.2372996440079445, '_timestamp': 1704215105.9675758, 'eval/precision_micro': 0.52}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 43, 'dt_min_samples_leaf': 72}",misty-meadow-233,DecisionTree,['TfIdf']
1097,"{'_runtime': 3.2413761615753174, 'test/recall_micro': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.11, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.1936, '_timestamp': 1704215101.330243, 'test/f1_micro': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/precision_micro': 0.4603174603174603, 'split': 10, 'eval/f1_micro': 0.44, '_step': 20, 'test/f1_macro': 0.15760869565217392, '_wandb': {'runtime': 1}, 'test/loss': 1.3302066853563077, 'eval/recall_micro': 0.44, 'test/precision_macro': 0.11507936507936509, 'test/recall_weighted': 0.4603174603174603, 'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, 'eval/loss': 1.2885286144160266, 'eval/precision_micro': 0.44, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 86, 'dt_min_samples_leaf': 75}",firm-aardvark-232,DecisionTree,['BoW']
1098,"{'eval/f1_macro': 0.2632850241545893, 'eval/precision_weighted': 0.29538461538461536, 'test/precision_weighted': 0.3622413622413622, 'eval/loss': 1.2953973805099952, 'test/f1_macro': 0.24761904761904763, 'test/recall_weighted': 0.4603174603174603, '_wandb': {'runtime': 1}, 'test/precision_micro': 0.4603174603174603, 'eval/accuracy': 0.44, 'test/precision_macro': 0.21309771309771308, 'test/accuracy': 0.4603174603174603, 'eval/recall_macro': 0.3416666666666667, '_timestamp': 1704215097.6791267, 'test/recall_macro': 0.3242424242424242, '_step': 20, 'split': 10, '_runtime': 3.239853620529175, 'eval/recall_weighted': 0.44, 'test/loss': 1.2327203320020346, 'test/f1_micro': 0.4603174603174603, 'eval/precision_macro': 0.21794871794871795, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, 'eval/f1_micro': 0.44, 'eval/f1_weighted': 0.3501449275362319, 'test/f1_weighted': 0.3971277399848828}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 42, 'dt_min_samples_leaf': 86}",sunny-meadow-231,DecisionTree,['TfIdf']
1099,"{'eval/f1_weighted': 0.26888888888888896, 'eval/recall_macro': 0.25, 'split': 10, 'eval/loss': 1.290462308510823, 'test/loss': 1.2854266288838343, '_timestamp': 1704215091.0780976, 'test/accuracy': 0.4603174603174603, 'test/f1_micro': 0.4603174603174603, 'test/recall_macro': 0.25, 'eval/recall_micro': 0.44, 'eval/precision_micro': 0.44, 'test/recall_weighted': 0.4603174603174603, 'eval/accuracy': 0.44, 'test/precision_weighted': 0.21189216427311663, 'eval/precision_macro': 0.11, '_runtime': 3.2573184967041016, 'eval/f1_macro': 0.1527777777777778, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.15760869565217392, 'test/f1_weighted': 0.290200138026225, 'test/recall_micro': 0.4603174603174603, '_wandb': {'runtime': 1}, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.11507936507936509, '_step': 20, 'test/precision_micro': 0.4603174603174603, 'eval/precision_weighted': 0.1936}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 85, 'dt_min_samples_leaf': 94}",volcanic-thunder-230,DecisionTree,['BoW']
1100,"{'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.4, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.47619047619047616, '_timestamp': 1704215088.798664, 'split': 10, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.16129032258064516, 'test/f1_micro': 0.47619047619047616, 'test/recall_micro': 0.47619047619047616, '_runtime': 3.0258750915527344, 'test/loss': 1.2954751333912875, 'eval/f1_macro': 0.14285714285714288, 'eval/precision_macro': 0.1, 'test/precision_macro': 0.11904761904761904, '_step': 20, 'test/accuracy': 0.47619047619047616, 'eval/f1_weighted': 0.22857142857142865, 'test/precision_weighted': 0.22675736961451248, 'test/recall_weighted': 0.47619047619047616, 'eval/precision_weighted': 0.16, 'eval/loss': 1.294978499404738, 'test/f1_weighted': 0.30721966205837176}","{'rf_max_depth': 2, 'trial.number': 29}",mild-fog-229,RandomForest,['TfIdf']
1101,"{'_timestamp': 1704215088.7219756, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.5238095238095238, 'test/f1_weighted': 0.36011904761904767, 'eval/precision_weighted': 0.16, 'test/recall_weighted': 0.5238095238095238, '_runtime': 3.6097896099090576, 'test/f1_macro': 0.17187500000000003, 'test/recall_micro': 0.5238095238095238, 'eval/precision_macro': 0.1, 'test/precision_macro': 0.13095238095238096, 'test/loss': 1.2588970748241275, 'test/recall_macro': 0.25, '_step': 20, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.5238095238095238, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.4, 'split': 10, '_wandb': {'runtime': 2}, 'eval/loss': 1.3126565071353458, 'eval/f1_macro': 0.14285714285714288, 'test/accuracy': 0.5238095238095238, 'eval/accuracy': 0.4, 'test/precision_weighted': 0.27437641723356015}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 41, 'dt_min_samples_leaf': 93}",usual-paper-228,DecisionTree,['TfIdf']
1102,"{'eval/f1_micro': 0.44, 'test/accuracy': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, '_wandb': {'runtime': 1}, 'test/f1_micro': 0.4603174603174603, 'eval/recall_micro': 0.44, 'test/precision_macro': 0.11507936507936509, 'test/loss': 1.3302066853563077, 'eval/recall_weighted': 0.44, 'test/precision_micro': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, '_timestamp': 1704215082.6170382, '_runtime': 3.0294623374938965, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'split': 10, 'eval/f1_macro': 0.1527777777777778, 'test/recall_macro': 0.25, 'eval/precision_micro': 0.44, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_weighted': 0.1936, '_step': 20, 'test/f1_weighted': 0.290200138026225, 'eval/loss': 1.2885286144160266, 'test/f1_macro': 0.15760869565217392, 'eval/accuracy': 0.44}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 84, 'dt_min_samples_leaf': 83}",smart-vortex-227,DecisionTree,['BoW']
1103,"{'_runtime': 3.391385793685913, 'eval/accuracy': 0.48, 'test/f1_macro': 0.2499166468206716, 'eval/f1_weighted': 0.39625806451612905, '_step': 20, 'test/loss': 1.2621223244828568, '_timestamp': 1704215082.647529, 'eval/f1_macro': 0.3701612903225806, 'test/precision_weighted': 0.43879268879268873, '_wandb': {'runtime': 2}, 'test/accuracy': 0.47619047619047616, 'eval/precision_macro': 0.5238095238095238, 'test/precision_macro': 0.3518939393939394, 'eval/precision_weighted': 0.46476190476190465, 'test/f1_weighted': 0.3779660312168052, 'eval/recall_micro': 0.48, 'split': 10, 'test/recall_weighted': 0.47619047619047616, 'test/f1_micro': 0.47619047619047616, 'eval/recall_macro': 0.3875, 'eval/precision_micro': 0.48, 'eval/recall_weighted': 0.48, 'test/precision_micro': 0.47619047619047616, 'eval/loss': 1.2494740750213034, 'eval/f1_micro': 0.48, 'test/recall_macro': 0.28402777777777777, 'test/recall_micro': 0.47619047619047616}","{'rf_max_depth': 10, 'trial.number': 28}",fluent-plant-226,RandomForest,['TfIdf']
1104,"{'eval/recall_micro': 0.36, '_wandb': {'runtime': 1}, 'test/recall_micro': 0.3968253968253968, 'test/precision_macro': 0.2702777777777778, 'eval/recall_weighted': 0.36, 'test/precision_micro': 0.3968253968253968, 'eval/loss': 1.320691757922265, 'test/loss': 1.2422969218318398, 'eval/f1_macro': 0.2955316742081448, 'test/f1_micro': 0.3968253968253968, 'eval/f1_weighted': 0.34900452488687783, 'test/f1_macro': 0.2729885057471264, 'test/precision_weighted': 0.4362257495590828, '_step': 20, 'split': 10, '_runtime': 2.6853365898132324, 'test/accuracy': 0.3968253968253968, 'test/f1_weighted': 0.4021164021164021, 'test/recall_macro': 0.3068181818181818, 'eval/precision_micro': 0.36, 'eval/accuracy': 0.36, 'eval/recall_macro': 0.325, 'eval/precision_macro': 0.29545454545454547, '_timestamp': 1704215079.464949, 'eval/f1_micro': 0.36, 'test/recall_weighted': 0.3968253968253968, 'eval/precision_weighted': 0.3677922077922078}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 40, 'dt_min_samples_leaf': 66}",scarlet-galaxy-225,DecisionTree,['TfIdf']
1105,"{'_step': 20, 'eval/f1_micro': 0.44, 'split': 10, 'test/accuracy': 0.4603174603174603, 'eval/precision_weighted': 0.1936, '_wandb': {'runtime': 1}, 'test/precision_macro': 0.11507936507936509, 'test/precision_micro': 0.4603174603174603, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.4603174603174603, '_runtime': 2.967728853225708, 'test/loss': 1.3302066853563077, 'eval/accuracy': 0.44, 'eval/precision_macro': 0.11, 'eval/precision_micro': 0.44, 'eval/recall_macro': 0.25, 'eval/loss': 1.2885286144160266, '_timestamp': 1704215076.1083608, 'test/f1_micro': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, 'eval/f1_macro': 0.1527777777777778, 'test/f1_macro': 0.15760869565217392, 'eval/f1_weighted': 0.26888888888888896}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 83, 'dt_min_samples_leaf': 88}",colorful-firebrand-224,DecisionTree,['BoW']
1106,"{'eval/f1_macro': 0.2077922077922078, 'eval/recall_macro': 0.275, 'split': 10, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.22282608695652173, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.25652173913043474, 'test/precision_macro': 0.29166666666666663, 'test/recall_weighted': 0.5079365079365079, 'eval/loss': 1.3223111841375297, 'test/loss': 1.2731273396630376, '_timestamp': 1704215076.134663, 'test/f1_macro': 0.21929824561403508, 'test/f1_weighted': 0.3709273182957394, 'test/recall_macro': 0.28125, 'test/precision_weighted': 0.4074074074074074, '_step': 20, 'eval/accuracy': 0.4, 'test/f1_micro': 0.5079365079365079, 'test/recall_micro': 0.5079365079365079, '_wandb': {'runtime': 2}, '_runtime': 3.423262357711792, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.5079365079365079, 'test/precision_micro': 0.5079365079365079, 'eval/f1_weighted': 0.2753246753246753, 'eval/precision_micro': 0.4}","{'rf_max_depth': 9, 'trial.number': 27}",spring-forest-223,RandomForest,['TfIdf']
1107,"{'eval/recall_macro': 0.35, 'test/precision_weighted': 0.35837742504409176, 'split': 10, 'eval/precision_micro': 0.48, 'test/accuracy': 0.5079365079365079, 'test/precision_micro': 0.5079365079365079, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.48, 'eval/f1_macro': 0.2760989010989011, 'test/f1_macro': 0.2623626373626374, 'eval/precision_macro': 0.23214285714285715, 'eval/loss': 1.3088549567407273, 'test/loss': 1.2689644340816222, '_timestamp': 1704215071.834393, 'eval/f1_weighted': 0.3679120879120879, 'test/precision_macro': 0.21944444444444444, 'test/recall_weighted': 0.5079365079365079, '_step': 20, 'eval/f1_micro': 0.48, 'eval/recall_micro': 0.48, 'test/recall_micro': 0.5079365079365079, '_runtime': 3.2616219520568848, 'test/f1_micro': 0.5079365079365079, 'test/f1_weighted': 0.4193267050409908, 'test/recall_macro': 0.3295454545454546, 'eval/recall_weighted': 0.48, 'eval/precision_weighted': 0.3028571428571428}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 39, 'dt_min_samples_leaf': 54}",still-music-222,DecisionTree,['TfIdf']
1108,"{'test/precision_macro': 0.11507936507936509, 'eval/precision_weighted': 0.1936, 'eval/recall_micro': 0.44, 'eval/precision_macro': 0.11, 'test/recall_micro': 0.4603174603174603, 'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'eval/recall_macro': 0.25, 'eval/recall_weighted': 0.44, 'test/loss': 1.3302066853563077, 'test/f1_micro': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'test/recall_macro': 0.25, '_runtime': 2.958285331726074, 'split': 10, '_wandb': {'runtime': 1}, 'test/precision_micro': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, '_step': 20, 'eval/precision_micro': 0.44, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_weighted': 0.4603174603174603, 'eval/loss': 1.2885286144160266, '_timestamp': 1704215067.8396134}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 82, 'dt_min_samples_leaf': 77}",effortless-sky-221,DecisionTree,['BoW']
1109,"{'test/recall_weighted': 0.47619047619047616, 'test/precision_weighted': 0.3919701213818861, 'test/f1_macro': 0.2747795414462081, 'eval/precision_micro': 0.4, 'test/loss': 1.2717476592659334, 'test/precision_micro': 0.47619047619047616, 'test/f1_weighted': 0.39217267153775087, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.30347222222222225, '_runtime': 3.386827230453491, 'eval/accuracy': 0.4, 'test/accuracy': 0.47619047619047616, 'eval/f1_weighted': 0.327594470046083, '_step': 20, '_wandb': {'runtime': 2}, 'eval/loss': 1.2075402707165026, 'test/f1_micro': 0.47619047619047616, 'test/recall_micro': 0.47619047619047616, 'eval/precision_weighted': 0.4123809523809524, 'split': 10, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_macro': 0.4702380952380952, 'eval/f1_macro': 0.30046082949308756, 'eval/recall_macro': 0.3125, 'test/precision_macro': 0.3107843137254902, '_timestamp': 1704215067.9039905, 'eval/recall_weighted': 0.4}","{'rf_max_depth': 14, 'trial.number': 26}",still-pyramid-220,RandomForest,['TfIdf']
1110,"{'eval/f1_macro': 0.29285714285714287, 'test/recall_macro': 0.27474747474747474, 'test/recall_weighted': 0.42857142857142855, 'split': 10, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.42857142857142855, 'eval/accuracy': 0.4, 'eval/f1_weighted': 0.3405714285714285, 'test/precision_weighted': 0.3999559082892416, 'test/accuracy': 0.42857142857142855, 'eval/precision_macro': 0.4236111111111111, 'test/precision_micro': 0.42857142857142855, 'eval/loss': 6.7991326476973875, 'eval/recall_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.3053661616161616, 'eval/precision_weighted': 0.3977777777777778, '_step': 20, 'test/loss': 3.971025971885774, '_timestamp': 1704215064.9121644, 'eval/precision_micro': 0.4, 'test/f1_weighted': 0.4031711699339673, '_runtime': 3.934908390045166, 'test/f1_macro': 0.2745597649166503, 'eval/recall_macro': 0.3041666666666667, 'test/recall_micro': 0.42857142857142855}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 38, 'dt_min_samples_leaf': 11}",crisp-cosmos-219,DecisionTree,['TfIdf']
1111,"{'eval/f1_micro': 0.44, 'test/recall_micro': 0.4603174603174603, 'eval/precision_weighted': 0.1936, 'test/precision_weighted': 0.21189216427311663, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.1527777777777778, 'eval/recall_micro': 0.44, '_step': 20, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.4603174603174603, '_timestamp': 1704215057.8682969, 'test/f1_micro': 0.4603174603174603, 'test/accuracy': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'eval/recall_macro': 0.25, 'eval/precision_micro': 0.44, 'test/precision_micro': 0.4603174603174603, 'test/loss': 1.2854266288838343, 'test/f1_macro': 0.15760869565217392, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.11, 'test/precision_macro': 0.11507936507936509, '_runtime': 3.0548558235168457, 'split': 10, 'eval/loss': 1.290462308510823, 'eval/f1_weighted': 0.26888888888888896, '_wandb': {'runtime': 1}}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 81, 'dt_min_samples_leaf': 94}",royal-wildflower-218,DecisionTree,['BoW']
1112,"{'eval/f1_macro': 0.14705882352941177, 'eval/f1_weighted': 0.23529411764705885, 'test/precision_micro': 0.47619047619047616, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.10416666666666669, '_timestamp': 1704215057.816558, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.47619047619047616, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.2304147465437788, '_step': 20, '_wandb': {'runtime': 1}, '_runtime': 3.2269701957702637, 'test/f1_macro': 0.16304347826086957, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.12096774193548387, 'split': 10, 'test/f1_weighted': 0.3105590062111801, 'test/loss': 1.2627736480479246, 'eval/accuracy': 0.4, 'test/accuracy': 0.47619047619047616, 'test/recall_macro': 0.25, 'test/recall_weighted': 0.47619047619047616, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.47619047619047616, 'eval/precision_weighted': 0.16666666666666669, 'eval/loss': 1.2795805868000107}","{'rf_max_depth': 3, 'trial.number': 25}",different-haze-217,RandomForest,['TfIdf']
1113,"{'_wandb': {'runtime': 1}, 'eval/f1_micro': 0.36, 'test/precision_micro': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, '_step': 20, '_timestamp': 1704215056.0348802, 'eval/f1_macro': 0.2955316742081448, 'test/f1_macro': 0.2729885057471264, 'test/f1_weighted': 0.4021164021164021, 'eval/precision_micro': 0.36, 'eval/recall_macro': 0.325, 'test/precision_macro': 0.2702777777777778, 'test/precision_weighted': 0.4362257495590828, 'eval/accuracy': 0.36, 'eval/precision_weighted': 0.3677922077922078, 'test/accuracy': 0.3968253968253968, 'eval/f1_weighted': 0.34900452488687783, '_runtime': 3.279670238494873, 'eval/loss': 1.320691757922265, 'test/loss': 1.2422969218318398, 'eval/recall_micro': 0.36, 'eval/recall_weighted': 0.36, 'split': 10, 'test/f1_micro': 0.3968253968253968, 'test/recall_macro': 0.3068181818181818, 'test/recall_micro': 0.3968253968253968, 'eval/precision_macro': 0.29545454545454547}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 37, 'dt_min_samples_leaf': 66}",fanciful-firebrand-216,DecisionTree,['TfIdf']
1114,"{'_runtime': 3.475323438644409, 'test/loss': 1.250523284650063, 'eval/f1_micro': 0.48, 'test/f1_macro': 0.1942469295410472, 'test/recall_macro': 0.265625, 'eval/precision_micro': 0.48, '_wandb': {'runtime': 2}, 'test/accuracy': 0.492063492063492, 'eval/f1_weighted': 0.35670995670995675, 'eval/precision_macro': 0.358695652173913, '_timestamp': 1704215051.5657043, 'eval/recall_macro': 0.35, 'eval/recall_micro': 0.48, 'test/precision_micro': 0.492063492063492, 'test/f1_weighted': 0.34385036065708335, 'split': 10, 'eval/accuracy': 0.48, 'test/recall_weighted': 0.492063492063492, 'test/precision_weighted': 0.48816029143898, 'eval/f1_macro': 0.2943722943722944, 'test/f1_micro': 0.492063492063492, 'eval/precision_weighted': 0.3739130434782609, '_step': 20, 'eval/loss': 1.3531515143318944, 'test/recall_micro': 0.492063492063492, 'eval/recall_weighted': 0.48, 'test/precision_macro': 0.3729508196721312}","{'rf_max_depth': 5, 'trial.number': 24}",generous-lion-215,RandomForest,['TfIdf']
1115,"{'test/loss': 1.3138032633831536, 'eval/f1_macro': 0.22126436781609193, 'test/accuracy': 0.4444444444444444, 'test/recall_macro': 0.29780564263322884, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.20098039215686275, 'test/precision_weighted': 0.2748210395269219, 'split': 10, 'eval/loss': 1.312828991102543, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.3369220151828847, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.4444444444444444, 'test/precision_micro': 0.4444444444444444, '_step': 20, '_wandb': {'runtime': 1}, '_timestamp': 1704215049.2766173, 'test/f1_micro': 0.4444444444444444, 'eval/f1_weighted': 0.3094252873563218, '_runtime': 2.7191812992095947, 'eval/precision_macro': 0.18253968253968253, 'eval/recall_weighted': 0.4, 'test/f1_macro': 0.23695652173913043, 'eval/recall_macro': 0.28181818181818186, 'test/recall_weighted': 0.4444444444444444, 'eval/precision_weighted': 0.25269841269841264}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 80, 'dt_min_samples_leaf': 56}",rich-salad-214,DecisionTree,['BoW']
1116,"{'split': 10, '_timestamp': 1704215047.8193269, 'test/f1_weighted': 0.4052287581699347, 'eval/recall_macro': 0.3416666666666667, 'test/recall_macro': 0.3318181818181818, 'eval/recall_weighted': 0.44, 'test/precision_weighted': 0.3620268620268621, 'eval/loss': 1.2968738573520882, 'eval/f1_micro': 0.44, 'eval/recall_micro': 0.44, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.21634615384615383, '_step': 20, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.2632850241545893, 'eval/f1_weighted': 0.3501449275362319, 'test/f1_macro': 0.25490196078431376, 'test/recall_micro': 0.47619047619047616, 'eval/precision_macro': 0.21794871794871795, 'test/precision_micro': 0.47619047619047616, 'test/f1_micro': 0.47619047619047616, 'test/recall_weighted': 0.47619047619047616, '_wandb': {'runtime': 1}, '_runtime': 3.259704828262329, 'test/loss': 1.226718025174548, 'test/accuracy': 0.47619047619047616, 'eval/precision_weighted': 0.29538461538461536}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 36, 'dt_min_samples_leaf': 81}",vague-bee-213,DecisionTree,['TfIdf']
1117,"{'_step': 20, 'split': 10, 'eval/precision_micro': 0.48, 'test/precision_macro': 0.3993055555555556, 'test/loss': 1.2889214293338926, '_timestamp': 1704215044.3713994, 'test/accuracy': 0.47619047619047616, 'eval/f1_weighted': 0.4038095238095238, 'test/recall_micro': 0.47619047619047616, '_runtime': 2.8079984188079834, 'eval/f1_macro': 0.3325396825396825, 'test/f1_macro': 0.3075335397316822, 'test/recall_weighted': 0.47619047619047616, 'test/recall_macro': 0.3229166666666667, 'eval/precision_weighted': 0.44, 'eval/accuracy': 0.48, 'eval/f1_micro': 0.48, 'test/f1_micro': 0.47619047619047616, 'test/f1_weighted': 0.42134748636296626, 'eval/recall_weighted': 0.48, '_wandb': {'runtime': 1}, 'eval/loss': 1.27810601977046, 'eval/recall_macro': 0.35833333333333334, 'test/precision_micro': 0.47619047619047616, 'eval/recall_micro': 0.48, 'eval/precision_macro': 0.4041666666666667, 'test/precision_weighted': 0.4874338624338625}","{'rf_max_depth': 8, 'trial.number': 23}",usual-night-212,RandomForest,['TfIdf']
1118,"{'_runtime': 2.877133846282959, 'eval/accuracy': 0.44, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.11, 'test/recall_weighted': 0.4603174603174603, 'eval/recall_macro': 0.25, 'split': 10, 'test/loss': 1.3302066853563077, 'test/recall_micro': 0.4603174603174603, 'eval/precision_weighted': 0.1936, 'eval/f1_macro': 0.1527777777777778, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'test/precision_micro': 0.4603174603174603, 'eval/loss': 1.2885286144160266, 'test/accuracy': 0.4603174603174603, 'eval/recall_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.11507936507936509, '_step': 20, '_wandb': {'runtime': 1}, '_timestamp': 1704215041.2365775, 'test/f1_macro': 0.15760869565217392, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.21189216427311663}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 79, 'dt_min_samples_leaf': 83}",daily-energy-211,DecisionTree,['BoW']
1119,"{'_runtime': 3.2464075088500977, 'test/f1_macro': 0.2623626373626374, 'eval/recall_weighted': 0.48, 'test/recall_macro': 0.3295454545454546, 'test/precision_micro': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.48, 'eval/recall_macro': 0.35, 'eval/precision_micro': 0.48, 'eval/f1_macro': 0.2760989010989011, 'eval/f1_weighted': 0.3679120879120879, 'eval/precision_weighted': 0.3028571428571428, 'eval/f1_micro': 0.48, 'test/precision_macro': 0.21944444444444444, 'test/precision_weighted': 0.35837742504409176, 'eval/loss': 1.3088549567407273, 'test/recall_micro': 0.5079365079365079, 'test/loss': 1.2689644340816222, '_timestamp': 1704215041.3067665, 'test/f1_micro': 0.5079365079365079, 'test/f1_weighted': 0.4193267050409908, 'eval/recall_micro': 0.48, '_step': 20, 'split': 10, 'test/accuracy': 0.5079365079365079, 'eval/precision_macro': 0.23214285714285715}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 35, 'dt_min_samples_leaf': 51}",pleasant-paper-210,DecisionTree,['TfIdf']
1120,"{'split': 10, '_wandb': {'runtime': 2}, '_runtime': 3.4611895084381104, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_macro': 0.1, '_step': 20, 'test/accuracy': 0.492063492063492, 'test/f1_macro': 0.19245524296675193, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.34043762432509234, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, 'eval/precision_weighted': 0.16, 'eval/loss': 1.3179830427880437, 'test/f1_micro': 0.492063492063492, 'eval/recall_macro': 0.25, 'test/precision_micro': 0.492063492063492, 'test/loss': 1.2758068601932917, '_timestamp': 1704215036.8472464, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.14285714285714288, 'test/recall_micro': 0.492063492063492, 'test/recall_weighted': 0.492063492063492, 'test/precision_weighted': 0.4843830005120328, 'test/recall_macro': 0.265625, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.3709677419354839}","{'rf_max_depth': 5, 'trial.number': 22}",zany-aardvark-209,RandomForest,['TfIdf']
1121,"{'split': 10, '_timestamp': 1704215034.3292103, 'test/accuracy': 0.47619047619047616, 'test/f1_micro': 0.47619047619047616, 'test/precision_macro': 0.21634615384615383, 'test/precision_micro': 0.47619047619047616, 'eval/recall_macro': 0.3416666666666667, '_wandb': {'runtime': 1}, 'eval/recall_micro': 0.44, 'eval/precision_macro': 0.21794871794871795, 'eval/precision_micro': 0.44, 'eval/loss': 1.2968738573520882, 'test/recall_macro': 0.3318181818181818, 'test/recall_micro': 0.47619047619047616, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.29538461538461536, 'eval/f1_macro': 0.2632850241545893, 'eval/f1_micro': 0.44, '_step': 20, '_runtime': 2.808558464050293, 'test/f1_macro': 0.25490196078431376, 'eval/f1_weighted': 0.3501449275362319, 'test/f1_weighted': 0.4052287581699347, 'test/loss': 1.226718025174548, 'eval/accuracy': 0.44, 'test/recall_weighted': 0.47619047619047616, 'test/precision_weighted': 0.3620268620268621}","{'dt_criterion': 'entropy', 'dt_max_depth': 16, 'trial.number': 34, 'dt_min_samples_leaf': 83}",misunderstood-snowflake-208,DecisionTree,['TfIdf']
1122,"{'test/f1_weighted': 0.3369220151828847, 'eval/f1_weighted': 0.3094252873563218, '_timestamp': 1704215033.4095955, 'test/recall_micro': 0.4444444444444444, 'test/precision_macro': 0.20098039215686275, 'eval/precision_weighted': 0.25269841269841264, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.4, 'test/accuracy': 0.4444444444444444, 'eval/loss': 1.312828991102543, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.29780564263322884, 'test/precision_micro': 0.4444444444444444, 'eval/f1_macro': 0.22126436781609193, 'test/loss': 1.3138032633831536, 'eval/precision_macro': 0.18253968253968253, '_step': 20, '_runtime': 3.5015976428985596, 'test/f1_macro': 0.23695652173913043, 'eval/recall_macro': 0.28181818181818186, 'eval/precision_micro': 0.4, 'split': 10, 'eval/recall_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.4444444444444444, 'test/precision_weighted': 0.2748210395269219, 'test/f1_micro': 0.4444444444444444}","{'dt_criterion': 'gini', 'dt_max_depth': 12, 'trial.number': 78, 'dt_min_samples_leaf': 66}",quiet-water-207,DecisionTree,['BoW']
1123,"{'eval/f1_weighted': 0.37309090909090914, 'test/f1_weighted': 0.34043762432509234, 'test/loss': 1.2799266216256089, 'test/accuracy': 0.492063492063492, 'test/recall_weighted': 0.492063492063492, 'test/precision_micro': 0.492063492063492, 'test/precision_weighted': 0.4843830005120328, '_wandb': {'runtime': 1}, 'test/f1_micro': 0.492063492063492, 'eval/recall_micro': 0.48, 'test/recall_micro': 0.492063492063492, 'eval/precision_macro': 0.6086956521739131, 'test/precision_macro': 0.3709677419354839, '_runtime': 3.360792398452759, 'eval/accuracy': 0.48, 'eval/f1_micro': 0.48, 'test/f1_macro': 0.19245524296675193, 'eval/precision_micro': 0.48, '_step': 20, 'eval/recall_weighted': 0.48, 'eval/precision_weighted': 0.5339130434782609, 'eval/loss': 1.2657543926310262, 'eval/recall_macro': 0.3625, 'split': 10, '_timestamp': 1704215028.5330544, 'eval/f1_macro': 0.33484848484848484, 'test/recall_macro': 0.265625}","{'rf_max_depth': 6, 'trial.number': 21}",iconic-wave-206,RandomForest,['TfIdf']
1124,"{'test/recall_weighted': 0.5079365079365079, 'eval/loss': 1.3088549567407273, 'test/loss': 1.2689644340816222, 'eval/precision_micro': 0.48, 'test/precision_micro': 0.5079365079365079, 'split': 10, '_timestamp': 1704215026.8305497, 'test/f1_weighted': 0.4193267050409908, '_wandb': {'runtime': 2}, 'eval/precision_weighted': 0.3028571428571428, 'test/f1_micro': 0.5079365079365079, 'test/precision_weighted': 0.35837742504409176, 'test/precision_macro': 0.21944444444444444, 'eval/f1_micro': 0.48, 'test/accuracy': 0.5079365079365079, 'eval/recall_micro': 0.48, 'test/recall_micro': 0.5079365079365079, 'eval/precision_macro': 0.23214285714285715, 'test/f1_macro': 0.2623626373626374, 'eval/f1_weighted': 0.3679120879120879, 'eval/recall_macro': 0.35, 'eval/recall_weighted': 0.48, '_runtime': 3.496731758117676, 'eval/f1_macro': 0.2760989010989011, 'test/recall_macro': 0.3295454545454546, '_step': 20, 'eval/accuracy': 0.48}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 33, 'dt_min_samples_leaf': 63}",playful-sound-205,DecisionTree,['TfIdf']
1125,"{'eval/precision_macro': 0.11, '_step': 20, '_timestamp': 1704215024.3627946, 'test/f1_macro': 0.15760869565217392, 'test/f1_micro': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'split': 10, '_wandb': {'runtime': 1}, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_weighted': 0.4603174603174603, '_runtime': 2.6398186683654785, 'eval/recall_micro': 0.44, 'test/precision_micro': 0.4603174603174603, 'eval/loss': 1.2885286144160266, 'test/precision_weighted': 0.21189216427311663, 'test/accuracy': 0.4603174603174603, 'eval/precision_micro': 0.44, 'eval/precision_weighted': 0.1936, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.1527777777777778, 'eval/recall_weighted': 0.44, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'test/precision_macro': 0.11507936507936509, 'test/loss': 1.3302066853563077, 'eval/f1_micro': 0.44, 'test/recall_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 77, 'dt_min_samples_leaf': 72}",comic-galaxy-204,DecisionTree,['BoW']
1126,"{'test/f1_macro': 0.18508114856429464, 'test/f1_micro': 0.4603174603174603, 'split': 10, 'eval/recall_macro': 0.3625, 'test/recall_macro': 0.24895833333333336, 'eval/precision_micro': 0.48, 'eval/recall_weighted': 0.48, 'test/precision_macro': 0.2436440677966102, 'test/precision_weighted': 0.35297282754909876, 'test/recall_weighted': 0.4603174603174603, '_runtime': 2.8324384689331055, 'eval/f1_weighted': 0.38066666666666665, '_timestamp': 1704215019.7634566, '_wandb': {'runtime': 1}, 'test/recall_micro': 0.4603174603174603, 'eval/loss': 1.2335729750452875, 'test/f1_weighted': 0.32784416305015557, 'eval/recall_micro': 0.48, 'eval/precision_macro': 0.6136363636363636, 'test/precision_micro': 0.4603174603174603, '_step': 20, 'test/loss': 1.338069036575784, 'eval/accuracy': 0.48, 'eval/f1_macro': 0.33958333333333335, 'eval/f1_micro': 0.48, 'test/accuracy': 0.4603174603174603, 'eval/precision_weighted': 0.5418181818181818}","{'rf_max_depth': 9, 'trial.number': 20}",clean-flower-203,RandomForest,['TfIdf']
1127,"{'_runtime': 3.264582633972168, 'eval/loss': 1.3126565071353458, 'eval/precision_micro': 0.4, 'eval/precision_weighted': 0.16, '_wandb': {'runtime': 1}, 'test/loss': 1.2588970748241275, '_timestamp': 1704215018.417425, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.25, 'test/recall_weighted': 0.5238095238095238, '_step': 20, 'eval/f1_micro': 0.4000000000000001, 'test/f1_weighted': 0.36011904761904767, 'test/recall_micro': 0.5238095238095238, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.14285714285714288, 'test/precision_macro': 0.13095238095238096, 'test/precision_weighted': 0.27437641723356015, 'split': 10, 'eval/f1_weighted': 0.22857142857142865, 'test/precision_micro': 0.5238095238095238, 'test/accuracy': 0.5238095238095238, 'test/f1_micro': 0.5238095238095238, 'eval/recall_weighted': 0.4, 'test/f1_macro': 0.17187500000000003, 'eval/precision_macro': 0.1, 'eval/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 32, 'dt_min_samples_leaf': 99}",astral-firebrand-202,DecisionTree,['TfIdf']
1128,"{'eval/recall_micro': 0.44, '_step': 20, 'test/accuracy': 0.4603174603174603, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.4603174603174603, '_runtime': 3.351469039916992, 'test/precision_macro': 0.11507936507936509, '_timestamp': 1704215016.8084311, 'eval/precision_micro': 0.44, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'eval/recall_weighted': 0.44, 'split': 10, 'eval/loss': 1.2885286144160266, 'test/f1_weighted': 0.290200138026225, 'eval/precision_weighted': 0.1936, 'eval/precision_macro': 0.11, 'test/precision_micro': 0.4603174603174603, 'test/loss': 1.3302066853563077, 'test/recall_macro': 0.25, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_weighted': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, 'eval/f1_macro': 0.1527777777777778, 'test/f1_macro': 0.15760869565217392}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 76, 'dt_min_samples_leaf': 87}",zesty-breeze-201,DecisionTree,['BoW']
1129,"{'eval/f1_weighted': 0.2995670995670996, 'test/recall_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'test/loss': 1.3397607067141388, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.240625, '_runtime': 3.4186103343963623, 'eval/loss': 1.3957256208998112, 'eval/f1_macro': 0.22294372294372297, 'test/f1_micro': 0.4444444444444444, 'eval/recall_macro': 0.3, '_wandb': {'runtime': 2}, 'test/f1_macro': 0.18329253365973072, '_step': 20, 'eval/precision_micro': 0.44, 'test/precision_micro': 0.4444444444444444, 'split': 10, 'test/accuracy': 0.4444444444444444, 'eval/precision_macro': 0.23369565217391303, 'test/precision_macro': 0.2038690476190476, 'eval/precision_weighted': 0.27391304347826084, '_timestamp': 1704215013.1242764, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/f1_weighted': 0.32573682267684717, 'eval/recall_weighted': 0.44, 'test/precision_weighted': 0.3142479213907785}","{'rf_max_depth': 18, 'trial.number': 19}",fine-thunder-200,RandomForest,['TfIdf']
1130,"{'eval/recall_macro': 0.25, 'eval/precision_macro': 0.1, 'test/precision_micro': 0.5238095238095238, 'test/loss': 1.2588970748241275, 'eval/accuracy': 0.4, '_timestamp': 1704215009.657326, 'eval/precision_weighted': 0.16, 'test/precision_weighted': 0.27437641723356015, '_runtime': 2.71527099609375, 'test/recall_weighted': 0.5238095238095238, 'eval/f1_macro': 0.14285714285714288, 'test/f1_macro': 0.17187500000000003, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.36011904761904767, '_wandb': {'runtime': 1}, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.13095238095238096, '_step': 20, 'eval/loss': 1.3126565071353458, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.4, 'split': 10, 'test/accuracy': 0.5238095238095238, 'test/f1_micro': 0.5238095238095238, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.5238095238095238}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 31, 'dt_min_samples_leaf': 97}",valiant-tree-199,DecisionTree,['TfIdf']
1131,"{'_timestamp': 1704215008.429113, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'test/recall_macro': 0.25, '_runtime': 3.250746965408325, 'eval/loss': 1.290462308510823, 'eval/accuracy': 0.44, 'test/f1_macro': 0.15760869565217392, 'test/f1_micro': 0.4603174603174603, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.44, 'test/precision_macro': 0.11507936507936509, 'test/precision_weighted': 0.21189216427311663, 'eval/precision_weighted': 0.1936, 'eval/f1_macro': 0.1527777777777778, 'eval/f1_weighted': 0.26888888888888896, '_wandb': {'runtime': 1}, 'test/loss': 1.2854266288838343, 'eval/precision_micro': 0.44, '_step': 20, 'split': 10, 'eval/f1_micro': 0.44, 'eval/precision_macro': 0.11, 'test/recall_micro': 0.4603174603174603, 'test/accuracy': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'eval/recall_weighted': 0.44}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 75, 'dt_min_samples_leaf': 100}",fiery-butterfly-198,DecisionTree,['BoW']
1132,"{'test/f1_weighted': 0.30020703933747417, 'eval/recall_macro': 0.2, 'test/recall_macro': 0.24166666666666667, 'test/precision_micro': 0.4603174603174603, 'eval/f1_micro': 0.32, '_wandb': {'runtime': 1}, 'eval/recall_micro': 0.32, 'split': 10, 'test/f1_macro': 0.15760869565217392, 'test/precision_macro': 0.11693548387096774, 'test/loss': 1.3036202112745916, 'eval/f1_weighted': 0.1939393939393939, 'eval/recall_weighted': 0.32, '_timestamp': 1704215004.26962, 'eval/loss': 1.3534411563968962, 'eval/f1_macro': 0.12121212121212122, 'test/accuracy': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, '_step': 20, 'eval/precision_micro': 0.32, 'eval/precision_weighted': 0.1391304347826087, 'test/precision_weighted': 0.2227342549923195, '_runtime': 3.3382458686828613, 'test/recall_micro': 0.4603174603174603, 'test/f1_micro': 0.4603174603174603, 'eval/precision_macro': 0.08695652173913043, 'eval/accuracy': 0.32}","{'rf_max_depth': 4, 'trial.number': 18}",polar-terrain-197,RandomForest,['TfIdf']
1133,"{'eval/recall_weighted': 0.44, 'test/precision_macro': 0.21634615384615383, 'split': 10, 'eval/f1_micro': 0.44, 'eval/recall_macro': 0.3416666666666667, '_wandb': {'runtime': 1}, 'eval/f1_weighted': 0.3501449275362319, '_step': 20, 'eval/recall_micro': 0.44, 'test/precision_weighted': 0.3620268620268621, 'test/recall_weighted': 0.47619047619047616, '_runtime': 3.2687408924102783, 'eval/accuracy': 0.44, 'eval/precision_macro': 0.21794871794871795, 'test/precision_micro': 0.47619047619047616, 'test/f1_macro': 0.25490196078431376, 'test/f1_micro': 0.47619047619047616, 'test/f1_weighted': 0.4052287581699347, 'eval/f1_macro': 0.2632850241545893, 'test/accuracy': 0.47619047619047616, 'test/recall_micro': 0.47619047619047616, 'eval/loss': 1.2968738573520882, '_timestamp': 1704215001.983974, 'test/recall_macro': 0.3318181818181818, 'test/loss': 1.226718025174548, 'eval/precision_micro': 0.44, 'eval/precision_weighted': 0.29538461538461536}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 30, 'dt_min_samples_leaf': 82}",expert-salad-196,DecisionTree,['TfIdf']
1134,"{'eval/loss': 1.2885286144160266, 'test/f1_micro': 0.4603174603174603, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.11, 'split': 10, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.1527777777777778, 'test/f1_weighted': 0.290200138026225, 'test/recall_micro': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, '_runtime': 2.891385555267334, 'eval/recall_macro': 0.25, '_wandb': {'runtime': 1}, 'test/loss': 1.3302066853563077, 'eval/f1_micro': 0.44, 'test/accuracy': 0.4603174603174603, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.1936, '_step': 20, 'eval/f1_weighted': 0.26888888888888896, 'test/precision_macro': 0.11507936507936509, 'test/recall_weighted': 0.4603174603174603, 'eval/recall_micro': 0.44, 'test/precision_weighted': 0.21189216427311663, '_timestamp': 1704214999.6254306, 'test/f1_macro': 0.15760869565217392}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 74, 'dt_min_samples_leaf': 80}",ethereal-snow-195,DecisionTree,['BoW']
1135,"{'eval/loss': 1.3337521506624292, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.28125, 'test/precision_weighted': 0.492063492063492, '_runtime': 3.400611400604248, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.375, 'eval/precision_weighted': 0.3739130434782609, 'eval/f1_macro': 0.2348484848484849, 'test/f1_macro': 0.2222222222222222, '_step': 20, 'eval/accuracy': 0.44, 'eval/recall_weighted': 0.44, 'test/accuracy': 0.5079365079365079, 'test/f1_micro': 0.5079365079365079, 'eval/f1_weighted': 0.3090909090909091, 'test/f1_weighted': 0.3738977072310406, '_wandb': {'runtime': 2}, 'eval/f1_micro': 0.44, 'split': 10, 'test/loss': 1.273742712127054, 'test/precision_micro': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, '_timestamp': 1704214996.1492715, 'eval/recall_macro': 0.3, 'test/recall_micro': 0.5079365079365079, 'eval/precision_macro': 0.358695652173913}","{'rf_max_depth': 7, 'trial.number': 17}",golden-spaceship-194,RandomForest,['TfIdf']
1136,"{'split': 10, 'test/accuracy': 0.3968253968253968, 'test/recall_weighted': 0.3968253968253968, '_wandb': {'runtime': 1}, 'eval/precision_macro': 0.29545454545454547, 'eval/recall_weighted': 0.36, 'test/recall_macro': 0.3068181818181818, 'test/recall_micro': 0.3968253968253968, 'test/precision_macro': 0.26498868778280543, '_step': 20, '_timestamp': 1704214993.7603977, 'test/f1_macro': 0.271589991928975, '_runtime': 3.2907066345214844, 'eval/f1_macro': 0.2955316742081448, 'eval/f1_micro': 0.36, 'eval/precision_weighted': 0.3677922077922078, 'eval/loss': 1.3290940385828676, 'eval/f1_weighted': 0.34900452488687783, 'eval/precision_micro': 0.36, 'test/f1_micro': 0.3968253968253968, 'test/f1_weighted': 0.3974659543666807, 'test/precision_micro': 0.3968253968253968, 'eval/recall_micro': 0.36, 'test/precision_weighted': 0.422861452273217, 'test/loss': 1.238891206786897, 'eval/accuracy': 0.36, 'eval/recall_macro': 0.325}","{'dt_criterion': 'gini', 'dt_max_depth': 13, 'trial.number': 29, 'dt_min_samples_leaf': 56}",snowy-durian-193,DecisionTree,['TfIdf']
1137,"{'test/f1_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, 'split': 10, 'test/accuracy': 0.4603174603174603, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.15760869565217392, 'eval/recall_micro': 0.44, 'test/recall_weighted': 0.4603174603174603, '_step': 20, 'eval/f1_macro': 0.1527777777777778, 'eval/precision_weighted': 0.1936, 'test/recall_micro': 0.4603174603174603, 'test/precision_macro': 0.11507936507936509, 'eval/accuracy': 0.44, 'eval/precision_macro': 0.11, '_timestamp': 1704214991.794358, 'eval/recall_weighted': 0.44, '_runtime': 3.293659925460815, 'eval/loss': 1.290462308510823, 'test/precision_micro': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, 'test/loss': 1.2854266288838343, 'eval/recall_macro': 0.25, 'test/f1_weighted': 0.290200138026225, 'test/recall_macro': 0.25, '_wandb': {'runtime': 1}, 'eval/f1_weighted': 0.26888888888888896}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 73, 'dt_min_samples_leaf': 92}",stellar-aardvark-192,DecisionTree,['BoW']
1138,"{'test/accuracy': 0.4603174603174603, 'split': 10, 'test/precision_macro': 0.21060606060606055, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.24895833333333336, '_runtime': 3.417112112045288, 'eval/precision_macro': 0.23026315789473684, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.34045899061378937, 'test/precision_micro': 0.4603174603174603, 'test/loss': 1.305987242457944, 'eval/loss': 1.3607250375817486, 'test/f1_macro': 0.19102167182662536, 'test/f1_micro': 0.4603174603174603, 'eval/recall_macro': 0.30000000000000004, 'eval/recall_micro': 0.4, 'eval/precision_weighted': 0.26842105263157895, '_step': 20, 'eval/f1_macro': 0.24904214559386972, 'test/recall_micro': 0.4603174603174603, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.4603174603174603, '_wandb': {'runtime': 2}, 'eval/f1_weighted': 0.3095785440613027, 'test/precision_weighted': 0.3270803270803271, '_timestamp': 1704214987.9241822}","{'rf_max_depth': 16, 'trial.number': 16}",blooming-sky-191,RandomForest,['TfIdf']
1139,"{'_step': 20, 'eval/precision_macro': 0.23214285714285715, 'eval/recall_micro': 0.48, '_wandb': {'runtime': 1}, '_runtime': 3.3802707195281982, 'test/f1_macro': 0.2623626373626374, 'eval/loss': 1.369079256325694, 'test/loss': 1.2393871129762446, 'eval/f1_weighted': 0.3679120879120879, 'test/recall_micro': 0.5079365079365079, 'eval/precision_micro': 0.48, 'test/precision_macro': 0.21944444444444444, 'eval/accuracy': 0.48, 'test/f1_micro': 0.5079365079365079, 'test/accuracy': 0.5079365079365079, 'test/f1_weighted': 0.4193267050409908, 'eval/recall_weighted': 0.48, 'test/recall_weighted': 0.5079365079365079, 'eval/precision_weighted': 0.3028571428571428, '_timestamp': 1704214985.6193595, 'eval/f1_macro': 0.2760989010989011, 'eval/f1_micro': 0.48, 'test/precision_weighted': 0.35837742504409176, 'test/precision_micro': 0.5079365079365079, 'split': 10, 'eval/recall_macro': 0.35, 'test/recall_macro': 0.3295454545454546}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 28, 'dt_min_samples_leaf': 38}",firm-lake-190,DecisionTree,['TfIdf']
1140,"{'split': 10, '_wandb': {'runtime': 1}, 'eval/precision_weighted': 0.25269841269841264, 'test/loss': 1.3138032633831536, 'eval/f1_weighted': 0.3094252873563218, 'eval/recall_macro': 0.28181818181818186, 'eval/precision_micro': 0.4, 'test/f1_weighted': 0.3369220151828847, 'eval/recall_micro': 0.4, 'test/precision_macro': 0.20098039215686275, 'test/accuracy': 0.4444444444444444, 'test/recall_macro': 0.29780564263322884, 'eval/precision_macro': 0.18253968253968253, 'test/precision_weighted': 0.2748210395269219, '_runtime': 3.209608554840088, '_timestamp': 1704214983.5552754, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.23695652173913043, 'test/recall_micro': 0.4444444444444444, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.4444444444444444, '_step': 20, 'eval/loss': 1.312828991102543, 'eval/f1_macro': 0.22126436781609193, 'test/recall_weighted': 0.4444444444444444, 'eval/accuracy': 0.4, 'test/f1_micro': 0.4444444444444444}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 72, 'dt_min_samples_leaf': 64}",daily-durian-189,DecisionTree,['BoW']
1141,"{'eval/accuracy': 0.52, 'test/f1_weighted': 0.3548883154794485, '_step': 20, '_wandb': {'runtime': 1}, 'test/loss': 1.2888205688288876, 'test/precision_weighted': 0.3355054302422723, 'test/accuracy': 0.47619047619047616, 'eval/recall_macro': 0.4041666666666667, 'eval/recall_micro': 0.52, 'test/precision_micro': 0.47619047619047616, 'test/recall_weighted': 0.47619047619047616, 'test/f1_macro': 0.20853858784893267, 'test/f1_micro': 0.47619047619047616, 'eval/precision_micro': 0.52, '_timestamp': 1704214979.004099, 'test/recall_macro': 0.26458333333333334, 'test/recall_micro': 0.47619047619047616, 'split': 10, 'eval/f1_micro': 0.52, '_runtime': 2.846799850463867, 'eval/precision_macro': 0.7440476190476191, 'test/precision_macro': 0.22280701754385965, 'eval/precision_weighted': 0.6904761904761905, 'eval/loss': 1.265107504873405, 'eval/f1_macro': 0.40414746543778807, 'eval/f1_weighted': 0.4477788018433179, 'eval/recall_weighted': 0.52}","{'rf_max_depth': 8, 'trial.number': 15}",copper-waterfall-188,RandomForest,['TfIdf']
1142,"{'test/precision_macro': 0.22671840354767184, 'split': 10, 'eval/accuracy': 0.52, 'test/f1_micro': 0.5079365079365079, 'test/recall_micro': 0.5079365079365079, '_runtime': 3.2471344470977783, 'eval/loss': 1.2819887792501807, 'eval/precision_macro': 0.25735294117647056, 'test/precision_weighted': 0.37546193643754616, 'test/recall_macro': 0.34696969696969693, 'eval/recall_weighted': 0.52, 'test/precision_micro': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, 'eval/f1_macro': 0.30952380952380953, 'eval/recall_macro': 0.39166666666666666, 'eval/precision_weighted': 0.3317647058823529, '_step': 20, 'test/accuracy': 0.5079365079365079, 'test/f1_macro': 0.26942567567567566, 'eval/f1_weighted': 0.40380952380952384, 'test/f1_weighted': 0.4276061776061776, 'eval/recall_micro': 0.52, '_wandb': {'runtime': 1}, 'test/loss': 1.2411116710838643, '_timestamp': 1704214976.8133123, 'eval/f1_micro': 0.52, 'eval/precision_micro': 0.52}","{'dt_criterion': 'gini', 'dt_max_depth': 18, 'trial.number': 27, 'dt_min_samples_leaf': 72}",magic-flower-187,DecisionTree,['TfIdf']
1143,"{'eval/f1_micro': 0.44, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'eval/recall_micro': 0.44, 'split': 10, 'test/loss': 1.3302066853563077, '_timestamp': 1704214974.8144698, 'test/f1_micro': 0.4603174603174603, 'test/recall_macro': 0.25, '_step': 20, 'eval/recall_macro': 0.25, '_wandb': {'runtime': 1}, 'eval/loss': 1.2885286144160266, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_weighted': 0.4603174603174603, '_runtime': 2.735609769821167, 'eval/precision_weighted': 0.1936, 'eval/accuracy': 0.44, 'test/f1_weighted': 0.290200138026225, 'eval/precision_macro': 0.11, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.11507936507936509, 'eval/f1_macro': 0.1527777777777778, 'test/precision_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.21189216427311663, 'test/recall_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 71, 'dt_min_samples_leaf': 74}",devoted-firebrand-186,DecisionTree,['BoW']
1144,"{'eval/precision_macro': 0.1, 'eval/accuracy': 0.4, 'test/f1_micro': 0.47619047619047616, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.16, '_runtime': 3.4437613487243652, 'eval/loss': 1.305424675532134, 'test/loss': 1.2538806327936107, 'test/f1_macro': 0.16129032258064516, 'test/precision_macro': 0.11904761904761904, 'test/precision_weighted': 0.22675736961451248, 'test/f1_weighted': 0.30721966205837176, 'test/recall_macro': 0.25, 'eval/precision_micro': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.47619047619047616, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_micro': 0.4, '_step': 20, '_wandb': {'runtime': 2}, '_timestamp': 1704214971.3089485, 'eval/f1_macro': 0.14285714285714288, 'test/recall_micro': 0.47619047619047616, 'test/recall_weighted': 0.47619047619047616, 'split': 10, 'eval/recall_macro': 0.25, 'test/precision_micro': 0.47619047619047616}","{'rf_max_depth': 3, 'trial.number': 14}",wild-rain-185,RandomForest,['TfIdf']
1145,"{'split': 10, 'test/recall_micro': 0.5079365079365079, 'eval/precision_macro': 0.23214285714285715, 'test/accuracy': 0.5079365079365079, 'eval/f1_weighted': 0.3679120879120879, 'eval/recall_weighted': 0.48, 'test/precision_weighted': 0.35837742504409176, 'eval/f1_macro': 0.2760989010989011, 'test/f1_weighted': 0.4193267050409908, 'eval/recall_macro': 0.35, 'eval/recall_micro': 0.48, 'eval/precision_weighted': 0.3028571428571428, '_timestamp': 1704214968.0480568, 'test/f1_macro': 0.2623626373626374, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.48, '_step': 20, '_runtime': 2.701903820037842, 'eval/loss': 1.3088549567407273, 'test/recall_macro': 0.3295454545454546, 'test/precision_macro': 0.21944444444444444, 'eval/f1_micro': 0.48, 'test/f1_micro': 0.5079365079365079, 'eval/precision_micro': 0.48, 'test/recall_weighted': 0.5079365079365079, 'test/loss': 1.2689644340816222, 'test/precision_micro': 0.5079365079365079}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 26, 'dt_min_samples_leaf': 48}",hardy-sky-184,DecisionTree,['TfIdf']
1146,"{'test/f1_micro': 0.4603174603174603, 'eval/recall_micro': 0.44, 'eval/precision_macro': 0.11, 'eval/loss': 1.290462308510823, 'test/f1_macro': 0.15760869565217392, '_step': 20, '_timestamp': 1704214967.1961834, 'eval/accuracy': 0.44, '_runtime': 3.3218674659729004, 'test/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, 'eval/precision_weighted': 0.1936, 'test/precision_weighted': 0.21189216427311663, 'test/loss': 1.2854266288838343, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.11507936507936509, 'test/recall_weighted': 0.4603174603174603, 'split': 10, 'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/f1_weighted': 0.290200138026225, 'eval/precision_micro': 0.44, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.44, 'eval/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 70, 'dt_min_samples_leaf': 93}",comic-gorge-183,DecisionTree,['BoW']
1147,"{'test/f1_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_weighted': 0.20736842105263156, '_step': 20, 'test/loss': 1.3005173410305912, 'test/f1_weighted': 0.32559949413882, 'test/precision_micro': 0.4603174603174603, 'eval/loss': 1.303086169703508, '_timestamp': 1704214964.273911, 'eval/f1_micro': 0.32, 'eval/recall_macro': 0.21666666666666665, 'eval/precision_micro': 0.32, 'test/precision_weighted': 0.2974172719935432, 'split': 10, 'test/recall_micro': 0.4603174603174603, 'eval/recall_weighted': 0.32, 'test/precision_macro': 0.2436440677966102, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.2027579162410623, 'eval/f1_weighted': 0.24110344827586208, 'eval/precision_macro': 0.15460526315789477, '_runtime': 3.138654947280884, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.32, 'eval/f1_macro': 0.1706896551724138, 'eval/recall_micro': 0.32, 'test/recall_macro': 0.2611111111111111}","{'rf_max_depth': 11, 'trial.number': 13}",noble-sun-182,RandomForest,['TfIdf']
1148,"{'split': 10, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.33939393939393936, 'eval/loss': 1.2871543048462406, 'eval/f1_micro': 0.44, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.22146739130434784, 'test/recall_weighted': 0.492063492063492, 'test/loss': 1.2234015778747367, 'test/f1_micro': 0.492063492063492, 'test/f1_weighted': 0.41649370416493714, '_timestamp': 1704214960.410415, 'eval/f1_macro': 0.265, 'eval/f1_weighted': 0.3440000000000001, 'eval/recall_macro': 0.3416666666666667, 'test/recall_micro': 0.492063492063492, '_wandb': {'runtime': 1}, '_runtime': 3.2478549480438232, 'eval/precision_weighted': 0.2826666666666667, '_step': 20, 'test/accuracy': 0.492063492063492, 'test/f1_macro': 0.2621419676214197, 'eval/recall_weighted': 0.44, 'eval/accuracy': 0.44, 'eval/precision_macro': 0.21666666666666667, 'test/precision_micro': 0.492063492063492, 'test/precision_weighted': 0.3687888198757764}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 25, 'dt_min_samples_leaf': 78}",floral-pond-181,DecisionTree,['TfIdf']
1149,"{'_wandb': {'runtime': 1}, 'eval/f1_macro': 0.1527777777777778, 'test/f1_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, 'eval/recall_macro': 0.25, 'test/precision_macro': 0.11507936507936509, 'split': 10, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'eval/precision_macro': 0.11, 'eval/recall_weighted': 0.44, 'test/f1_macro': 0.15760869565217392, 'test/recall_macro': 0.25, '_runtime': 3.277538299560547, 'test/loss': 1.3302066853563077, 'test/f1_weighted': 0.290200138026225, 'eval/f1_weighted': 0.26888888888888896, 'eval/loss': 1.2885286144160266, 'test/accuracy': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_weighted': 0.1936, 'test/precision_weighted': 0.21189216427311663, '_step': 20, '_timestamp': 1704214958.654699, 'eval/recall_micro': 0.44, 'test/precision_micro': 0.4603174603174603}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 69, 'dt_min_samples_leaf': 81}",peachy-wildflower-180,DecisionTree,['BoW']
1150,"{'_wandb': {'runtime': 2}, 'eval/loss': 1.2318062931373697, 'eval/accuracy': 0.48, 'test/accuracy': 0.47619047619047616, 'eval/recall_micro': 0.48, 'eval/precision_micro': 0.48, 'eval/recall_weighted': 0.48, 'eval/precision_weighted': 0.5339130434782609, 'test/loss': 1.3181527290100383, '_timestamp': 1704214956.272049, 'eval/f1_micro': 0.48, 'test/recall_macro': 0.26944444444444443, 'test/precision_weighted': 0.28167877320419693, 'split': 10, 'eval/recall_macro': 0.3625, 'eval/precision_macro': 0.6086956521739131, 'test/precision_micro': 0.47619047619047616, '_step': 20, '_runtime': 3.372098922729492, 'eval/f1_macro': 0.33484848484848484, 'test/f1_micro': 0.47619047619047616, 'eval/f1_weighted': 0.37309090909090914, 'test/f1_weighted': 0.3341359015516319, 'test/recall_weighted': 0.47619047619047616, 'test/f1_macro': 0.2045880149812734, 'test/recall_micro': 0.47619047619047616, 'test/precision_macro': 0.2062146892655367}","{'rf_max_depth': 6, 'trial.number': 12}",dandy-deluge-179,RandomForest,['TfIdf']
1151,"{'eval/precision_macro': 0.1, 'test/precision_macro': 0.13095238095238096, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.25, 'eval/precision_weighted': 0.16, 'test/f1_weighted': 0.36011904761904767, 'test/recall_weighted': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015, '_step': 20, 'test/f1_macro': 0.17187500000000003, 'test/f1_micro': 0.5238095238095238, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.5238095238095238, 'eval/recall_weighted': 0.4, '_wandb': {'runtime': 1}, 'eval/loss': 1.3126565071353458, 'test/recall_macro': 0.25, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.5238095238095238, 'test/loss': 1.2588970748241275, 'eval/f1_macro': 0.14285714285714288, '_timestamp': 1704214952.1237974, 'eval/accuracy': 0.4, 'test/accuracy': 0.5238095238095238, 'split': 10, '_runtime': 3.273888349533081}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 24, 'dt_min_samples_leaf': 96}",lemon-sound-178,DecisionTree,['TfIdf']
1152,"{'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.23695652173913043, 'eval/recall_micro': 0.4, 'eval/f1_macro': 0.22126436781609193, 'eval/f1_weighted': 0.3094252873563218, 'eval/recall_weighted': 0.4, '_step': 20, 'eval/loss': 1.312828991102543, 'test/accuracy': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, 'eval/precision_micro': 0.4, '_runtime': 2.7261159420013428, '_timestamp': 1704214949.781674, 'eval/recall_macro': 0.28181818181818186, 'test/precision_micro': 0.4444444444444444, '_wandb': {'runtime': 1}, 'eval/precision_macro': 0.18253968253968253, 'test/recall_micro': 0.4444444444444444, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.3369220151828847, 'test/precision_macro': 0.20098039215686275, 'split': 10, 'test/recall_macro': 0.29780564263322884, 'test/recall_weighted': 0.4444444444444444, 'eval/precision_weighted': 0.25269841269841264, 'test/precision_weighted': 0.2748210395269219, 'test/loss': 1.3138032633831536}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 68, 'dt_min_samples_leaf': 57}",valiant-pine-177,DecisionTree,['BoW']
1153,"{'_wandb': {'runtime': 2}, 'test/f1_macro': 0.15760869565217392, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.4603174603174603, 'eval/loss': 1.3036821564268368, 'test/recall_macro': 0.24166666666666667, 'test/precision_weighted': 0.2227342549923195, 'test/accuracy': 0.4603174603174603, 'eval/precision_macro': 0.1, 'eval/precision_weighted': 0.16, 'test/loss': 1.307152923736896, 'test/recall_weighted': 0.4603174603174603, '_step': 20, 'eval/accuracy': 0.4, 'test/f1_micro': 0.4603174603174603, 'test/f1_weighted': 0.30020703933747417, 'test/recall_micro': 0.4603174603174603, 'eval/precision_micro': 0.4, '_runtime': 3.3595731258392334, '_timestamp': 1704214947.928908, 'eval/f1_macro': 0.14285714285714288, 'eval/f1_weighted': 0.22857142857142865, 'test/precision_macro': 0.11693548387096774, 'split': 10, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.4}","{'rf_max_depth': 2, 'trial.number': 11}",rose-bee-176,RandomForest,['TfIdf']
1154,"{'test/precision_weighted': 0.35837742504409176, 'eval/recall_micro': 0.48, 'eval/precision_micro': 0.48, 'test/precision_micro': 0.5079365079365079, 'eval/accuracy': 0.48, 'eval/f1_macro': 0.2760989010989011, 'eval/f1_weighted': 0.3679120879120879, 'test/f1_weighted': 0.4193267050409908, 'split': 10, 'eval/f1_micro': 0.48, 'test/f1_micro': 0.5079365079365079, 'eval/precision_macro': 0.23214285714285715, 'eval/recall_weighted': 0.48, 'test/precision_macro': 0.21944444444444444, '_runtime': 2.651116132736206, 'test/accuracy': 0.5079365079365079, 'test/recall_macro': 0.3295454545454546, 'eval/loss': 1.3088549567407273, '_timestamp': 1704214942.267559, 'test/recall_weighted': 0.5079365079365079, 'test/f1_macro': 0.2623626373626374, 'eval/recall_macro': 0.35, 'test/recall_micro': 0.5079365079365079, '_step': 20, '_wandb': {'runtime': 1}, 'test/loss': 1.2689644340816222, 'eval/precision_weighted': 0.3028571428571428}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 23, 'dt_min_samples_leaf': 58}",smooth-rain-175,DecisionTree,['TfIdf']
1155,"{'test/loss': 1.3302066853563077, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.4603174603174603, 'split': 10, 'eval/loss': 1.2885286144160266, 'eval/f1_micro': 0.44, 'test/accuracy': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603, 'eval/precision_weighted': 0.1936, 'test/precision_micro': 0.4603174603174603, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.1527777777777778, 'eval/precision_macro': 0.11, '_runtime': 3.286428689956665, '_timestamp': 1704214942.1073728, 'test/f1_weighted': 0.290200138026225, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.44, 'test/precision_weighted': 0.21189216427311663, 'eval/f1_weighted': 0.26888888888888896, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.11507936507936509, '_step': 20, 'test/f1_macro': 0.15760869565217392, 'test/f1_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 67, 'dt_min_samples_leaf': 73}",brisk-wave-174,DecisionTree,['BoW']
1156,"{'test/f1_micro': 0.492063492063492, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.492063492063492, '_step': 20, 'eval/f1_macro': 0.2077922077922078, 'eval/recall_macro': 0.275, 'test/precision_micro': 0.492063492063492, 'test/accuracy': 0.492063492063492, '_wandb': {'runtime': 2}, 'test/loss': 1.2775288260251276, 'test/recall_micro': 0.492063492063492, 'test/precision_macro': 0.4375, 'test/recall_weighted': 0.492063492063492, 'eval/loss': 1.3776761820578602, 'test/f1_macro': 0.28571428571428575, 'split': 10, 'eval/f1_micro': 0.4000000000000001, 'eval/accuracy': 0.4, 'test/recall_macro': 0.303125, 'eval/precision_macro': 0.22282608695652173, 'eval/recall_weighted': 0.4, 'eval/f1_weighted': 0.2753246753246753, 'test/f1_weighted': 0.4077097505668935, 'eval/precision_weighted': 0.25652173913043474, '_runtime': 3.4068329334259033, '_timestamp': 1704214937.745426}","{'rf_max_depth': 12, 'trial.number': 10}",fallen-sunset-173,RandomForest,['TfIdf']
1157,"{'test/precision_weighted': 0.21189216427311663, 'eval/f1_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.4603174603174603, 'split': 10, '_timestamp': 1704214935.0643482, 'test/precision_micro': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603, '_step': 20, 'test/f1_weighted': 0.290200138026225, 'eval/recall_micro': 0.44, '_runtime': 2.719372272491455, 'eval/accuracy': 0.44, 'eval/precision_macro': 0.11, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'eval/precision_micro': 0.44, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'eval/f1_weighted': 0.26888888888888896, 'eval/f1_macro': 0.1527777777777778, 'test/precision_macro': 0.11507936507936509, 'eval/precision_weighted': 0.1936, 'test/f1_micro': 0.4603174603174603, '_wandb': {'runtime': 1}, 'eval/loss': 1.2885286144160266, 'test/loss': 1.3302066853563077}","{'dt_criterion': 'gini', 'dt_max_depth': 9, 'trial.number': 66, 'dt_min_samples_leaf': 86}",clean-thunder-172,DecisionTree,['BoW']
1158,"{'split': 10, '_wandb': {'runtime': 1}, 'test/f1_micro': 0.5079365079365079, 'test/f1_weighted': 0.4276061776061776, 'eval/recall_micro': 0.52, 'eval/precision_macro': 0.25735294117647056, 'test/precision_weighted': 0.37546193643754616, 'test/precision_macro': 0.22671840354767184, '_runtime': 2.833123207092285, 'test/f1_macro': 0.26942567567567566, 'test/recall_micro': 0.5079365079365079, 'eval/precision_weighted': 0.3317647058823529, 'test/loss': 1.2763908365658756, 'eval/accuracy': 0.52, 'test/accuracy': 0.5079365079365079, 'test/recall_macro': 0.34696969696969693, 'eval/recall_weighted': 0.52, 'test/precision_micro': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, 'eval/loss': 1.2372996440079445, 'eval/f1_weighted': 0.40380952380952384, '_step': 20, '_timestamp': 1704214934.2532623, 'eval/recall_macro': 0.39166666666666666, 'eval/f1_macro': 0.30952380952380953, 'eval/f1_micro': 0.52, 'eval/precision_micro': 0.52}","{'dt_criterion': 'entropy', 'dt_max_depth': 15, 'trial.number': 22, 'dt_min_samples_leaf': 72}",mild-eon-171,DecisionTree,['TfIdf']
1159,"{'_timestamp': 1704214929.0645585, 'eval/precision_weighted': 0.2577777777777778, 'eval/loss': 1.300171476784707, 'eval/recall_micro': 0.4, '_wandb': {'runtime': 1}, 'test/f1_micro': 0.5238095238095238, 'eval/recall_weighted': 0.4, 'split': 10, 'test/f1_macro': 0.2681372549019608, 'eval/f1_weighted': 0.30857142857142855, 'test/f1_weighted': 0.4107376283846872, 'eval/precision_macro': 0.2111111111111111, 'test/precision_macro': 0.34469696969696967, '_runtime': 2.990440607070923, 'eval/f1_macro': 0.24285714285714288, 'test/precision_weighted': 0.4343434343434344, '_step': 20, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.5238095238095238, 'eval/recall_macro': 0.30000000000000004, 'test/recall_macro': 0.3090277777777778, 'test/recall_micro': 0.5238095238095238, 'test/loss': 1.3056919756641727, 'eval/accuracy': 0.4, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238}","{'rf_max_depth': 17, 'trial.number': 9}",crimson-surf-170,RandomForest,['TfIdf']
1160,"{'_step': 20, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_macro': 0.18253968253968253, 'eval/loss': 1.312828991102543, 'eval/accuracy': 0.4, 'eval/recall_macro': 0.28181818181818186, '_runtime': 2.661590576171875, 'eval/f1_macro': 0.22126436781609193, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.4444444444444444, 'test/precision_micro': 0.4444444444444444, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/accuracy': 0.4444444444444444, 'eval/f1_weighted': 0.3094252873563218, 'test/recall_macro': 0.29780564263322884, 'test/recall_weighted': 0.4444444444444444, '_wandb': {'runtime': 1}, 'test/loss': 1.3138032633831536, 'test/f1_micro': 0.4444444444444444, 'split': 10, 'test/f1_weighted': 0.3369220151828847, 'test/precision_macro': 0.20098039215686275, 'test/precision_weighted': 0.2748210395269219, '_timestamp': 1704214926.8168535, 'test/f1_macro': 0.23695652173913043, 'eval/precision_weighted': 0.25269841269841264}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 65, 'dt_min_samples_leaf': 67}",daily-frog-169,DecisionTree,['BoW']
1161,"{'_step': 20, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.14285714285714288, 'test/recall_macro': 0.25, 'eval/loss': 1.3126565071353458, 'test/loss': 1.2588970748241275, 'test/f1_micro': 0.5238095238095238, 'split': 10, 'eval/f1_micro': 0.4000000000000001, 'test/recall_weighted': 0.5238095238095238, 'eval/precision_weighted': 0.16, '_runtime': 3.261345386505127, 'test/f1_macro': 0.17187500000000003, 'eval/recall_macro': 0.25, 'eval/recall_weighted': 0.4, 'test/accuracy': 0.5238095238095238, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.36011904761904767, 'eval/recall_micro': 0.4, 'test/precision_macro': 0.13095238095238096, 'test/precision_micro': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015, '_timestamp': 1704214926.4278245, 'eval/accuracy': 0.4, 'test/recall_micro': 0.5238095238095238, 'eval/precision_macro': 0.1, 'eval/precision_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 11, 'trial.number': 21, 'dt_min_samples_leaf': 97}",deep-flower-168,DecisionTree,['TfIdf']
1162,"{'eval/recall_macro': 0.37916666666666665, 'test/recall_micro': 0.4603174603174603, 'eval/recall_weighted': 0.48, 'split': 10, '_runtime': 3.4669947624206543, 'eval/f1_micro': 0.48, 'eval/recall_micro': 0.48, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.30901875901875897, '_step': 20, '_wandb': {'runtime': 2}, 'test/loss': 1.379062217910666, 'eval/f1_macro': 0.3761904761904762, 'test/precision_weighted': 0.4399864910503208, 'eval/accuracy': 0.48, 'eval/precision_macro': 0.6125, 'test/precision_macro': 0.4082151300236406, 'eval/precision_weighted': 0.6, 'eval/loss': 1.2189357418214852, 'test/f1_weighted': 0.4023637737923452, 'test/recall_weighted': 0.4603174603174603, 'test/recall_macro': 0.31805555555555554, 'eval/precision_micro': 0.48, 'test/precision_micro': 0.4603174603174603, '_timestamp': 1704214922.3126578, 'test/f1_micro': 0.4603174603174603, 'eval/f1_weighted': 0.41904761904761906}","{'rf_max_depth': 24, 'trial.number': 8}",jolly-eon-167,RandomForest,['TfIdf']
1163,"{'eval/accuracy': 0.44, 'test/accuracy': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'eval/f1_macro': 0.1527777777777778, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.1936, 'test/f1_micro': 0.4603174603174603, 'eval/loss': 1.290462308510823, 'test/f1_weighted': 0.290200138026225, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.11507936507936509, 'split': 10, '_wandb': {'runtime': 1}, '_runtime': 2.689507484436035, '_timestamp': 1704214918.6393254, 'test/f1_macro': 0.15760869565217392, 'eval/f1_weighted': 0.26888888888888896, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.4603174603174603, '_step': 20, 'test/precision_micro': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, 'eval/precision_macro': 0.11, 'eval/f1_micro': 0.44, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'test/loss': 1.2854266288838343}","{'dt_criterion': 'gini', 'dt_max_depth': 11, 'trial.number': 64, 'dt_min_samples_leaf': 100}",happy-plant-166,DecisionTree,['BoW']
1164,"{'test/recall_micro': 0.4126984126984127, 'eval/precision_macro': 0.3990196078431373, 'test/precision_weighted': 0.34661172161172166, '_timestamp': 1704214918.2514784, 'eval/recall_micro': 0.52, 'test/precision_micro': 0.4126984126984127, 'eval/precision_weighted': 0.4144313725490196, 'eval/f1_macro': 0.4004329004329004, 'eval/recall_macro': 0.4333333333333333, 'test/precision_macro': 0.20993589743589744, 'test/recall_weighted': 0.4126984126984127, 'eval/accuracy': 0.52, 'test/accuracy': 0.4126984126984127, 'eval/precision_micro': 0.52, '_wandb': {'runtime': 1}, '_runtime': 3.337470531463623, 'eval/f1_micro': 0.52, 'split': 10, 'test/recall_macro': 0.25202020202020203, 'eval/recall_weighted': 0.52, '_step': 20, 'eval/loss': 1.168052888107484, 'test/loss': 1.8677439053888512, 'test/f1_micro': 0.4126984126984127, 'test/f1_weighted': 0.3758828317651848, 'test/f1_macro': 0.22759552538964303, 'eval/f1_weighted': 0.4453679653679654}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 20, 'dt_min_samples_leaf': 14}",confused-frog-165,DecisionTree,['TfIdf']
1165,"{'test/recall_micro': 0.5079365079365079, 'test/precision_weighted': 0.5119720204465967, 'test/loss': 1.298997099213524, 'eval/f1_macro': 0.3120535714285715, 'eval/recall_micro': 0.44, '_runtime': 3.320223093032837, 'test/accuracy': 0.5079365079365079, 'test/f1_macro': 0.2463171036204744, 'eval/accuracy': 0.44, 'test/recall_weighted': 0.5079365079365079, 'eval/f1_micro': 0.44, 'test/precision_micro': 0.5079365079365079, '_wandb': {'runtime': 1}, 'eval/loss': 1.2853474850554212, 'eval/precision_micro': 0.44, '_timestamp': 1704214913.96769, 'test/f1_micro': 0.5079365079365079, 'eval/precision_macro': 0.4772727272727273, 'eval/recall_macro': 0.33749999999999997, 'test/recall_macro': 0.2934027777777778, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.5021186440677966, 'split': 10, 'eval/f1_weighted': 0.3461428571428572, 'test/f1_weighted': 0.3778174107762123, '_step': 20, 'eval/precision_weighted': 0.4236363636363636}","{'rf_max_depth': 6, 'trial.number': 7}",deep-field-164,RandomForest,['TfIdf']
1166,"{'_runtime': 2.8862130641937256, 'eval/f1_macro': 0.3577922077922078, 'eval/precision_weighted': 0.4244444444444444, 'eval/f1_weighted': 0.41932467532467527, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_macro': 0.3680555555555556, 'test/loss': 1.8629125441826344, '_timestamp': 1704214911.257574, 'test/f1_weighted': 0.4292180596236465, 'test/recall_macro': 0.33484848484848484, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.4115362811791383, '_step': 20, 'split': 10, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.32388754588593427, 'test/f1_micro': 0.4603174603174603, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.32723214285714286, 'eval/recall_micro': 0.44, 'test/precision_micro': 0.4603174603174603, 'eval/loss': 1.388947953701752, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.375, 'test/accuracy': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 19, 'dt_min_samples_leaf': 21}",firm-durian-163,DecisionTree,['TfIdf']
1167,"{'eval/f1_micro': 0.44, 'test/accuracy': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_weighted': 0.1936, '_wandb': {'runtime': 1}, 'eval/loss': 1.2885286144160266, 'test/f1_weighted': 0.290200138026225, 'test/recall_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, '_runtime': 3.3167598247528076, 'test/f1_macro': 0.15760869565217392, 'eval/recall_macro': 0.25, 'test/precision_micro': 0.4603174603174603, '_step': 20, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.25, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.1527777777777778, 'split': 10, 'test/loss': 1.3302066853563077, 'eval/precision_macro': 0.11, '_timestamp': 1704214910.9825947, 'test/precision_macro': 0.11507936507936509, 'test/f1_micro': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 63, 'dt_min_samples_leaf': 78}",fearless-universe-162,DecisionTree,['BoW']
1168,"{'eval/recall_micro': 0.4, '_step': 20, '_timestamp': 1704214905.9295008, 'test/f1_macro': 0.21871492704826037, 'test/recall_macro': 0.25520833333333337, 'eval/precision_micro': 0.4, 'eval/loss': 3.0540296890642455, 'eval/precision_weighted': 0.24, 'test/precision_weighted': 0.3075007780890134, 'test/loss': 2.0190256974325704, 'test/accuracy': 0.42857142857142855, 'eval/recall_macro': 0.275, 'eval/precision_macro': 0.175, 'test/recall_micro': 0.42857142857142855, 'test/precision_micro': 0.42857142857142855, '_runtime': 3.5050148963928223, 'eval/f1_macro': 0.21071428571428577, 'eval/f1_micro': 0.4000000000000001, 'test/f1_weighted': 0.33819678264122705, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.4, 'test/f1_micro': 0.42857142857142855, 'test/precision_macro': 0.2267156862745098, 'split': 10, 'eval/f1_weighted': 0.29714285714285715, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.42857142857142855}","{'rf_max_depth': 32, 'trial.number': 6}",ethereal-shadow-161,RandomForest,['TfIdf']
1169,"{'test/recall_macro': 0.3068181818181818, '_runtime': 2.632682085037231, '_timestamp': 1704214902.8301132, 'test/recall_micro': 0.3968253968253968, 'eval/accuracy': 0.36, 'test/accuracy': 0.3968253968253968, 'test/precision_micro': 0.3968253968253968, 'eval/precision_weighted': 0.3677922077922078, 'eval/f1_weighted': 0.34900452488687783, 'test/f1_macro': 0.271589991928975, 'test/f1_micro': 0.3968253968253968, 'test/precision_macro': 0.26498868778280543, '_step': 20, 'eval/recall_micro': 0.36, 'eval/precision_micro': 0.36, 'eval/recall_weighted': 0.36, 'test/recall_weighted': 0.3968253968253968, 'split': 10, 'eval/loss': 1.356821839642209, 'test/loss': 1.2148867650715736, 'eval/f1_micro': 0.36, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.2955316742081448, 'test/f1_weighted': 0.3974659543666807, 'eval/recall_macro': 0.325, 'eval/precision_macro': 0.29545454545454547, 'test/precision_weighted': 0.422861452273217}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 18, 'dt_min_samples_leaf': 44}",grateful-frost-160,DecisionTree,['TfIdf']
1170,"{'eval/f1_micro': 0.44, 'test/f1_macro': 0.15760869565217392, '_step': 20, 'eval/recall_micro': 0.44, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.11507936507936509, 'test/loss': 1.3302066853563077, 'eval/accuracy': 0.44, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_weighted': 0.1936, '_timestamp': 1704214902.7673347, 'eval/f1_macro': 0.1527777777777778, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'test/precision_micro': 0.4603174603174603, 'split': 10, 'eval/loss': 1.2885286144160266, 'eval/f1_weighted': 0.26888888888888896, 'test/precision_weighted': 0.21189216427311663, '_wandb': {'runtime': 1}, '_runtime': 3.336918592453003, 'test/f1_weighted': 0.290200138026225, 'test/accuracy': 0.4603174603174603, 'test/f1_micro': 0.4603174603174603, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.44}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 62, 'dt_min_samples_leaf': 71}",gallant-aardvark-159,DecisionTree,['BoW']
1171,"{'test/precision_macro': 0.12096774193548387, 'eval/precision_weighted': 0.16, 'test/precision_weighted': 0.2304147465437788, 'test/f1_macro': 0.16304347826086957, 'eval/recall_macro': 0.25, 'test/f1_micro': 0.47619047619047616, 'test/f1_weighted': 0.3105590062111801, 'test/recall_macro': 0.25, '_step': 20, '_wandb': {'runtime': 1}, '_timestamp': 1704214897.023227, 'eval/f1_macro': 0.14285714285714288, 'eval/precision_macro': 0.1, 'eval/recall_weighted': 0.4, '_runtime': 2.8198399543762207, 'test/loss': 1.257717925080633, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.47619047619047616, 'split': 10, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.47619047619047616, 'eval/loss': 1.2940942567666909, 'eval/accuracy': 0.4, 'eval/f1_weighted': 0.22857142857142865, 'test/precision_micro': 0.47619047619047616, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.47619047619047616}","{'rf_max_depth': 4, 'trial.number': 5}",earnest-microwave-158,RandomForest,['TfIdf']
1172,"{'test/f1_weighted': 0.36011904761904767, '_timestamp': 1704214897.067265, 'test/f1_macro': 0.17187500000000003, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'eval/f1_macro': 0.14285714285714288, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_weighted': 0.16, 'eval/accuracy': 0.4, 'test/accuracy': 0.5238095238095238, 'test/loss': 1.2588970748241275, 'test/recall_weighted': 0.5238095238095238, 'test/recall_micro': 0.5238095238095238, 'eval/precision_macro': 0.1, '_runtime': 3.359457015991211, 'eval/loss': 1.3126565071353458, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, '_step': 20, 'split': 10, 'test/precision_weighted': 0.27437641723356015, 'test/f1_micro': 0.5238095238095238, 'test/precision_micro': 0.5238095238095238, 'test/precision_macro': 0.13095238095238096, '_wandb': {'runtime': 2}, 'eval/f1_weighted': 0.22857142857142865}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 17, 'dt_min_samples_leaf': 97}",scarlet-wind-157,DecisionTree,['TfIdf']
1173,"{'eval/f1_macro': 0.22126436781609193, 'eval/f1_micro': 0.4000000000000001, 'test/recall_micro': 0.4444444444444444, 'eval/precision_macro': 0.18253968253968253, 'eval/precision_micro': 0.4, '_runtime': 2.789666175842285, 'eval/loss': 1.312828991102543, 'test/recall_macro': 0.29780564263322884, '_step': 20, 'test/accuracy': 0.4444444444444444, 'eval/f1_weighted': 0.3094252873563218, 'test/f1_weighted': 0.3369220151828847, '_wandb': {'runtime': 1}, 'test/loss': 1.3138032633831536, 'eval/recall_weighted': 0.4, 'test/precision_weighted': 0.2748210395269219, 'eval/accuracy': 0.4, 'test/f1_micro': 0.4444444444444444, 'eval/recall_micro': 0.4, 'test/precision_macro': 0.20098039215686275, 'test/precision_micro': 0.4444444444444444, 'eval/recall_macro': 0.28181818181818186, 'test/recall_weighted': 0.4444444444444444, 'split': 10, '_timestamp': 1704214893.955285, 'test/f1_macro': 0.23695652173913043, 'eval/precision_weighted': 0.25269841269841264}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 61, 'dt_min_samples_leaf': 56}",upbeat-galaxy-156,DecisionTree,['BoW']
1174,"{'eval/accuracy': 0.48, 'test/recall_macro': 0.265625, 'eval/recall_micro': 0.48, 'test/recall_micro': 0.492063492063492, 'test/recall_weighted': 0.492063492063492, '_wandb': {'runtime': 1}, 'eval/loss': 1.272109874436289, '_timestamp': 1704214888.9271028, 'test/f1_macro': 0.1942469295410472, 'split': 10, 'eval/precision_micro': 0.48, 'eval/precision_weighted': 0.5339130434782609, 'eval/f1_weighted': 0.37309090909090914, 'test/precision_micro': 0.492063492063492, 'test/precision_weighted': 0.48816029143898, '_step': 20, 'eval/f1_macro': 0.33484848484848484, 'eval/f1_micro': 0.48, 'eval/precision_macro': 0.6086956521739131, 'test/f1_weighted': 0.34385036065708335, 'eval/recall_macro': 0.3625, 'eval/recall_weighted': 0.48, 'test/precision_macro': 0.3729508196721312, '_runtime': 2.981642723083496, 'test/loss': 1.242647359746739, 'test/accuracy': 0.492063492063492, 'test/f1_micro': 0.492063492063492}","{'rf_max_depth': 11, 'trial.number': 4}",silvery-bird-155,RandomForest,['TfIdf']
1175,"{'eval/f1_macro': 0.2356254856254856, 'eval/f1_weighted': 0.30508158508158506, 'test/recall_weighted': 0.42857142857142855, 'test/recall_macro': 0.2871212121212121, 'test/recall_micro': 0.42857142857142855, 'eval/recall_macro': 0.26666666666666666, 'eval/precision_macro': 0.234375, 'test/loss': 1.3790317392977782, 'test/f1_micro': 0.42857142857142855, 'eval/recall_weighted': 0.36, 'test/precision_macro': 0.2451073232323233, 'eval/precision_weighted': 0.28833333333333333, 'eval/loss': 1.3677011264314138, '_timestamp': 1704214888.8995254, 'eval/accuracy': 0.36, 'eval/f1_micro': 0.36, 'split': 10, '_wandb': {'runtime': 1}, 'test/accuracy': 0.42857142857142855, 'test/f1_macro': 0.26256714300192563, 'eval/recall_micro': 0.36, 'test/precision_weighted': 0.3816137566137566, '_runtime': 3.3707144260406494, 'test/f1_weighted': 0.40239953283431545, 'test/precision_micro': 0.42857142857142855, '_step': 20, 'eval/precision_micro': 0.36}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 16, 'dt_min_samples_leaf': 30}",zesty-armadillo-154,DecisionTree,['TfIdf']
1176,"{'eval/f1_weighted': 0.3094252873563218, 'eval/precision_micro': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.29780564263322884, 'eval/precision_macro': 0.18253968253968253, 'eval/precision_weighted': 0.25269841269841264, 'test/recall_micro': 0.4444444444444444, '_runtime': 3.2784576416015625, 'test/accuracy': 0.4444444444444444, 'test/f1_macro': 0.23695652173913043, 'test/f1_micro': 0.4444444444444444, 'eval/recall_macro': 0.28181818181818186, 'split': 10, 'test/f1_weighted': 0.3369220151828847, 'eval/recall_micro': 0.4, 'test/precision_macro': 0.20098039215686275, 'test/loss': 1.3138032633831536, '_timestamp': 1704214886.2234137, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.22126436781609193, 'eval/recall_weighted': 0.4, '_step': 20, '_wandb': {'runtime': 1}, 'eval/loss': 1.312828991102543, 'test/precision_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'test/precision_weighted': 0.2748210395269219}","{'dt_criterion': 'gini', 'dt_max_depth': 8, 'trial.number': 60, 'dt_min_samples_leaf': 47}",super-wildflower-153,DecisionTree,['BoW']
1177,"{'eval/f1_weighted': 0.3605860805860806, 'eval/recall_macro': 0.3625, 'test/precision_micro': 0.3968253968253968, 'test/precision_weighted': 0.4837154159909578, 'eval/f1_macro': 0.3566849816849817, 'eval/f1_micro': 0.36, '_timestamp': 1704214881.7903256, 'test/accuracy': 0.3968253968253968, 'test/f1_weighted': 0.41832668089978026, 'eval/recall_micro': 0.36, '_runtime': 2.7759275436401367, 'eval/accuracy': 0.36, 'test/f1_micro': 0.3968253968253968, '_step': 20, 'split': 10, 'eval/precision_micro': 0.36, 'eval/recall_weighted': 0.36, 'test/recall_weighted': 0.3968253968253968, 'test/f1_macro': 0.3167153996101364, 'test/recall_micro': 0.3968253968253968, 'test/loss': 2.4639213456728037, 'test/recall_macro': 0.32702020202020204, 'eval/precision_macro': 0.3645833333333333, 'eval/precision_weighted': 0.3733333333333333, '_wandb': {'runtime': 1}, 'eval/loss': 1.3670804819912588, 'test/precision_macro': 0.36026186790505677}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 15, 'dt_min_samples_leaf': 17}",colorful-plant-152,DecisionTree,['TfIdf']
1178,"{'_step': 20, 'split': 10, 'test/loss': 1.2617937324993478, 'eval/f1_macro': 0.14285714285714288, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1, 'eval/precision_micro': 0.4, 'test/f1_macro': 0.1942469295410472, 'test/f1_weighted': 0.34385036065708335, 'eval/recall_weighted': 0.4, '_runtime': 3.3973000049591064, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.492063492063492, 'test/recall_micro': 0.492063492063492, 'test/precision_weighted': 0.48816029143898, 'eval/loss': 1.3406924418148267, 'test/f1_micro': 0.492063492063492, 'test/precision_macro': 0.3729508196721312, 'test/precision_micro': 0.492063492063492, '_wandb': {'runtime': 2}, 'eval/precision_weighted': 0.16, 'test/recall_macro': 0.265625, 'test/recall_weighted': 0.492063492063492, '_timestamp': 1704214881.126629, 'eval/recall_macro': 0.25}","{'rf_max_depth': 2, 'trial.number': 3}",swift-wave-151,RandomForest,['TfIdf']
1179,"{'test/f1_macro': 0.15760869565217392, 'eval/recall_micro': 0.44, 'eval/precision_macro': 0.11, 'eval/precision_weighted': 0.1936, 'eval/loss': 1.290462308510823, 'eval/accuracy': 0.44, 'test/accuracy': 0.4603174603174603, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25, 'eval/precision_micro': 0.44, 'test/loss': 1.2854266288838343, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.11507936507936509, 'split': 10, '_runtime': 3.2592239379882812, 'eval/f1_macro': 0.1527777777777778, 'test/precision_micro': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'test/recall_weighted': 0.4603174603174603, '_wandb': {'runtime': 1}, '_timestamp': 1704214878.011157, 'eval/f1_weighted': 0.26888888888888896, 'test/precision_weighted': 0.21189216427311663, '_step': 20, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 59, 'dt_min_samples_leaf': 90}",giddy-meadow-150,DecisionTree,['BoW']
1180,"{'eval/precision_weighted': 0.4, '_step': 20, '_wandb': {'runtime': 1}, 'test/accuracy': 0.492063492063492, 'eval/precision_macro': 0.3458333333333333, 'eval/recall_weighted': 0.44, 'test/precision_micro': 0.492063492063492, 'eval/loss': 1.273192391456088, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.3272005772005772, 'test/recall_weighted': 0.492063492063492, 'test/f1_macro': 0.3233580145344851, 'eval/accuracy': 0.44, 'eval/recall_micro': 0.44, 'eval/f1_micro': 0.44, 'test/recall_micro': 0.492063492063492, 'split': 10, '_timestamp': 1704214873.5346043, 'eval/f1_weighted': 0.4043636363636364, 'test/recall_macro': 0.33484848484848484, '_runtime': 2.762681245803833, 'test/f1_weighted': 0.44221791280614814, 'eval/recall_macro': 0.35, 'test/loss': 1.2290868069230363, 'eval/f1_macro': 0.33545454545454545, 'test/f1_micro': 0.492063492063492, 'test/precision_weighted': 0.4134542705971278}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 14, 'dt_min_samples_leaf': 16}",dainty-leaf-149,DecisionTree,['TfIdf']
1181,"{'eval/accuracy': 0.36, 'eval/recall_micro': 0.36, 'eval/precision_macro': 0.09375, 'eval/f1_micro': 0.36, 'test/f1_weighted': 0.3709273182957394, 'test/recall_weighted': 0.5079365079365079, 'test/loss': 1.2784134990607912, 'test/recall_macro': 0.28125, 'test/precision_micro': 0.5079365079365079, 'test/f1_micro': 0.5079365079365079, 'eval/f1_weighted': 0.21176470588235297, 'test/precision_macro': 0.29166666666666663, 'test/precision_weighted': 0.4074074074074074, '_step': 20, '_runtime': 3.6114442348480225, 'test/f1_macro': 0.21929824561403508, 'test/recall_micro': 0.5079365079365079, 'eval/precision_micro': 0.36, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.13235294117647062, 'eval/recall_macro': 0.225, 'test/accuracy': 0.5079365079365079, 'eval/recall_weighted': 0.36, 'eval/precision_weighted': 0.15, 'split': 10, 'eval/loss': 1.3156078647188574, '_timestamp': 1704214872.9338171}","{'rf_max_depth': 3, 'trial.number': 2}",wobbly-tree-148,RandomForest,['TfIdf']
1182,"{'eval/f1_micro': 0.44, 'eval/precision_micro': 0.44, 'eval/precision_weighted': 0.1936, 'test/f1_macro': 0.15760869565217392, 'eval/f1_weighted': 0.26888888888888896, '_timestamp': 1704214869.1462705, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.44, '_wandb': {'runtime': 1}, 'test/precision_macro': 0.11507936507936509, 'test/precision_weighted': 0.21189216427311663, '_step': 20, 'test/loss': 1.3302066853563077, 'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, 'test/f1_micro': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'eval/recall_weighted': 0.44, 'split': 10, 'test/precision_micro': 0.4603174603174603, '_runtime': 2.608213424682617, 'eval/loss': 1.2885286144160266, 'test/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'test/recall_weighted': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 58, 'dt_min_samples_leaf': 81}",silvery-forest-147,DecisionTree,['BoW']
1183,"{'_wandb': {'runtime': 1}, 'eval/loss': 1.35292803881297, 'test/recall_macro': 0.3371212121212121, 'eval/precision_weighted': 0.3361904761904762, 'test/precision_macro': 0.27666369578134287, 'test/f1_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, '_step': 20, 'test/loss': 1.2983588499947631, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.4603174603174603, '_runtime': 3.3709557056427, '_timestamp': 1704214865.8265986, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.4603174603174603, 'eval/precision_micro': 0.4, 'test/recall_micro': 0.4603174603174603, 'eval/f1_macro': 0.2972027972027972, 'test/f1_macro': 0.2989193642178717, 'test/f1_weighted': 0.4324296882932278, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.2738095238095238, 'test/precision_weighted': 0.4147733167341011, 'split': 10, 'eval/accuracy': 0.4, 'eval/f1_weighted': 0.36531468531468536, 'eval/recall_macro': 0.325}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 13, 'dt_min_samples_leaf': 36}",driven-salad-146,DecisionTree,['TfIdf']
1184,"{'eval/recall_macro': 0.31666666666666665, 'test/precision_micro': 0.4444444444444444, 'eval/f1_weighted': 0.359020979020979, 'test/recall_macro': 0.24791666666666667, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.35633333333333334, '_step': 20, '_wandb': {'runtime': 1}, '_runtime': 3.0704660415649414, 'test/loss': 1.4882435624179209, 'eval/f1_macro': 0.30506993006993005, 'test/recall_micro': 0.4444444444444444, 'eval/precision_macro': 0.3260416666666667, 'split': 10, 'eval/recall_micro': 0.4, 'test/precision_weighted': 0.5015873015873016, '_timestamp': 1704214864.0131671, 'test/accuracy': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, 'test/f1_weighted': 0.36596119929453264, 'test/precision_macro': 0.38, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.21805555555555556, 'eval/loss': 1.3115284064409862, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.4444444444444444}","{'rf_max_depth': 24, 'trial.number': 1}",wild-sky-145,RandomForest,['TfIdf']
1185,"{'_timestamp': 1704214861.5984836, 'test/f1_macro': 0.23695652173913043, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.4444444444444444, 'eval/precision_weighted': 0.25269841269841264, 'eval/loss': 1.312828991102543, 'eval/accuracy': 0.4, 'eval/f1_weighted': 0.3094252873563218, 'test/recall_macro': 0.29780564263322884, 'test/precision_macro': 0.20098039215686275, 'eval/f1_macro': 0.22126436781609193, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_macro': 0.18253968253968253, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.4444444444444444, '_runtime': 3.317415475845337, 'test/loss': 1.3138032633831536, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.2748210395269219, '_step': 20, 'test/f1_micro': 0.4444444444444444, 'test/f1_weighted': 0.3369220151828847, 'eval/recall_macro': 0.28181818181818186, 'test/precision_micro': 0.4444444444444444, 'split': 10, '_wandb': {'runtime': 1}, 'test/accuracy': 0.4444444444444444}","{'dt_criterion': 'gini', 'dt_max_depth': 9, 'trial.number': 57, 'dt_min_samples_leaf': 60}",wandering-universe-144,DecisionTree,['BoW']
1186,"{'eval/recall_weighted': 0.4, 'test/precision_macro': 0.3832908163265306, '_runtime': 1292.3277277946472, 'eval/recall_macro': 0.275, 'eval/precision_macro': 0.34782608695652173, 'test/precision_weighted': 0.4040330417881438, 'eval/accuracy': 0.4, 'test/recall_macro': 0.2845238095238095, 'eval/precision_weighted': 0.3565217391304348, 'test/loss': 1.3716053583779502, 'test/f1_micro': 0.380952380952381, '_wandb': {'runtime': 1291}, 'eval/f1_weighted': 0.28484848484848485, 'test/recall_micro': 0.380952380952381, 'test/accuracy': 0.380952380952381, 'test/f1_macro': 0.2584684684684685, '_step': 20, 'eval/f1_macro': 0.2196969696969697, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.380952380952381, 'eval/loss': 1.2823163790346053, 'test/f1_weighted': 0.3101615901615902, 'split': 10, '_timestamp': 1704216149.372285, 'test/recall_weighted': 0.380952380952381}","{'rf_max_depth': 4, 'trial.number': 0}",blooming-meadow-143,RandomForest,['pre-trained:microsoft/codebert-base']
1187,"{'_timestamp': 1704214857.993959, 'eval/f1_macro': 0.35559640522875813, 'eval/precision_macro': 0.4044913419913419, 'test/precision_micro': 0.380952380952381, 'eval/precision_weighted': 0.4259740259740259, 'test/f1_micro': 0.380952380952381, 'test/recall_macro': 0.3997668997668997, 'eval/recall_macro': 0.37083333333333335, 'eval/recall_weighted': 0.36, 'test/precision_weighted': 0.42327816216705105, 'test/accuracy': 0.380952380952381, 'test/f1_macro': 0.3154046673286991, 'eval/f1_micro': 0.36, 'test/f1_weighted': 0.36928563547232857, 'eval/recall_micro': 0.36, 'split': 10, 'eval/loss': 23.067938169034974, 'eval/f1_weighted': 0.3628431372549019, '_step': 20, 'eval/accuracy': 0.36, 'test/precision_macro': 0.30423789173789173, '_runtime': 2.6371889114379883, 'eval/precision_micro': 0.36, 'test/recall_micro': 0.380952380952381, 'test/recall_weighted': 0.380952380952381, '_wandb': {'runtime': 1}, 'test/loss': 22.312737812310623}","{'n_neighbours': 1, 'trial.number': 9}",fearless-cloud-142,KNeighbours,['TfIdf']
1188,"{'test/precision_macro': 0.3174659622028043, 'test/recall_micro': 0.42857142857142855, 'eval/precision_macro': 0.37386363636363634, 'test/recall_weighted': 0.42857142857142855, '_wandb': {'runtime': 1}, 'eval/loss': 1.2320766972172947, 'split': 10, 'eval/precision_weighted': 0.4381818181818181, 'eval/f1_weighted': 0.4259047619047618, 'test/recall_macro': 0.3196969696969697, 'test/f1_macro': 0.3105042016806723, 'eval/precision_micro': 0.44, '_step': 20, 'test/accuracy': 0.42857142857142855, 'test/precision_micro': 0.42857142857142855, 'test/f1_micro': 0.42857142857142855, 'eval/recall_macro': 0.375, 'eval/f1_macro': 0.35952380952380947, 'test/precision_weighted': 0.40141215329185254, '_timestamp': 1704214857.505001, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/f1_weighted': 0.408936908096572, 'eval/recall_micro': 0.44, 'eval/recall_weighted': 0.44, '_runtime': 3.301936149597168, 'test/loss': 1.2984308492362169}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 12, 'dt_min_samples_leaf': 27}",stellar-sun-141,DecisionTree,['TfIdf']
1189,"{'_step': 20, 'eval/loss': 1.30853018082525, 'test/loss': 1.2640284270521842, 'eval/accuracy': 0.44, '_timestamp': 1704214856.0179048, 'eval/recall_macro': 0.3, 'test/recall_weighted': 0.492063492063492, 'eval/precision_weighted': 0.3666666666666667, 'test/f1_micro': 0.492063492063492, 'eval/f1_weighted': 0.3019607843137255, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.24795081967213117, 'eval/recall_micro': 0.44, 'test/precision_micro': 0.492063492063492, 'split': 10, '_wandb': {'runtime': 2}, 'eval/f1_macro': 0.2303921568627451, 'test/accuracy': 0.492063492063492, 'test/recall_micro': 0.492063492063492, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.1926129426129426, 'test/precision_weighted': 0.361176164454853, 'eval/precision_micro': 0.44, '_runtime': 2.369953870773315, 'test/f1_weighted': 0.34219043742853267, 'test/recall_macro': 0.265625, 'eval/precision_macro': 0.3541666666666667}","{'rf_max_depth': 3, 'trial.number': 0}",trim-donkey-140,RandomForest,['TfIdf']
1190,"{'eval/precision_micro': 0.44, 'test/recall_weighted': 0.4603174603174603, '_runtime': 3.446493625640869, 'test/f1_weighted': 0.290200138026225, 'test/precision_weighted': 0.21189216427311663, '_step': 20, 'test/precision_macro': 0.11507936507936509, '_timestamp': 1704214853.4056785, 'eval/f1_weighted': 0.26888888888888896, 'eval/precision_weighted': 0.1936, 'eval/loss': 1.2885286144160266, 'eval/recall_weighted': 0.44, 'test/precision_micro': 0.4603174603174603, 'eval/f1_micro': 0.44, '_wandb': {'runtime': 2}, 'test/loss': 1.3302066853563077, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'test/f1_micro': 0.4603174603174603, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.44, 'split': 10, 'test/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.1527777777777778}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 56, 'dt_min_samples_leaf': 69}",eager-plant-139,DecisionTree,['BoW']
1191,"{'test/precision_weighted': 0.42327816216705105, '_timestamp': 1704214850.8952234, 'eval/accuracy': 0.36, 'eval/f1_macro': 0.35559640522875813, 'test/f1_weighted': 0.36928563547232857, 'eval/precision_micro': 0.36, 'eval/loss': 23.067938169034974, 'test/precision_micro': 0.380952380952381, '_wandb': {'runtime': 1}, 'test/accuracy': 0.380952380952381, 'test/recall_weighted': 0.380952380952381, 'test/loss': 22.312737812310623, 'eval/f1_micro': 0.36, 'test/f1_micro': 0.380952380952381, 'eval/recall_macro': 0.37083333333333335, 'test/recall_micro': 0.380952380952381, '_step': 20, 'test/recall_macro': 0.3997668997668997, 'test/precision_macro': 0.30423789173789173, 'test/f1_macro': 0.3154046673286991, 'eval/f1_weighted': 0.3628431372549019, 'eval/recall_micro': 0.36, 'eval/precision_macro': 0.4044913419913419, 'split': 10, '_runtime': 2.767322301864624, 'eval/recall_weighted': 0.36, 'eval/precision_weighted': 0.4259740259740259}","{'n_neighbours': 1, 'trial.number': 8}",wild-durian-138,KNeighbours,['TfIdf']
1192,"{'_wandb': {'runtime': 2}, 'test/loss': 1.2588970748241275, 'test/f1_micro': 0.5238095238095238, 'eval/accuracy': 0.4, 'test/f1_macro': 0.17187500000000003, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.36011904761904767, 'test/precision_macro': 0.13095238095238096, 'test/precision_micro': 0.5238095238095238, 'eval/precision_weighted': 0.16, '_runtime': 3.2552783489227295, 'eval/f1_macro': 0.14285714285714288, 'test/accuracy': 0.5238095238095238, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1, 'split': 10, 'test/recall_micro': 0.5238095238095238, 'eval/precision_micro': 0.4, '_timestamp': 1704214850.9261105, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_weighted': 0.4, 'eval/loss': 1.3126565071353458, 'eval/recall_macro': 0.25, 'test/recall_weighted': 0.5238095238095238, '_step': 20, 'test/recall_macro': 0.25, 'test/precision_weighted': 0.27437641723356015}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 11, 'dt_min_samples_leaf': 99}",dauntless-night-137,DecisionTree,['TfIdf']
1193,"{'eval/accuracy': 0.48, 'test/f1_micro': 0.47619047619047616, 'eval/precision_micro': 0.48, 'test/precision_macro': 0.32789046653144016, 'eval/precision_macro': 0.525, 'test/precision_micro': 0.47619047619047616, 'split': 10, 'eval/f1_micro': 0.48, 'eval/f1_weighted': 0.4825974025974025, 'eval/recall_weighted': 0.48, 'eval/loss': 3.809953832366572, 'test/recall_macro': 0.3653846153846154, 'test/recall_micro': 0.47619047619047616, 'test/recall_weighted': 0.47619047619047616, '_step': 20, 'eval/f1_macro': 0.4915584415584415, 'test/f1_weighted': 0.4780849974398361, 'eval/precision_weighted': 0.496, '_runtime': 2.76482892036438, 'eval/recall_macro': 0.4708333333333333, 'eval/recall_micro': 0.48, 'test/accuracy': 0.47619047619047616, 'test/f1_macro': 0.33991935483870966, 'test/precision_weighted': 0.4892494929006085, '_wandb': {'runtime': 1}, 'test/loss': 7.577697735486167, '_timestamp': 1704214844.361826}","{'n_neighbours': 4, 'trial.number': 7}",deep-breeze-135,KNeighbours,['TfIdf']
1194,"{'_timestamp': 1704214844.4508188, 'eval/recall_macro': 0.25, 'test/loss': 1.2854266288838343, 'test/precision_macro': 0.11507936507936509, 'test/f1_micro': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, 'eval/accuracy': 0.44, 'test/accuracy': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, '_step': 20, '_wandb': {'runtime': 1}, 'test/f1_macro': 0.15760869565217392, 'eval/f1_macro': 0.1527777777777778, 'eval/f1_micro': 0.44, 'test/precision_micro': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'eval/recall_micro': 0.44, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_weighted': 0.1936, 'split': 10, 'eval/loss': 1.290462308510823, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, '_runtime': 2.698518753051758, 'test/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 55, 'dt_min_samples_leaf': 99}",divine-deluge-136,DecisionTree,['BoW']
1195,"{'eval/accuracy': 0.44, 'test/precision_weighted': 0.4134542705971278, 'eval/f1_weighted': 0.4043636363636364, 'test/f1_macro': 0.3233580145344851, 'eval/loss': 1.273192391456088, '_timestamp': 1704214842.7410274, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.492063492063492, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.3272005772005772, 'test/recall_weighted': 0.492063492063492, '_runtime': 3.326066255569458, 'test/loss': 1.2290868069230363, 'eval/f1_macro': 0.33545454545454545, 'eval/precision_macro': 0.3458333333333333, 'test/precision_micro': 0.492063492063492, '_step': 20, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.492063492063492, 'test/f1_weighted': 0.44221791280614814, 'split': 10, 'test/accuracy': 0.492063492063492, 'eval/recall_macro': 0.35, 'test/recall_macro': 0.33484848484848484, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 10, 'dt_min_samples_leaf': 22}",sweet-firefly-134,DecisionTree,['TfIdf']
1196,"{'split': 10, 'eval/f1_macro': 0.35559640522875813, 'test/recall_micro': 0.380952380952381, 'test/precision_macro': 0.30423789173789173, 'eval/loss': 23.067938169034974, 'eval/recall_micro': 0.36, 'test/precision_micro': 0.380952380952381, '_step': 20, '_wandb': {'runtime': 1}, '_timestamp': 1704214836.972313, 'eval/f1_micro': 0.36, 'test/accuracy': 0.380952380952381, 'test/f1_micro': 0.380952380952381, 'eval/f1_weighted': 0.3628431372549019, 'eval/recall_macro': 0.37083333333333335, 'eval/precision_micro': 0.36, 'test/f1_weighted': 0.36928563547232857, 'test/recall_macro': 0.3997668997668997, 'test/precision_weighted': 0.42327816216705105, '_runtime': 2.571049928665161, 'eval/precision_macro': 0.4044913419913419, 'test/recall_weighted': 0.380952380952381, 'eval/accuracy': 0.36, 'eval/recall_weighted': 0.36, 'test/loss': 22.312737812310623, 'test/f1_macro': 0.3154046673286991, 'eval/precision_weighted': 0.4259740259740259}","{'n_neighbours': 1, 'trial.number': 6}",atomic-shadow-133,KNeighbours,['TfIdf']
1197,"{'split': 10, 'test/f1_weighted': 0.290200138026225, 'eval/precision_micro': 0.44, 'eval/loss': 1.2885286144160266, 'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603, 'eval/recall_weighted': 0.44, 'test/precision_micro': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_macro': 0.25, 'test/precision_macro': 0.11507936507936509, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.15760869565217392, 'test/f1_micro': 0.4603174603174603, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.44, '_wandb': {'runtime': 1}, 'test/loss': 1.3302066853563077, 'eval/accuracy': 0.44, 'eval/precision_weighted': 0.1936, 'eval/precision_macro': 0.11, 'test/recall_weighted': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, '_step': 20, '_runtime': 3.3995513916015625, '_timestamp': 1704214836.8463924}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 54, 'dt_min_samples_leaf': 79}",skilled-sponge-132,DecisionTree,['BoW']
1198,"{'test/recall_micro': 0.5079365079365079, 'eval/precision_micro': 0.48, 'test/precision_weighted': 0.35837742504409176, 'test/precision_macro': 0.21944444444444444, '_runtime': 2.721285343170166, 'eval/loss': 1.3088549567407273, 'test/f1_micro': 0.5079365079365079, 'eval/precision_macro': 0.23214285714285715, 'test/recall_weighted': 0.5079365079365079, 'eval/f1_macro': 0.2760989010989011, 'eval/f1_micro': 0.48, '_wandb': {'runtime': 1}, 'test/loss': 1.2689644340816222, 'eval/accuracy': 0.48, 'eval/precision_weighted': 0.3028571428571428, '_step': 20, 'split': 10, '_timestamp': 1704214833.8673244, 'eval/recall_macro': 0.35, 'eval/recall_micro': 0.48, 'eval/f1_weighted': 0.3679120879120879, 'test/precision_micro': 0.5079365079365079, 'test/accuracy': 0.5079365079365079, 'test/f1_macro': 0.2623626373626374, 'test/f1_weighted': 0.4193267050409908, 'test/recall_macro': 0.3295454545454546, 'eval/recall_weighted': 0.48}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 9, 'dt_min_samples_leaf': 60}",ethereal-snowball-131,DecisionTree,['TfIdf']
1199,"{'test/precision_micro': 0.4603174603174603, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.15760869565217392, 'test/recall_macro': 0.25, 'test/recall_weighted': 0.4603174603174603, '_step': 20, 'eval/f1_macro': 0.1527777777777778, 'eval/precision_micro': 0.44, '_runtime': 2.6360268592834473, 'test/loss': 1.2854266288838343, 'test/accuracy': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/precision_macro': 0.11507936507936509, 'eval/precision_weighted': 0.1936, 'split': 10, '_timestamp': 1704214829.590552, 'test/recall_micro': 0.4603174603174603, '_wandb': {'runtime': 1}, 'test/f1_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'eval/recall_weighted': 0.44, 'test/f1_weighted': 0.290200138026225, 'eval/recall_micro': 0.44, 'test/precision_weighted': 0.21189216427311663, 'eval/loss': 1.290462308510823, 'eval/recall_macro': 0.25, 'eval/accuracy': 0.44}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 53, 'dt_min_samples_leaf': 90}",confused-bush-129,DecisionTree,['BoW']
1200,"{'eval/loss': 16.10874047621313, 'eval/recall_micro': 0.48, 'test/recall_micro': 0.4444444444444444, 'eval/recall_weighted': 0.48, 'eval/f1_micro': 0.48, 'eval/f1_weighted': 0.462121212121212, 'test/recall_macro': 0.29632867132867136, 'eval/precision_macro': 0.4583333333333333, 'test/precision_macro': 0.3249458874458875, 'test/accuracy': 0.4444444444444444, 'test/f1_macro': 0.29974747474747476, 'test/f1_weighted': 0.4534391534391534, '_step': 20, 'split': 10, '_runtime': 2.6785905361175537, 'test/loss': 15.194226291321971, 'eval/recall_macro': 0.4708333333333333, '_wandb': {'runtime': 1}, '_timestamp': 1704214829.8728805, 'eval/accuracy': 0.48, 'eval/precision_micro': 0.48, 'test/precision_micro': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'eval/f1_macro': 0.45643939393939387, 'eval/precision_weighted': 0.45866666666666667, 'test/precision_weighted': 0.47732426303854875}","{'n_neighbours': 2, 'trial.number': 5}",devout-star-130,KNeighbours,['TfIdf']
1201,"{'test/accuracy': 0.36507936507936506, 'eval/recall_micro': 0.4, 'test/precision_micro': 0.36507936507936506, '_timestamp': 1704216075.8691654, 'split': 10, '_wandb': {'runtime': 1248}, 'test/f1_weighted': 0.32842531625944177, 'test/precision_macro': 0.2375, 'test/recall_weighted': 0.36507936507936506, 'eval/precision_weighted': 0.3714285714285714, '_step': 20, 'eval/f1_macro': 0.22849462365591397, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.24938556067588324, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, '_runtime': 1249.1821513175964, 'test/precision_weighted': 0.3277777777777778, 'eval/accuracy': 0.4, 'eval/f1_weighted': 0.29892473118279567, 'test/f1_micro': 0.36507936507936506, 'eval/recall_macro': 0.275, 'test/f1_macro': 0.22598438930798412, 'test/recall_micro': 0.36507936507936506, 'test/loss': 5.141000230115603, 'eval/precision_macro': 0.35714285714285715, 'eval/loss': 5.359924939129554}","{'n_neighbours': 6, 'trial.number': 0}",stellar-sea-128,KNeighbours,['pre-trained:microsoft/codebert-base']
1202,"{'eval/f1_macro': 0.2955316742081448, 'eval/precision_weighted': 0.3677922077922078, '_wandb': {'runtime': 1}, 'test/f1_micro': 0.3968253968253968, 'eval/precision_micro': 0.36, '_runtime': 3.1952433586120605, 'test/loss': 1.2422969218318398, 'eval/accuracy': 0.36, 'test/precision_micro': 0.3968253968253968, 'test/precision_weighted': 0.4362257495590828, '_step': 20, 'test/accuracy': 0.3968253968253968, 'test/f1_weighted': 0.4021164021164021, 'eval/recall_weighted': 0.36, 'split': 10, 'test/recall_micro': 0.3968253968253968, 'eval/precision_macro': 0.29545454545454547, 'eval/loss': 1.320691757922265, 'test/f1_macro': 0.2729885057471264, 'test/recall_macro': 0.3068181818181818, 'test/precision_macro': 0.2702777777777778, '_timestamp': 1704214826.1599064, 'eval/f1_micro': 0.36, 'eval/f1_weighted': 0.34900452488687783, 'eval/recall_macro': 0.325, 'eval/recall_micro': 0.36, 'test/recall_weighted': 0.3968253968253968}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 8, 'dt_min_samples_leaf': 69}",likely-voice-127,DecisionTree,['TfIdf']
1203,"{'split': 10, 'test/recall_weighted': 0.47619047619047616, '_step': 20, '_wandb': {'runtime': 1}, '_timestamp': 1704214823.7431524, 'test/accuracy': 0.47619047619047616, 'test/f1_micro': 0.47619047619047616, 'eval/precision_macro': 0.4903846153846154, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, 'eval/accuracy': 0.44, 'test/f1_macro': 0.3217703349282297, 'eval/recall_macro': 0.42916666666666664, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.47619047619047616, 'eval/f1_weighted': 0.4355354790137398, 'eval/precision_weighted': 0.45794871794871805, '_runtime': 3.1085004806518555, 'test/loss': 9.73875515762229, 'eval/f1_macro': 0.4457305979045109, 'eval/f1_micro': 0.44, 'test/f1_weighted': 0.4536847168426117, 'test/precision_macro': 0.3260052447552447, 'test/precision_micro': 0.47619047619047616, 'test/precision_weighted': 0.43825341325341327, 'eval/loss': 7.877320693876808, 'test/recall_macro': 0.32313519813519814}","{'n_neighbours': 3, 'trial.number': 4}",visionary-voice-126,KNeighbours,['TfIdf']
1204,"{'eval/f1_micro': 0.44, 'test/precision_macro': 0.11507936507936509, 'split': 10, 'test/f1_micro': 0.4603174603174603, 'eval/recall_micro': 0.44, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'test/accuracy': 0.4603174603174603, 'eval/precision_macro': 0.11, '_step': 20, 'eval/accuracy': 0.44, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.1527777777777778, 'eval/f1_weighted': 0.26888888888888896, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, '_runtime': 3.306070327758789, '_timestamp': 1704214821.9814105, 'test/recall_macro': 0.25, 'eval/precision_weighted': 0.1936, 'eval/loss': 1.2885286144160266, 'test/loss': 1.3302066853563077, 'test/f1_weighted': 0.290200138026225, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_weighted': 0.21189216427311663, 'test/f1_macro': 0.15760869565217392}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 52, 'dt_min_samples_leaf': 78}",swift-sun-125,DecisionTree,['BoW']
1205,"{'test/recall_micro': 0.492063492063492, 'eval/precision_macro': 0.475, 'test/precision_macro': 0.3331439393939394, '_runtime': 2.787405490875244, '_timestamp': 1704214819.0652044, '_step': 20, 'test/recall_macro': 0.32247474747474747, 'eval/precision_micro': 0.48, 'test/precision_micro': 0.492063492063492, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.48, 'test/accuracy': 0.492063492063492, 'test/f1_weighted': 0.44752456538170815, 'eval/precision_weighted': 0.4773333333333334, 'eval/f1_weighted': 0.4582424242424243, 'eval/recall_macro': 0.4125, 'test/f1_macro': 0.3167478354978355, 'eval/recall_micro': 0.48, 'eval/recall_weighted': 0.48, 'test/recall_weighted': 0.492063492063492, 'test/precision_weighted': 0.42777777777777776, 'test/f1_micro': 0.492063492063492, 'split': 10, 'eval/loss': 3.963058617729593, 'test/loss': 3.444921305363444, 'eval/f1_macro': 0.4221969696969697, 'eval/f1_micro': 0.48}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 7, 'dt_min_samples_leaf': 9}",woven-leaf-124,DecisionTree,['TfIdf']
1206,"{'test/f1_macro': 0.41867690058479534, 'eval/recall_weighted': 0.44, 'split': 10, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/accuracy': 0.5396825396825397, '_step': 20, 'test/f1_weighted': 0.53866146848603, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.544362153463536, 'test/loss': 5.431056829220902, 'test/recall_macro': 0.44493006993007, 'eval/loss': 3.855686537713073, 'eval/precision_macro': 0.375, 'test/recall_weighted': 0.5396825396825397, 'eval/f1_macro': 0.38333333333333336, 'eval/f1_weighted': 0.4013333333333334, 'eval/recall_macro': 0.4041666666666667, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.5396825396825397, 'test/precision_macro': 0.40694124423963135, 'eval/precision_weighted': 0.38, 'test/f1_micro': 0.5396825396825397, '_timestamp': 1704214816.2893493, '_wandb': {'runtime': 1}, 'test/precision_micro': 0.5396825396825397, '_runtime': 3.2460134029388428}","{'n_neighbours': 5, 'trial.number': 3}",iconic-mountain-123,KNeighbours,['TfIdf']
1207,"{'eval/recall_macro': 0.25, 'test/precision_macro': 0.11507936507936509, 'test/recall_weighted': 0.4603174603174603, '_runtime': 3.284559726715088, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.4603174603174603, '_timestamp': 1704214813.7289488, 'eval/precision_weighted': 0.1936, 'eval/loss': 1.290462308510823, 'test/loss': 1.2854266288838343, 'eval/accuracy': 0.44, 'eval/f1_weighted': 0.26888888888888896, 'test/f1_weighted': 0.290200138026225, '_step': 20, 'split': 10, '_wandb': {'runtime': 1}, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.21189216427311663, 'eval/recall_weighted': 0.44, 'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, 'test/recall_macro': 0.25, 'test/f1_macro': 0.15760869565217392, 'test/precision_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 51, 'dt_min_samples_leaf': 93}",glowing-armadillo-122,DecisionTree,['BoW']
1208,"{'test/precision_macro': 0.13095238095238096, 'split': 10, '_runtime': 3.311323404312134, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.36011904761904767, 'eval/recall_micro': 0.4, 'eval/recall_weighted': 0.4, 'eval/precision_micro': 0.4, 'test/f1_macro': 0.17187500000000003, 'test/f1_micro': 0.5238095238095238, 'test/recall_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, 'eval/loss': 1.3126565071353458, 'test/loss': 1.2588970748241275, 'eval/f1_micro': 0.4000000000000001, 'test/precision_micro': 0.5238095238095238, '_step': 20, '_timestamp': 1704214811.3192945, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.14285714285714288, 'test/recall_macro': 0.25, 'eval/precision_weighted': 0.16, '_wandb': {'runtime': 1}, 'eval/recall_macro': 0.25, 'eval/precision_macro': 0.1, 'test/accuracy': 0.5238095238095238, 'test/precision_weighted': 0.27437641723356015}","{'dt_criterion': 'entropy', 'dt_max_depth': 19, 'trial.number': 6, 'dt_min_samples_leaf': 99}",effortless-tree-121,DecisionTree,['TfIdf']
1209,"{'test/accuracy': 0.47619047619047616, 'test/precision_macro': 0.3852813852813852, 'test/precision_weighted': 0.47392290249433106, '_runtime': 3.1973352432250977, 'test/recall_macro': 0.40646853146853146, 'test/precision_micro': 0.47619047619047616, 'test/f1_macro': 0.3887205387205387, 'eval/recall_weighted': 0.36, 'test/loss': 2.868362509295454, 'eval/loss': 2.6894043047971805, 'eval/f1_weighted': 0.30666666666666664, 'eval/recall_micro': 0.36, 'test/recall_weighted': 0.47619047619047616, 'eval/accuracy': 0.36, '_timestamp': 1704214808.7376833, 'eval/f1_macro': 0.29166666666666663, 'test/f1_micro': 0.47619047619047616, 'eval/recall_macro': 0.3375, 'eval/precision_micro': 0.36, 'eval/precision_weighted': 0.2674285714285714, 'eval/precision_macro': 0.2571428571428571, '_step': 20, 'split': 10, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.36, 'test/f1_weighted': 0.4713697824808935, 'test/recall_micro': 0.47619047619047616}","{'n_neighbours': 9, 'trial.number': 2}",vivid-rain-120,KNeighbours,['TfIdf']
1210,"{'eval/f1_micro': 0.44, 'eval/precision_weighted': 0.1936, 'test/precision_weighted': 0.21189216427311663, '_wandb': {'runtime': 2}, '_runtime': 3.582430839538574, 'eval/f1_macro': 0.1527777777777778, 'test/recall_micro': 0.4603174603174603, '_step': 20, 'eval/recall_micro': 0.44, 'split': 10, 'eval/f1_weighted': 0.26888888888888896, 'eval/precision_macro': 0.11, 'eval/loss': 1.2885286144160266, 'test/f1_micro': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'test/loss': 1.3302066853563077, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.11507936507936509, '_timestamp': 1704214805.78818, 'eval/accuracy': 0.44, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.44, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'test/f1_weighted': 0.290200138026225, 'eval/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 50, 'dt_min_samples_leaf': 69}",clear-valley-119,DecisionTree,['BoW']
1211,"{'eval/loss': 3.9628721367755526, 'test/recall_macro': 0.2598484848484849, 'test/precision_macro': 0.18596491228070175, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.44, 'eval/recall_weighted': 0.44, 'eval/recall_macro': 0.30833333333333335, 'split': 10, 'test/f1_micro': 0.5079365079365079, 'test/recall_micro': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, 'eval/precision_weighted': 0.2914285714285714, '_timestamp': 1704214803.1144884, 'eval/f1_micro': 0.44, 'test/f1_weighted': 0.3820105820105821, 'test/accuracy': 0.5079365079365079, 'test/precision_micro': 0.5079365079365079, 'test/f1_macro': 0.20555555555555555, 'eval/f1_weighted': 0.32825806451612904, 'eval/recall_micro': 0.44, 'eval/precision_macro': 0.23214285714285715, '_runtime': 3.311610460281372, 'test/loss': 2.3105613572986297, 'eval/f1_macro': 0.24516129032258063, '_step': 20, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.31662489557226403}","{'dt_criterion': 'gini', 'dt_max_depth': 3, 'trial.number': 5, 'dt_min_samples_leaf': 6}",deft-spaceship-118,DecisionTree,['TfIdf']
1212,"{'_step': 20, 'eval/f1_macro': 0.35559640522875813, 'test/precision_macro': 0.30423789173789173, '_runtime': 3.2128422260284424, 'test/f1_micro': 0.380952380952381, 'eval/precision_macro': 0.4044913419913419, 'eval/precision_weighted': 0.4259740259740259, 'eval/loss': 23.067938169034974, 'test/loss': 22.312737812310623, 'eval/recall_micro': 0.36, '_wandb': {'runtime': 1}, '_timestamp': 1704214801.2986145, 'test/precision_micro': 0.380952380952381, 'test/precision_weighted': 0.42327816216705105, 'test/accuracy': 0.380952380952381, 'test/f1_weighted': 0.36928563547232857, 'eval/f1_weighted': 0.3628431372549019, 'split': 10, 'eval/accuracy': 0.36, 'eval/recall_macro': 0.37083333333333335, 'eval/f1_micro': 0.36, 'test/f1_macro': 0.3154046673286991, 'eval/precision_micro': 0.36, 'eval/recall_weighted': 0.36, 'test/recall_weighted': 0.380952380952381, 'test/recall_macro': 0.3997668997668997, 'test/recall_micro': 0.380952380952381}","{'n_neighbours': 1, 'trial.number': 1}",colorful-oath-117,KNeighbours,['TfIdf']
1213,"{'eval/f1_micro': 0.44, 'test/f1_weighted': 0.290200138026225, 'eval/recall_macro': 0.25, '_wandb': {'runtime': 1}, '_runtime': 3.240788459777832, 'test/accuracy': 0.4603174603174603, 'eval/precision_macro': 0.11, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.1936, '_step': 20, 'eval/f1_macro': 0.1527777777777778, 'test/precision_weighted': 0.21189216427311663, 'eval/f1_weighted': 0.26888888888888896, 'test/precision_micro': 0.4603174603174603, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.25, 'split': 10, 'test/loss': 1.3302066853563077, 'eval/accuracy': 0.44, 'test/f1_micro': 0.4603174603174603, 'test/precision_macro': 0.11507936507936509, 'eval/loss': 1.2885286144160266, 'test/f1_macro': 0.15760869565217392, 'test/recall_micro': 0.4603174603174603, '_timestamp': 1704214797.2217124, 'eval/precision_micro': 0.44, 'test/recall_weighted': 0.4603174603174603}","{'dt_criterion': 'gini', 'dt_max_depth': 11, 'trial.number': 49, 'dt_min_samples_leaf': 86}",cool-silence-116,DecisionTree,['BoW']
1214,"{'test/f1_macro': 0.3217703349282297, 'test/recall_macro': 0.32313519813519814, 'eval/precision_micro': 0.44, 'eval/loss': 7.877320693876808, 'test/recall_weighted': 0.47619047619047616, '_wandb': {'runtime': 1}, 'eval/precision_weighted': 0.45794871794871805, '_step': 20, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/precision_micro': 0.47619047619047616, 'split': 10, 'test/f1_weighted': 0.4536847168426117, 'test/precision_weighted': 0.43825341325341327, 'test/f1_micro': 0.47619047619047616, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.47619047619047616, 'test/precision_macro': 0.3260052447552447, '_timestamp': 1704214794.3635046, 'eval/recall_macro': 0.42916666666666664, 'eval/precision_macro': 0.4903846153846154, 'eval/recall_weighted': 0.44, '_runtime': 1.8774187564849856, 'eval/f1_macro': 0.4457305979045109, 'test/accuracy': 0.47619047619047616, 'eval/f1_weighted': 0.4355354790137398, 'test/loss': 9.73875515762229}","{'n_neighbours': 3, 'trial.number': 0}",lyric-field-114,KNeighbours,['TfIdf']
1215,"{'test/recall_macro': 0.3295454545454546, 'test/precision_micro': 0.5079365079365079, 'test/f1_macro': 0.2623626373626374, 'eval/precision_macro': 0.23214285714285715, 'test/recall_weighted': 0.5079365079365079, 'split': 10, 'test/precision_macro': 0.21944444444444444, 'eval/recall_micro': 0.48, '_step': 20, '_runtime': 4.4255383014678955, 'eval/f1_macro': 0.2760989010989011, 'eval/f1_micro': 0.48, 'test/accuracy': 0.5079365079365079, 'eval/accuracy': 0.48, 'test/recall_micro': 0.5079365079365079, 'eval/precision_weighted': 0.3028571428571428, 'eval/loss': 1.3088549567407273, 'test/f1_weighted': 0.4193267050409908, 'test/loss': 1.2689644340816222, '_timestamp': 1704214794.2316363, 'test/precision_weighted': 0.35837742504409176, 'eval/recall_weighted': 0.48, '_wandb': {'runtime': 1}, 'test/f1_micro': 0.5079365079365079, 'eval/f1_weighted': 0.3679120879120879, 'eval/recall_macro': 0.35, 'eval/precision_micro': 0.48}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 4, 'dt_min_samples_leaf': 45}",atomic-cosmos-114,DecisionTree,['TfIdf']
1216,"{'eval/loss': 1.312828991102543, 'eval/f1_macro': 0.22126436781609193, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.4444444444444444, 'test/precision_weighted': 0.2748210395269219, 'test/f1_macro': 0.23695652173913043, 'eval/recall_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/loss': 1.3138032633831536, 'test/accuracy': 0.4444444444444444, 'test/f1_weighted': 0.3369220151828847, 'eval/recall_macro': 0.28181818181818186, 'eval/precision_macro': 0.18253968253968253, 'split': 10, '_wandb': {'runtime': 1}, '_runtime': 2.7729358673095703, 'eval/f1_weighted': 0.3094252873563218, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.4444444444444444, '_step': 20, 'test/precision_micro': 0.4444444444444444, '_timestamp': 1704214786.588209, 'eval/accuracy': 0.4, 'test/recall_micro': 0.4444444444444444, 'eval/precision_weighted': 0.25269841269841264, 'test/recall_macro': 0.29780564263322884, 'test/precision_macro': 0.20098039215686275}","{'dt_criterion': 'entropy', 'dt_max_depth': 18, 'trial.number': 48, 'dt_min_samples_leaf': 61}",warm-salad-113,DecisionTree,['BoW']
1217,"{'test/loss': 9.722190844116115, 'eval/precision_macro': 0.4362179487179487, 'test/recall_weighted': 0.492063492063492, 'eval/precision_weighted': 0.4632820512820512, '_step': 20, 'test/accuracy': 0.492063492063492, 'test/f1_micro': 0.492063492063492, 'eval/recall_macro': 0.3875, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.492063492063492, 'test/precision_micro': 0.492063492063492, '_timestamp': 1704214785.9628654, '_wandb': {'runtime': 2}, 'test/precision_macro': 0.4084887334887335, 'split': 10, '_runtime': 3.352112293243408, 'test/f1_macro': 0.4052631578947368, 'eval/f1_weighted': 0.43825120772946863, 'test/f1_weighted': 0.5028125870231134, 'eval/recall_weighted': 0.44, 'test/precision_weighted': 0.5169114835781502, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'eval/precision_micro': 0.44, 'eval/loss': 13.450594123804338, 'eval/f1_macro': 0.3984903381642512, 'test/recall_macro': 0.4055555555555555}","{'dt_criterion': 'entropy', 'dt_max_depth': 14, 'trial.number': 3, 'dt_min_samples_leaf': 6}",efficient-elevator-112,DecisionTree,['TfIdf']
1218,"{'test/recall_micro': 0.4603174603174603, 'test/recall_macro': 0.2921717171717172, '_timestamp': 1704214778.9391837, 'eval/accuracy': 0.52, 'eval/f1_macro': 0.3915360501567398, 'eval/f1_weighted': 0.4431849529780564, 'test/accuracy': 0.4603174603174603, 'test/f1_weighted': 0.4053534457261166, 'eval/recall_macro': 0.4125, 'split': 10, 'eval/precision_micro': 0.52, 'test/precision_macro': 0.2830710955710956, 'eval/precision_weighted': 0.4934736842105263, 'eval/loss': 2.554340924752472, 'test/f1_micro': 0.4603174603174603, 'eval/precision_macro': 0.5184210526315789, 'test/precision_micro': 0.4603174603174603, '_runtime': 2.84883975982666, 'test/f1_macro': 0.26922172030867686, 'test/loss': 4.565661829663863, 'test/recall_weighted': 0.4603174603174603, 'eval/recall_weighted': 0.52, 'test/precision_weighted': 0.38186813186813184, '_step': 20, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.52, 'eval/recall_micro': 0.52}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 2, 'dt_min_samples_leaf': 9}",robust-frog-111,DecisionTree,['TfIdf']
1219,"{'eval/accuracy': 0.4, 'test/f1_macro': 0.23695652173913043, 'test/precision_macro': 0.20098039215686275, 'test/loss': 1.3138032633831536, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.2748210395269219, '_step': 20, 'split': 10, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.29780564263322884, 'test/precision_micro': 0.4444444444444444, 'test/accuracy': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, '_timestamp': 1704214778.8608549, 'eval/f1_weighted': 0.3094252873563218, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.4444444444444444, 'eval/loss': 1.312828991102543, 'eval/f1_macro': 0.22126436781609193, 'eval/recall_macro': 0.28181818181818186, 'eval/precision_weighted': 0.25269841269841264, '_runtime': 3.217343807220459, 'test/f1_weighted': 0.3369220151828847, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.4444444444444444, 'eval/precision_macro': 0.18253968253968253}","{'dt_criterion': 'gini', 'dt_max_depth': 13, 'trial.number': 47, 'dt_min_samples_leaf': 50}",fresh-eon-110,DecisionTree,['BoW']
1220,"{'test/recall_weighted': 0.4603174603174603, 'split': 10, '_runtime': 2.6721737384796143, 'test/loss': 1.3302066853563077, 'eval/f1_macro': 0.1527777777777778, '_timestamp': 1704214771.8701177, 'test/f1_macro': 0.15760869565217392, 'eval/precision_macro': 0.11, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.1936, 'eval/f1_micro': 0.44, 'eval/f1_weighted': 0.26888888888888896, 'test/f1_weighted': 0.290200138026225, 'eval/recall_micro': 0.44, 'test/precision_macro': 0.11507936507936509, 'test/precision_weighted': 0.21189216427311663, '_step': 20, 'eval/loss': 1.2885286144160266, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, '_wandb': {'runtime': 1}, 'test/accuracy': 0.4603174603174603, 'test/f1_micro': 0.4603174603174603, 'test/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 46, 'dt_min_samples_leaf': 74}",divine-morning-109,DecisionTree,['BoW']
1221,"{'split': 10, 'test/loss': 1.2432332134607214, '_wandb': {'runtime': 1}, '_runtime': 3.290827512741089, 'eval/f1_micro': 0.52, 'test/f1_weighted': 0.41675895164267257, 'eval/precision_weighted': 0.344, 'eval/loss': 1.2039205746998165, 'test/accuracy': 0.5238095238095238, 'test/recall_macro': 0.3196969696969697, 'test/recall_micro': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, 'test/f1_macro': 0.2686046511627907, '_step': 20, 'eval/f1_weighted': 0.3975757575757575, 'test/precision_weighted': 0.35010482180293495, 'eval/accuracy': 0.52, 'eval/precision_micro': 0.52, 'test/precision_macro': 0.23679245283018868, '_timestamp': 1704214771.2021866, 'eval/f1_macro': 0.303030303030303, 'eval/recall_micro': 0.52, 'eval/precision_macro': 0.275, 'test/precision_micro': 0.5238095238095238, 'test/f1_micro': 0.5238095238095238, 'eval/recall_macro': 0.375, 'eval/recall_weighted': 0.52}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 1, 'dt_min_samples_leaf': 13}",snowy-lake-108,DecisionTree,['TfIdf']
1222,"{'test/loss': 2.0498571978782323, 'eval/f1_macro': 0.22979797979797975, 'test/accuracy': 0.30158730158730157, 'test/recall_macro': 0.2375, 'eval/precision_micro': 0.28, '_step': 20, 'split': 10, 'test/recall_micro': 0.30158730158730157, 'eval/recall_weighted': 0.28, '_runtime': 1304.422677278519, '_timestamp': 1704216070.0637822, 'test/f1_micro': 0.30158730158730157, '_wandb': {'runtime': 1304}, 'eval/accuracy': 0.28, 'eval/recall_micro': 0.28, 'test/precision_macro': 0.218703007518797, 'test/precision_weighted': 0.29661057405418306, 'eval/loss': 4.427516064226626, 'eval/f1_weighted': 0.261010101010101, 'test/f1_weighted': 0.29770580007226394, 'eval/recall_macro': 0.24583333333333335, 'test/precision_micro': 0.30158730158730157, 'test/recall_weighted': 0.30158730158730157, 'eval/precision_weighted': 0.24533333333333332, 'eval/f1_micro': 0.28, 'test/f1_macro': 0.22644805048456165, 'eval/precision_macro': 0.21666666666666667}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 0, 'dt_min_samples_leaf': 11}",summer-water-107,DecisionTree,['pre-trained:microsoft/codebert-base']
1223,"{'test/f1_macro': 0.15760869565217392, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, '_step': 20, 'eval/accuracy': 0.44, 'eval/precision_weighted': 0.1936, '_timestamp': 1704214763.815631, 'eval/recall_macro': 0.25, 'eval/precision_macro': 0.11, 'eval/loss': 1.2885286144160266, 'eval/f1_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/loss': 1.3302066853563077, 'eval/f1_macro': 0.1527777777777778, 'test/f1_micro': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603, 'test/precision_macro': 0.11507936507936509, 'split': 10, 'test/f1_weighted': 0.290200138026225, '_wandb': {'runtime': 1}, 'eval/precision_micro': 0.44, '_runtime': 2.904557704925537, 'test/accuracy': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.25}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 45, 'dt_min_samples_leaf': 89}",stellar-bird-105,DecisionTree,['BoW']
1224,"{'eval/f1_weighted': 0.31738562091503275, '_step': 20, '_runtime': 1.8762667179107664, 'eval/recall_macro': 0.31666666666666665, 'test/recall_macro': 0.27954545454545454, 'test/recall_weighted': 0.4126984126984127, 'eval/accuracy': 0.36, 'eval/precision_weighted': 0.29727272727272724, 'test/precision_weighted': 0.3756613756613757, 'test/loss': 2.300232039223179, 'test/accuracy': 0.4126984126984127, 'eval/precision_macro': 0.2534090909090909, 'eval/recall_weighted': 0.36, 'test/precision_micro': 0.4126984126984127, 'split': 10, 'eval/f1_micro': 0.36, 'test/f1_weighted': 0.3908007647503446, 'eval/precision_micro': 0.36, 'test/precision_macro': 0.24166666666666667, '_wandb': {'runtime': 1}, 'eval/loss': 2.7052268916236, 'test/f1_micro': 0.4126984126984127, 'eval/recall_micro': 0.36, '_timestamp': 1704214764.2047477, 'eval/f1_macro': 0.273202614379085, 'test/f1_macro': 0.2556022408963585, 'test/recall_micro': 0.4126984126984127}","{'dt_criterion': 'gini', 'dt_max_depth': 14, 'trial.number': 0, 'dt_min_samples_leaf': 11}",youthful-morning-106,DecisionTree,['TfIdf']
1225,"{'_wandb': {'runtime': 1}, 'eval/recall_weighted': 0.4, 'eval/f1_macro': 0.22126436781609193, 'test/f1_macro': 0.23695652173913043, 'test/f1_weighted': 0.3369220151828847, 'test/precision_macro': 0.20098039215686275, 'test/precision_weighted': 0.2748210395269219, 'eval/loss': 1.312828991102543, 'eval/precision_macro': 0.18253968253968253, 'test/loss': 1.3138032633831536, '_timestamp': 1704214755.9095085, 'test/accuracy': 0.4444444444444444, 'eval/f1_weighted': 0.3094252873563218, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.29780564263322884, '_step': 20, 'eval/accuracy': 0.4, 'eval/recall_macro': 0.28181818181818186, '_runtime': 3.1943745613098145, 'test/precision_micro': 0.4444444444444444, 'split': 10, 'test/recall_micro': 0.4444444444444444, 'eval/precision_micro': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'eval/precision_weighted': 0.25269841269841264}","{'dt_criterion': 'gini', 'dt_max_depth': 16, 'trial.number': 44, 'dt_min_samples_leaf': 66}",helpful-sun-104,DecisionTree,['BoW']
1226,"{'eval/precision_micro': 0.44, 'test/recall_macro': 0.25, 'eval/recall_micro': 0.44, 'eval/recall_weighted': 0.44, 'split': 10, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'test/precision_macro': 0.11507936507936509, 'test/precision_weighted': 0.21189216427311663, 'eval/loss': 1.290462308510823, 'eval/f1_micro': 0.44, 'eval/f1_weighted': 0.26888888888888896, 'test/f1_weighted': 0.290200138026225, 'eval/precision_weighted': 0.1936, '_runtime': 3.226878881454468, 'test/precision_micro': 0.4603174603174603, '_wandb': {'runtime': 1}, 'test/recall_weighted': 0.4603174603174603, '_step': 20, 'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, 'eval/precision_macro': 0.11, 'test/loss': 1.2854266288838343, 'test/f1_macro': 0.15760869565217392, 'test/f1_micro': 0.4603174603174603, '_timestamp': 1704214747.7260268}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 43, 'dt_min_samples_leaf': 99}",valiant-bee-103,DecisionTree,['BoW']
1227,"{'eval/accuracy': 0.44, 'eval/precision_micro': 0.44, 'eval/f1_weighted': 0.26888888888888896, 'eval/precision_macro': 0.11, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_weighted': 0.1936, '_wandb': {'runtime': 1}, 'test/recall_micro': 0.4603174603174603, 'test/loss': 1.3302066853563077, 'eval/recall_macro': 0.25, '_timestamp': 1704214738.8644705, 'eval/f1_micro': 0.44, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.25, '_step': 20, '_runtime': 2.5775434970855713, 'test/precision_macro': 0.11507936507936509, 'eval/loss': 1.2885286144160266, 'test/f1_micro': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, 'split': 10, 'eval/f1_macro': 0.1527777777777778, 'test/f1_weighted': 0.290200138026225, 'eval/recall_weighted': 0.44}","{'dt_criterion': 'gini', 'dt_max_depth': 8, 'trial.number': 42, 'dt_min_samples_leaf': 85}",devoted-universe-102,DecisionTree,['BoW']
1228,"{'eval/loss': 1.290462308510823, 'test/f1_weighted': 0.290200138026225, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.25, 'test/precision_micro': 0.4603174603174603, '_step': 20, '_wandb': {'runtime': 1}, '_timestamp': 1704214731.260577, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/accuracy': 0.4603174603174603, 'eval/precision_macro': 0.11, 'test/loss': 1.2854266288838343, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.1936, 'split': 10, 'eval/f1_macro': 0.1527777777777778, 'eval/recall_macro': 0.25, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.11507936507936509, 'test/recall_weighted': 0.4603174603174603, '_runtime': 3.154114007949829, 'test/f1_macro': 0.15760869565217392, 'test/precision_weighted': 0.21189216427311663, 'test/f1_micro': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_micro': 0.4603174603174603}","{'dt_criterion': 'gini', 'dt_max_depth': 11, 'trial.number': 41, 'dt_min_samples_leaf': 90}",faithful-breeze-101,DecisionTree,['BoW']
1229,"{'_runtime': 3.4928696155548096, 'eval/loss': 1.312828991102543, 'test/loss': 1.3138032633831536, 'eval/precision_weighted': 0.25269841269841264, '_timestamp': 1704214723.3266137, 'eval/f1_macro': 0.22126436781609193, 'eval/recall_micro': 0.4, '_step': 20, 'split': 10, 'test/recall_micro': 0.4444444444444444, 'eval/recall_weighted': 0.4, 'test/accuracy': 0.4444444444444444, 'test/f1_macro': 0.23695652173913043, 'eval/f1_weighted': 0.3094252873563218, 'eval/recall_macro': 0.28181818181818186, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.20098039215686275, 'test/recall_weighted': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, 'test/f1_weighted': 0.3369220151828847, 'eval/precision_macro': 0.18253968253968253, 'test/precision_micro': 0.4444444444444444, 'test/precision_weighted': 0.2748210395269219, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/recall_macro': 0.29780564263322884}","{'dt_criterion': 'gini', 'dt_max_depth': 15, 'trial.number': 40, 'dt_min_samples_leaf': 60}",dulcet-cosmos-100,DecisionTree,['BoW']
1230,"{'_timestamp': 1704214719.0834095, 'eval/loss': 1.4453569886166877, 'test/precision_weighted': 0.3982142857142857, '_wandb': {'runtime': 1}, 'eval/recall_macro': 0.3, 'eval/recall_weighted': 0.44, 'test/recall_micro': 0.5079365079365079, 'eval/precision_macro': 0.25, 'eval/precision_weighted': 0.3, 'test/loss': 1.258991439820828, 'test/accuracy': 0.5079365079365079, 'eval/f1_weighted': 0.32380952380952377, 'eval/precision_micro': 0.44, '_runtime': 2.770838499069214, 'eval/f1_micro': 0.44, 'test/f1_micro': 0.5079365079365079, 'test/precision_macro': 0.303125, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.23809523809523808, 'test/f1_macro': 0.2955359358933447, 'test/precision_micro': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, '_step': 20, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.3278817956237311, 'split': 10, 'test/f1_weighted': 0.4271390694111681}","{'rf_max_depth': 25, 'trial.number': 29}",astral-terrain-99,RandomForest,['BoW']
1231,"{'_step': 20, 'split': 10, 'test/loss': 1.3613630191050154, 'eval/precision_micro': 0.44, '_runtime': 2.641587257385254, 'test/accuracy': 0.4126984126984127, 'eval/recall_micro': 0.44, 'eval/f1_micro': 0.44, 'eval/loss': 1.369363388421602, 'eval/f1_weighted': 0.3727586206896551, 'test/precision_macro': 0.2113970588235294, 'eval/f1_macro': 0.3254310344827586, 'test/f1_weighted': 0.31627762215997507, 'eval/precision_macro': 0.3194444444444444, 'test/recall_weighted': 0.4126984126984127, '_wandb': {'runtime': 1}, '_timestamp': 1704214714.3519633, 'eval/precision_weighted': 0.3422222222222222, 'eval/recall_weighted': 0.44, 'test/f1_macro': 0.21274509803921568, 'test/f1_micro': 0.4126984126984127, 'test/recall_macro': 0.2574016022291884, 'test/recall_micro': 0.4126984126984127, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.3568181818181818, 'test/precision_micro': 0.4126984126984127, 'test/precision_weighted': 0.2781279178338002}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 39, 'dt_min_samples_leaf': 26}",brisk-bird-98,DecisionTree,['BoW']
1232,"{'_step': 20, 'split': 10, 'eval/loss': 1.2507985003687143, 'test/f1_micro': 0.5396825396825397, 'test/precision_macro': 0.44787549407114624, 'test/accuracy': 0.5396825396825397, 'eval/f1_weighted': 0.3825714285714286, 'test/recall_micro': 0.5396825396825397, 'test/precision_micro': 0.5396825396825397, 'test/f1_weighted': 0.47412176992008925, 'eval/recall_micro': 0.48, 'eval/precision_weighted': 0.5818181818181818, 'test/precision_weighted': 0.4832643202208421, 'eval/accuracy': 0.48, 'eval/f1_micro': 0.48, 'eval/recall_macro': 0.3541666666666667, 'eval/precision_macro': 0.6136363636363636, 'test/recall_weighted': 0.5396825396825397, 'test/loss': 1.2131690687952124, 'test/recall_macro': 0.38185906835100386, 'eval/precision_micro': 0.48, '_wandb': {'runtime': 2}, '_runtime': 3.4047582149505615, '_timestamp': 1704214711.46008, 'eval/f1_macro': 0.32767857142857143, 'test/f1_macro': 0.3683728036669213, 'eval/recall_weighted': 0.48}","{'rf_max_depth': 19, 'trial.number': 28}",neat-wave-97,RandomForest,['BoW']
1233,"{'_runtime': 3.237643003463745, 'eval/accuracy': 0.4, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.29780564263322884, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.4444444444444444, 'eval/loss': 1.307826154387776, '_timestamp': 1704214706.649504, 'test/f1_micro': 0.4444444444444444, 'eval/recall_macro': 0.28181818181818186, 'eval/precision_weighted': 0.25269841269841264, 'split': 10, 'test/f1_macro': 0.23695652173913043, 'test/recall_micro': 0.4444444444444444, 'test/precision_micro': 0.4444444444444444, 'eval/f1_macro': 0.22126436781609193, 'test/precision_macro': 0.20098039215686275, 'test/accuracy': 0.4444444444444444, 'eval/f1_weighted': 0.3094252873563218, 'test/precision_weighted': 0.2748210395269219, '_step': 20, 'test/loss': 1.3324346513875287, 'eval/precision_macro': 0.18253968253968253, 'eval/recall_weighted': 0.4, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.4000000000000001, 'test/f1_weighted': 0.3369220151828847}","{'dt_criterion': 'gini', 'dt_max_depth': 14, 'trial.number': 38, 'dt_min_samples_leaf': 37}",magic-dream-96,DecisionTree,['BoW']
1234,"{'_timestamp': 1704214703.3281517, 'test/accuracy': 0.492063492063492, 'eval/f1_weighted': 0.31139784946236554, 'eval/recall_macro': 0.3125, 'eval/recall_micro': 0.44, 'eval/precision_weighted': 0.2704761904761905, 'test/precision_weighted': 0.43858654572940287, 'split': 10, 'eval/accuracy': 0.44, '_step': 20, '_wandb': {'runtime': 2}, 'test/loss': 1.308384896916932, 'test/f1_micro': 0.492063492063492, 'eval/f1_macro': 0.2446236559139785, 'eval/loss': 1.2019355958768836, 'eval/precision_macro': 0.24404761904761904, 'test/precision_micro': 0.492063492063492, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.3639883047268396, 'test/recall_macro': 0.36968475073313783, 'test/recall_micro': 0.492063492063492, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.4136904761904762, '_runtime': 3.4862494468688965, 'test/f1_weighted': 0.4456390674377571, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.492063492063492}","{'rf_max_depth': 25, 'trial.number': 27}",rose-blaze-95,RandomForest,['BoW']
1235,"{'test/recall_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.11507936507936509, 'split': 10, 'test/f1_micro': 0.4603174603174603, 'test/recall_macro': 0.25, '_timestamp': 1704214698.4167955, 'test/f1_weighted': 0.290200138026225, 'eval/recall_micro': 0.44, 'eval/precision_weighted': 0.1936, 'test/precision_weighted': 0.21189216427311663, 'eval/loss': 1.2885286144160266, 'eval/f1_weighted': 0.26888888888888896, 'test/accuracy': 0.4603174603174603, 'eval/recall_macro': 0.25, '_step': 20, 'eval/f1_macro': 0.1527777777777778, 'eval/f1_micro': 0.44, 'eval/precision_macro': 0.11, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, '_runtime': 3.1994826793670654, 'test/loss': 1.3302066853563077, 'eval/accuracy': 0.44, 'test/f1_macro': 0.15760869565217392, 'eval/recall_weighted': 0.44, '_wandb': {'runtime': 1}}","{'dt_criterion': 'gini', 'dt_max_depth': 11, 'trial.number': 37, 'dt_min_samples_leaf': 73}",celestial-planet-94,DecisionTree,['BoW']
1236,"{'test/loss': 1.1424903168566327, 'test/accuracy': 0.492063492063492, 'eval/loss': 1.2474489771818529, 'eval/precision_macro': 0.3636363636363637, 'test/precision_micro': 0.492063492063492, 'test/recall_weighted': 0.492063492063492, 'eval/recall_macro': 0.375, 'eval/f1_macro': 0.32291666666666663, 'test/recall_macro': 0.3136772501691857, 'eval/accuracy': 0.48, 'eval/f1_weighted': 0.35666666666666663, 'test/f1_micro': 0.492063492063492, 'eval/recall_micro': 0.48, '_timestamp': 1704214694.3456993, 'split': 10, 'test/f1_macro': 0.2991718657159833, 'test/f1_weighted': 0.4183079629158059, 'eval/precision_micro': 0.48, 'test/precision_macro': 0.3550170068027211, '_step': 20, 'eval/precision_weighted': 0.3418181818181818, '_runtime': 3.4006543159484863, 'eval/f1_micro': 0.48, 'test/recall_micro': 0.492063492063492, 'eval/recall_weighted': 0.48, 'test/precision_weighted': 0.4149389914696037, '_wandb': {'runtime': 1}}","{'rf_max_depth': 22, 'trial.number': 26}",curious-oath-93,RandomForest,['BoW']
1237,"{'split': 10, 'eval/f1_micro': 0.44, 'eval/precision_macro': 0.11, 'test/precision_macro': 0.11507936507936509, 'eval/recall_micro': 0.44, '_runtime': 2.5387983322143555, 'test/loss': 1.2854266288838343, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'eval/recall_weighted': 0.44, 'eval/loss': 1.290462308510823, 'test/f1_weighted': 0.290200138026225, 'test/recall_macro': 0.25, 'test/f1_micro': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'eval/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, '_wandb': {'runtime': 1}, 'eval/precision_weighted': 0.1936, 'test/precision_weighted': 0.21189216427311663, '_step': 20, '_timestamp': 1704214689.5863383, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.1527777777777778}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 36, 'dt_min_samples_leaf': 98}",zany-universe-92,DecisionTree,['BoW']
1238,"{'_runtime': 3.686836242675781, 'eval/loss': 1.431073028763923, 'test/loss': 1.193307229949114, 'test/precision_macro': 0.30964285714285716, 'split': 10, 'test/accuracy': 0.5079365079365079, 'test/f1_macro': 0.2978395061728395, 'eval/recall_macro': 0.3625, 'test/recall_micro': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, 'test/f1_micro': 0.5079365079365079, 'eval/precision_weighted': 0.38, 'eval/f1_micro': 0.48, 'eval/f1_weighted': 0.37714285714285706, 'eval/recall_micro': 0.48, 'test/recall_macro': 0.3252382697947214, 'eval/precision_micro': 0.48, 'eval/recall_weighted': 0.48, 'test/precision_weighted': 0.3821315192743765, '_timestamp': 1704214684.3734562, 'eval/accuracy': 0.48, 'eval/f1_macro': 0.32142857142857145, 'test/precision_micro': 0.5079365079365079, '_wandb': {'runtime': 2}, '_step': 20, 'test/f1_weighted': 0.4195571232608269, 'eval/precision_macro': 0.375}","{'rf_max_depth': 31, 'trial.number': 25}",good-violet-91,RandomForest,['BoW']
1239,"{'_wandb': {'runtime': 2}, 'test/f1_micro': 0.4444444444444444, 'test/f1_macro': 0.23695652173913043, '_timestamp': 1704214682.5097969, 'eval/f1_macro': 0.22126436781609193, 'test/precision_macro': 0.20098039215686275, 'eval/precision_weighted': 0.25269841269841264, 'eval/loss': 1.312828991102543, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.2748210395269219, 'test/accuracy': 0.4444444444444444, 'test/loss': 1.3138032633831536, 'eval/f1_micro': 0.4000000000000001, 'test/f1_weighted': 0.3369220151828847, 'split': 10, '_runtime': 3.7320077419281006, 'eval/f1_weighted': 0.3094252873563218, 'eval/recall_macro': 0.28181818181818186, 'eval/recall_micro': 0.4, '_step': 20, 'eval/recall_weighted': 0.4, 'eval/precision_macro': 0.18253968253968253, 'test/recall_macro': 0.29780564263322884, 'test/recall_micro': 0.4444444444444444, 'test/precision_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'eval/accuracy': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 35, 'dt_min_samples_leaf': 65}",swift-totem-90,DecisionTree,['BoW']
1240,"{'_wandb': {'runtime': 2}, 'eval/f1_macro': 0.3035714285714286, 'test/f1_weighted': 0.4284853548011442, '_runtime': 3.425560712814331, '_timestamp': 1704214675.876201, 'test/loss': 1.724312417271355, 'test/recall_macro': 0.3337609970674487, 'test/f1_macro': 0.3011164274322169, 'test/recall_micro': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, 'test/precision_weighted': 0.379448881001676, '_step': 20, 'eval/f1_weighted': 0.36, 'split': 10, 'eval/loss': 1.2821402646781588, 'eval/recall_micro': 0.44, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.3533333333333333, 'eval/precision_macro': 0.3333333333333333, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.28610248447204967, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/accuracy': 0.5079365079365079, 'test/f1_micro': 0.5079365079365079, 'eval/recall_macro': 0.33749999999999997, 'test/precision_micro': 0.5079365079365079}","{'rf_max_depth': 22, 'trial.number': 24}",valiant-wind-89,RandomForest,['BoW']
1241,"{'_runtime': 3.2185542583465576, 'test/f1_micro': 0.4603174603174603, 'eval/recall_macro': 0.25, 'eval/precision_weighted': 0.1936, 'test/precision_weighted': 0.21189216427311663, '_step': 20, '_timestamp': 1704214673.6959584, 'test/f1_macro': 0.15760869565217392, 'eval/f1_weighted': 0.26888888888888896, 'eval/recall_micro': 0.44, 'test/recall_weighted': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, 'test/precision_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'test/precision_macro': 0.11507936507936509, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, 'split': 10, 'eval/accuracy': 0.44, 'eval/recall_weighted': 0.44, 'eval/loss': 1.2885286144160266, 'eval/f1_micro': 0.44, 'test/recall_macro': 0.25, 'test/loss': 1.3302066853563077, 'test/f1_weighted': 0.290200138026225}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 34, 'dt_min_samples_leaf': 86}",valiant-voice-88,DecisionTree,['BoW']
1242,"{'eval/recall_weighted': 0.52, '_step': 20, 'test/loss': 1.2303957849995268, 'test/recall_micro': 0.5396825396825397, 'eval/accuracy': 0.52, 'test/recall_macro': 0.3645527859237537, 'test/f1_weighted': 0.4524220133976231, 'eval/recall_micro': 0.52, 'eval/precision_weighted': 0.4838095238095238, 'split': 10, '_runtime': 2.8802857398986816, 'eval/f1_micro': 0.52, 'eval/precision_micro': 0.52, 'test/precision_weighted': 0.4392868258414476, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.3862903225806451, 'eval/precision_macro': 0.5357142857142857, 'eval/loss': 1.189540208611781, '_timestamp': 1704214667.0776618, 'test/recall_weighted': 0.5396825396825397, 'test/precision_macro': 0.4159663865546218, 'test/precision_micro': 0.5396825396825397, 'test/accuracy': 0.5396825396825397, 'test/f1_micro': 0.5396825396825397, 'eval/recall_macro': 0.4125, 'test/f1_macro': 0.3510716925351071, 'eval/f1_weighted': 0.42206451612903223}","{'rf_max_depth': 20, 'trial.number': 23}",gentle-shadow-87,RandomForest,['BoW']
1243,"{'eval/precision_micro': 0.44, 'test/precision_weighted': 0.21189216427311663, 'eval/f1_micro': 0.44, 'test/recall_micro': 0.4603174603174603, 'eval/precision_weighted': 0.1936, '_step': 20, 'test/loss': 1.3302066853563077, 'eval/accuracy': 0.44, 'test/recall_macro': 0.25, 'test/precision_macro': 0.11507936507936509, 'split': 10, '_wandb': {'runtime': 1}, 'test/accuracy': 0.4603174603174603, 'eval/recall_macro': 0.25, 'eval/f1_macro': 0.1527777777777778, 'test/f1_macro': 0.15760869565217392, 'test/f1_weighted': 0.290200138026225, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'eval/loss': 1.2885286144160266, '_timestamp': 1704214666.5920615, 'eval/f1_weighted': 0.26888888888888896, 'eval/recall_micro': 0.44, '_runtime': 3.379580497741699, 'test/f1_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'eval/recall_weighted': 0.44}","{'dt_criterion': 'entropy', 'dt_max_depth': 3, 'trial.number': 33, 'dt_min_samples_leaf': 76}",woven-terrain-86,DecisionTree,['BoW']
1244,"{'_wandb': {'runtime': 1}, 'test/recall_micro': 0.5555555555555556, 'test/precision_macro': 0.45217391304347826, 'test/recall_weighted': 0.5555555555555556, 'test/precision_weighted': 0.4915804002760525, '_runtime': 2.753163576126098, 'test/loss': 1.1989334289766838, 'eval/accuracy': 0.48, 'eval/precision_micro': 0.48, 'eval/recall_weighted': 0.48, '_timestamp': 1704214658.7687905, 'eval/f1_micro': 0.48, 'test/f1_micro': 0.5555555555555556, 'eval/precision_macro': 0.381578947368421, 'test/accuracy': 0.5555555555555556, 'test/f1_weighted': 0.48933324171419407, 'eval/f1_macro': 0.32717569786535305, 'eval/f1_weighted': 0.38633825944170774, 'eval/precision_weighted': 0.3905263157894737, 'eval/loss': 1.175814260680234, '_step': 20, 'split': 10, 'test/f1_macro': 0.37864357864357856, 'eval/recall_macro': 0.3625, 'eval/recall_micro': 0.48, 'test/recall_macro': 0.3899235844800361, 'test/precision_micro': 0.5555555555555556}","{'rf_max_depth': 20, 'trial.number': 22}",sparkling-disco-85,RandomForest,['BoW']
1245,"{'test/recall_micro': 0.4444444444444444, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.25269841269841264, 'eval/f1_micro': 0.4000000000000001, 'eval/f1_weighted': 0.3094252873563218, 'eval/accuracy': 0.4, 'test/f1_micro': 0.4444444444444444, 'test/f1_weighted': 0.3369220151828847, 'eval/recall_macro': 0.28181818181818186, 'test/recall_macro': 0.29780564263322884, 'test/loss': 1.3138032633831536, '_timestamp': 1704214658.3879027, 'test/accuracy': 0.4444444444444444, 'test/precision_weighted': 0.2748210395269219, '_runtime': 3.3603646755218506, 'eval/loss': 1.312828991102543, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.20098039215686275, 'test/precision_micro': 0.4444444444444444, 'split': 10, 'eval/precision_macro': 0.18253968253968253, '_wandb': {'runtime': 2}, 'test/recall_weighted': 0.4444444444444444, 'test/f1_macro': 0.23695652173913043, '_step': 20, 'eval/f1_macro': 0.22126436781609193, 'eval/recall_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 32, 'dt_min_samples_leaf': 62}",dashing-bee-84,DecisionTree,['BoW']
1246,"{'_runtime': 2.5133965015411377, 'eval/recall_macro': 0.25, 'test/recall_weighted': 0.4603174603174603, 'eval/loss': 1.290462308510823, '_timestamp': 1704214649.3597264, 'eval/precision_micro': 0.44, 'test/f1_micro': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'test/precision_weighted': 0.21189216427311663, 'split': 10, '_wandb': {'runtime': 1}, 'test/loss': 1.2854266288838343, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.44, 'test/precision_micro': 0.4603174603174603, 'test/precision_macro': 0.11507936507936509, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'eval/precision_weighted': 0.1936, '_step': 20, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.1527777777777778, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'eval/f1_micro': 0.44, 'eval/f1_weighted': 0.26888888888888896, 'eval/recall_micro': 0.44}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 31, 'dt_min_samples_leaf': 100}",deft-yogurt-82,DecisionTree,['BoW']
1247,"{'test/recall_weighted': 0.5555555555555556, 'eval/precision_weighted': 0.4504761904761906, 'test/precision_weighted': 0.47427923550372536, '_wandb': {'runtime': 2}, 'eval/accuracy': 0.52, 'eval/f1_macro': 0.39938556067588327, 'test/f1_micro': 0.5555555555555556, 'eval/recall_micro': 0.52, 'eval/loss': 1.1239539905569904, 'test/accuracy': 0.5555555555555556, 'test/f1_weighted': 0.46307634164777023, 'eval/recall_macro': 0.425, 'test/precision_macro': 0.378061224489796, 'test/recall_macro': 0.35207534401082785, 'eval/precision_macro': 0.494047619047619, '_step': 20, 'test/f1_macro': 0.31607142857142856, '_runtime': 3.4095473289489746, '_timestamp': 1704214651.2138264, 'eval/f1_weighted': 0.421874039938556, 'test/recall_micro': 0.5555555555555556, 'eval/recall_weighted': 0.52, 'split': 10, 'test/loss': 1.181160227912404, 'eval/f1_micro': 0.52, 'test/precision_micro': 0.5555555555555556, 'eval/precision_micro': 0.52}","{'rf_max_depth': 14, 'trial.number': 21}",polar-wind-83,RandomForest,['BoW']
1248,"{'eval/f1_micro': 0.52, 'test/f1_weighted': 0.3820909517112049, 'eval/recall_micro': 0.52, 'test/recall_weighted': 0.4603174603174603, 'test/recall_macro': 0.27785923753665687, 'split': 10, '_wandb': {'runtime': 1}, 'test/loss': 1.3036740191861655, 'eval/accuracy': 0.52, '_runtime': 2.852299451828003, 'test/f1_micro': 0.4603174603174603, 'eval/precision_weighted': 0.39719298245614026, 'test/f1_macro': 0.24789029535864976, 'eval/f1_weighted': 0.421576354679803, 'eval/precision_macro': 0.381578947368421, 'test/precision_macro': 0.24255952380952375, 'eval/recall_macro': 0.4125, 'test/recall_micro': 0.4603174603174603, 'eval/precision_micro': 0.52, 'test/precision_micro': 0.4603174603174603, 'eval/loss': 1.2126004202372878, 'eval/recall_weighted': 0.52, 'test/precision_weighted': 0.34136432350718066, '_step': 20, '_timestamp': 1704214644.1374805, 'eval/f1_macro': 0.36884236453201974, 'test/accuracy': 0.4603174603174603}","{'rf_max_depth': 28, 'trial.number': 20}",good-waterfall-81,RandomForest,['BoW']
1249,"{'eval/precision_macro': 0.3645833333333333, 'test/precision_macro': 0.5059523809523809, 'test/recall_weighted': 0.36507936507936506, 'eval/precision_weighted': 0.4016666666666666, 'eval/recall_macro': 0.3, 'eval/precision_micro': 0.48, 'test/precision_micro': 0.36507936507936506, '_step': 20, '_runtime': 3.1169326305389404, 'eval/f1_micro': 0.48, 'test/accuracy': 0.36507936507936506, 'eval/f1_weighted': 0.3432380952380953, 'eval/f1_macro': 0.24047619047619048, 'test/recall_macro': 0.2771135265700483, 'test/precision_weighted': 0.44784580498866217, 'split': 10, '_timestamp': 1704214643.8628125, 'eval/recall_micro': 0.48, 'test/recall_micro': 0.36507936507936506, '_wandb': {'runtime': 1}, 'eval/loss': 14.409041236332, 'test/loss': 16.815419427757142, 'eval/accuracy': 0.48, 'test/f1_macro': 0.22917968107841524, 'test/f1_micro': 0.36507936507936506, 'test/f1_weighted': 0.2663180500431857, 'eval/recall_weighted': 0.48}","{'smoothing': 0.8887678414994261, 'trial.number': 4}",noble-water-80,Bernolli,['TfIdf']
1250,"{'eval/precision_macro': 0.18253968253968253, 'test/recall_weighted': 0.4444444444444444, 'test/loss': 1.3138032633831536, 'eval/f1_weighted': 0.3094252873563218, 'eval/precision_weighted': 0.25269841269841264, 'test/precision_weighted': 0.2748210395269219, '_step': 20, 'eval/precision_micro': 0.4, 'eval/accuracy': 0.4, 'eval/recall_macro': 0.28181818181818186, 'test/recall_macro': 0.29780564263322884, 'eval/recall_weighted': 0.4, '_wandb': {'runtime': 1}, 'test/f1_weighted': 0.3369220151828847, 'test/precision_micro': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, '_timestamp': 1704214641.8778503, 'eval/loss': 1.312828991102543, 'eval/f1_macro': 0.22126436781609193, 'test/f1_macro': 0.23695652173913043, 'test/recall_micro': 0.4444444444444444, 'test/precision_macro': 0.20098039215686275, '_runtime': 3.2726263999938965, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.4444444444444444, 'eval/recall_micro': 0.4, 'split': 10}","{'dt_criterion': 'entropy', 'dt_max_depth': 7, 'trial.number': 30, 'dt_min_samples_leaf': 44}",iconic-frost-79,DecisionTree,['BoW']
1251,"{'eval/f1_weighted': 0.3432380952380953, 'eval/accuracy': 0.48, 'eval/f1_macro': 0.24047619047619048, 'eval/recall_weighted': 0.48, 'eval/loss': 14.582718462264268, 'eval/recall_macro': 0.3, 'eval/recall_micro': 0.48, 'test/recall_micro': 0.36507936507936506, 'eval/precision_macro': 0.3645833333333333, 'test/precision_micro': 0.36507936507936506, '_wandb': {'runtime': 1}, '_timestamp': 1704214637.629529, 'eval/f1_micro': 0.48, 'test/recall_macro': 0.2771135265700483, 'test/f1_weighted': 0.2663180500431857, '_step': 20, 'split': 10, 'test/accuracy': 0.36507936507936506, 'eval/precision_micro': 0.48, 'test/precision_macro': 0.5059523809523809, 'test/precision_weighted': 0.44784580498866217, '_runtime': 3.3619539737701416, 'test/f1_macro': 0.22917968107841524, 'test/f1_micro': 0.36507936507936506, 'test/recall_weighted': 0.36507936507936506, 'test/loss': 16.9752831768753, 'eval/precision_weighted': 0.4016666666666666}","{'smoothing': 0.9002972885569909, 'trial.number': 3}",happy-fire-77,Bernolli,['TfIdf']
1252,"{'_wandb': {'runtime': 1}, 'eval/loss': 1.4377249704440118, 'eval/f1_micro': 0.44, '_step': 20, 'split': 10, 'test/loss': 1.171999589630134, 'test/f1_micro': 0.5079365079365079, 'test/recall_macro': 0.31057551319648097, 'test/precision_macro': 0.38181818181818183, 'eval/f1_weighted': 0.2992941176470588, 'eval/precision_macro': 0.3541666666666667, 'eval/recall_weighted': 0.44, '_timestamp': 1704214637.5695152, 'test/recall_micro': 0.5079365079365079, 'test/precision_micro': 0.5079365079365079, 'eval/recall_macro': 0.3125, 'eval/precision_micro': 0.44, 'test/recall_weighted': 0.5079365079365079, 'eval/accuracy': 0.44, '_runtime': 2.769104242324829, 'test/accuracy': 0.5079365079365079, 'test/precision_weighted': 0.41818181818181815, 'eval/f1_macro': 0.24705882352941175, 'test/f1_macro': 0.2854877680459076, 'test/f1_weighted': 0.40483141812045464, 'eval/recall_micro': 0.44, 'eval/precision_weighted': 0.3266666666666667}","{'rf_max_depth': 16, 'trial.number': 19}",lemon-moon-78,RandomForest,['BoW']
1253,"{'_runtime': 2.589794635772705, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'eval/precision_micro': 0.44, 'test/accuracy': 0.4126984126984127, 'test/f1_micro': 0.4126984126984127, 'test/f1_macro': 0.21274509803921568, 'test/f1_weighted': 0.31627762215997507, 'test/precision_macro': 0.2113970588235294, 'test/recall_micro': 0.4126984126984127, '_wandb': {'runtime': 1}, 'eval/recall_micro': 0.44, 'eval/precision_macro': 0.3194444444444444, '_step': 20, 'test/loss': 1.3521139946410932, 'eval/f1_macro': 0.3254310344827586, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.3422222222222222, 'test/precision_weighted': 0.2781279178338002, '_timestamp': 1704214634.6906946, 'test/precision_micro': 0.4126984126984127, 'split': 10, 'eval/loss': 1.2951034378459425, 'eval/f1_weighted': 0.3727586206896551, 'eval/recall_macro': 0.3568181818181818, 'test/recall_macro': 0.2574016022291884, 'test/recall_weighted': 0.4126984126984127}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 29, 'dt_min_samples_leaf': 34}",absurd-monkey-76,DecisionTree,['BoW']
1254,"{'eval/recall_micro': 0.44, 'split': 10, 'test/accuracy': 0.380952380952381, 'eval/f1_weighted': 0.3697695852534562, 'eval/precision_macro': 0.3625, 'test/precision_weighted': 0.4471210706504824, 'test/f1_weighted': 0.3046700003221743, 'test/recall_macro': 0.3079106280193237, 'test/recall_micro': 0.380952380952381, '_wandb': {'runtime': 1}, '_runtime': 2.885530710220337, 'eval/f1_micro': 0.44, 'test/precision_macro': 0.5181372549019607, 'test/f1_micro': 0.380952380952381, 'test/recall_weighted': 0.380952380952381, 'eval/recall_macro': 0.30454545454545456, 'test/precision_micro': 0.380952380952381, '_step': 20, 'test/loss': 10.26532543556258, 'test/f1_macro': 0.2789053876010398, 'eval/precision_weighted': 0.398, 'eval/loss': 7.814492322365441, 'eval/accuracy': 0.44, 'eval/recall_weighted': 0.44, '_timestamp': 1704214628.8952918, 'eval/f1_macro': 0.28801843317972353, 'eval/precision_micro': 0.44}","{'smoothing': 0.5121113645454545, 'trial.number': 2}",stoic-snow-74,Bernolli,['TfIdf']
1255,"{'eval/precision_micro': 0.44, 'split': 10, '_timestamp': 1704214629.2858129, 'test/f1_macro': 0.231237322515213, 'test/f1_micro': 0.5079365079365079, 'eval/recall_weighted': 0.44, 'test/loss': 1.2085184048506603, 'eval/f1_macro': 0.22294372294372297, 'test/recall_micro': 0.5079365079365079, 'eval/precision_macro': 0.23369565217391303, '_runtime': 2.796534776687622, 'eval/recall_micro': 0.44, 'test/precision_macro': 0.21726190476190477, 'test/recall_weighted': 0.5079365079365079, '_step': 20, 'eval/loss': 1.3442612048031526, 'test/accuracy': 0.5079365079365079, 'test/precision_micro': 0.5079365079365079, 'eval/f1_weighted': 0.2995670995670996, 'test/recall_macro': 0.2873900293255132, 'test/precision_weighted': 0.32180650037792896, 'eval/precision_weighted': 0.27391304347826084, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.44, 'test/f1_weighted': 0.38043723236421007, 'eval/recall_macro': 0.3, 'eval/accuracy': 0.44}","{'rf_max_depth': 11, 'trial.number': 18}",hearty-voice-75,RandomForest,['BoW']
1256,"{'test/precision_weighted': 0.2748210395269219, 'test/f1_micro': 0.4444444444444444, 'eval/precision_micro': 0.4, 'eval/f1_weighted': 0.3094252873563218, '_wandb': {'runtime': 1}, '_runtime': 3.1803669929504395, 'test/f1_macro': 0.23695652173913043, 'test/precision_micro': 0.4444444444444444, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.22126436781609193, 'test/loss': 1.3138032633831536, 'eval/f1_micro': 0.4000000000000001, 'test/recall_micro': 0.4444444444444444, '_step': 20, 'split': 10, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.18253968253968253, 'test/accuracy': 0.4444444444444444, 'eval/recall_macro': 0.28181818181818186, 'eval/precision_weighted': 0.25269841269841264, 'test/precision_macro': 0.20098039215686275, '_timestamp': 1704214627.069938, 'test/recall_macro': 0.29780564263322884, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.4444444444444444, 'eval/loss': 1.312828991102543, 'test/f1_weighted': 0.3369220151828847}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 28, 'dt_min_samples_leaf': 51}",expert-wildflower-73,DecisionTree,['BoW']
1257,"{'_step': 20, 'test/recall_micro': 0.4603174603174603, 'eval/recall_weighted': 0.52, 'test/precision_macro': 0.3248792270531401, 'test/recall_weighted': 0.4603174603174603, 'test/precision_weighted': 0.3766582317306955, '_wandb': {'runtime': 2}, '_runtime': 3.463754653930664, 'test/loss': 1.1555605273327538, 'eval/f1_macro': 0.404147465437788, 'eval/recall_macro': 0.4125, 'eval/precision_macro': 0.6190476190476191, 'eval/f1_weighted': 0.4363502304147465, 'test/f1_weighted': 0.39967017109874253, 'eval/precision_weighted': 0.5504761904761906, 'eval/loss': 1.174363007635672, 'test/f1_macro': 0.3012987012987013, 'test/precision_micro': 0.4603174603174603, 'split': 10, 'test/accuracy': 0.4603174603174603, 'eval/accuracy': 0.52, 'eval/f1_micro': 0.52, 'eval/recall_micro': 0.52, 'test/recall_macro': 0.31570747800586507, 'eval/precision_micro': 0.52, '_timestamp': 1704214623.3384156, 'test/f1_micro': 0.4603174603174603}","{'rf_max_depth': 23, 'trial.number': 17}",dulcet-disco-72,RandomForest,['BoW']
1258,"{'eval/precision_macro': 0.358695652173913, 'eval/loss': 11.907874516992862, 'test/f1_micro': 0.380952380952381, 'eval/recall_macro': 0.2772727272727273, '_runtime': 3.2431881427764893, 'test/recall_macro': 0.29794685990338166, '_wandb': {'runtime': 1}, 'eval/recall_weighted': 0.44, 'split': 10, 'test/loss': 14.570350325260598, 'test/accuracy': 0.380952380952381, 'test/recall_weighted': 0.380952380952381, '_step': 20, '_timestamp': 1704214620.7109911, 'test/recall_micro': 0.380952380952381, 'eval/precision_weighted': 0.391304347826087, 'eval/f1_macro': 0.2303921568627451, 'eval/f1_micro': 0.44, 'test/precision_macro': 0.5492424242424243, 'test/precision_weighted': 0.481962481962482, 'test/f1_macro': 0.2599691974691975, 'test/f1_weighted': 0.29091014805300525, 'eval/precision_micro': 0.44, 'test/precision_micro': 0.380952380952381, 'eval/accuracy': 0.44, 'eval/f1_weighted': 0.3254901960784313, 'eval/recall_micro': 0.44}","{'smoothing': 0.7402000063015053, 'trial.number': 1}",brisk-glade-71,Bernolli,['TfIdf']
1259,"{'test/f1_micro': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, 'eval/precision_micro': 0.44, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, '_wandb': {'runtime': 1}, 'eval/loss': 1.2885286144160266, 'test/f1_weighted': 0.290200138026225, 'eval/precision_macro': 0.11, 'test/precision_macro': 0.11507936507936509, '_timestamp': 1704214618.7052855, 'test/f1_macro': 0.15760869565217392, 'test/accuracy': 0.4603174603174603, 'eval/f1_macro': 0.1527777777777778, 'eval/f1_micro': 0.44, 'eval/precision_weighted': 0.1936, 'split': 10, 'test/recall_micro': 0.4603174603174603, 'eval/recall_macro': 0.25, '_runtime': 3.238825559616089, 'eval/f1_weighted': 0.26888888888888896, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.44, 'test/loss': 1.3302066853563077, 'eval/accuracy': 0.44, '_step': 20}","{'dt_criterion': 'entropy', 'dt_max_depth': 13, 'trial.number': 27, 'dt_min_samples_leaf': 83}",happy-pine-70,DecisionTree,['BoW']
1260,"{'eval/f1_macro': 0.14705882352941177, 'split': 10, '_timestamp': 1704214614.1082263, 'test/precision_micro': 0.5079365079365079, 'eval/loss': 1.3173060424686849, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.4, '_runtime': 2.869593620300293, 'test/f1_macro': 0.20833333333333331, 'test/f1_micro': 0.5079365079365079, 'test/f1_weighted': 0.3571428571428571, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.42063492063492064, 'test/loss': 1.2301331238982325, 'test/recall_weighted': 0.5079365079365079, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.375, 'eval/precision_weighted': 0.16666666666666669, 'eval/f1_weighted': 0.23529411764705885, 'test/recall_macro': 0.2727272727272727, '_wandb': {'runtime': 1}, 'test/accuracy': 0.5079365079365079, 'test/recall_micro': 0.5079365079365079, 'eval/precision_macro': 0.10416666666666669, '_step': 20}","{'rf_max_depth': 5, 'trial.number': 16}",rosy-snow-69,RandomForest,['BoW']
1261,"{'eval/recall_macro': 0.3, 'test/loss': 17.20724151402069, 'test/f1_weighted': 0.2744949494949495, '_timestamp': 1704214611.9205704, 'eval/precision_weighted': 0.4016666666666666, 'eval/precision_micro': 0.48, 'test/accuracy': 0.380952380952381, 'test/recall_macro': 0.2879830917874396, 'eval/f1_macro': 0.24047619047619048, 'eval/f1_weighted': 0.3432380952380953, 'test/precision_macro': 0.5504385964912281, '_runtime': 2.06048846244812, 'eval/loss': 14.815351411026075, 'test/precision_weighted': 0.4995822890559733, '_step': 20, '_wandb': {'runtime': 1}, 'test/recall_micro': 0.380952380952381, 'test/f1_macro': 0.2350378787878788, 'eval/recall_micro': 0.48, 'eval/recall_weighted': 0.48, 'split': 10, 'eval/precision_macro': 0.3645833333333333, 'test/f1_micro': 0.380952380952381, 'test/precision_micro': 0.380952380952381, 'test/recall_weighted': 0.380952380952381, 'eval/accuracy': 0.48, 'eval/f1_micro': 0.48}","{'smoothing': 0.9169334463775012, 'trial.number': 0}",classic-brook-67,Bernolli,['TfIdf']
1262,"{'eval/recall_macro': 0.25, 'test/precision_micro': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, '_runtime': 2.9781885147094727, 'eval/accuracy': 0.44, 'test/f1_macro': 0.15760869565217392, 'test/f1_weighted': 0.290200138026225, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.11507936507936509, 'eval/f1_weighted': 0.26888888888888896, 'test/loss': 1.3302066853563077, '_timestamp': 1704214611.9527194, 'eval/f1_macro': 0.1527777777777778, 'test/f1_micro': 0.4603174603174603, 'test/recall_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, 'eval/loss': 1.2885286144160266, 'eval/f1_micro': 0.44, 'eval/precision_weighted': 0.1936, '_step': 20, 'eval/recall_micro': 0.44, 'split': 10, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.11, 'test/recall_weighted': 0.4603174603174603, '_wandb': {'runtime': 1}, 'test/accuracy': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 26, 'dt_min_samples_leaf': 80}",gentle-gorge-68,DecisionTree,['BoW']
1263,"{'_wandb': {'runtime': 1}, 'eval/loss': 1.312939816736084, 'test/loss': 1.2587773266360467, 'eval/accuracy': 0.44, 'test/accuracy': 0.492063492063492, 'eval/recall_macro': 0.3125, 'test/recall_micro': 0.492063492063492, 'eval/f1_weighted': 0.2992941176470588, 'eval/precision_weighted': 0.3266666666666667, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.3025109970674487, '_step': 20, 'split': 10, '_runtime': 3.275517702102661, '_timestamp': 1704214607.5490718, 'eval/f1_micro': 0.44, 'test/f1_weighted': 0.3906629318394024, 'eval/recall_weighted': 0.44, 'test/f1_micro': 0.492063492063492, 'eval/precision_macro': 0.3541666666666667, 'eval/precision_micro': 0.44, 'test/recall_weighted': 0.492063492063492, 'eval/f1_macro': 0.24705882352941175, 'test/f1_macro': 0.2735294117647059, 'test/precision_macro': 0.33796296296296297, 'test/precision_micro': 0.492063492063492, 'test/precision_weighted': 0.3768371546149324}","{'rf_max_depth': 11, 'trial.number': 15}",kind-pine-66,RandomForest,['BoW']
1264,"{'test/loss': 1.3138032633831536, 'eval/f1_macro': 0.22126436781609193, 'test/f1_macro': 0.23695652173913043, 'eval/f1_weighted': 0.3094252873563218, 'test/recall_micro': 0.4444444444444444, 'eval/precision_macro': 0.18253968253968253, 'test/precision_macro': 0.20098039215686275, '_step': 20, 'split': 10, 'eval/recall_macro': 0.28181818181818186, 'test/recall_macro': 0.29780564263322884, 'test/f1_micro': 0.4444444444444444, 'test/precision_weighted': 0.2748210395269219, 'eval/precision_weighted': 0.25269841269841264, '_wandb': {'runtime': 1}, 'test/recall_weighted': 0.4444444444444444, 'eval/loss': 1.312828991102543, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_weighted': 0.4, '_timestamp': 1704214603.7417629, 'test/accuracy': 0.4444444444444444, 'eval/recall_micro': 0.4, '_runtime': 3.0573859214782715, 'test/f1_weighted': 0.3369220151828847, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.4444444444444444}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 25, 'dt_min_samples_leaf': 53}",firm-fog-65,DecisionTree,['BoW']
1265,"{'eval/f1_macro': 0.25625, 'eval/precision_macro': 0.3636363636363637, 'test/precision_weighted': 0.5148983570036202, 'test/recall_weighted': 0.492063492063492, 'test/recall_micro': 0.492063492063492, '_timestamp': 1704214598.8720767, 'eval/accuracy': 0.44, 'test/recall_macro': 0.2758290096999774, 'test/f1_micro': 0.492063492063492, 'eval/precision_weighted': 0.3418181818181818, 'eval/recall_macro': 0.3125, '_wandb': {'runtime': 1}, 'test/loss': 1.227644437962169, 'test/f1_weighted': 0.3787363430220574, 'eval/f1_weighted': 0.314, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, '_step': 20, 'eval/loss': 1.2109542511621587, 'test/f1_macro': 0.23620129870129877, 'eval/recall_micro': 0.44, 'test/precision_macro': 0.4605263157894737, 'split': 10, '_runtime': 2.816962718963623, 'test/accuracy': 0.492063492063492, 'eval/f1_micro': 0.44, 'test/precision_micro': 0.492063492063492}","{'rf_max_depth': 18, 'trial.number': 14}",cool-oath-64,RandomForest,['BoW']
1266,"{'_step': 20, 'eval/f1_macro': 0.1527777777777778, 'test/recall_weighted': 0.4603174603174603, 'split': 10, 'test/loss': 1.3302066853563077, 'eval/f1_micro': 0.44, 'eval/recall_weighted': 0.44, '_wandb': {'runtime': 1}, 'eval/recall_micro': 0.44, 'test/precision_weighted': 0.21189216427311663, 'eval/accuracy': 0.44, 'test/f1_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'test/precision_macro': 0.11507936507936509, 'eval/loss': 1.2885286144160266, 'eval/precision_weighted': 0.1936, 'eval/recall_macro': 0.25, 'test/accuracy': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/f1_weighted': 0.290200138026225, '_runtime': 3.212019443511963, '_timestamp': 1704214595.6881964, 'test/f1_macro': 0.15760869565217392, 'test/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, 'test/precision_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 6, 'trial.number': 24, 'dt_min_samples_leaf': 71}",fancy-oath-63,DecisionTree,['BoW']
1267,"{'eval/precision_macro': 0.09782608695652174, 'eval/precision_micro': 0.36, 'test/precision_weighted': 0.32180650037792896, 'eval/accuracy': 0.36, 'test/f1_macro': 0.208128078817734, 'eval/f1_micro': 0.36, 'test/loss': 1.2601401026931882, 'eval/f1_macro': 0.13636363636363635, 'eval/recall_micro': 0.36, 'test/recall_macro': 0.26466275659824046, '_runtime': 3.326061964035034, 'test/recall_weighted': 0.492063492063492, 'test/recall_micro': 0.492063492063492, 'test/f1_micro': 0.492063492063492, 'test/f1_weighted': 0.36429744311517714, 'split': 10, 'eval/f1_weighted': 0.21818181818181817, 'eval/recall_macro': 0.225, 'test/precision_macro': 0.21726190476190477, 'test/precision_micro': 0.492063492063492, 'eval/precision_weighted': 0.1565217391304348, '_timestamp': 1704214591.1707458, '_wandb': {'runtime': 1}, 'test/accuracy': 0.492063492063492, 'eval/recall_weighted': 0.36, '_step': 20, 'eval/loss': 1.3171769409646163}","{'rf_max_depth': 8, 'trial.number': 13}",glowing-waterfall-62,RandomForest,['BoW']
1268,"{'_timestamp': 1704214587.4674911, 'eval/precision_weighted': 0.1936, '_runtime': 3.266862154006958, 'eval/f1_micro': 0.44, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_macro': 0.11, 'eval/recall_weighted': 0.44, 'test/precision_weighted': 0.21189216427311663, '_wandb': {'runtime': 1}, 'test/accuracy': 0.4603174603174603, 'test/f1_micro': 0.4603174603174603, 'test/f1_weighted': 0.290200138026225, 'test/f1_macro': 0.15760869565217392, 'test/loss': 1.2854266288838343, 'eval/f1_macro': 0.1527777777777778, 'test/precision_macro': 0.11507936507936509, '_step': 20, 'eval/f1_weighted': 0.26888888888888896, 'eval/recall_micro': 0.44, 'eval/precision_micro': 0.44, 'split': 10, 'test/recall_micro': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, 'eval/loss': 1.290462308510823, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.25}","{'dt_criterion': 'entropy', 'dt_max_depth': 8, 'trial.number': 23, 'dt_min_samples_leaf': 100}",lyric-butterfly-61,DecisionTree,['BoW']
1269,"{'_timestamp': 1704214584.0703192, 'test/loss': 1.2006507399267712, 'eval/f1_macro': 0.31182795698924726, 'eval/precision_macro': 0.35714285714285715, 'eval/precision_micro': 0.44, 'test/f1_weighted': 0.44652036469775264, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.34446903902549064, 'eval/recall_weighted': 0.44, 'eval/loss': 1.288388986275551, 'eval/recall_macro': 0.35, 'eval/precision_weighted': 0.3314285714285714, '_runtime': 2.7151002883911133, 'eval/accuracy': 0.44, 'test/accuracy': 0.5238095238095238, 'test/recall_weighted': 0.5238095238095238, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.3330368745938921, 'test/f1_micro': 0.5238095238095238, 'eval/f1_weighted': 0.3389247311827957, 'test/precision_weighted': 0.47330687830687834, 'test/precision_macro': 0.4420833333333334, 'test/precision_micro': 0.5238095238095238, '_step': 20, 'split': 10, '_wandb': {'runtime': 1}, 'test/recall_micro': 0.5238095238095238}","{'rf_max_depth': 15, 'trial.number': 12}",good-sunset-59,RandomForest,['BoW']
1270,"{'eval/accuracy': 0.48, 'eval/recall_macro': 0.4833333333333333, '_runtime': 1260.986243724823, 'test/f1_weighted': 0.1090455607618079, 'test/recall_macro': 0.1699660633484163, 'eval/precision_weighted': 0.5733333333333334, '_wandb': {'runtime': 1260}, 'eval/f1_weighted': 0.4957142857142857, 'test/recall_micro': 0.14285714285714285, 'test/precision_weighted': 0.10176477417856727, 'test/precision_micro': 0.14285714285714285, 'eval/loss': 13.547130018129948, 'test/loss': 20.45505881027776, '_timestamp': 1704215843.7435868, 'eval/f1_micro': 0.48, 'test/f1_macro': 0.12486651411136536, 'eval/precision_micro': 0.48, '_step': 20, 'test/f1_micro': 0.14285714285714285, 'test/recall_weighted': 0.14285714285714285, 'split': 10, 'eval/f1_macro': 0.4633928571428571, 'test/accuracy': 0.14285714285714285, 'eval/precision_macro': 0.5, 'eval/recall_weighted': 0.48, 'test/precision_macro': 0.11611807732497388, 'eval/recall_micro': 0.48}","{'smoothing': 0.8127564755815958, 'trial.number': 0}",ancient-capybara-60,Bernolli,['pre-trained:microsoft/codebert-base']
1271,"{'test/f1_weighted': 0.290200138026225, 'split': 10, 'test/f1_macro': 0.15760869565217392, 'eval/f1_macro': 0.1527777777777778, 'test/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, 'test/f1_micro': 0.4603174603174603, 'eval/recall_micro': 0.44, '_wandb': {'runtime': 1}, 'eval/f1_weighted': 0.26888888888888896, 'eval/recall_weighted': 0.44, '_step': 20, '_runtime': 2.9078242778778076, 'eval/loss': 1.2885286144160266, '_timestamp': 1704214578.7048612, 'eval/f1_micro': 0.44, 'test/accuracy': 0.4603174603174603, 'eval/precision_macro': 0.11, 'test/precision_macro': 0.11507936507936509, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_weighted': 0.1936, 'test/loss': 1.3302066853563077, 'test/precision_weighted': 0.21189216427311663, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.25, 'eval/precision_micro': 0.44, 'test/precision_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 22, 'dt_min_samples_leaf': 83}",wobbly-feather-58,DecisionTree,['BoW']
1272,"{'_step': 20, '_timestamp': 1704214576.5316026, 'eval/f1_micro': 0.52, 'eval/precision_macro': 0.4232456140350877, 'eval/precision_micro': 0.52, 'eval/precision_weighted': 0.423859649122807, 'test/f1_macro': 0.25406504065040647, 'test/f1_micro': 0.492063492063492, 'eval/f1_weighted': 0.42919540229885056, 'test/precision_macro': 0.24439775910364148, 'test/recall_weighted': 0.492063492063492, 'test/precision_weighted': 0.3449824374194122, 'split': 10, 'test/accuracy': 0.492063492063492, 'test/f1_weighted': 0.3942444186346626, 'test/recall_macro': 0.29398826979472137, 'test/recall_micro': 0.492063492063492, '_wandb': {'runtime': 2}, 'eval/recall_weighted': 0.52, 'eval/loss': 1.1332059636284029, 'eval/accuracy': 0.52, 'eval/f1_macro': 0.3807471264367816, '_runtime': 3.412135601043701, 'eval/recall_macro': 0.4125, 'eval/recall_micro': 0.52, 'test/loss': 1.3016339952650275, 'test/precision_micro': 0.492063492063492}","{'rf_max_depth': 32, 'trial.number': 11}",glowing-vortex-57,RandomForest,['BoW']
1273,"{'_step': 20, 'test/f1_weighted': 0.290200138026225, 'split': 10, '_wandb': {'runtime': 1}, 'eval/f1_weighted': 0.26888888888888896, 'eval/loss': 1.2885286144160266, 'eval/f1_micro': 0.44, 'test/recall_micro': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, 'eval/precision_weighted': 0.1936, 'eval/f1_macro': 0.1527777777777778, 'test/accuracy': 0.4603174603174603, 'test/recall_macro': 0.25, 'test/precision_weighted': 0.21189216427311663, 'test/loss': 1.3302066853563077, '_timestamp': 1704214570.6722903, 'test/f1_micro': 0.4603174603174603, 'eval/recall_macro': 0.25, 'test/recall_weighted': 0.4603174603174603, 'eval/accuracy': 0.44, 'eval/precision_macro': 0.11, '_runtime': 3.2784423828125, 'test/f1_macro': 0.15760869565217392, 'eval/recall_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_macro': 0.11507936507936509}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 21, 'dt_min_samples_leaf': 77}",solar-snowball-56,DecisionTree,['BoW']
1274,"{'eval/accuracy': 0.36, 'test/accuracy': 0.5079365079365079, 'eval/f1_weighted': 0.21176470588235297, 'test/f1_weighted': 0.3816782468467862, '_wandb': {'runtime': 2}, 'test/recall_micro': 0.5079365079365079, '_timestamp': 1704214567.3049216, 'test/f1_micro': 0.5079365079365079, 'test/precision_micro': 0.5079365079365079, 'eval/recall_macro': 0.225, 'test/recall_macro': 0.29591275659824046, 'test/precision_macro': 0.33764367816091956, 'test/precision_weighted': 0.3841452289728152, 'test/f1_macro': 0.25245540975878056, 'eval/precision_micro': 0.36, 'test/recall_weighted': 0.5079365079365079, '_step': 20, 'eval/precision_macro': 0.09375, 'split': 10, 'eval/loss': 1.3627976168014642, 'test/loss': 1.2218140846902257, 'eval/recall_weighted': 0.36, '_runtime': 3.489872694015503, 'eval/f1_macro': 0.13235294117647062, 'eval/f1_micro': 0.36, 'eval/recall_micro': 0.36, 'eval/precision_weighted': 0.15}","{'rf_max_depth': 5, 'trial.number': 10}",ruby-salad-55,RandomForest,['BoW']
1275,"{'_timestamp': 1704214562.230347, 'test/accuracy': 0.4444444444444444, 'test/precision_weighted': 0.2748210395269219, '_runtime': 3.170197010040283, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.22126436781609193, 'eval/recall_macro': 0.28181818181818186, 'test/recall_micro': 0.4444444444444444, 'test/precision_micro': 0.4444444444444444, 'split': 10, 'test/recall_weighted': 0.4444444444444444, 'eval/precision_weighted': 0.25269841269841264, 'eval/recall_micro': 0.4, 'test/f1_macro': 0.23695652173913043, 'eval/precision_micro': 0.4, '_step': 20, 'eval/f1_weighted': 0.3094252873563218, 'test/recall_macro': 0.29780564263322884, 'eval/recall_weighted': 0.4, 'test/f1_micro': 0.4444444444444444, 'test/precision_macro': 0.20098039215686275, 'eval/f1_micro': 0.4000000000000001, 'test/f1_weighted': 0.3369220151828847, 'test/loss': 1.3138032633831536, 'eval/accuracy': 0.4, 'eval/precision_macro': 0.18253968253968253, 'eval/loss': 1.312828991102543}","{'dt_criterion': 'gini', 'dt_max_depth': 5, 'trial.number': 20, 'dt_min_samples_leaf': 53}",woven-sound-54,DecisionTree,['BoW']
1276,"{'_wandb': {'runtime': 1}, 'eval/recall_micro': 0.48, 'test/recall_macro': 0.3039772727272727, 'test/accuracy': 0.5238095238095238, 'test/f1_macro': 0.262618841832325, 'eval/precision_macro': 0.369047619047619, 'test/precision_macro': 0.3836206896551724, 'eval/loss': 1.220781232650013, 'test/recall_micro': 0.5238095238095238, 'eval/precision_micro': 0.48, 'eval/recall_weighted': 0.48, 'test/precision_micro': 0.5238095238095238, '_timestamp': 1704214558.9078617, 'eval/f1_macro': 0.3279569892473118, 'test/f1_micro': 0.5238095238095238, 'test/f1_weighted': 0.3950446557188131, 'test/precision_weighted': 0.41379310344827586, '_step': 20, '_runtime': 3.312443733215332, 'eval/recall_macro': 0.375, 'test/recall_weighted': 0.5238095238095238, 'eval/precision_weighted': 0.3504761904761905, 'eval/f1_weighted': 0.3647311827956989, 'split': 10, 'test/loss': 1.19631478528156, 'eval/accuracy': 0.48, 'eval/f1_micro': 0.48}","{'rf_max_depth': 11, 'trial.number': 9}",lilac-star-53,RandomForest,['BoW']
1277,"{'_runtime': 1235.7725236415863, 'test/f1_macro': 0.15, 'test/precision_micro': 0.42857142857142855, '_timestamp': 1704215788.7719016, 'eval/f1_macro': 0.14285714285714288, 'eval/precision_micro': 0.4, 'eval/accuracy': 0.4, 'eval/recall_macro': 0.25, 'eval/precision_weighted': 0.16, 'test/accuracy': 0.42857142857142855, 'test/f1_micro': 0.42857142857142855, 'test/recall_macro': 0.25, 'split': 10, 'eval/f1_micro': 0.4000000000000001, 'test/loss': 1.3003962200507857, 'eval/recall_weighted': 0.4, 'test/precision_weighted': 0.1836734693877551, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_micro': 0.42857142857142855, 'test/precision_macro': 0.10714285714285714, 'test/recall_weighted': 0.42857142857142855, '_step': 20, '_wandb': {'runtime': 1235}, 'eval/loss': 1.3647135481834798, 'test/f1_weighted': 0.2571428571428571, 'eval/recall_micro': 0.4, 'eval/precision_macro': 0.1}",{'trial.number': 0},gallant-wood-52,LogisticRegression,['pre-trained:microsoft/codebert-base']
1278,"{'eval/precision_macro': 0.11, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.1527777777777778, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_weighted': 0.21189216427311663, '_step': 20, 'split': 10, 'test/recall_weighted': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'test/precision_macro': 0.11507936507936509, 'test/f1_micro': 0.4603174603174603, 'eval/precision_weighted': 0.1936, '_runtime': 3.013996124267578, 'test/loss': 1.3302066853563077, 'eval/f1_weighted': 0.26888888888888896, 'test/f1_weighted': 0.290200138026225, 'eval/loss': 1.2885286144160266, 'test/accuracy': 0.4603174603174603, 'eval/precision_micro': 0.44, '_timestamp': 1704214553.642776, 'eval/recall_macro': 0.25, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.4603174603174603, 'test/recall_macro': 0.25, 'test/precision_micro': 0.4603174603174603}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 19, 'dt_min_samples_leaf': 72}",efficient-capybara-51,DecisionTree,['BoW']
1279,"{'test/recall_macro': 0.25, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.24212648022171832, 'eval/accuracy': 0.4, 'eval/recall_micro': 0.4, 'eval/precision_weighted': 0.16, '_wandb': {'runtime': 1}, 'eval/recall_macro': 0.25, 'eval/f1_micro': 0.4000000000000001, 'test/accuracy': 0.492063492063492, 'test/precision_micro': 0.492063492063492, 'eval/loss': 1.3427724454554917, 'eval/f1_macro': 0.14285714285714288, '_timestamp': 1704214550.5661275, 'test/f1_weighted': 0.3245525160418777, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.123015873015873, '_step': 20, '_runtime': 3.2122225761413574, 'eval/f1_weighted': 0.22857142857142865, 'test/recall_weighted': 0.492063492063492, 'eval/precision_macro': 0.1, 'test/f1_macro': 0.16489361702127658, 'test/recall_micro': 0.492063492063492, 'test/f1_micro': 0.492063492063492, 'split': 10, 'test/loss': 1.2323318230606164}","{'rf_max_depth': 2, 'trial.number': 8}",hearty-paper-50,RandomForest,['BoW']
1280,"{'test/accuracy': 0.4603174603174603, '_step': 20, '_timestamp': 1704214545.578858, 'test/recall_macro': 0.25, 'split': 10, 'eval/recall_macro': 0.25, 'eval/f1_weighted': 0.26888888888888896, 'test/precision_macro': 0.11507936507936509, 'test/precision_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'eval/precision_micro': 0.44, 'eval/precision_weighted': 0.1936, '_runtime': 3.1573679447174072, 'test/f1_micro': 0.4603174603174603, 'eval/loss': 1.290462308510823, 'eval/f1_macro': 0.1527777777777778, 'test/recall_micro': 0.4603174603174603, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.4603174603174603, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.15760869565217392, 'eval/accuracy': 0.44, 'test/f1_weighted': 0.290200138026225, 'eval/recall_micro': 0.44, 'test/precision_weighted': 0.21189216427311663, '_wandb': {'runtime': 1}, 'test/loss': 1.2854266288838343}","{'dt_criterion': 'entropy', 'dt_max_depth': 12, 'trial.number': 18, 'dt_min_samples_leaf': 95}",quiet-hill-49,DecisionTree,['BoW']
1281,"{'_wandb': {'runtime': 1}, 'eval/precision_macro': 0.1, 'eval/recall_weighted': 0.4, '_step': 20, 'test/f1_weighted': 0.3245525160418777, 'test/precision_micro': 0.492063492063492, 'eval/precision_weighted': 0.16, '_runtime': 3.1650333404541016, 'eval/accuracy': 0.4, 'test/f1_micro': 0.492063492063492, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_macro': 0.25, 'test/loss': 1.238075594947665, 'eval/recall_micro': 0.4, 'eval/loss': 1.2944281513980451, 'test/recall_micro': 0.492063492063492, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.24212648022171832, 'eval/f1_macro': 0.14285714285714288, 'test/accuracy': 0.492063492063492, 'test/f1_macro': 0.16489361702127658, 'test/precision_macro': 0.123015873015873, '_timestamp': 1704214542.2119825, 'eval/f1_micro': 0.4000000000000001, 'test/recall_weighted': 0.492063492063492, 'split': 10, 'test/recall_macro': 0.25}","{'rf_max_depth': 2, 'trial.number': 7}",twilight-gorge-48,RandomForest,['BoW']
1282,"{'_wandb': {'runtime': 1}, 'test/f1_weighted': 0.3369220151828847, 'eval/recall_macro': 0.28181818181818186, 'eval/precision_weighted': 0.25269841269841264, 'split': 10, 'test/loss': 1.3138032633831536, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, '_step': 20, '_timestamp': 1704214537.396323, 'test/precision_macro': 0.20098039215686275, '_runtime': 3.193882942199707, 'eval/loss': 1.312828991102543, 'test/f1_micro': 0.4444444444444444, 'test/precision_micro': 0.4444444444444444, 'eval/f1_macro': 0.22126436781609193, 'test/accuracy': 0.4444444444444444, 'test/f1_macro': 0.23695652173913043, 'test/recall_macro': 0.29780564263322884, 'test/recall_micro': 0.4444444444444444, 'eval/precision_macro': 0.18253968253968253, 'test/recall_weighted': 0.4444444444444444, 'eval/f1_micro': 0.4000000000000001, 'test/precision_weighted': 0.2748210395269219, 'eval/recall_micro': 0.4, 'eval/accuracy': 0.4, 'eval/f1_weighted': 0.3094252873563218}","{'dt_criterion': 'gini', 'dt_max_depth': 8, 'trial.number': 17, 'dt_min_samples_leaf': 56}",snowy-water-47,DecisionTree,['BoW']
1283,"{'_step': 20, '_runtime': 2.9247806072235107, '_timestamp': 1704214533.7616715, 'test/precision_macro': 0.25416666666666665, 'eval/f1_micro': 0.4000000000000001, 'test/recall_micro': 0.5079365079365079, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.5079365079365079, 'eval/recall_macro': 0.25, 'test/recall_macro': 0.2727272727272727, 'eval/precision_weighted': 0.16, 'split': 10, 'eval/accuracy': 0.4, 'test/accuracy': 0.5079365079365079, 'test/f1_micro': 0.5079365079365079, 'test/recall_weighted': 0.5079365079365079, '_wandb': {'runtime': 1}, 'eval/loss': 1.3307087142495564, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, 'eval/f1_macro': 0.14285714285714288, 'eval/f1_weighted': 0.22857142857142865, 'test/f1_weighted': 0.3621140763997907, 'eval/precision_macro': 0.1, 'test/f1_macro': 0.20879120879120883, 'test/loss': 1.2453404367422602, 'test/precision_weighted': 0.3415343915343916}","{'rf_max_depth': 3, 'trial.number': 6}",misunderstood-universe-46,RandomForest,['BoW']
1284,"{'eval/f1_micro': 0.44, 'eval/precision_macro': 0.3194444444444444, 'eval/precision_weighted': 0.3422222222222222, 'test/recall_macro': 0.2574016022291884, 'test/precision_macro': 0.2113970588235294, '_step': 20, '_runtime': 2.761560440063477, 'eval/f1_macro': 0.3254310344827586, 'eval/accuracy': 0.44, 'eval/f1_weighted': 0.3727586206896551, 'test/recall_micro': 0.4126984126984127, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.2781279178338002, 'split': 10, 'test/precision_micro': 0.4126984126984127, 'test/loss': 1.409555423817716, 'eval/recall_micro': 0.44, 'test/accuracy': 0.4126984126984127, 'test/f1_macro': 0.21274509803921568, 'test/f1_micro': 0.4126984126984127, 'test/f1_weighted': 0.31627762215997507, 'eval/recall_macro': 0.3568181818181818, '_wandb': {'runtime': 1}, 'eval/loss': 1.272023166828556, '_timestamp': 1704214528.7135575, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.4126984126984127}","{'dt_criterion': 'entropy', 'dt_max_depth': 20, 'trial.number': 16, 'dt_min_samples_leaf': 31}",ruby-music-45,DecisionTree,['BoW']
1285,"{'eval/precision_macro': 0.381578947368421, 'test/precision_micro': 0.5238095238095238, 'test/f1_macro': 0.25967025998731763, 'test/f1_weighted': 0.4108463930911616, 'eval/f1_weighted': 0.4172906403940887, 'test/recall_micro': 0.5238095238095238, '_step': 20, 'test/loss': 1.2586694994081593, 'test/recall_weighted': 0.5238095238095238, 'eval/loss': 1.2365523157888645, 'eval/accuracy': 0.52, 'eval/f1_micro': 0.52, 'eval/precision_micro': 0.52, 'test/precision_macro': 0.2379807692307692, 'eval/precision_weighted': 0.383859649122807, 'split': 10, 'eval/f1_macro': 0.3777709359605912, 'eval/recall_macro': 0.425, 'test/precision_weighted': 0.34935897435897434, 'test/accuracy': 0.5238095238095238, 'eval/recall_micro': 0.52, 'test/recall_macro': 0.3101173020527859, '_runtime': 3.3142640590667725, '_timestamp': 1704214525.959248, 'eval/recall_weighted': 0.52, '_wandb': {'runtime': 2}, 'test/f1_micro': 0.5238095238095238}","{'rf_max_depth': 17, 'trial.number': 5}",lucky-plant-44,RandomForest,['BoW']
1286,"{'eval/precision_macro': 0.3522727272727273, 'eval/recall_weighted': 0.4, 'test/f1_micro': 0.380952380952381, 'eval/recall_micro': 0.4, 'test/accuracy': 0.380952380952381, 'eval/f1_weighted': 0.28900000000000003, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.24062500000000003, 'test/f1_macro': 0.1411764705882353, 'eval/recall_macro': 0.2875, 'eval/precision_micro': 0.4, 'eval/precision_weighted': 0.3236363636363636, '_wandb': {'runtime': 2}, '_timestamp': 1704214521.6563888, 'eval/loss': 1.2590952874713357, 'test/precision_macro': 0.09836065573770492, 'test/f1_weighted': 0.21512605042016805, 'test/recall_macro': 0.25, 'test/recall_micro': 0.380952380952381, 'test/recall_weighted': 0.380952380952381, 'test/precision_weighted': 0.14988290398126464, 'test/loss': 1.3780774750500386, 'eval/f1_micro': 0.4000000000000001, 'test/precision_micro': 0.380952380952381, '_step': 20, '_runtime': 3.363391876220703, 'split': 10}",{'trial.number': 0},efficient-resonance-42,LogisticRegression,['TfIdf']
1287,"{'eval/accuracy': 0.4, 'eval/precision_micro': 0.4, 'test/precision_micro': 0.4444444444444444, '_runtime': 2.6802589893341064, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_micro': 0.4, 'eval/precision_weighted': 0.25269841269841264, 'test/recall_micro': 0.4444444444444444, 'test/precision_macro': 0.20098039215686275, 'test/recall_weighted': 0.4444444444444444, 'eval/precision_macro': 0.18253968253968253, 'eval/recall_weighted': 0.4, 'eval/f1_macro': 0.22126436781609193, 'test/f1_macro': 0.23695652173913043, 'test/f1_weighted': 0.3369220151828847, 'eval/recall_macro': 0.28181818181818186, 'split': 10, 'eval/loss': 1.312828991102543, 'test/f1_micro': 0.4444444444444444, 'test/accuracy': 0.4444444444444444, 'eval/f1_weighted': 0.3094252873563218, 'test/loss': 1.3138032633831536, 'test/recall_macro': 0.29780564263322884, 'test/precision_weighted': 0.2748210395269219, '_step': 20, '_wandb': {'runtime': 1}, '_timestamp': 1704214520.384573}","{'dt_criterion': 'entropy', 'dt_max_depth': 5, 'trial.number': 15, 'dt_min_samples_leaf': 44}",smooth-dream-43,DecisionTree,['BoW']
1288,"{'test/recall_weighted': 0.47619047619047616, 'eval/precision_micro': 0.4, 'test/recall_micro': 0.47619047619047616, 'eval/precision_macro': 0.10416666666666669, 'test/precision_weighted': 0.373015873015873, 'split': 10, 'eval/f1_weighted': 0.23529411764705885, 'test/f1_weighted': 0.34888928521887325, 'test/recall_macro': 0.2651209677419355, 'eval/precision_weighted': 0.16666666666666669, 'test/f1_macro': 0.21847690387016228, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_micro': 0.4, 'eval/loss': 1.389790156211393, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.14705882352941177, 'test/precision_macro': 0.375, '_runtime': 3.350796699523926, '_timestamp': 1704214517.7621708, 'test/f1_micro': 0.47619047619047616, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.47619047619047616, 'test/loss': 1.207806569602631, '_wandb': {'runtime': 1}, 'test/accuracy': 0.47619047619047616, 'eval/recall_macro': 0.25, '_step': 20}","{'rf_max_depth': 14, 'trial.number': 4}",zany-armadillo-41,RandomForest,['BoW']
1289,"{'test/recall_macro': 0.25, 'test/recall_micro': 0.4603174603174603, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/f1_macro': 0.15760869565217392, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.4603174603174603, 'eval/precision_weighted': 0.1936, '_runtime': 3.1216206550598145, 'split': 10, 'eval/f1_macro': 0.1527777777777778, 'test/precision_micro': 0.4603174603174603, '_step': 20, 'test/f1_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'test/accuracy': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/f1_weighted': 0.290200138026225, 'test/precision_weighted': 0.21189216427311663, 'test/loss': 1.2854266288838343, 'eval/recall_macro': 0.25, 'test/precision_macro': 0.11507936507936509, 'eval/loss': 1.290462308510823, '_timestamp': 1704214512.5758996, 'eval/recall_micro': 0.44}","{'dt_criterion': 'gini', 'dt_max_depth': 10, 'trial.number': 14, 'dt_min_samples_leaf': 96}",balmy-music-40,DecisionTree,['BoW']
1290,"{'test/loss': 1.208420008425945, 'test/f1_macro': 0.22416020671834624, 'eval/precision_micro': 0.44, 'eval/precision_weighted': 0.33391304347826084, '_runtime': 2.657142400741577, 'eval/f1_micro': 0.44, 'test/recall_weighted': 0.492063492063492, 'split': 10, '_timestamp': 1704214508.8324664, 'test/f1_micro': 0.492063492063492, 'eval/f1_weighted': 0.30642424242424243, 'eval/f1_macro': 0.2515151515151515, 'test/recall_macro': 0.2793255131964809, '_wandb': {'runtime': 1}, 'eval/recall_macro': 0.3125, '_step': 20, 'eval/accuracy': 0.44, 'test/recall_micro': 0.492063492063492, 'eval/precision_macro': 0.358695652173913, 'test/precision_macro': 0.20324675324675323, 'test/precision_weighted': 0.30933828076685216, 'eval/loss': 1.2634953294716904, 'test/accuracy': 0.492063492063492, 'eval/recall_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/f1_weighted': 0.37065747918461095, 'test/precision_micro': 0.492063492063492}","{'rf_max_depth': 11, 'trial.number': 3}",good-universe-39,RandomForest,['BoW']
1291,"{'test/f1_macro': 0.23695652173913043, 'test/recall_micro': 0.4444444444444444, 'test/loss': 1.3077176958037864, 'test/precision_micro': 0.4444444444444444, 'eval/f1_macro': 0.22126436781609193, 'eval/f1_weighted': 0.3094252873563218, 'eval/recall_macro': 0.28181818181818186, 'eval/loss': 1.3031661935477543, 'eval/accuracy': 0.4, 'eval/precision_macro': 0.18253968253968253, 'eval/recall_weighted': 0.4, 'eval/precision_weighted': 0.25269841269841264, 'test/precision_weighted': 0.2748210395269219, 'test/accuracy': 0.4444444444444444, 'test/f1_micro': 0.4444444444444444, 'test/f1_weighted': 0.3369220151828847, 'test/precision_macro': 0.20098039215686275, 'eval/recall_micro': 0.4, '_step': 20, '_wandb': {'runtime': 1}, '_runtime': 2.697381019592285, 'eval/f1_micro': 0.4000000000000001, 'test/recall_weighted': 0.4444444444444444, 'split': 10, '_timestamp': 1704214503.430133, 'test/recall_macro': 0.29780564263322884, 'eval/precision_micro': 0.4}","{'dt_criterion': 'entropy', 'dt_max_depth': 10, 'trial.number': 13, 'dt_min_samples_leaf': 43}",gallant-yogurt-38,DecisionTree,['BoW']
1292,"{'eval/accuracy': 0.4, 'test/recall_micro': 0.47619047619047616, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.20833333333333331, 'test/precision_weighted': 0.30423280423280424, 'split': 10, '_timestamp': 1704214502.9345813, 'eval/f1_macro': 0.14285714285714288, 'test/loss': 1.2423133526917032, 'eval/recall_macro': 0.25, 'eval/precision_weighted': 0.16, 'test/f1_macro': 0.19863563402889245, 'test/accuracy': 0.47619047619047616, '_step': 20, 'eval/f1_weighted': 0.22857142857142865, 'eval/recall_micro': 0.4, 'eval/loss': 1.3000111090805078, '_runtime': 3.328456163406372, 'test/f1_micro': 0.47619047619047616, 'test/recall_macro': 0.2565982404692082, 'test/recall_weighted': 0.47619047619047616, '_wandb': {'runtime': 1}, 'test/f1_weighted': 0.34561390099110806, 'eval/precision_macro': 0.1, 'test/precision_micro': 0.47619047619047616, 'eval/f1_micro': 0.4000000000000001}","{'rf_max_depth': 8, 'trial.number': 2}",rural-brook-37,RandomForest,['BoW']
1293,"{'eval/loss': 1.363134407284573, 'test/recall_weighted': 0.47619047619047616, 'eval/f1_weighted': 0.3556666666666668, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.5236363636363636, 'test/loss': 1.2719059645078832, '_timestamp': 1704214495.9203012, 'test/f1_weighted': 0.4011303511303512, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.44, 'split': 10, 'eval/recall_micro': 0.44, 'test/precision_micro': 0.47619047619047616, 'test/f1_macro': 0.29128787878787876, 'test/f1_micro': 0.47619047619047616, 'test/accuracy': 0.47619047619047616, 'test/recall_micro': 0.47619047619047616, 'eval/precision_macro': 0.6022727272727273, '_runtime': 2.716034173965454, 'eval/f1_micro': 0.44, 'test/precision_macro': 0.3231292517006803, 'eval/f1_macro': 0.32395833333333335, 'eval/recall_macro': 0.33749999999999997, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.37825288845697014, '_step': 20, 'test/recall_macro': 0.30910923753665687}","{'rf_max_depth': 20, 'trial.number': 1}",glamorous-armadillo-36,RandomForest,['BoW']
1294,"{'eval/accuracy': 0.44, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.25, 'test/precision_macro': 0.11507936507936509, 'test/loss': 1.2854266288838343, 'test/f1_weighted': 0.290200138026225, 'test/recall_micro': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, 'test/f1_micro': 0.4603174603174603, 'eval/loss': 1.290462308510823, '_runtime': 3.2982330322265625, 'eval/precision_macro': 0.11, 'eval/f1_macro': 0.1527777777777778, '_wandb': {'runtime': 1}, 'eval/precision_weighted': 0.1936, 'split': 10, '_timestamp': 1704214495.808471, 'test/accuracy': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/precision_weighted': 0.21189216427311663, '_step': 20, 'eval/recall_macro': 0.25, 'eval/precision_micro': 0.44, 'test/f1_macro': 0.15760869565217392, 'eval/recall_weighted': 0.44, 'eval/f1_micro': 0.44}","{'dt_criterion': 'entropy', 'dt_max_depth': 4, 'trial.number': 12, 'dt_min_samples_leaf': 99}",drawn-smoke-35,DecisionTree,['BoW']
1295,"{'eval/accuracy': 0.48, 'eval/recall_micro': 0.48, 'eval/precision_weighted': 0.46, 'eval/f1_macro': 0.3380952380952381, 'test/accuracy': 0.5079365079365079, 'test/precision_macro': 0.2843528368794326, 'test/precision_micro': 0.5079365079365079, 'split': 10, 'eval/loss': 1.3207316706510324, 'test/f1_macro': 0.2847503373819163, 'eval/f1_weighted': 0.38780952380952377, 'test/recall_micro': 0.5079365079365079, '_step': 20, 'test/loss': 1.2284034135770017, '_timestamp': 1704214489.456299, 'test/recall_macro': 0.31321903902549064, 'eval/recall_weighted': 0.48, 'test/f1_weighted': 0.43013516697727217, '_wandb': {'runtime': 1}, 'test/recall_weighted': 0.5079365079365079, 'test/precision_weighted': 0.39301193290555, '_runtime': 1.800534963607788, 'eval/f1_micro': 0.48, 'test/f1_micro': 0.5079365079365079, 'eval/recall_macro': 0.3625, 'eval/precision_macro': 0.5, 'eval/precision_micro': 0.48}","{'rf_max_depth': 25, 'trial.number': 0}",denim-shape-34,RandomForest,['BoW']
1296,"{'eval/f1_weighted': 0.26888888888888896, 'test/precision_macro': 0.11507936507936509, '_step': 20, '_runtime': 3.180764675140381, 'test/loss': 1.3302066853563077, 'test/recall_weighted': 0.4603174603174603, '_wandb': {'runtime': 1}, 'eval/accuracy': 0.44, 'eval/recall_macro': 0.25, 'eval/precision_micro': 0.44, 'eval/loss': 1.2885286144160266, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.4603174603174603, 'eval/precision_macro': 0.11, 'test/f1_micro': 0.4603174603174603, 'eval/precision_weighted': 0.1936, 'split': 10, 'eval/f1_macro': 0.1527777777777778, 'eval/f1_micro': 0.44, 'test/recall_macro': 0.25, 'eval/recall_weighted': 0.44, 'test/precision_weighted': 0.21189216427311663, '_timestamp': 1704214487.4598446, 'test/accuracy': 0.4603174603174603, 'test/f1_macro': 0.15760869565217392, 'test/f1_weighted': 0.290200138026225, 'test/precision_micro': 0.4603174603174603}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 11, 'dt_min_samples_leaf': 88}",zesty-smoke-33,DecisionTree,['BoW']
1297,"{'test/accuracy': 0.4603174603174603, 'eval/f1_weighted': 0.26888888888888896, 'test/f1_weighted': 0.290200138026225, '_step': 20, '_wandb': {'runtime': 1}, '_runtime': 2.7644855976104736, 'test/recall_micro': 0.4603174603174603, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, 'test/precision_weighted': 0.21189216427311663, 'split': 10, 'eval/recall_micro': 0.44, 'test/recall_macro': 0.25, 'eval/precision_macro': 0.11, 'test/loss': 1.2854266288838343, 'test/f1_macro': 0.15760869565217392, 'test/f1_micro': 0.4603174603174603, 'test/precision_macro': 0.11507936507936509, 'eval/precision_weighted': 0.1936, 'eval/f1_micro': 0.44, 'eval/recall_macro': 0.25, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, '_timestamp': 1704214478.6235447, 'eval/accuracy': 0.44, 'eval/f1_macro': 0.1527777777777778, 'eval/loss': 1.290462308510823}","{'dt_criterion': 'entropy', 'dt_max_depth': 9, 'trial.number': 10, 'dt_min_samples_leaf': 100}",daily-galaxy-32,DecisionTree,['BoW']
1298,"{'eval/recall_weighted': 0.4, 'split': 10, 'eval/loss': 1.312828991102543, 'test/loss': 1.3138032633831536, 'test/f1_macro': 0.23695652173913043, 'eval/f1_weighted': 0.3094252873563218, 'eval/precision_macro': 0.18253968253968253, 'test/f1_micro': 0.4444444444444444, 'test/f1_weighted': 0.3369220151828847, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, '_wandb': {'runtime': 1}, '_runtime': 3.1319429874420166, 'test/recall_macro': 0.29780564263322884, 'eval/f1_micro': 0.4000000000000001, 'test/recall_micro': 0.4444444444444444, 'eval/precision_weighted': 0.25269841269841264, 'eval/accuracy': 0.4, 'test/accuracy': 0.4444444444444444, 'test/precision_weighted': 0.2748210395269219, '_step': 20, 'test/recall_weighted': 0.4444444444444444, '_timestamp': 1704214470.831776, 'eval/f1_macro': 0.22126436781609193, 'eval/recall_macro': 0.28181818181818186, 'test/precision_macro': 0.20098039215686275, 'test/precision_micro': 0.4444444444444444}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 9, 'dt_min_samples_leaf': 66}",rare-leaf-31,DecisionTree,['BoW']
1299,"{'_wandb': {'runtime': 1}, 'eval/precision_macro': 0.18253968253968253, 'test/precision_macro': 0.20098039215686275, '_timestamp': 1704214462.5829787, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, 'eval/precision_weighted': 0.25269841269841264, 'eval/f1_micro': 0.4000000000000001, 'test/f1_weighted': 0.3369220151828847, 'test/precision_micro': 0.4444444444444444, 'eval/f1_macro': 0.22126436781609193, 'eval/recall_macro': 0.28181818181818186, 'test/precision_weighted': 0.2748210395269219, '_step': 20, 'test/recall_macro': 0.29780564263322884, 'test/f1_macro': 0.23695652173913043, 'eval/f1_weighted': 0.3094252873563218, 'test/recall_micro': 0.4444444444444444, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.4444444444444444, 'eval/loss': 1.312828991102543, 'test/accuracy': 0.4444444444444444, 'eval/accuracy': 0.4, '_runtime': 3.1953437328338623, 'test/loss': 1.3138032633831536, 'split': 10, 'test/f1_micro': 0.4444444444444444}","{'dt_criterion': 'gini', 'dt_max_depth': 4, 'trial.number': 8, 'dt_min_samples_leaf': 61}",serene-elevator-30,DecisionTree,['BoW']
1300,"{'eval/f1_macro': 0.22126436781609193, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_micro': 0.4, '_timestamp': 1704214453.6827862, 'eval/recall_weighted': 0.4, 'test/precision_weighted': 0.2748210395269219, 'eval/loss': 1.307869724320568, 'test/loss': 1.8620020555075667, 'eval/recall_micro': 0.4, 'test/precision_macro': 0.20098039215686275, 'eval/precision_weighted': 0.25269841269841264, '_step': 20, 'test/f1_micro': 0.4444444444444444, 'test/recall_micro': 0.4444444444444444, 'test/f1_weighted': 0.3369220151828847, 'eval/precision_macro': 0.18253968253968253, '_wandb': {'runtime': 1}, '_runtime': 2.5907461643218994, 'eval/f1_weighted': 0.3094252873563218, 'eval/recall_macro': 0.28181818181818186, 'test/recall_macro': 0.29780564263322884, 'test/precision_micro': 0.4444444444444444, 'split': 10, 'eval/accuracy': 0.4, 'test/accuracy': 0.4444444444444444, 'test/f1_macro': 0.23695652173913043, 'test/recall_weighted': 0.4444444444444444}","{'dt_criterion': 'gini', 'dt_max_depth': 2, 'trial.number': 7, 'dt_min_samples_leaf': 14}",fallen-sea-29,DecisionTree,['BoW']
1301,"{'test/loss': 4.564887836649346, 'eval/f1_weighted': 0.43, 'test/f1_weighted': 0.3263547034975606, 'test/recall_macro': 0.25549833308454, 'eval/loss': 5.379822218220437, 'eval/precision_macro': 0.4096153846153846, 'eval/precision_micro': 0.44, 'test/precision_macro': 0.2603194103194103, 'test/precision_micro': 0.3492063492063492, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'eval/recall_weighted': 0.44, 'eval/recall_micro': 0.44, '_step': 20, 'eval/f1_macro': 0.3791666666666667, 'test/accuracy': 0.3492063492063492, '_runtime': 3.307927131652832, '_timestamp': 1704214447.110846, 'test/f1_micro': 0.3492063492063492, 'eval/recall_macro': 0.3715909090909091, 'test/recall_weighted': 0.3492063492063492, 'split': 10, '_wandb': {'runtime': 1}, 'test/f1_macro': 0.25212121212121213, 'test/recall_micro': 0.3492063492063492, 'eval/precision_weighted': 0.4369230769230769, 'test/precision_weighted': 0.3153933153933154}","{'dt_criterion': 'gini', 'dt_max_depth': 16, 'trial.number': 6, 'dt_min_samples_leaf': 8}",dulcet-sun-28,DecisionTree,['BoW']
1302,"{'eval/precision_weighted': 0.3422222222222222, 'split': 10, 'test/accuracy': 0.4126984126984127, 'test/f1_weighted': 0.31627762215997507, 'test/f1_micro': 0.4126984126984127, 'test/recall_macro': 0.2574016022291884, 'eval/recall_weighted': 0.44, 'test/recall_weighted': 0.4126984126984127, 'eval/f1_macro': 0.3254310344827586, 'eval/precision_macro': 0.3194444444444444, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'eval/recall_macro': 0.3568181818181818, 'test/precision_micro': 0.4126984126984127, '_wandb': {'runtime': 1}, 'eval/loss': 1.369363388421602, '_timestamp': 1704214438.713492, 'test/f1_macro': 0.21274509803921568, 'eval/precision_micro': 0.44, 'test/precision_weighted': 0.2781279178338002, '_step': 20, '_runtime': 3.095989942550659, 'test/loss': 1.3613630191050154, 'eval/recall_micro': 0.44, 'test/recall_micro': 0.4126984126984127, 'test/precision_macro': 0.2113970588235294, 'eval/f1_weighted': 0.3727586206896551}","{'dt_criterion': 'gini', 'dt_max_depth': 13, 'trial.number': 5, 'dt_min_samples_leaf': 30}",proud-shadow-27,DecisionTree,['BoW']
1303,"{'split': 10, 'test/f1_macro': 0.23695652173913043, 'test/recall_micro': 0.4444444444444444, 'test/recall_macro': 0.29780564263322884, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.20098039215686275, '_runtime': 3.1886682510375977, 'eval/f1_weighted': 0.3094252873563218, 'test/f1_weighted': 0.3369220151828847, 'eval/recall_micro': 0.4, 'eval/f1_macro': 0.22126436781609193, 'test/accuracy': 0.4444444444444444, 'eval/recall_macro': 0.28181818181818186, 'eval/precision_macro': 0.18253968253968253, '_timestamp': 1704214430.4935813, 'eval/precision_weighted': 0.25269841269841264, '_step': 20, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'eval/loss': 1.312828991102543, 'test/loss': 1.3138032633831536, 'eval/accuracy': 0.4, 'test/precision_micro': 0.4444444444444444, 'test/precision_weighted': 0.2748210395269219}","{'dt_criterion': 'entropy', 'dt_max_depth': 17, 'trial.number': 4, 'dt_min_samples_leaf': 68}",wise-puddle-26,DecisionTree,['BoW']
1304,"{'test/f1_weighted': 0.36267138434321095, 'eval/recall_micro': 0.48, 'test/recall_micro': 0.4444444444444444, 'eval/precision_micro': 0.48, 'test/precision_weighted': 0.3183890577507599, 'split': 10, 'eval/accuracy': 0.48, 'test/f1_micro': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'eval/precision_weighted': 0.3813333333333333, 'eval/f1_micro': 0.48, 'eval/f1_weighted': 0.4234965034965035, '_step': 20, '_timestamp': 1704214423.0489256, 'eval/f1_macro': 0.36975524475524474, 'test/accuracy': 0.4444444444444444, 'test/f1_macro': 0.2662538699690402, 'eval/precision_macro': 0.3416666666666666, 'eval/loss': 2.6534332094977104, 'test/loss': 1.3376816641501323, 'test/precision_micro': 0.4444444444444444, '_wandb': {'runtime': 1}, '_runtime': 3.195104598999023, 'eval/recall_macro': 0.40681818181818186, 'test/recall_macro': 0.30285614768373387, 'eval/recall_weighted': 0.48, 'test/precision_macro': 0.25265957446808507}","{'dt_criterion': 'gini', 'dt_max_depth': 7, 'trial.number': 3, 'dt_min_samples_leaf': 21}",vague-dust-25,DecisionTree,['BoW']
1305,"{'eval/f1_micro': 0.4000000000000001, 'test/f1_micro': 0.4444444444444444, 'eval/precision_weighted': 0.25269841269841264, '_wandb': {'runtime': 1}, '_timestamp': 1704214414.2184262, 'eval/accuracy': 0.4, 'eval/recall_weighted': 0.4, 'test/precision_macro': 0.20098039215686275, 'test/precision_micro': 0.4444444444444444, 'eval/loss': 1.3206005417435918, '_step': 20, 'test/f1_macro': 0.23695652173913043, 'eval/recall_micro': 0.4, 'test/recall_micro': 0.4444444444444444, 'test/precision_weighted': 0.2748210395269219, 'test/accuracy': 0.4444444444444444, 'test/recall_macro': 0.29780564263322884, 'split': 10, '_runtime': 2.547476291656494, 'test/loss': 1.3238704328122746, 'eval/f1_weighted': 0.3094252873563218, 'test/f1_weighted': 0.3369220151828847, 'eval/precision_macro': 0.18253968253968253, 'eval/precision_micro': 0.4, 'test/recall_weighted': 0.4444444444444444, 'eval/f1_macro': 0.22126436781609193, 'eval/recall_macro': 0.28181818181818186}","{'dt_criterion': 'entropy', 'dt_max_depth': 2, 'trial.number': 2, 'dt_min_samples_leaf': 18}",decent-gorge-24,DecisionTree,['BoW']
1306,"{'_runtime': 3.1649796962738037, 'test/accuracy': 0.4444444444444444, 'test/recall_weighted': 0.4444444444444444, 'eval/accuracy': 0.4, 'test/f1_macro': 0.23695652173913043, 'eval/f1_weighted': 0.3094252873563218, 'eval/recall_macro': 0.28181818181818186, 'test/precision_weighted': 0.2748210395269219, 'test/f1_micro': 0.4444444444444444, 'test/recall_macro': 0.29780564263322884, 'eval/precision_micro': 0.4, '_step': 20, 'test/f1_weighted': 0.3369220151828847, 'eval/precision_macro': 0.18253968253968253, '_timestamp': 1704214406.6824408, 'eval/recall_weighted': 0.4, 'split': 10, '_wandb': {'runtime': 1}, 'test/loss': 1.3473244593571108, 'eval/recall_micro': 0.4, 'eval/precision_weighted': 0.25269841269841264, 'eval/f1_micro': 0.4000000000000001, 'test/recall_micro': 0.4444444444444444, 'test/precision_macro': 0.20098039215686275, 'eval/loss': 1.3144734723488667, 'eval/f1_macro': 0.22126436781609193, 'test/precision_micro': 0.4444444444444444}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 1, 'dt_min_samples_leaf': 41}",copper-rain-23,DecisionTree,['BoW']
1307,"{'test/f1_macro': 0.15760869565217392, 'eval/recall_micro': 0.44, '_timestamp': 1704214398.4167693, 'test/f1_micro': 0.4603174603174603, 'test/precision_weighted': 0.21189216427311663, 'eval/accuracy': 0.44, 'eval/f1_micro': 0.44, 'test/f1_weighted': 0.290200138026225, 'test/precision_macro': 0.11507936507936509, '_step': 20, 'eval/loss': 1.2885286144160266, 'test/recall_macro': 0.25, 'eval/precision_micro': 0.44, 'eval/recall_weighted': 0.44, 'eval/precision_weighted': 0.1936, '_runtime': 2.230879306793213, 'test/loss': 1.3302066853563077, 'eval/f1_macro': 0.1527777777777778, 'eval/f1_weighted': 0.26888888888888896, 'test/recall_micro': 0.4603174603174603, 'split': 10, 'eval/recall_macro': 0.25, 'test/accuracy': 0.4603174603174603, 'test/precision_micro': 0.4603174603174603, 'test/recall_weighted': 0.4603174603174603, '_wandb': {'runtime': 1}, 'eval/precision_macro': 0.11}","{'dt_criterion': 'gini', 'dt_max_depth': 6, 'trial.number': 0, 'dt_min_samples_leaf': 72}",hardy-dream-22,DecisionTree,['BoW']
1308,"{'_step': 20, 'test/f1_weighted': 0.4238120376355671, 'eval/precision_micro': 0.4, 'eval/recall_weighted': 0.4, '_wandb': {'runtime': 1}, 'test/loss': 21.168494847576746, 'test/f1_macro': 0.3705910633484163, 'test/recall_macro': 0.3692002442002442, 'test/precision_macro': 0.4538194444444445, 'eval/precision_weighted': 0.4633333333333334, 'test/precision_weighted': 0.5004188712522046, '_runtime': 3.201899766921997, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_macro': 0.37083333333333335, 'test/precision_micro': 0.4126984126984127, '_timestamp': 1704214317.7260587, 'test/accuracy': 0.4126984126984127, 'eval/f1_weighted': 0.42189473684210527, 'eval/recall_micro': 0.4, 'test/recall_weighted': 0.4126984126984127, 'split': 10, 'eval/loss': 21.626192033470293, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.3578947368421053, 'eval/recall_macro': 0.36136363636363633, 'test/f1_micro': 0.4126984126984127, 'test/recall_micro': 0.4126984126984127}","{'n_neighbours': 1, 'trial.number': 9}",fearless-energy-21,KNeighbours,['BoW']
1309,"{'_timestamp': 1704214309.3210337, 'test/accuracy': 0.4126984126984127, 'eval/precision_macro': 0.37083333333333335, 'eval/f1_micro': 0.4000000000000001, 'eval/recall_macro': 0.36136363636363633, 'test/recall_macro': 0.3692002442002442, 'test/precision_macro': 0.4538194444444445, 'split': 10, 'test/loss': 21.168494847576746, 'eval/accuracy': 0.4, 'eval/f1_weighted': 0.42189473684210527, 'test/f1_weighted': 0.4238120376355671, 'eval/recall_micro': 0.4, 'eval/precision_micro': 0.4, 'eval/f1_macro': 0.3578947368421053, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.4126984126984127, 'eval/loss': 21.626192033470293, 'test/f1_macro': 0.3705910633484163, 'test/precision_micro': 0.4126984126984127, 'test/precision_weighted': 0.5004188712522046, '_step': 20, '_wandb': {'runtime': 1}, '_runtime': 3.734329462051392, 'test/f1_micro': 0.4126984126984127, 'test/recall_micro': 0.4126984126984127, 'eval/precision_weighted': 0.4633333333333334}","{'n_neighbours': 1, 'trial.number': 8}",flowing-galaxy-20,KNeighbours,['BoW']
1310,"{'test/accuracy': 0.4126984126984127, 'test/f1_micro': 0.4126984126984127, 'test/f1_weighted': 0.4238120376355671, '_step': 20, 'test/precision_macro': 0.4538194444444445, 'test/loss': 21.168494847576746, 'test/recall_macro': 0.3692002442002442, 'eval/recall_macro': 0.36136363636363633, 'eval/f1_micro': 0.4000000000000001, 'eval/precision_micro': 0.4, 'eval/loss': 21.626192033470293, '_wandb': {'runtime': 1}, 'test/f1_macro': 0.3705910633484163, 'eval/f1_weighted': 0.42189473684210527, 'test/recall_micro': 0.4126984126984127, 'eval/precision_macro': 0.37083333333333335, '_timestamp': 1704214300.5038688, 'eval/accuracy': 0.4, 'eval/f1_macro': 0.3578947368421053, 'eval/recall_micro': 0.4, 'eval/recall_weighted': 0.4, '_runtime': 3.208293914794922, 'test/precision_micro': 0.4126984126984127, 'test/recall_weighted': 0.4126984126984127, 'eval/precision_weighted': 0.4633333333333334, 'test/precision_weighted': 0.5004188712522046, 'split': 10}","{'n_neighbours': 1, 'trial.number': 7}",smooth-dawn-19,KNeighbours,['BoW']
1311,"{'test/f1_weighted': 0.37435520656349974, 'eval/recall_micro': 0.2, 'eval/precision_macro': 0.1419642857142857, 'eval/f1_weighted': 0.1898168498168498, 'eval/recall_macro': 0.16818181818181818, 'test/recall_micro': 0.42857142857142855, 'test/precision_weighted': 0.33314659197012136, '_step': 20, '_wandb': {'runtime': 1}, '_timestamp': 1704214293.682886, 'test/f1_micro': 0.42857142857142855, 'test/precision_micro': 0.42857142857142855, 'test/recall_macro': 0.3287037037037037, 'eval/recall_weighted': 0.2, 'eval/precision_weighted': 0.18557142857142855, 'split': 10, '_runtime': 2.876169204711914, 'test/precision_macro': 0.25498366013071894, 'test/f1_macro': 0.28645665916639884, 'test/loss': 7.155078834246231, 'eval/f1_micro': 0.20000000000000004, 'test/accuracy': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, 'eval/loss': 12.406579767193495, 'eval/accuracy': 0.2, 'eval/precision_micro': 0.2, 'eval/f1_macro': 0.15155677655677657}","{'n_neighbours': 5, 'trial.number': 6}",ancient-jazz-18,KNeighbours,['BoW']
1312,"{'split': 10, 'eval/accuracy': 0.4, 'test/f1_weighted': 0.4238120376355671, 'eval/recall_macro': 0.36136363636363633, 'test/recall_macro': 0.3692002442002442, '_timestamp': 1704214286.8283646, 'test/f1_macro': 0.3705910633484163, 'test/precision_macro': 0.4538194444444445, 'eval/precision_weighted': 0.4633333333333334, 'eval/f1_micro': 0.4000000000000001, 'test/recall_micro': 0.4126984126984127, 'test/loss': 21.168494847576746, 'eval/f1_macro': 0.3578947368421053, 'eval/precision_micro': 0.4, 'test/precision_weighted': 0.5004188712522046, '_step': 20, '_wandb': {'runtime': 1}, 'eval/loss': 21.626192033470293, 'eval/precision_macro': 0.37083333333333335, 'test/accuracy': 0.4126984126984127, 'eval/recall_weighted': 0.4, 'test/recall_weighted': 0.4126984126984127, '_runtime': 3.2396867275238037, 'eval/f1_weighted': 0.42189473684210527, 'test/precision_micro': 0.4126984126984127, 'test/f1_micro': 0.4126984126984127, 'eval/recall_micro': 0.4}","{'n_neighbours': 1, 'trial.number': 5}",elated-planet-17,KNeighbours,['BoW']
1313,"{'eval/accuracy': 0.4, 'test/recall_micro': 0.4126984126984127, 'test/precision_micro': 0.4126984126984127, 'eval/precision_weighted': 0.4633333333333334, 'split': 10, '_runtime': 2.6015210151672363, 'eval/precision_macro': 0.37083333333333335, 'eval/f1_macro': 0.3578947368421053, 'eval/f1_micro': 0.4000000000000001, 'test/precision_macro': 0.4538194444444445, 'test/precision_weighted': 0.5004188712522046, 'eval/recall_weighted': 0.4, '_step': 20, 'eval/loss': 21.626192033470293, '_timestamp': 1704214278.95366, 'test/recall_macro': 0.3692002442002442, 'test/accuracy': 0.4126984126984127, 'test/f1_macro': 0.3705910633484163, 'test/f1_weighted': 0.4238120376355671, 'eval/recall_micro': 0.4, '_wandb': {'runtime': 1}, 'test/f1_micro': 0.4126984126984127, 'test/recall_weighted': 0.4126984126984127, 'test/loss': 21.168494847576746, 'eval/f1_weighted': 0.42189473684210527, 'eval/recall_macro': 0.36136363636363633, 'eval/precision_micro': 0.4}","{'n_neighbours': 1, 'trial.number': 4}",valiant-sponge-16,KNeighbours,['BoW']
1314,"{'split': 10, '_runtime': 3.2322659492492676, 'eval/recall_macro': 0.36136363636363633, '_wandb': {'runtime': 1}, 'test/loss': 21.168494847576746, 'eval/f1_macro': 0.3578947368421053, 'test/f1_micro': 0.4126984126984127, 'test/precision_weighted': 0.5004188712522046, 'eval/accuracy': 0.4, 'eval/f1_micro': 0.4000000000000001, 'test/f1_macro': 0.3705910633484163, 'test/recall_micro': 0.4126984126984127, 'test/recall_weighted': 0.4126984126984127, '_step': 20, '_timestamp': 1704214272.128674, 'test/f1_weighted': 0.4238120376355671, 'test/accuracy': 0.4126984126984127, 'eval/loss': 21.626192033470293, 'eval/f1_weighted': 0.42189473684210527, 'eval/recall_micro': 0.4, 'test/recall_macro': 0.3692002442002442, 'eval/recall_weighted': 0.4, 'eval/precision_macro': 0.37083333333333335, 'eval/precision_micro': 0.4, 'test/precision_macro': 0.4538194444444445, 'test/precision_micro': 0.4126984126984127, 'eval/precision_weighted': 0.4633333333333334}","{'n_neighbours': 1, 'trial.number': 3}",confused-fire-15,KNeighbours,['BoW']
1315,"{'_wandb': {'runtime': 1}, 'eval/f1_macro': 0.24935064935064935, 'eval/f1_micro': 0.32, 'eval/recall_weighted': 0.32, 'eval/precision_micro': 0.32, 'test/precision_macro': 0.2811594202898551, 'test/precision_micro': 0.42857142857142855, 'eval/loss': 4.101456862353092, '_timestamp': 1704214265.6634774, 'eval/f1_weighted': 0.3085714285714286, 'test/recall_macro': 0.3644179894179894, 'eval/precision_macro': 0.2414141414141414, 'test/precision_weighted': 0.3440993788819876, 'test/accuracy': 0.42857142857142855, 'test/recall_weighted': 0.42857142857142855, 'eval/recall_macro': 0.26363636363636367, 'eval/precision_weighted': 0.3022222222222222, '_runtime': 3.1882383823394775, 'eval/recall_micro': 0.32, 'test/recall_micro': 0.42857142857142855, 'eval/accuracy': 0.32, 'test/f1_weighted': 0.3787847998374315, '_step': 20, 'split': 10, 'test/loss': 1.8606911846432617, 'test/f1_macro': 0.3146040777619725, 'test/f1_micro': 0.42857142857142855}","{'n_neighbours': 10, 'trial.number': 2}",neat-smoke-14,KNeighbours,['BoW']
1316,"{'test/recall_micro': 0.4126984126984127, 'eval/precision_macro': 0.37083333333333335, 'eval/f1_weighted': 0.42189473684210527, 'eval/recall_weighted': 0.4, 'test/precision_micro': 0.4126984126984127, 'eval/loss': 21.626192033470293, '_timestamp': 1704214257.3967278, 'test/f1_micro': 0.4126984126984127, 'test/precision_macro': 0.4538194444444445, 'eval/precision_weighted': 0.4633333333333334, 'eval/accuracy': 0.4, 'test/accuracy': 0.4126984126984127, 'test/f1_macro': 0.3705910633484163, 'eval/precision_micro': 0.4, '_step': 20, 'split': 10, 'test/loss': 21.168494847576746, 'eval/recall_macro': 0.36136363636363633, 'eval/recall_micro': 0.4, '_wandb': {'runtime': 1}, 'eval/f1_micro': 0.4000000000000001, 'test/precision_weighted': 0.5004188712522046, 'eval/f1_macro': 0.3578947368421053, 'test/f1_weighted': 0.4238120376355671, 'test/recall_weighted': 0.4126984126984127, '_runtime': 3.223423719406128, 'test/recall_macro': 0.3692002442002442}","{'n_neighbours': 1, 'trial.number': 1}",vivid-gorge-13,KNeighbours,['BoW']
1317,"{'_step': 20, 'eval/f1_micro': 0.28, 'test/recall_weighted': 0.4126984126984127, 'eval/precision_macro': 0.422159090909091, 'test/precision_micro': 0.4126984126984127, 'split': 10, '_runtime': 2.357491970062256, 'eval/accuracy': 0.28, 'test/f1_micro': 0.4126984126984127, 'eval/loss': 6.9576550941114235, 'test/accuracy': 0.4126984126984127, 'test/f1_weighted': 0.3714692135744768, 'eval/recall_micro': 0.28, 'eval/recall_weighted': 0.28, 'test/precision_weighted': 0.3422360248447205, 'test/f1_macro': 0.29927295716769403, 'eval/f1_weighted': 0.2947692307692308, 'test/recall_micro': 0.4126984126984127, '_wandb': {'runtime': 1}, 'eval/f1_macro': 0.2793706293706294, 'eval/precision_weighted': 0.385, 'eval/recall_macro': 0.2534090909090909, 'test/recall_macro': 0.337962962962963, 'test/loss': 6.663043856706165, '_timestamp': 1704214247.607202, 'eval/precision_micro': 0.28, 'test/precision_macro': 0.2733091787439613}","{'n_neighbours': 6, 'trial.number': 0}",kind-planet-12,KNeighbours,['BoW']
1318,"{'test/recall_macro': 0.22748447204968944, 'eval/f1_weighted': 0.5361904761904762, 'eval/recall_macro': 0.46704545454545454, 'test/recall_micro': 0.30158730158730157, 'test/precision_weighted': 0.19968391396962823, 'eval/accuracy': 0.56, 'test/f1_macro': 0.18307692307692305, 'test/recall_weighted': 0.30158730158730157, 'eval/precision_weighted': 0.5796078431372549, 'eval/precision_macro': 0.5906862745098039, 'eval/recall_weighted': 0.56, 'eval/f1_macro': 0.49404761904761896, 'test/f1_micro': 0.30158730158730157, 'test/f1_weighted': 0.23306471306471305, 'eval/recall_micro': 0.56, 'test/precision_micro': 0.30158730158730157, '_runtime': 2.607166290283203, 'eval/loss': 6.38185384105327, '_timestamp': 1704214034.3957622, 'eval/precision_micro': 0.56, '_step': 20, 'test/loss': 8.072088144427624, 'test/precision_macro': 0.1634199134199134, 'eval/f1_micro': 0.56, 'test/accuracy': 0.30158730158730157, '_wandb': {'runtime': 1}, 'split': 10}","{'smoothing': 0.3151132863870465, 'trial.number': 4}",ruby-grass-11,Bernolli,['BoW']
1319,"{'test/recall_macro': 0.2252329192546584, 'eval/f1_micro': 0.52, 'eval/f1_weighted': 0.5178989898989899, 'eval/recall_micro': 0.52, 'test/precision_micro': 0.2857142857142857, '_wandb': {'runtime': 1}, 'test/f1_micro': 0.2857142857142857, 'eval/recall_weighted': 0.52, 'test/precision_macro': 0.20535714285714285, '_timestamp': 1704214026.7858744, 'test/f1_macro': 0.2038246067657832, 'test/recall_micro': 0.2857142857142857, '_step': 20, 'test/accuracy': 0.2857142857142857, 'eval/precision_weighted': 0.53, 'test/loss': 7.569694766603528, 'eval/f1_macro': 0.48737373737373735, 'test/f1_weighted': 0.26133256721492015, 'eval/accuracy': 0.52, 'eval/precision_macro': 0.47916666666666663, 'test/recall_weighted': 0.2857142857142857, '_runtime': 3.193502426147461, 'eval/loss': 5.890720638763993, 'eval/precision_micro': 0.52, 'split': 10, 'eval/recall_macro': 0.5113636363636364, 'test/precision_weighted': 0.26473922902494335}","{'smoothing': 0.131081641971596, 'trial.number': 3}",stoic-darkness-10,Bernolli,['BoW']
1320,"{'eval/recall_micro': 0.52, 'eval/precision_macro': 0.3684210526315789, 'test/precision_weighted': 0.17720057720057722, '_step': 20, 'test/f1_micro': 0.3333333333333333, 'eval/recall_macro': 0.40454545454545454, 'test/recall_micro': 0.3333333333333333, 'test/precision_macro': 0.14090909090909093, 'eval/loss': 8.849363176648259, 'test/accuracy': 0.3333333333333333, 'eval/f1_weighted': 0.44177777777777777, 'test/recall_macro': 0.23524844720496893, 'eval/f1_macro': 0.37222222222222223, 'test/f1_macro': 0.15452091767881243, 'test/f1_weighted': 0.2106120000856843, 'test/recall_weighted': 0.3333333333333333, 'split': 10, '_timestamp': 1704214018.634507, 'eval/accuracy': 0.52, 'eval/f1_micro': 0.52, 'eval/precision_micro': 0.52, '_wandb': {'runtime': 1}, '_runtime': 3.261615037918091, 'test/loss': 10.61842549797551, 'eval/recall_weighted': 0.52, 'test/precision_micro': 0.3333333333333333, 'eval/precision_weighted': 0.4084210526315789}","{'smoothing': 0.47961281845381887, 'trial.number': 2}",radiant-bush-9,Bernolli,['BoW']
1321,"{'_wandb': {'runtime': 1}, '_runtime': 2.606753349304199, 'test/precision_micro': 0.36507936507936506, 'test/accuracy': 0.36507936507936506, 'test/f1_micro': 0.36507936507936506, 'eval/f1_weighted': 0.4054838709677419, 'test/recall_micro': 0.36507936507936506, 'split': 10, 'eval/loss': 11.466189037056743, 'eval/f1_micro': 0.48, 'eval/precision_micro': 0.48, 'eval/recall_weighted': 0.48, '_timestamp': 1704214009.6252513, 'eval/accuracy': 0.48, 'test/f1_weighted': 0.22300607485792673, 'eval/recall_micro': 0.48, 'test/recall_macro': 0.25698757763975155, 'eval/precision_macro': 0.3625, 'eval/precision_weighted': 0.398, '_step': 20, 'test/loss': 13.88373278782104, 'eval/recall_macro': 0.35454545454545455, 'test/precision_macro': 0.15732758620689655, 'test/recall_weighted': 0.36507936507936506, 'eval/f1_macro': 0.3326612903225806, 'test/f1_macro': 0.16358024691358028, 'test/precision_weighted': 0.19403393541324576}","{'smoothing': 0.6307586587799178, 'trial.number': 1}",drawn-rain-8,Bernolli,['BoW']
1322,"{'eval/f1_weighted': 0.44177777777777777, 'test/f1_weighted': 0.22375800697907253, '_timestamp': 1704214001.909535, 'eval/accuracy': 0.52, 'eval/f1_micro': 0.52, 'test/accuracy': 0.31746031746031744, 'eval/precision_weighted': 0.4084210526315789, '_step': 20, 'test/recall_micro': 0.31746031746031744, 'test/precision_micro': 0.31746031746031744, 'test/recall_weighted': 0.31746031746031744, 'eval/loss': 7.45687695714676, 'test/loss': 9.08613116721506, 'eval/precision_micro': 0.52, 'eval/recall_macro': 0.40454545454545454, 'eval/recall_micro': 0.52, 'test/recall_macro': 0.2313664596273292, 'eval/precision_macro': 0.3684210526315789, 'split': 10, '_wandb': {'runtime': 1}, 'test/f1_macro': 0.17023882424984693, 'test/f1_micro': 0.31746031746031744, 'eval/f1_macro': 0.37222222222222223, 'test/precision_macro': 0.14930555555555555, 'test/precision_weighted': 0.1862874779541446, '_runtime': 2.364640951156616, 'eval/recall_weighted': 0.52}","{'smoothing': 0.3940781233234616, 'trial.number': 0}",dazzling-silence-7,Bernolli,['BoW']
1323,"{'eval/f1_macro': 0.49999999999999994, 'test/f1_weighted': 0.4583768721699755, '_wandb': {'runtime': 5}, 'test/loss': 1.7278629740353946, 'eval/accuracy': 0.56, 'eval/recall_macro': 0.4875, 'eval/precision_macro': 0.5595238095238095, 'split': 10, '_runtime': 5.548674821853638, 'test/f1_micro': 0.47619047619047616, 'eval/f1_weighted': 0.54, 'eval/recall_micro': 0.56, 'eval/precision_weighted': 0.5619047619047619, '_timestamp': 1704213275.2144558, 'eval/f1_micro': 0.56, 'eval/precision_micro': 0.56, 'eval/recall_weighted': 0.56, 'test/precision_micro': 0.47619047619047616, 'test/recall_weighted': 0.47619047619047616, '_step': 20, 'test/recall_micro': 0.47619047619047616, 'test/recall_macro': 0.4442982456140351, 'test/precision_macro': 0.4103174603174603, 'test/accuracy': 0.47619047619047616, 'test/f1_macro': 0.41138975966562175, 'eval/loss': 1.9333552160965832, 'test/precision_weighted': 0.4668178382464097}",{'trial.number': 0},dulcet-aardvark-6,LogisticRegression,['BoW']
