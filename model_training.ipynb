{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           docstring  \\\n0  Attempt to convert the specified value to epoc...   \n1  Generate a server side cookie given the cookie...   \n2  Generate httponly cookie from HS2 cookie\\n@par...   \n3  Copies all files from source to target and set...   \n4          Saves the configuration info to the disk.   \n\n                                                code  relevance  \\\n0  private static String coerceToEpoch(String s) ...          2   \n1  private Cookie createCookie(String str) throws...          2   \n2  private static String getHttpOnlyCookieHeader(...          2   \n3  public static void copy(Path sourcePath, Path ...          3   \n4  public synchronized void save() {\\n        if ...          3   \n\n                          repo  \\\n0  spring-projects/spring-boot   \n1                 apache/spark   \n2                 apache/spark   \n3                 apache/flink   \n4            jenkinsci/jenkins   \n\n                                            func_url  split  \n0  https://github.com/spring-projects/spring-boot...  train  \n1  https://github.com/apache/spark/blob/25ee0474f...  train  \n2  https://github.com/apache/spark/blob/25ee0474f...  train  \n3  https://github.com/apache/flink/blob/b62db93bf...  train  \n4  https://github.com/jenkinsci/jenkins/blob/44c4...  train  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>docstring</th>\n      <th>code</th>\n      <th>relevance</th>\n      <th>repo</th>\n      <th>func_url</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Attempt to convert the specified value to epoc...</td>\n      <td>private static String coerceToEpoch(String s) ...</td>\n      <td>2</td>\n      <td>spring-projects/spring-boot</td>\n      <td>https://github.com/spring-projects/spring-boot...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Generate a server side cookie given the cookie...</td>\n      <td>private Cookie createCookie(String str) throws...</td>\n      <td>2</td>\n      <td>apache/spark</td>\n      <td>https://github.com/apache/spark/blob/25ee0474f...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Generate httponly cookie from HS2 cookie\\n@par...</td>\n      <td>private static String getHttpOnlyCookieHeader(...</td>\n      <td>2</td>\n      <td>apache/spark</td>\n      <td>https://github.com/apache/spark/blob/25ee0474f...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Copies all files from source to target and set...</td>\n      <td>public static void copy(Path sourcePath, Path ...</td>\n      <td>3</td>\n      <td>apache/flink</td>\n      <td>https://github.com/apache/flink/blob/b62db93bf...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Saves the configuration info to the disk.</td>\n      <td>public synchronized void save() {\\n        if ...</td>\n      <td>3</td>\n      <td>jenkinsci/jenkins</td>\n      <td>https://github.com/jenkinsci/jenkins/blob/44c4...</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/processed.pickle')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSION = 400\n",
    "\n",
    "def get_tokens_and_embeddings(natural_language, code, tokenizer, model):\n",
    "\n",
    "    nl_tokens = tokenizer.tokenize(natural_language)\n",
    "    code_tokens = tokenizer.tokenize(code)\n",
    "\n",
    "    tokens = ['CLS'] + nl_tokens + ['SEP'] + code_tokens + ['EOS']\n",
    "\n",
    "    if len(tokens) > EMBEDDING_DIMENSION:\n",
    "        tokens = tokens[:EMBEDDING_DIMENSION]\n",
    "\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    embedding = model(torch.tensor(token_ids)[None, :])[0][0]\n",
    "\n",
    "    pad_value_before = (EMBEDDING_DIMENSION - len(tokens)) // 2\n",
    "    pad_value_after = pad_value_before + ((EMBEDDING_DIMENSION - len(tokens)) % 2)\n",
    "\n",
    "    padded = nn.functional.pad(embedding, (0, 0, pad_value_before, pad_value_after), \"constant\", 0)\n",
    "\n",
    "    return tokens, len(tokens), padded.detach().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "bert_model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "bert_model.to(device)\n",
    "\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           docstring  \\\n0  Attempt to convert the specified value to epoc...   \n1  Generate a server side cookie given the cookie...   \n2  Generate httponly cookie from HS2 cookie\\n@par...   \n3  Copies all files from source to target and set...   \n4          Saves the configuration info to the disk.   \n5  Randomize server list using local IPv4 address...   \n6  Decompress an input stream from a file, based ...   \n7  Save distribution statistics to the file syste...   \n8  Score the given multi layer network\\n@param mo...   \n9  This method takes a string as input reverses i...   \n\n                                                code  relevance  \\\n0  private static String coerceToEpoch(String s) ...          2   \n1  private Cookie createCookie(String str) throws...          2   \n2  private static String getHttpOnlyCookieHeader(...          2   \n3  public static void copy(Path sourcePath, Path ...          3   \n4  public synchronized void save() {\\n        if ...          3   \n5  public static <T extends EurekaEndpoint> List<...          0   \n6  public static InputStream decompress(final Inp...          3   \n7  public void save(@NonNull File meanFile, @NonN...          0   \n8  public static double score(MultiLayerNetwork m...          0   \n9  private static String reverseString(String in)...          3   \n\n                            repo  \\\n0    spring-projects/spring-boot   \n1                   apache/spark   \n2                   apache/spark   \n3                   apache/flink   \n4              jenkinsci/jenkins   \n5                 Netflix/eureka   \n6         apache/incubator-druid   \n7  deeplearning4j/deeplearning4j   \n8  deeplearning4j/deeplearning4j   \n9                zaproxy/zaproxy   \n\n                                            func_url  split  \n0  https://github.com/spring-projects/spring-boot...  train  \n1  https://github.com/apache/spark/blob/25ee0474f...  train  \n2  https://github.com/apache/spark/blob/25ee0474f...  train  \n3  https://github.com/apache/flink/blob/b62db93bf...  train  \n4  https://github.com/jenkinsci/jenkins/blob/44c4...  train  \n5  https://github.com/Netflix/eureka/blob/48446d9...  train  \n6  https://github.com/apache/incubator-druid/blob...  train  \n7  https://github.com/deeplearning4j/deeplearning...  train  \n8  https://github.com/deeplearning4j/deeplearning...  train  \n9  https://github.com/zaproxy/zaproxy/blob/0cbe51...  train  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>docstring</th>\n      <th>code</th>\n      <th>relevance</th>\n      <th>repo</th>\n      <th>func_url</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Attempt to convert the specified value to epoc...</td>\n      <td>private static String coerceToEpoch(String s) ...</td>\n      <td>2</td>\n      <td>spring-projects/spring-boot</td>\n      <td>https://github.com/spring-projects/spring-boot...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Generate a server side cookie given the cookie...</td>\n      <td>private Cookie createCookie(String str) throws...</td>\n      <td>2</td>\n      <td>apache/spark</td>\n      <td>https://github.com/apache/spark/blob/25ee0474f...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Generate httponly cookie from HS2 cookie\\n@par...</td>\n      <td>private static String getHttpOnlyCookieHeader(...</td>\n      <td>2</td>\n      <td>apache/spark</td>\n      <td>https://github.com/apache/spark/blob/25ee0474f...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Copies all files from source to target and set...</td>\n      <td>public static void copy(Path sourcePath, Path ...</td>\n      <td>3</td>\n      <td>apache/flink</td>\n      <td>https://github.com/apache/flink/blob/b62db93bf...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Saves the configuration info to the disk.</td>\n      <td>public synchronized void save() {\\n        if ...</td>\n      <td>3</td>\n      <td>jenkinsci/jenkins</td>\n      <td>https://github.com/jenkinsci/jenkins/blob/44c4...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Randomize server list using local IPv4 address...</td>\n      <td>public static &lt;T extends EurekaEndpoint&gt; List&lt;...</td>\n      <td>0</td>\n      <td>Netflix/eureka</td>\n      <td>https://github.com/Netflix/eureka/blob/48446d9...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Decompress an input stream from a file, based ...</td>\n      <td>public static InputStream decompress(final Inp...</td>\n      <td>3</td>\n      <td>apache/incubator-druid</td>\n      <td>https://github.com/apache/incubator-druid/blob...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Save distribution statistics to the file syste...</td>\n      <td>public void save(@NonNull File meanFile, @NonN...</td>\n      <td>0</td>\n      <td>deeplearning4j/deeplearning4j</td>\n      <td>https://github.com/deeplearning4j/deeplearning...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Score the given multi layer network\\n@param mo...</td>\n      <td>public static double score(MultiLayerNetwork m...</td>\n      <td>0</td>\n      <td>deeplearning4j/deeplearning4j</td>\n      <td>https://github.com/deeplearning4j/deeplearning...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>This method takes a string as input reverses i...</td>\n      <td>private static String reverseString(String in)...</td>\n      <td>3</td>\n      <td>zaproxy/zaproxy</td>\n      <td>https://github.com/zaproxy/zaproxy/blob/0cbe51...</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:100]\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           docstring  \\\n0  Attempt to convert the specified value to epoc...   \n1  Generate a server side cookie given the cookie...   \n2  Generate httponly cookie from HS2 cookie\\n@par...   \n3  Copies all files from source to target and set...   \n4          Saves the configuration info to the disk.   \n\n                                                code  relevance  \\\n0  private static String coerceToEpoch(String s) ...          2   \n1  private Cookie createCookie(String str) throws...          2   \n2  private static String getHttpOnlyCookieHeader(...          2   \n3  public static void copy(Path sourcePath, Path ...          3   \n4  public synchronized void save() {\\n        if ...          3   \n\n                          repo  \\\n0  spring-projects/spring-boot   \n1                 apache/spark   \n2                 apache/spark   \n3                 apache/flink   \n4            jenkinsci/jenkins   \n\n                                            func_url  split  \\\n0  https://github.com/spring-projects/spring-boot...  train   \n1  https://github.com/apache/spark/blob/25ee0474f...  train   \n2  https://github.com/apache/spark/blob/25ee0474f...  train   \n3  https://github.com/apache/flink/blob/b62db93bf...  train   \n4  https://github.com/jenkinsci/jenkins/blob/44c4...  train   \n\n                                              tokens  token_count  \\\n0  [CLS, Attempt, Ġto, Ġconvert, Ġthe, Ġspecified...          202   \n1  [CLS, Gener, ate, Ġa, Ġserver, Ġside, Ġcookie,...          223   \n2  [CLS, Gener, ate, Ġhttp, only, Ġcookie, Ġfrom,...          129   \n3  [CLS, Cop, ies, Ġall, Ġfiles, Ġfrom, Ġsource, ...          253   \n4  [CLS, S, aves, Ġthe, Ġconfiguration, Ġinfo, Ġt...          321   \n\n                                          embeddings  \n0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>docstring</th>\n      <th>code</th>\n      <th>relevance</th>\n      <th>repo</th>\n      <th>func_url</th>\n      <th>split</th>\n      <th>tokens</th>\n      <th>token_count</th>\n      <th>embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Attempt to convert the specified value to epoc...</td>\n      <td>private static String coerceToEpoch(String s) ...</td>\n      <td>2</td>\n      <td>spring-projects/spring-boot</td>\n      <td>https://github.com/spring-projects/spring-boot...</td>\n      <td>train</td>\n      <td>[CLS, Attempt, Ġto, Ġconvert, Ġthe, Ġspecified...</td>\n      <td>202</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Generate a server side cookie given the cookie...</td>\n      <td>private Cookie createCookie(String str) throws...</td>\n      <td>2</td>\n      <td>apache/spark</td>\n      <td>https://github.com/apache/spark/blob/25ee0474f...</td>\n      <td>train</td>\n      <td>[CLS, Gener, ate, Ġa, Ġserver, Ġside, Ġcookie,...</td>\n      <td>223</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Generate httponly cookie from HS2 cookie\\n@par...</td>\n      <td>private static String getHttpOnlyCookieHeader(...</td>\n      <td>2</td>\n      <td>apache/spark</td>\n      <td>https://github.com/apache/spark/blob/25ee0474f...</td>\n      <td>train</td>\n      <td>[CLS, Gener, ate, Ġhttp, only, Ġcookie, Ġfrom,...</td>\n      <td>129</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Copies all files from source to target and set...</td>\n      <td>public static void copy(Path sourcePath, Path ...</td>\n      <td>3</td>\n      <td>apache/flink</td>\n      <td>https://github.com/apache/flink/blob/b62db93bf...</td>\n      <td>train</td>\n      <td>[CLS, Cop, ies, Ġall, Ġfiles, Ġfrom, Ġsource, ...</td>\n      <td>253</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Saves the configuration info to the disk.</td>\n      <td>public synchronized void save() {\\n        if ...</td>\n      <td>3</td>\n      <td>jenkinsci/jenkins</td>\n      <td>https://github.com/jenkinsci/jenkins/blob/44c4...</td>\n      <td>train</td>\n      <td>[CLS, S, aves, Ġthe, Ġconfiguration, Ġinfo, Ġt...</td>\n      <td>321</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tokens', 'token_count', 'embeddings']] = df.progress_apply(lambda x: get_tokens_and_embeddings(x['docstring'], x['code'], tokenizer=bert_tokenizer, model=bert_model), axis=1, result_type='expand')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train Classification Model\n",
    "Classes: 0, 1, 2, 3 - relevance score provided by dataset, with 3 being the highest and 0 being the lowest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create dataset to use for training\n",
    "1. Start with X = cosine similarity and y = relvance score\n",
    "2. Later add more features to X (code and docstring embeddings, results from static analysis?)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "data": {
      "text/plain": "   split                                         embeddings  relevance\n0  train  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          2\n1  train  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          2\n2  train  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          2\n3  train  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          3\n4  train  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>split</th>\n      <th>embeddings</th>\n      <th>relevance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = df[['split', 'embeddings', 'relevance']].copy().dropna()\n",
    "model_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "data": {
      "text/plain": "                                          embeddings  relevance\n0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          2\n1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          2\n2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          2\n3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          3\n4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...          3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>embeddings</th>\n      <th>relevance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = model_df[model_df.split == 'train'].drop('split', axis = 1)\n",
    "test_df = model_df[model_df.split == 'test'].drop('split', axis = 1)\n",
    "\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [],
   "source": [
    "embedding_dims = 768\n",
    "kernel_size = 3\n",
    "hidden_dims = 132\n",
    "number_of_class = 4\n",
    "dropout = 0.5\n",
    "learning_rate = 1e-4\n",
    "epochs = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv1d(embedding_dims, hidden_dims, kernel_size),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(kernel_size),\n",
    "    nn.Linear(hidden_dims, number_of_class),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (132) to match target batch_size (0).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[287], line 12\u001B[0m\n\u001B[1;32m      8\u001B[0m y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(row\u001B[38;5;241m.\u001B[39mrelevance)\n\u001B[1;32m     10\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m model(x)\n\u001B[0;32m---> 12\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_hat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# loss.append([loss.item])\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# loss.backward()\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# optimizer.step()\u001B[39;00m\n",
      "File \u001B[0;32m~/workspace/Programming/JavaDoc_Code_Similarity/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/workspace/Programming/JavaDoc_Code_Similarity/venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:1174\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m   1173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m-> 1174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1175\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1176\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/Programming/JavaDoc_Code_Similarity/venv/lib/python3.11/site-packages/torch/nn/functional.py:3029\u001B[0m, in \u001B[0;36mcross_entropy\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   3027\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3028\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3029\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: Expected input batch_size (132) to match target batch_size (0)."
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "\n",
    "for i in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "\n",
    "    for index, row in train_df.iterrows():\n",
    "        x = torch.tensor(row.embeddings).T\n",
    "        y = torch.tensor(row.relevance)\n",
    "\n",
    "        y_hat = model(x)\n",
    "\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        break\n",
    "        # loss.append([loss.item])\n",
    "        # loss.backward()\n",
    "        # optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.lineplot(loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred, zero_division=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
