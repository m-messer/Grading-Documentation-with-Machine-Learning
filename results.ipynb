{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results\n",
    "Get results from Weights and Biases and produce plots for paper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             summary  \\\n0  {'_step': 8, 'eval/runtime': 43.7549, 'eval/re...   \n1  {'train/total_flos': 1028463566524416.0, 'eval...   \n2  {'_wandb': {'runtime': 5150}, 'train/loss': 0,...   \n3  {'test/f1_macro': 0.8903430662282452, 'eval/re...   \n4  {'test/f1_weighted': 0.88553575990578, 'train/...   \n\n                                              config                 name  \\\n0  {'bf16': False, 'fp16': False, 'fsdp': '[]', '...  grateful-gorge-1364   \n1  {'bf16': False, 'fp16': False, 'fsdp': '[]', '...     fancy-river-1361   \n2  {'bf16': False, 'fp16': False, 'fsdp': '[]', '...  golden-terrain-1356   \n3  {'bf16': False, 'fp16': False, 'fsdp': '[]', '...     laced-paper-1355   \n4  {'bf16': False, 'fp16': False, 'fsdp': '[]', '...    fresh-violet-1354   \n\n                                    group  \n0            LORA:microsoft/codebert-base  \n1            LORA:microsoft/codebert-base  \n2  Fine-Tuned LLM:microsoft/codebert-base  \n3  Fine-Tuned LLM:microsoft/codebert-base  \n4  Fine-Tuned LLM:microsoft/codebert-base  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary</th>\n      <th>config</th>\n      <th>name</th>\n      <th>group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'_step': 8, 'eval/runtime': 43.7549, 'eval/re...</td>\n      <td>{'bf16': False, 'fp16': False, 'fsdp': '[]', '...</td>\n      <td>grateful-gorge-1364</td>\n      <td>LORA:microsoft/codebert-base</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'train/total_flos': 1028463566524416.0, 'eval...</td>\n      <td>{'bf16': False, 'fp16': False, 'fsdp': '[]', '...</td>\n      <td>fancy-river-1361</td>\n      <td>LORA:microsoft/codebert-base</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'_wandb': {'runtime': 5150}, 'train/loss': 0,...</td>\n      <td>{'bf16': False, 'fp16': False, 'fsdp': '[]', '...</td>\n      <td>golden-terrain-1356</td>\n      <td>Fine-Tuned LLM:microsoft/codebert-base</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'test/f1_macro': 0.8903430662282452, 'eval/re...</td>\n      <td>{'bf16': False, 'fp16': False, 'fsdp': '[]', '...</td>\n      <td>laced-paper-1355</td>\n      <td>Fine-Tuned LLM:microsoft/codebert-base</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'test/f1_weighted': 0.88553575990578, 'train/...</td>\n      <td>{'bf16': False, 'fp16': False, 'fsdp': '[]', '...</td>\n      <td>fresh-violet-1354</td>\n      <td>Fine-Tuned LLM:microsoft/codebert-base</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\"messer/JavaDoc-Relevance-Binary-Classifier\")\n",
    "\n",
    "summary_list, config_list, name_list, group_list = [], [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append(\n",
    "        {k: v for k,v in run.config.items()\n",
    "         if not k.startswith('_')})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "    group_list.append(run.group)\n",
    "\n",
    "runs_df = pd.DataFrame({\n",
    "    \"summary\": summary_list,\n",
    "    \"config\": config_list,\n",
    "    \"name\": name_list,\n",
    "    \"group\": group_list\n",
    "})\n",
    "\n",
    "runs_df.to_csv(\"data/training_results.csv\")\n",
    "runs_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process WandB API call results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "runs_df = pd.read_csv('data/training_results.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "                  name                                   group  \\\n0  grateful-gorge-1364            LORA:microsoft/codebert-base   \n1     fancy-river-1361            LORA:microsoft/codebert-base   \n2  golden-terrain-1356  Fine-Tuned LLM:microsoft/codebert-base   \n3     laced-paper-1355  Fine-Tuned LLM:microsoft/codebert-base   \n4    fresh-violet-1354  Fine-Tuned LLM:microsoft/codebert-base   \n\n                                              config  \n0  {'bf16': False, 'fp16': False, 'fsdp': '[]', '...  \n1  {'bf16': False, 'fp16': False, 'fsdp': '[]', '...  \n2  {'bf16': False, 'fp16': False, 'fsdp': '[]', '...  \n3  {'bf16': False, 'fp16': False, 'fsdp': '[]', '...  \n4  {'bf16': False, 'fp16': False, 'fsdp': '[]', '...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>group</th>\n      <th>config</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>grateful-gorge-1364</td>\n      <td>LORA:microsoft/codebert-base</td>\n      <td>{'bf16': False, 'fp16': False, 'fsdp': '[]', '...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fancy-river-1361</td>\n      <td>LORA:microsoft/codebert-base</td>\n      <td>{'bf16': False, 'fp16': False, 'fsdp': '[]', '...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>golden-terrain-1356</td>\n      <td>Fine-Tuned LLM:microsoft/codebert-base</td>\n      <td>{'bf16': False, 'fp16': False, 'fsdp': '[]', '...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>laced-paper-1355</td>\n      <td>Fine-Tuned LLM:microsoft/codebert-base</td>\n      <td>{'bf16': False, 'fp16': False, 'fsdp': '[]', '...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fresh-violet-1354</td>\n      <td>Fine-Tuned LLM:microsoft/codebert-base</td>\n      <td>{'bf16': False, 'fp16': False, 'fsdp': '[]', '...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([runs_df[['name', 'group', 'config']], pd.json_normalize(runs_df['summary'])], axis=1)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Group and produce plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "grey = (187/255, 187/255, 187/255)\n",
    "darkgreen = (51/255, 117/255, 56/255)\n",
    "teal = (93/255, 168/255, 153/255)\n",
    "blue = (148/255, 203/255, 236/255)\n",
    "yellow = (220/255, 205/255, 125/255)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['test/accuracy', 'test/precision_weighted', 'test/recall_weighted', 'test/f1_weighted'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[134], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m grouped_df \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgroup\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest/accuracy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest/precision_weighted\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest/recall_weighted\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest/f1_weighted\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgroup\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[1;32m      2\u001B[0m grouped_df\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgroup\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprecision_weighted\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecall_weighted\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1_weighted\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      3\u001B[0m grouped_df\n",
      "File \u001B[0;32m~/workspace/Programming/JavaDoc_Code_Similarity/venv/lib/python3.11/site-packages/pandas/core/frame.py:3767\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3765\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[1;32m   3766\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 3767\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   3769\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[1;32m   3770\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[0;32m~/workspace/Programming/JavaDoc_Code_Similarity/venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:5877\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   5874\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   5875\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[0;32m-> 5877\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5879\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[1;32m   5880\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[1;32m   5881\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[0;32m~/workspace/Programming/JavaDoc_Code_Similarity/venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:5941\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[0;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[1;32m   5938\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   5940\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[0;32m-> 5941\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['test/accuracy', 'test/precision_weighted', 'test/recall_weighted', 'test/f1_weighted'] not in index\""
     ]
    }
   ],
   "source": [
    "grouped_df = df[['group', 'test/accuracy', 'test/precision_weighted', 'test/recall_weighted', 'test/f1_weighted']].groupby('group').max().reset_index()\n",
    "grouped_df.columns = ['group', 'accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "grouped_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = sns.barplot(grouped_df[['group', 'accuracy']].sort_values('accuracy', ascending=False), y='group', x='accuracy', color=grey)\n",
    "acc.set(title='Maximum Test Accuracy', xlabel='Accuracy', ylabel='Model Type')\n",
    "acc.get_figure().savefig('plots/accuracy.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recall = sns.barplot(grouped_df[['group', 'recall_weighted']].sort_values('recall_weighted', ascending=False), y='group', x='recall_weighted', color=grey)\n",
    "recall.set(title='Maximum Test Recall', xlabel='Weighted Recall', ylabel='Model Type')\n",
    "recall.get_figure().savefig('plots/recall.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precision = sns.barplot(grouped_df[['group', 'precision_weighted']].sort_values('precision_weighted', ascending=False), y='group', x='precision_weighted', color=grey)\n",
    "precision.set(title='Maximum Test Precision', xlabel='Weighted Precision', ylabel='Model Type')\n",
    "precision.get_figure().savefig('plots/precision.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f1 = sns.barplot(grouped_df[['group', 'f1_weighted']].sort_values('f1_weighted', ascending=False), y='group', x='f1_weighted', color=grey)\n",
    "f1.set(title='Maximum Test F1 Score', xlabel='Weighted F1 Score', ylabel='Model Type')\n",
    "f1.get_figure().savefig('plots/f1.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_df_melted = grouped_df.melt(id_vars=['group'])\n",
    "grouped_df_melted['variable'] = grouped_df_melted['variable'].map(lambda metric_name: metric_name.title().replace('_Weighted', ''))\n",
    "grouped_df_melted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = sns.barplot(grouped_df_melted.sort_values(['value'], ascending=False), y='group', x='value', hue='variable', hue_order=['Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "\n",
    "\n",
    "hatches = ['//', 'x', '\\\\', 'o']\n",
    "colors = [grey, teal, blue, darkgreen]\n",
    "styles = zip(hatches, colors)\n",
    "\n",
    "\n",
    "for style, these_bars in zip(styles, metrics.containers):\n",
    "    for this_bar in these_bars:\n",
    "        this_bar.set_hatch(3 * style[0])\n",
    "        this_bar.set_facecolor(style[1])\n",
    "        this_bar.set_edgecolor('black')\n",
    "\n",
    "metrics.set(xlabel='Maximum Result', ylabel='Model Type')\n",
    "metrics.legend(title='Metric')\n",
    "\n",
    "metrics.get_figure().savefig('plots/metric_results.pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
